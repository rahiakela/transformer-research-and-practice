{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/transformers-research-and-practice/blob/main/sentence-transformer-works/06_fine_tuning_sentence_transformers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Fine-Tune Sentence Transformers Models"
      ],
      "metadata": {
        "id": "I729oEbmU1rv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Reference**:\n",
        "\n",
        "[Train and Fine-Tune Sentence Transformers Models](https://huggingface.co/blog/how-to-train-sentence-transformers)"
      ],
      "metadata": {
        "id": "Ykd3Dj_5btws"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZWjnEb3_XT0Y"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install sentence-transformers\n",
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sentence_transformers import SentenceTransformer, models\n",
        "from sentence_transformers import losses\n",
        "from sentence_transformers import InputExample\n",
        "from datasets import load_dataset\n",
        "\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "HthSwlcU4hHQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sentence Transformers\n"
      ],
      "metadata": {
        "id": "P2CPLypZUwTk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Step 1: use an existing language model\n",
        "word_embedding_model = models.Transformer('distilroberta-base')\n",
        "\n",
        "## Step 2: use a pool function over the token embeddings\n",
        "pooling_model = models.Pooling(word_embedding_model.get_word_embedding_dimension())\n",
        "\n",
        "## Join steps 1 and 2 using the modules argument\n",
        "model = SentenceTransformer(modules=[word_embedding_model, pooling_model])"
      ],
      "metadata": {
        "id": "pixb3XSjXaqm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(word_embedding_model.get_word_embedding_dimension())"
      ],
      "metadata": {
        "id": "MqyGPoj_49FT",
        "outputId": "1b2755c1-0247-4fc6-af0f-5b44af3cd2a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "768\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Preparing dataset\n"
      ],
      "metadata": {
        "id": "HYB2Vtvga1Zh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_id = \"embedding-data/QQP_triplets\"\n",
        "# dataset_id = \"embedding-data/sentence-compression\"\n",
        "\n",
        "dataset = load_dataset(dataset_id)"
      ],
      "metadata": {
        "id": "max24luaa5OR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"- The {dataset_id} dataset has {dataset['train'].num_rows} examples.\")\n",
        "print(f\"- Each example is a {type(dataset['train'][0])} with a {type(dataset['train'][0]['set'])} as value.\")\n",
        "print(f\"- Examples look like this: {dataset['train'][0]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2VUd11y8bP_a",
        "outputId": "c8dcf076-35ec-4a40-dfe5-860cd702c9f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "- The embedding-data/QQP_triplets dataset has 101762 examples.\n",
            "- Each example is a <class 'dict'> with a <class 'dict'> as value.\n",
            "- Examples look like this: {'set': {'query': 'Why in India do we not have one on one political debate as in USA?', 'pos': ['Why cant we have a public debate between politicians in India like the one in US?'], 'neg': ['Can people on Quora stop India Pakistan debate? We are sick and tired seeing this everyday in bulk?', 'Why do politicians, instead of having a decent debate on issues going in and around the world, end up fighting always?', 'Can educated politicians make a difference in India?', 'What are some unusual aspects about politics and government in India?', 'What is debate?', 'Why does civic public communication and discourse seem so hollow in modern India?', 'What is a Parliamentary debate?', \"Why do we always have two candidates at the U.S. presidential debate. yet the ballot has about 7 candidates? Isn't that a misrepresentation of democracy?\", 'Why is civic public communication and discourse so hollow in modern India?', \"Aren't the Presidential debates teaching our whole country terrible communication skills and why is deliberate misrepresentation even allowed?\", 'Why are most Indian politicians uneducated?', 'Does Indian political leaders capable of doing face to face debates while running for office?', 'What is wrong with the Indian political system and the environment it has built in connection with the people of India? Have parties divided people more?', 'What is a debate?', 'Why do we have legislative council in india?', 'Why does the office of president of India, being politically neutral, not ask for Population control in India?', \"Why don't we discuss tax and foreign policies more in Indian elections but are instead obsessed with socialist schemes?\", 'Why do Indian politicians lack nationalist thinking?', 'Do you hate indian politicians?', 'Is India facing more stessful times and politically charged atmosphere when compared to Congress regime?', 'Who is the best politician in India? Why?', \"We all know about the present condition of Indian politicians; they are all just using us to run their train, but still, they win elections and rule over us. Why aren't people giving their vote to NOTA?\", 'Who are clean politicians in India?', 'Why are you not believing in Democracy of India?', 'What does politics in India mean? What are they actually doing?', 'What are the strongest arguments for a debate in favour of brain drain in India and what sources must be used for making a good short speech?', 'Do we really need an election commission in India?', 'Why is there no concept of political correctness in India? Is it a good thing or a bad thing?', 'Why is population control not on agenda of any political party in India?', 'Who are some of the most dangerous or worst politicians in India?']}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Convert the examples into `InputExample`s. It might around 10 seconds in Google Colab."
      ],
      "metadata": {
        "id": "-O2o_92kuzCa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_examples = []\n",
        "train_data = dataset['train']['set']\n",
        "# For agility, we employ only 1/2 of our available data\n",
        "n_examples = dataset['train'].num_rows // 2\n",
        "\n",
        "for i in range(n_examples):\n",
        "  example = train_data[i]\n",
        "  # using only one of the positives and one of the negatives\n",
        "  train_examples.append(InputExample(texts=[example['query'], example['pos'][0], example['neg'][0]]))"
      ],
      "metadata": {
        "id": "yQ9v7x2J1C75"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"We have a {type(train_examples)} of length {len(train_examples)} containing {type(train_examples[0])}'s.\")"
      ],
      "metadata": {
        "id": "j1XgafnCFHbA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cc4d33df-7198-4da2-86b6-53ae0a57252f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We have a <class 'list'> of length 50881 containing <class 'sentence_transformers.readers.InputExample.InputExample'>'s.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We wrap our training dataset into a Pytorch `Dataloader` to shuffle examples and get batch sizes."
      ],
      "metadata": {
        "id": "6qVYjIIOyppB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=16)"
      ],
      "metadata": {
        "id": "gbrXjod4dhJW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Loss functions\n"
      ],
      "metadata": {
        "id": "0HeVHzC-8bbe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_loss = losses.TripletLoss(model=model)"
      ],
      "metadata": {
        "id": "t1gFBA6EFK10"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training model\n"
      ],
      "metadata": {
        "id": "QTSVaysgVHZk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 10\n",
        "\n",
        "warmup_steps = int(len(train_dataloader) * num_epochs * 0.1) #10% of train data"
      ],
      "metadata": {
        "id": "rBBR6OseFW0J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training takes around 45 minutes with a Google Colab Pro account. Decrease the number of epochs and examples if you are using a free account or no GPU."
      ],
      "metadata": {
        "id": "Y17niC39k9S7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(train_objectives=[(train_dataloader, train_loss)],\n",
        "          epochs=num_epochs,\n",
        "          warmup_steps=warmup_steps\n",
        "        )"
      ],
      "metadata": {
        "id": "7Ana59pTFjKn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Saving to Hub"
      ],
      "metadata": {
        "id": "uQEnJz5MVMPA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!huggingface-cli login"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2iwjWb7HyTEX",
        "outputId": "adbe4d21-ca24-4232-c444-f872a11bce9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "        _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
            "        _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
            "        _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
            "        _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
            "        _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
            "\n",
            "        To login, `huggingface_hub` now requires a token generated from https://huggingface.co/settings/tokens .\n",
            "        \n",
            "Token: \n",
            "Login successful\n",
            "Your token has been saved to /root/.huggingface/token\n",
            "\u001b[1m\u001b[31mAuthenticated through git-credential store but this isn't the helper defined on your machine.\n",
            "You might have to re-authenticate when pushing to the Hugging Face Hub. Run the following command in your terminal in case you want to set this credential helper as the default\n",
            "\n",
            "git config --global credential.helper store\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_to_hub(\n",
        "    \"distilroberta-base-sentence-transformer\",\n",
        "    organization=\"embedding-data\",\n",
        "    train_datasets=[\"embedding-data/QQP_triplets\"],\n",
        "    exist_ok=True,\n",
        "    )"
      ],
      "metadata": {
        "id": "sM6pu_adyUw6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fine-tune model\n"
      ],
      "metadata": {
        "id": "Rq2ROpPUVSS6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will fine-tune our Sentence Transformer model."
      ],
      "metadata": {
        "id": "iErisVnE5sCa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelB = SentenceTransformer('embedding-data/distilroberta-base-sentence-transformer')"
      ],
      "metadata": {
        "id": "JPEqCxxr0REd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_id = \"embedding-data/sentence-compression\"\n",
        "datasetB = load_dataset(dataset_id)"
      ],
      "metadata": {
        "id": "akDLR6IS0sdU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Examples look like this: {datasetB['train']['set'][0]}\")"
      ],
      "metadata": {
        "id": "fwYA76vY2YbZ",
        "outputId": "136f291b-5167-4bbd-f4c4-a712c9a794ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Examples look like this: [\"The USHL completed an expansion draft on Monday as 10 players who were on the rosters of USHL teams during the 2009-10 season were selected by the League's two newest entries, the Muskegon Lumberjacks and Dubuque Fighting Saints.\", 'USHL completes expansion draft']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datasetB['train']['set'][0]"
      ],
      "metadata": {
        "id": "6YFMJVf8Z9AL",
        "outputId": "7a43674f-3076-4acd-b0c2-06915746bbcb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"The USHL completed an expansion draft on Monday as 10 players who were on the rosters of USHL teams during the 2009-10 season were selected by the League's two newest entries, the Muskegon Lumberjacks and Dubuque Fighting Saints.\",\n",
              " 'USHL completes expansion draft']"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "datasetB['train']['set'][1]"
      ],
      "metadata": {
        "id": "-H_4Aqr_Z9rq",
        "outputId": "b748982f-2438-4076-cb4e-b42b46b4a599",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Major League Baseball Commissioner Bud Selig will be speaking at St. Norbert College next month.',\n",
              " 'Bud Selig to speak at St. Norbert College']"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example = datasetB['train']['set']\n",
        "example[0]"
      ],
      "metadata": {
        "id": "jJLd8ZxzaK6Z",
        "outputId": "84d45963-f4ee-49f1-c143-b45bc8b78c53",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[\"The USHL completed an expansion draft on Monday as 10 players who were on the rosters of USHL teams during the 2009-10 season were selected by the League's two newest entries, the Muskegon Lumberjacks and Dubuque Fighting Saints.\",\n",
              " 'USHL completes expansion draft']"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example[1]"
      ],
      "metadata": {
        "id": "Jc-OmhcsaRjW",
        "outputId": "1faabb15-a386-425c-f723-2b8ad764917d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Major League Baseball Commissioner Bud Selig will be speaking at St. Norbert College next month.',\n",
              " 'Bud Selig to speak at St. Norbert College']"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_examplesB = []\n",
        "train_dataB = datasetB['train']['set']\n",
        "n_examples = datasetB['train'].num_rows\n",
        "\n",
        "for i in range(n_examples):\n",
        "  example = train_dataB[i]\n",
        "  train_examplesB.append(InputExample(texts=[example[0], example[1]]))"
      ],
      "metadata": {
        "id": "2s1c05zF2g7C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloaderB = DataLoader(train_examplesB, shuffle=True, batch_size=64)\n",
        "train_lossB = losses.MultipleNegativesRankingLoss(model=modelB)\n",
        "num_epochsB = 10\n",
        "warmup_stepsB = int(len(train_dataloaderB) * num_epochsB * 0.1) #10% of train data"
      ],
      "metadata": {
        "id": "cMYfDAbd53xC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelB.fit(train_objectives=[(train_dataloaderB, train_lossB)],\n",
        "          epochs=num_epochsB,\n",
        "          warmup_steps=warmup_stepsB)"
      ],
      "metadata": {
        "id": "lfRC496k6hS8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "modelB.save_to_hub(\n",
        "    \"distilroberta-base-sentence-transformer\",\n",
        "    organization=\"embedding-data\",\n",
        "    train_datasets=[\"embedding-data/sentence-compression\"],\n",
        "    exist_ok=True,\n",
        "    )"
      ],
      "metadata": {
        "id": "Ilq1kA6Rbboh"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}