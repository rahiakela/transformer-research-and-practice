{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/transformers-research-and-practice/blob/main/llamindex-projects/01_rag_with_llamaindex_openai.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##RAG System using Llama-index with OpenAI"
      ],
      "metadata": {
        "id": "Pz3Zpji7j-n8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## Retrieval augmented generation\n",
        "\n",
        "import os\n",
        "import os.path\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()"
      ],
      "metadata": {
        "id": "_l9S4siYkGBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4QBuAFZkjJuo"
      },
      "outputs": [],
      "source": [
        "os.environ['OPENAI_API_KEY']=os.getenv(\"OPENAI_API_KEY\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index import VectorStoreIndex,SimpleDirectoryReader\n",
        "from llama_index.retrievers import VectorIndexRetriever\n",
        "from llama_index.query_engine import RetrieverQueryEngine\n",
        "from llama_index.indices.postprocessor import SimilarityPostprocessor\n",
        "from llama_index.response.pprint_utils import pprint_response\n",
        "\n",
        "from llama_index import (\n",
        "    VectorStoreIndex,\n",
        "    SimpleDirectoryReader,\n",
        "    StorageContext,\n",
        "    load_index_from_storage,\n",
        ")"
      ],
      "metadata": {
        "id": "j4vnIvEmkL8m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Load documents"
      ],
      "metadata": {
        "id": "9J55K8YakM6G"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wDuUuqRQjJuo"
      },
      "outputs": [],
      "source": [
        "documents=SimpleDirectoryReader(\"data\").load_data()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n5ZY0F08jJuo"
      },
      "outputs": [],
      "source": [
        "documents"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Vector Index"
      ],
      "metadata": {
        "id": "E4hJTFtQkRX8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CcS-cus9jJup",
        "outputId": "40bcaa9b-e0ca-4212-804a-4e7cba14c881"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "e:\\New Recordings\\Langchain Videos\\LLAmindex\\Projects\\Llama_index\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n",
            "Parsing nodes: 100%|██████████| 25/25 [00:00<00:00, 247.44it/s]\n",
            "Generating embeddings: 100%|██████████| 36/36 [00:03<00:00, 11.11it/s]\n"
          ]
        }
      ],
      "source": [
        "index=VectorStoreIndex.from_documents(documents,show_progress=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WC1qHkEHjJup",
        "outputId": "a1ea32dd-d990-4f53-c3c5-46dc9bc45bb1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<llama_index.indices.vector_store.base.VectorStoreIndex at 0x21c577edf90>"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "index"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Query vector index"
      ],
      "metadata": {
        "id": "3t8OyU-AkX2J"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ioKx_44ljJup"
      },
      "outputs": [],
      "source": [
        "query_engine=index.as_query_engine()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YZhqvkWwjJup"
      },
      "outputs": [],
      "source": [
        "retriever=VectorIndexRetriever(index=index,similarity_top_k=4)\n",
        "postprocessor=SimilarityPostprocessor(similarity_cutoff=0.80)\n",
        "\n",
        "query_engine=RetrieverQueryEngine(retriever=retriever, node_postprocessors=[postprocessor])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y_hA7ULzjJup"
      },
      "outputs": [],
      "source": [
        "response=query_engine.query(\"What is attention is all yopu need?\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rLu-hZ09jJuq",
        "outputId": "fb16b276-15ad-479f-a11d-ccf84f4ca9d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Final Response: The paper \"Attention Is All You Need\" proposes a new\n",
            "network architecture called the Transformer. This architecture is\n",
            "based solely on attention mechanisms and does not use recurrent or\n",
            "convolutional neural networks. The paper demonstrates that the\n",
            "Transformer models outperform existing models in terms of quality,\n",
            "parallelizability, and training time. The Transformer achieves state-\n",
            "of-the-art results in machine translation tasks and generalizes well\n",
            "to other tasks such as English constituency parsing.\n",
            "______________________________________________________________________\n",
            "Source Node 1/1\n",
            "Node ID: be144ab8-cb0a-44fa-af69-3dbfe555e41a\n",
            "Similarity: 0.8107415810551661\n",
            "Text: Provided proper attribution is provided, Google hereby grants\n",
            "permission to reproduce the tables and figures in this paper solely\n",
            "for use in journalistic or scholarly works. Attention Is All You Need\n",
            "Ashish Vaswani∗ Google Brain avaswani@google.comNoam Shazeer∗ Google\n",
            "Brain noam@google.comNiki Parmar∗ Google Research\n",
            "nikip@google.comJakob Uszkor...\n",
            "The paper \"Attention Is All You Need\" proposes a new network architecture called the Transformer. This architecture is based solely on attention mechanisms and does not use recurrent or convolutional neural networks. The paper demonstrates that the Transformer models outperform existing models in terms of quality, parallelizability, and training time. The Transformer achieves state-of-the-art results in machine translation tasks and generalizes well to other tasks such as English constituency parsing.\n"
          ]
        }
      ],
      "source": [
        "pprint_response(response,show_source=True)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Save vector index"
      ],
      "metadata": {
        "id": "UeG_2I8bkkC4"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K5wvAtRHjJuq",
        "outputId": "1d064c83-afe8-464c-daa3-4eb7275095a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Transformers are a model architecture that rely entirely on an attention mechanism to draw global dependencies between input and output. They eschew recurrence and do not use sequence-aligned RNNs or convolution. Transformers allow for significantly more parallelization and have been shown to achieve state-of-the-art results in tasks such as translation. They can be trained faster than architectures based on recurrent or convolutional layers.\n"
          ]
        }
      ],
      "source": [
        "# check if storage already exists\n",
        "PERSIST_DIR = \"./storage\"\n",
        "if not os.path.exists(PERSIST_DIR):\n",
        "    # load the documents and create the index\n",
        "    documents = SimpleDirectoryReader(\"data\").load_data()\n",
        "    index = VectorStoreIndex.from_documents(documents)\n",
        "    # store it for later\n",
        "    index.storage_context.persist(persist_dir=PERSIST_DIR)\n",
        "else:\n",
        "    # load the existing index\n",
        "    storage_context = StorageContext.from_defaults(persist_dir=PERSIST_DIR)\n",
        "    index = load_index_from_storage(storage_context)\n",
        "\n",
        "# either way we can now query the index\n",
        "query_engine = index.as_query_engine()\n",
        "response = query_engine.query(\"What are transformers?\")\n",
        "print(response)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}