{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "multilingual-named-entity-recognition.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPQXpyXjzzgxW2giVFnpK1t",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "5b601fb0c8f44a34a5f7e669f44bc352": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_23a7504cf716448080a6cfafa99fa677",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_293e47f75e234649bfeacfef697319f0",
              "IPY_MODEL_7440ca9029d6442f81f0c098ab16e5d9",
              "IPY_MODEL_2b53c9878595486886ffab5a16a7378f"
            ]
          }
        },
        "23a7504cf716448080a6cfafa99fa677": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "293e47f75e234649bfeacfef697319f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_831bf4f08e624d138f1a51ef6b70c872",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_651c2579655e49b9b3b3308bdc5c2cba"
          }
        },
        "7440ca9029d6442f81f0c098ab16e5d9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_71f13a79f3c949549ad8cab8f676c2aa",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 3,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 3,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_158a3b76727f433a87aef3e14fc7db4f"
          }
        },
        "2b53c9878595486886ffab5a16a7378f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b4b12bb0aa2d4ee0b21261350b6b36fc",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 3/3 [00:00&lt;00:00, 74.88it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_146661f84fb24c82b5104be84757a398"
          }
        },
        "831bf4f08e624d138f1a51ef6b70c872": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "651c2579655e49b9b3b3308bdc5c2cba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "71f13a79f3c949549ad8cab8f676c2aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "158a3b76727f433a87aef3e14fc7db4f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b4b12bb0aa2d4ee0b21261350b6b36fc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "146661f84fb24c82b5104be84757a398": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/transformers-research-and-practice/blob/main/natural-language-processing-with-transformers/04-multilingual-ner/multilingual_named_entity_recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Multilingual Named Entity Recognition"
      ],
      "metadata": {
        "id": "IcdvovQpzhkI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook we will explore how a single Transformer model called XLM-RoBERTa can be fine-tuned to\n",
        "perform named entity recognition (NER) across several languages. NER is a common NLP task that identifies\n",
        "entities like people, organizations, or locations in text. These entities can be used for various applications such as\n",
        "gaining insights from company documents, augmenting the quality of search engines, or simply building a\n",
        "structured database from a corpus."
      ],
      "metadata": {
        "id": "iaOVAWdCzu8J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Setup"
      ],
      "metadata": {
        "id": "Tx8XRrYJz6SS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "pip -q install transformers\n",
        "pip -q install datasets"
      ],
      "metadata": {
        "id": "VYnilI_Qz7Yh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import XLMRobertaConfig\n",
        "from transformers.modeling_outputs import TokenClassifierOutput\n",
        "from transformers.models.roberta.modeling_roberta import RobertaModel\n",
        "from transformers.models.roberta.modeling_roberta import RobertaPreTrainedModel\n",
        "from transformers import AutoConfig\n",
        "from transformers import TrainingArguments\n",
        "\n",
        "from datasets import get_dataset_config_names\n",
        "from datasets import load_dataset\n",
        "from datasets import DatasetDict\n",
        "\n",
        "from itertools import chain\n",
        "from collections import defaultdict\n",
        "from collections import Counter\n",
        "\n",
        "from IPython.display import HTML, display, set_matplotlib_formats"
      ],
      "metadata": {
        "id": "6pGaeyjn4SuG"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "CF3O4o6dBwmB"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_df(df, max_cols=15, header=True, index=True):\n",
        "    # 15 cols seems to be limit for O'reilly\n",
        "    return display(HTML(df.to_html(header=header, index=index, max_cols=max_cols)))"
      ],
      "metadata": {
        "id": "HjFrvYj543xi"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##The Dataset"
      ],
      "metadata": {
        "id": "z7Ok2tF-0TV1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "we will be using a subset of the Cross-lingual TRansfer Evaluation of Multilingual Encoders\n",
        "(XTREME) benchmark called Wikiann or PAN-X. This dataset consists of Wikipedia articles in many\n",
        "languages, including the four most commonly spoken languages in Switzerland: German (62.9%), French (22.9%),\n",
        "Italian (8.4%), and English (5.9%). \n",
        "\n",
        "Each article is annotated with LOC (location), PER (person) and ORG\n",
        "(organization) tags in the “inside-outside-beginning” (IOB2) format, where a B-prefix indicates the beginning of\n",
        "an entity, and consecutive positions of the same entity are given an I- prefix. An O tag indicates that the token does\n",
        "not belong to any entity. \n",
        "\n",
        "For example, the following sentence\n",
        "\n"
      ],
      "metadata": {
        "id": "db96XyEI0XwC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = \"Jeff Dean is a computer scientist at Google in California\".split()\n",
        "labels = [\"B-PER\", \"I-PER\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-ORG\", \"O\", \"B-LOC\"]\n",
        "\n",
        "df = pd.DataFrame(data=[tokens, labels], index=[\"Tokens\", \"Tags\"])\n",
        "display_df(df, header=None)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "oS3u-g2h4OZx",
        "outputId": "1f6a4bbd-bf88-42f5-e9b2-e7d9b60ac5e2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Tokens</th>\n",
              "      <td>Jeff</td>\n",
              "      <td>Dean</td>\n",
              "      <td>is</td>\n",
              "      <td>a</td>\n",
              "      <td>computer</td>\n",
              "      <td>scientist</td>\n",
              "      <td>at</td>\n",
              "      <td>Google</td>\n",
              "      <td>in</td>\n",
              "      <td>California</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Tags</th>\n",
              "      <td>B-PER</td>\n",
              "      <td>I-PER</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>B-ORG</td>\n",
              "      <td>O</td>\n",
              "      <td>B-LOC</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To load PAN-X with HuggingFace Datasets we first need to manually download the file AmazonPhotos.zip from\n",
        "XTREME’s [Amazon Cloud Drive](https://www.amazon.com/clouddrive/share/d3KGCRCIYwhKJF0H3eWA26hjg2ZCRhjpEQtDL70FSBN), and place it in a local directory (data in our example).\n",
        "\n",
        "For example, to load the\n",
        "German corpus we use the “de” code as follows:"
      ],
      "metadata": {
        "id": "4oPeblXYzSU4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "load_dataset(\"xtreme\", \"PAN-X.de\", data_dir=\"data\")"
      ],
      "metadata": {
        "id": "S81zl_ojzbDS",
        "outputId": "a6944dd6-c230-425c-ca6e-a09d0dbd00f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347,
          "referenced_widgets": [
            "5b601fb0c8f44a34a5f7e669f44bc352",
            "23a7504cf716448080a6cfafa99fa677",
            "293e47f75e234649bfeacfef697319f0",
            "7440ca9029d6442f81f0c098ab16e5d9",
            "2b53c9878595486886ffab5a16a7378f",
            "831bf4f08e624d138f1a51ef6b70c872",
            "651c2579655e49b9b3b3308bdc5c2cba",
            "71f13a79f3c949549ad8cab8f676c2aa",
            "158a3b76727f433a87aef3e14fc7db4f",
            "b4b12bb0aa2d4ee0b21261350b6b36fc",
            "146661f84fb24c82b5104be84757a398"
          ]
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using custom data configuration PAN-X.de-data_dir=data\n",
            "Reusing dataset xtreme (/root/.cache/huggingface/datasets/xtreme/PAN-X.de-data_dir=data/1.0.0/2fc6b63c5326cc0d1f73060649612889b3a7ed8a6605c91cecdbd228a7158b17)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5b601fb0c8f44a34a5f7e669f44bc352",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    validation: Dataset({\n",
              "        features: ['tokens', 'ner_tags', 'langs'],\n",
              "        num_rows: 10000\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['tokens', 'ner_tags', 'langs'],\n",
              "        num_rows: 10000\n",
              "    })\n",
              "    train: Dataset({\n",
              "        features: ['tokens', 'ner_tags', 'langs'],\n",
              "        num_rows: 20000\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this case, `load_dataset` returns a `DatasetDict` where each key corresponds to one of the splits, and each\n",
        "value is a `Dataset` object with `features` and `num_rows` attributes.\n",
        "\n",
        "To keep track of each language, let’s create a Python `defaultdict` that stores the language code as the key and\n",
        "a PAN-X corpus of type `DatasetDict` as the value:"
      ],
      "metadata": {
        "id": "auhJfETdz2Mi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "languages = [\"de\", \"fr\", \"it\", \"en\"]\n",
        "fractions = [0.629, 0.229, 0.084, 0.059]\n",
        "\n",
        "# return a DatasetDict if a key doesn't exist\n",
        "panx_ch = defaultdict(DatasetDict)\n",
        "\n",
        "for lang, frac in zip(languages, fractions):\n",
        "  # load monolingual corpus\n",
        "  ds = load_dataset(\"xtreme\", f\"PAN-X.{lang}\", data_dir=\"data\")\n",
        "  # shuffle and downsample each split according to spoken proportion\n",
        "  for split in ds.keys():\n",
        "    panx_ch[lang][split] = (ds[split].shuffle(seed=0).select(range(int(frac * ds[split].num_rows))))"
      ],
      "metadata": {
        "id": "VzInvqNT0HU7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we’ve used the `Dataset.shuffle` function to make sure we don’t accidentally bias our dataset splits,\n",
        "while `Dataset.select` allows us to downsample each corpus according to the values in fracs. \n",
        "\n",
        "Let’s have a\n",
        "look at how many examples we have per language in the training sets by accessing the `Dataset.num_rows`\n",
        "attribute:"
      ],
      "metadata": {
        "id": "eebqOoNH2Rxk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame({lang:[panx_ch[lang][\"train\"].num_rows] for lang in languages}, index=[\"Number of training examples\"])"
      ],
      "metadata": {
        "id": "4CNTHUkq2Wd6",
        "outputId": "a39af6c4-56c7-4110-bdc7-f5413a332ff3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-fa9462e7-17c1-4dc6-8670-5248f6f49f9a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>de</th>\n",
              "      <th>fr</th>\n",
              "      <th>it</th>\n",
              "      <th>en</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Number of training examples</th>\n",
              "      <td>12580</td>\n",
              "      <td>4580</td>\n",
              "      <td>1680</td>\n",
              "      <td>1180</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fa9462e7-17c1-4dc6-8670-5248f6f49f9a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fa9462e7-17c1-4dc6-8670-5248f6f49f9a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fa9462e7-17c1-4dc6-8670-5248f6f49f9a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                de    fr    it    en\n",
              "Number of training examples  12580  4580  1680  1180"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let’s inspect one of the examples in the German corpus\n",
        "panx_ch[\"de\"][\"train\"][0]"
      ],
      "metadata": {
        "id": "xbKa3xjx4FDJ",
        "outputId": "7b20e383-5031-46d2-8ee8-d04bdbefae9d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'langs': ['de',\n",
              "  'de',\n",
              "  'de',\n",
              "  'de',\n",
              "  'de',\n",
              "  'de',\n",
              "  'de',\n",
              "  'de',\n",
              "  'de',\n",
              "  'de',\n",
              "  'de',\n",
              "  'de'],\n",
              " 'ner_tags': [0, 0, 0, 0, 5, 6, 0, 0, 5, 5, 6, 0],\n",
              " 'tokens': ['2.000',\n",
              "  'Einwohnern',\n",
              "  'an',\n",
              "  'der',\n",
              "  'Danziger',\n",
              "  'Bucht',\n",
              "  'in',\n",
              "  'der',\n",
              "  'polnischen',\n",
              "  'Woiwodschaft',\n",
              "  'Pommern',\n",
              "  '.']}"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In particular, we see that the `ner_tags` column corresponds to the mapping of each entity to an integer. This is a bit cryptic to the human eye,\n",
        "so let’s create a new column with the familiar `LOC, PER`, and `ORG` tags. \n",
        "\n",
        "To do this, the first thing to notice is that\n",
        "our `Dataset` object has a `features` attribute that specifies the underlying data types associated with each\n",
        "column:"
      ],
      "metadata": {
        "id": "7j5A6aGF4eGg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "panx_ch[\"de\"][\"train\"].features"
      ],
      "metadata": {
        "id": "iC50G_s24rBE",
        "outputId": "90c49f1b-0992-4dc7-daad-3d4c9df86259",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'langs': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None),\n",
              " 'ner_tags': Sequence(feature=ClassLabel(num_classes=7, names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC'], names_file=None, id=None), length=-1, id=None),\n",
              " 'tokens': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None)}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `Sequence` class specifies that the field contains a list of features, which in the case of `ner_tags`\n",
        "corresponds to a list of ClassLabel `features`. \n",
        "\n",
        "Let’s pick out this feature from the training set as follows:"
      ],
      "metadata": {
        "id": "vP3N9iiQ5Fet"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tags = panx_ch[\"de\"][\"train\"].features[\"ner_tags\"].feature\n",
        "tags"
      ],
      "metadata": {
        "id": "R1zLCuLd5NbJ",
        "outputId": "d59f7b85-3ea0-438d-8e82-69c4594bc946",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ClassLabel(num_classes=7, names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC'], names_file=None, id=None)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "langs = panx_ch[\"de\"][\"train\"].features[\"langs\"].feature\n",
        "langs"
      ],
      "metadata": {
        "id": "cJ-mHc905kxv",
        "outputId": "349df7d6-db0e-4e62-909d-4d8f3dbf256d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Value(dtype='string', id=None)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = panx_ch[\"de\"][\"train\"].features[\"tokens\"].feature\n",
        "tokens"
      ],
      "metadata": {
        "id": "0s48UN_j5vYH",
        "outputId": "6fcdbc74-de32-4c67-8dad-51493b38a586",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Value(dtype='string', id=None)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "One handy property of the `ClassLabel` feature is that it has conversion methods to convert from the class name\n",
        "to an integer and vice versa. \n",
        "\n",
        "For example, we can find the integer associated with the `B-PER` tag by using the `ClassLabel.str2int` function as follows:"
      ],
      "metadata": {
        "id": "bH-QFkQ_555A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tags.str2int(\"B-PER\")"
      ],
      "metadata": {
        "id": "7du04g8J5_cY",
        "outputId": "c2371c02-fb7f-4885-d747-301e8030afda",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tags.str2int(\"I-PER\")"
      ],
      "metadata": {
        "id": "Ol0LgsLp6HNN",
        "outputId": "8c395956-cc08-4589-90c3-71d6bcea8fb9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Similarly, we can map back from an integer to the corresponding class name:"
      ],
      "metadata": {
        "id": "ZLJMDoar6O4J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tags.int2str(1)"
      ],
      "metadata": {
        "id": "aX4WP3G46Ps1",
        "outputId": "c8994038-198f-425b-ca6f-073afb8285aa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'B-PER'"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tags.int2str(3)"
      ],
      "metadata": {
        "id": "GydnOv9o6T27",
        "outputId": "af57cbf1-e1f4-4ad0-953d-5d36ef87a6ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'B-ORG'"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s use the `ClassLabel.int2str` function to create a new column in our training set with class names for\n",
        "each tag. \n",
        "\n",
        "We’ll use the `Dataset.map` function to return a dict with the key corresponding to the new column\n",
        "name and the value as a list of class names:"
      ],
      "metadata": {
        "id": "LcQJg5lw7HT7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_tag_names(batch):\n",
        "  return {\"ner_tags_str\": [tags.int2str(idx) for idx in batch[\"ner_tags\"]]}"
      ],
      "metadata": {
        "id": "aeZ-GwAD7LGe"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "panx_de = panx_ch[\"de\"].map(create_tag_names)"
      ],
      "metadata": {
        "id": "CJQYPVQx7e-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "panx_de[\"train\"][0]"
      ],
      "metadata": {
        "id": "0oC72KTh7n3r",
        "outputId": "47a2c9aa-7913-4dc7-9549-de555f90d159",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'langs': ['de',\n",
              "  'de',\n",
              "  'de',\n",
              "  'de',\n",
              "  'de',\n",
              "  'de',\n",
              "  'de',\n",
              "  'de',\n",
              "  'de',\n",
              "  'de',\n",
              "  'de',\n",
              "  'de'],\n",
              " 'ner_tags': [0, 0, 0, 0, 5, 6, 0, 0, 5, 5, 6, 0],\n",
              " 'ner_tags_str': ['O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'B-LOC',\n",
              "  'I-LOC',\n",
              "  'O',\n",
              "  'O',\n",
              "  'B-LOC',\n",
              "  'B-LOC',\n",
              "  'I-LOC',\n",
              "  'O'],\n",
              " 'tokens': ['2.000',\n",
              "  'Einwohnern',\n",
              "  'an',\n",
              "  'der',\n",
              "  'Danziger',\n",
              "  'Bucht',\n",
              "  'in',\n",
              "  'der',\n",
              "  'polnischen',\n",
              "  'Woiwodschaft',\n",
              "  'Pommern',\n",
              "  '.']}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have our tags in human-readable format, let’s see how the tokens and tags align for the first example in the training set:"
      ],
      "metadata": {
        "id": "7oEDlzsY9PjS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "de_example = panx_de[\"train\"][0]\n",
        "df = pd.DataFrame([de_example[\"tokens\"], de_example[\"ner_tags_str\"]], [\"Tokens\", \"Tags\"])\n",
        "display_df(df, header=None)"
      ],
      "metadata": {
        "id": "0cz6q-129TE7",
        "outputId": "92c32519-3f0b-4e72-915e-df13d604fad2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Tokens</th>\n",
              "      <td>2.000</td>\n",
              "      <td>Einwohnern</td>\n",
              "      <td>an</td>\n",
              "      <td>der</td>\n",
              "      <td>Danziger</td>\n",
              "      <td>Bucht</td>\n",
              "      <td>in</td>\n",
              "      <td>der</td>\n",
              "      <td>polnischen</td>\n",
              "      <td>Woiwodschaft</td>\n",
              "      <td>Pommern</td>\n",
              "      <td>.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Tags</th>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>B-LOC</td>\n",
              "      <td>I-LOC</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>B-LOC</td>\n",
              "      <td>B-LOC</td>\n",
              "      <td>I-LOC</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As a sanity check that we don’t have any unusual imbalance in the tags, let’s calculate the frequencies of each\n",
        "entity across each split:"
      ],
      "metadata": {
        "id": "D2BDepCm99Pb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "split2freqs = {}\n",
        "\n",
        "for split in panx_de.keys():\n",
        "  tag_names = []\n",
        "  for row in panx_de[split][\"ner_tags_str\"]:\n",
        "    tag_names.append([t.split(\"-\")[1] for t in row if t.startswith(\"B\")])\n",
        "  \n",
        "  split2freqs[split] = Counter(chain.from_iterable(tag_names))\n",
        "\n",
        "pd.DataFrame.from_dict(split2freqs, orient=\"index\")"
      ],
      "metadata": {
        "id": "0Bbkg4QJ99zW",
        "outputId": "583cf203-49f9-47c9-9c7d-b494d4ccfa52",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-3ae9f360-6c37-4f3a-adbc-a8df039a6891\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ORG</th>\n",
              "      <th>LOC</th>\n",
              "      <th>PER</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>validation</th>\n",
              "      <td>2683</td>\n",
              "      <td>3172</td>\n",
              "      <td>2893</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>test</th>\n",
              "      <td>2573</td>\n",
              "      <td>3180</td>\n",
              "      <td>3071</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>train</th>\n",
              "      <td>5366</td>\n",
              "      <td>6186</td>\n",
              "      <td>5810</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3ae9f360-6c37-4f3a-adbc-a8df039a6891')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3ae9f360-6c37-4f3a-adbc-a8df039a6891 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3ae9f360-6c37-4f3a-adbc-a8df039a6891');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "             ORG   LOC   PER\n",
              "validation  2683  3172  2893\n",
              "test        2573  3180  3071\n",
              "train       5366  6186  5810"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This looks good - the distribution of the `PER, LOC`, and `ORG` frequencies are roughly the same for each split, so\n",
        "the validation and test sets should provide a good measure of our `NER` tagger’s ability to generalize."
      ],
      "metadata": {
        "id": "dOExucIm_EI8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Training a Named Entity Recognition Tagger"
      ],
      "metadata": {
        "id": "K5bC4fAi_KQ6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We know that for text classification, BERT uses the special `[CLS]` token to represent an entire sequence of text.\n",
        "\n",
        "This representation is then fed through a fully connected\n",
        "or dense layer to output the distribution of all the discrete label values.\n",
        "\n",
        "BERT and other encoder\n",
        "Transformers take a similar approach for NER, except that the representation of every input token is fed into the\n",
        "same fully-connected layer to output the entity of the token.\n",
        "\n",
        "For this reason, NER is often framed as a token\n",
        "classification task.\n",
        "\n",
        "<img src='https://github.com/rahiakela/transformers-research-and-practice/blob/main/natural-language-processing-with-transformers/04-multilingual-ner/images/1.png?raw=1' width='600'/>\n",
        "\n",
        "So far, so good, but how should we handle subwords in a token classification task?\n",
        "\n",
        "For example, the last name `Sparrow` is tokenized by WordPiece into the subwords `Spa` and `##rrow`, so which one (or both)\n",
        "should be assigned the `I-PER` label?\n",
        "\n",
        "Although we could have chosen to include the representation from the `##rrow`\n",
        "subword by assigning it a copy of the `I-LOC` label, this introduces extra complexity when subwords are associated\n",
        "with a `B-entity` because then we need to copy these tags and this violates the `IOB2` format.\n",
        "\n",
        "Fortunately, all this intuition from `BERT` carries over to `XLM-R` since the architecture is based on `RoBERTa`,\n",
        "which is identical to `BERT`! However, there are some slight differences, especially around the choice of tokenizer."
      ],
      "metadata": {
        "id": "FYewOAqF_SJo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###SentencePiece Tokenization"
      ],
      "metadata": {
        "id": "x3QnT0vYgor1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instead of using a WordPiece tokenizer, XLM-R uses a tokenizer called SentencePiece that is trained on the raw\n",
        "text of all 100 languages. The SentencePiece tokenizer is based on a type of subword segmentation called Unigram\n",
        "and encodes input text as a sequence of Unicode characters. \n",
        "\n",
        "This last feature is especially useful for multilingual\n",
        "corpora since it allows SentencePiece to be agnostic about accents, punctuation, and the fact that many languages\n",
        "like Japanese do not have whitespace characters.\n",
        "\n",
        "To get a feel for how `SentencePiece` compares to `WordPiece`, let’s load the BERT and `XLM-R` tokenizers in the\n",
        "usual way with `Transformers`:"
      ],
      "metadata": {
        "id": "F73slUmQgpmM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bert_model_name = \"bert-base-cased\"\n",
        "xlmr_model_name = \"xlm-roberta-base\"\n",
        "\n",
        "bert_tokenizer = AutoTokenizer.from_pretrained(bert_model_name)\n",
        "xlmr_tokenizer = AutoTokenizer.from_pretrained(xlmr_model_name)"
      ],
      "metadata": {
        "id": "bBnVP4BthVwG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "By encoding a small sequence of text we can also retrieve the special tokens that each model used during\n",
        "pretraining:"
      ],
      "metadata": {
        "id": "R6pe8Y-9h9zR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Jack Sparrow loves New York!\"\n",
        "bert_tokens = bert_tokenizer(text).tokens()\n",
        "xmlr_tokens = xlmr_tokenizer(text).tokens()"
      ],
      "metadata": {
        "id": "cb72SFjYh-Wy"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame([bert_tokens, xmlr_tokens], [\"BERT\", \"XLM-R\"])\n",
        "display_df(df, header=None)"
      ],
      "metadata": {
        "id": "b0bR5QFPihUL",
        "outputId": "ec1d3d28-d897-4350-87d6-2d5e8e29ff3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>BERT</th>\n",
              "      <td>[CLS]</td>\n",
              "      <td>Jack</td>\n",
              "      <td>Spa</td>\n",
              "      <td>##rrow</td>\n",
              "      <td>loves</td>\n",
              "      <td>New</td>\n",
              "      <td>York</td>\n",
              "      <td>!</td>\n",
              "      <td>[SEP]</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>XLM-R</th>\n",
              "      <td>&lt;s&gt;</td>\n",
              "      <td>▁Jack</td>\n",
              "      <td>▁Spar</td>\n",
              "      <td>row</td>\n",
              "      <td>▁love</td>\n",
              "      <td>s</td>\n",
              "      <td>▁New</td>\n",
              "      <td>▁York</td>\n",
              "      <td>!</td>\n",
              "      <td>&lt;/s&gt;</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we see that instead of the `[CLS]` and `[SEP]` tokens that BERT uses for sentence classification tasks, XLMR\n",
        "uses `<s>` and `<\\s>` to denote the start and end of a sequence.\n",
        "\n",
        "Another special feature of SentencePiece is that it\n",
        "treats raw text as a sequence of Unicode characters, with whitespace given the Unicode symbol `U+2581` or `_`\n",
        "character. By assigning a special symbol for whitespace, SentencePiece is able to detokenize a sequence without\n",
        "ambiguities.\n",
        "\n",
        "We can see that WordPiece has lost the information that there is no whitespace\n",
        "between `York` and `!`. \n",
        "\n",
        "By contrast, SentencePiece preserves the whitespace in the tokenized text so we can\n",
        "convert back to the raw text without ambiguity:"
      ],
      "metadata": {
        "id": "TXYeixbkmWtR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\".join(xmlr_tokens).replace(\"▁\", \" \")"
      ],
      "metadata": {
        "id": "9CQx2E3KogOp",
        "outputId": "9d2b2b14-42a9-48e2-ee97-d6d9caa619ac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<s> Jack Sparrow loves New York!</s>'"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Transformers Model Class Anatomy"
      ],
      "metadata": {
        "id": "YZAB5-xBpLbW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Transformers library is organized around dedicated classes for each\n",
        "architecture and task:\n",
        "\n",
        "* Sequence classification\n",
        "* Extractive question answering\n",
        "* Language modeling\n",
        "* Named entity recognition\n",
        "* Summarization\n",
        "* Translation\n",
        "\n",
        "and the associated classes are named according to a `ModelNameForTask` convention. Most of the time, we load\n",
        "these models using the `ModelNameForTask.from_pretrained` function and since the architecture can\n",
        "usually be guessed from the name alone (e.g. `bert-base-uncased`), Transformers provides a convenient set of AutoClasses to automatically load the relevant configuration, vocabulary, or weights. \n",
        "\n",
        "In practice, these\n",
        "`AutoClasses` are extremely useful because it means that we can switch to a completely different architecture in our\n",
        "experiments by simply changing the model name!"
      ],
      "metadata": {
        "id": "tcH6UomnpMYp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###XLM-R Model for Token Classification"
      ],
      "metadata": {
        "id": "GWfxlylE3kDk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The separation of bodies and heads allows us to build a custom head for any task and just mount it on top of a\n",
        "pretrained model!\n",
        "\n",
        "Let’s go through the exercise of building a a custom token classification head for `XLM-R`. Since\n",
        "`XLM-R` uses the same model architecture as `RoBERTa`, we will use `RoBERTa` as the base model, but augmented\n",
        "with settings specific to `XLM-R`.\n",
        "\n",
        "To get started we need a data structure that will represent our `XLM-R` NER tagger.\n",
        "\n",
        "As a first guess, we’ll need a\n",
        "configuration file to initialize the model and a `forward` function to generate the outputs. \n",
        "\n",
        "With these\n",
        "considerations, let’s go ahead and build our `XLM-R` class for token classification:\n",
        "\n"
      ],
      "metadata": {
        "id": "E7MGxxTu3k1g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class XLMRobertaForTokenClassification(RobertaPreTrainedModel):\n",
        "  config_class = XLMRobertaConfig\n",
        "\n",
        "  def __init__(self, config):\n",
        "    super().__init__(config)\n",
        "\n",
        "    self.num_labels = config.num_labels\n",
        "    # load model body\n",
        "    self.roberta = RobertaModel(config, add_pooling_layer=False)\n",
        "    # setup token classification head\n",
        "    self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "    self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
        "    # load and initialize weights\n",
        "    self.init_weights()\n",
        "\n",
        "  def forward(self, input_ids=None, attention_mask=None, token_type_ids=None, labels=None, **kwargs):\n",
        "    pass"
      ],
      "metadata": {
        "id": "-Xvbo5WJ5NqW"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The only thing left to do is to define what the model should do in a forward pass. \n",
        "\n",
        "We define the following behavior\n",
        "in the `forward` function:"
      ],
      "metadata": {
        "id": "3F-Q4TN569jw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def forward(self, input_ids=None, attention_mask=None, token_type_ids=None, labels=None, **kwargs):\n",
        "    # use model body to get encoder representations\n",
        "    outputs = self.roberta(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, **kwargs)\n",
        "    # apply classifier to encoder representation\n",
        "    sequence_output = self.dropout(outputs[0])\n",
        "    logits = self.classifier(sequence_output)\n",
        "    # calculate losses\n",
        "    loss = None\n",
        "    if labels is not None:\n",
        "      loss_fct = nn.CrossEntropyLoss()\n",
        "      loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
        "    # return model output object\n",
        "    return TokenClassifierOutput(loss=loss, logits=logits, hidden_states=outputs.hidden_states, attentions=outputs.attentions)"
      ],
      "metadata": {
        "id": "bki-ZBrT7ADZ"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The only thing left to do is updating the placeholder function in the model class with our freshly baked functions:"
      ],
      "metadata": {
        "id": "WKjiyvpR-tDK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "XLMRobertaForTokenClassification.forward = forward"
      ],
      "metadata": {
        "id": "3hNc1kXl-tjQ"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Loading a Custom Model"
      ],
      "metadata": {
        "id": "BUGOTkK4-_Sr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we are ready to load our token classification model. Here we need to provide some additional information\n",
        "beyond the model name, including the tags that we will use to label each entity and the mapping of each tag to an\n",
        "ID and vice versa. \n",
        "\n",
        "All of this information can be derived from our `tags` variable, which as a `ClassLabel` object has a names attribute that we can use to derive the mapping:"
      ],
      "metadata": {
        "id": "5zbJR9in_AIQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index2tag = {idx: tag for idx, tag in enumerate(tags.names)}\n",
        "tag2index = {tag: idx for idx, tag in enumerate(tags.names)}"
      ],
      "metadata": {
        "id": "9hXn9EtEAkug"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "With this information and the `ClassLabel.num_classes` attribute, we can load the XLM-R configuration for\n",
        "NER as follows:"
      ],
      "metadata": {
        "id": "sjprBBb1BAnf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xlmr_config = AutoConfig.from_pretrained(xlmr_model_name, \n",
        "                                         num_labels=tags.num_classes,\n",
        "                                         id2label=index2tag,\n",
        "                                         label2id=tag2index)"
      ],
      "metadata": {
        "id": "rvKAne9DBCvn"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we can load the model weights as usual with the `from_pretrained ` function. \n",
        "\n",
        "Note that we did not\n",
        "implement this ourselves; we get this for free by inheriting from `RobertaPreTrainedModel`:"
      ],
      "metadata": {
        "id": "ajxqMh7LBkM6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xlmr_model = (XLMRobertaForTokenClassification.from_pretrained(xlmr_model_name, config=xlmr_config).to(device))"
      ],
      "metadata": {
        "id": "TVwMjixjBpQq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As a sanity check that we have initialized the tokenizer and model correctly.\n",
        "\n",
        "Let’s test the predictions on our small\n",
        "sequence of known entities:"
      ],
      "metadata": {
        "id": "zuvCBz2AC66z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = xlmr_tokenizer.encode(text, return_tensors=\"pt\")\n",
        "\n",
        "df = pd.DataFrame([xmlr_tokens, input_ids[0].numpy()], [\"Tokens\", \"Inpud IDs\"])\n",
        "display_df(df, header=None)"
      ],
      "metadata": {
        "id": "KlUM0c6YC9JI",
        "outputId": "1a065ca6-259f-43fb-ca61-2c8bbe7de70a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Tokens</th>\n",
              "      <td>&lt;s&gt;</td>\n",
              "      <td>▁Jack</td>\n",
              "      <td>▁Spar</td>\n",
              "      <td>row</td>\n",
              "      <td>▁love</td>\n",
              "      <td>s</td>\n",
              "      <td>▁New</td>\n",
              "      <td>▁York</td>\n",
              "      <td>!</td>\n",
              "      <td>&lt;/s&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Inpud IDs</th>\n",
              "      <td>0</td>\n",
              "      <td>21763</td>\n",
              "      <td>37456</td>\n",
              "      <td>15555</td>\n",
              "      <td>5161</td>\n",
              "      <td>7</td>\n",
              "      <td>2356</td>\n",
              "      <td>5753</td>\n",
              "      <td>38</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see, the start `<s>` and end `</s>` tokens are given the IDs 0 and 2 respectively. \n",
        "\n",
        "For reference we can\n",
        "find the mappings of the other special characters via the `all_special_ids` and `all_special_tokens`\n",
        "attributes of `xlmr_tokenizer`:"
      ],
      "metadata": {
        "id": "dwuYRyLWERev"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame([xlmr_tokenizer.all_special_tokens, xlmr_tokenizer.all_special_ids], index=[\"Special Token\", \"Special Token ID\"])\n",
        "display_df(df, header=None)"
      ],
      "metadata": {
        "id": "MhCVg7nJEWpj",
        "outputId": "f7b168e3-201d-41ad-a6ed-87309871a055",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Special Token</th>\n",
              "      <td>&lt;s&gt;</td>\n",
              "      <td>&lt;/s&gt;</td>\n",
              "      <td>&lt;unk&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;mask&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Special Token ID</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>250001</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we need to pass the inputs to the model and extract the predictions by taking the `argmax` to get the most\n",
        "likely class per token:"
      ],
      "metadata": {
        "id": "Gnv3_gzfE9J2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = xlmr_model(input_ids.to(device)).logits\n",
        "predictions = torch.argmax(outputs, dim=1)\n",
        "\n",
        "print(f\"Number of tokens in sequence: {len(xmlr_tokens)}\")\n",
        "print(f\"Shape of outputs: {outputs.shape}\")"
      ],
      "metadata": {
        "id": "eWVZpoEmE_DB",
        "outputId": "14ad376e-5291-4b83-a3af-ad1596bfb5a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of tokens in sequence: 10\n",
            "Shape of outputs: torch.Size([1, 10, 7])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we see that the logits have the shape `[batch_size, num_tokens, num_tags]`, with each token\n",
        "given a logit among the 7 possible NER tags. \n",
        "\n",
        "By enumerating over the sequence, we can quickly see what the\n",
        "pretrained model predicts:"
      ],
      "metadata": {
        "id": "O4O1-7kQF0US"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tags.names = ['O', 'B-ORG', 'B-LOC', '', 'B-LOC', 'B-ORG', 'I-ORG', '']\n",
        "preds = [tags.names[p] for p in predictions[0].cpu().numpy()]\n",
        "df = pd.DataFrame([xmlr_tokens, preds], [\"Tokens\", \"Tags\"])\n",
        "display_df(df, header=None)"
      ],
      "metadata": {
        "id": "N3JyfzDQF3Wp",
        "outputId": "c954b861-86de-44b5-d82c-aa1dfe9e6188",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Tokens</th>\n",
              "      <td>&lt;s&gt;</td>\n",
              "      <td>▁Jack</td>\n",
              "      <td>▁Spar</td>\n",
              "      <td>row</td>\n",
              "      <td>▁love</td>\n",
              "      <td>s</td>\n",
              "      <td>▁New</td>\n",
              "      <td>▁York</td>\n",
              "      <td>!</td>\n",
              "      <td>&lt;/s&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Tags</th>\n",
              "      <td>O</td>\n",
              "      <td></td>\n",
              "      <td>B-ORG</td>\n",
              "      <td></td>\n",
              "      <td>B-ORG</td>\n",
              "      <td></td>\n",
              "      <td>B-LOC</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}