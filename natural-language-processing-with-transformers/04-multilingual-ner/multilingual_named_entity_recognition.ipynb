{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "multilingual-named-entity-recognition.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMDafBE107cZOAqCGssUHrf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e455ad78950a4eaf8d513f7d3e667921": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d75bf86f69a1497e88346ac3e42c81cd",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e64f7023364d4a258968ef049930008c",
              "IPY_MODEL_784ff4ef0de6425d95025e89eb137ff9",
              "IPY_MODEL_60351791ad3d43f2b8e0a176649bb3ef"
            ]
          }
        },
        "d75bf86f69a1497e88346ac3e42c81cd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e64f7023364d4a258968ef049930008c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fbd4171152f747e1ba51f87260297aac",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_18de0bbd4423471d96920739f46aa611"
          }
        },
        "784ff4ef0de6425d95025e89eb137ff9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a4d11aa48d774439bb381fbd573f5b72",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 3,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 3,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5d9d10ce08864a3198cdbc3c6763e6b7"
          }
        },
        "60351791ad3d43f2b8e0a176649bb3ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a4dd554db7794184ad2a86810b9950e0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 3/3 [00:00&lt;00:00, 51.34it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0f65f2af276343838d68e890c9616ae0"
          }
        },
        "fbd4171152f747e1ba51f87260297aac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "18de0bbd4423471d96920739f46aa611": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a4d11aa48d774439bb381fbd573f5b72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5d9d10ce08864a3198cdbc3c6763e6b7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a4dd554db7794184ad2a86810b9950e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0f65f2af276343838d68e890c9616ae0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2d12ca22390445308f217c454cd893a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_af99a139fcf545d7b612aca14bfd0346",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8d3de88dd0e242d69b802234471bf6af",
              "IPY_MODEL_bcabab9608b0424aa6b9026195b9d8c6",
              "IPY_MODEL_d5ad3d8ac43142658408243a1fe1c37a"
            ]
          }
        },
        "af99a139fcf545d7b612aca14bfd0346": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8d3de88dd0e242d69b802234471bf6af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6f941fb6524d4f4489ff7174f66f240e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_25b785411c3646fd8206cfde359f1564"
          }
        },
        "bcabab9608b0424aa6b9026195b9d8c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_82ba9c7ed338488ea2950d033c5b6e6a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 7,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 7,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6bd629e1b1a742829d3355a955e42c16"
          }
        },
        "d5ad3d8ac43142658408243a1fe1c37a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d444cb00c7f74a6b98f93f0b238ee7e0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 7/7 [00:01&lt;00:00,  6.23ba/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4a3b4e0f9f684a1da38dd6c2f1641ae5"
          }
        },
        "6f941fb6524d4f4489ff7174f66f240e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "25b785411c3646fd8206cfde359f1564": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "82ba9c7ed338488ea2950d033c5b6e6a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6bd629e1b1a742829d3355a955e42c16": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d444cb00c7f74a6b98f93f0b238ee7e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4a3b4e0f9f684a1da38dd6c2f1641ae5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/transformers-research-and-practice/blob/main/natural-language-processing-with-transformers/04-multilingual-ner/multilingual_named_entity_recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Multilingual Named Entity Recognition"
      ],
      "metadata": {
        "id": "IcdvovQpzhkI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook we will explore how a single Transformer model called XLM-RoBERTa can be fine-tuned to\n",
        "perform named entity recognition (NER) across several languages. NER is a common NLP task that identifies\n",
        "entities like people, organizations, or locations in text. These entities can be used for various applications such as\n",
        "gaining insights from company documents, augmenting the quality of search engines, or simply building a\n",
        "structured database from a corpus."
      ],
      "metadata": {
        "id": "iaOVAWdCzu8J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Setup"
      ],
      "metadata": {
        "id": "Tx8XRrYJz6SS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%shell\n",
        "\n",
        "pip -q install transformers\n",
        "pip -q install datasets\n",
        "pip -q install seqeval"
      ],
      "metadata": {
        "id": "VYnilI_Qz7Yh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.functional import cross_entropy\n",
        "\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import XLMRobertaConfig\n",
        "from transformers.modeling_outputs import TokenClassifierOutput\n",
        "from transformers.models.roberta.modeling_roberta import RobertaModel\n",
        "from transformers.models.roberta.modeling_roberta import RobertaPreTrainedModel\n",
        "from transformers import AutoConfig\n",
        "from transformers import TrainingArguments\n",
        "from transformers import Trainer\n",
        "from transformers import DataCollatorForTokenClassification\n",
        "\n",
        "from seqeval.metrics import classification_report\n",
        "from seqeval.metrics import f1_score\n",
        "\n",
        "from datasets import get_dataset_config_names\n",
        "from datasets import load_dataset\n",
        "from datasets import DatasetDict\n",
        "\n",
        "from itertools import chain\n",
        "from collections import defaultdict\n",
        "from collections import Counter\n",
        "\n",
        "from IPython.display import HTML, display, set_matplotlib_formats"
      ],
      "metadata": {
        "id": "6pGaeyjn4SuG"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "CF3O4o6dBwmB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def display_df(df, max_cols=15, header=True, index=True):\n",
        "    # 15 cols seems to be limit for O'reilly\n",
        "    return display(HTML(df.to_html(header=header, index=index, max_cols=max_cols)))"
      ],
      "metadata": {
        "id": "HjFrvYj543xi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##The Dataset"
      ],
      "metadata": {
        "id": "z7Ok2tF-0TV1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "we will be using a subset of the Cross-lingual TRansfer Evaluation of Multilingual Encoders\n",
        "(XTREME) benchmark called Wikiann or PAN-X. This dataset consists of Wikipedia articles in many\n",
        "languages, including the four most commonly spoken languages in Switzerland: German (62.9%), French (22.9%),\n",
        "Italian (8.4%), and English (5.9%). \n",
        "\n",
        "Each article is annotated with LOC (location), PER (person) and ORG\n",
        "(organization) tags in the “inside-outside-beginning” (IOB2) format, where a B-prefix indicates the beginning of\n",
        "an entity, and consecutive positions of the same entity are given an I- prefix. An O tag indicates that the token does\n",
        "not belong to any entity. \n",
        "\n",
        "For example, the following sentence\n",
        "\n"
      ],
      "metadata": {
        "id": "db96XyEI0XwC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = \"Jeff Dean is a computer scientist at Google in California\".split()\n",
        "labels = [\"B-PER\", \"I-PER\", \"O\", \"O\", \"O\", \"O\", \"O\", \"B-ORG\", \"O\", \"B-LOC\"]\n",
        "\n",
        "df = pd.DataFrame(data=[tokens, labels], index=[\"Tokens\", \"Tags\"])\n",
        "display_df(df, header=None)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "id": "oS3u-g2h4OZx",
        "outputId": "97ddea85-1faf-455a-f96d-38440585fbd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Tokens</th>\n",
              "      <td>Jeff</td>\n",
              "      <td>Dean</td>\n",
              "      <td>is</td>\n",
              "      <td>a</td>\n",
              "      <td>computer</td>\n",
              "      <td>scientist</td>\n",
              "      <td>at</td>\n",
              "      <td>Google</td>\n",
              "      <td>in</td>\n",
              "      <td>California</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Tags</th>\n",
              "      <td>B-PER</td>\n",
              "      <td>I-PER</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>B-ORG</td>\n",
              "      <td>O</td>\n",
              "      <td>B-LOC</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To load PAN-X with HuggingFace Datasets we first need to manually download the file AmazonPhotos.zip from\n",
        "XTREME’s [Amazon Cloud Drive](https://www.amazon.com/clouddrive/share/d3KGCRCIYwhKJF0H3eWA26hjg2ZCRhjpEQtDL70FSBN), and place it in a local directory (data in our example).\n",
        "\n",
        "For example, to load the\n",
        "German corpus we use the “de” code as follows:"
      ],
      "metadata": {
        "id": "4oPeblXYzSU4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "load_dataset(\"xtreme\", \"PAN-X.de\", data_dir=\"data\")"
      ],
      "metadata": {
        "id": "S81zl_ojzbDS",
        "outputId": "3f9cab6c-fc77-42ce-984d-4d690a2ff4af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347,
          "referenced_widgets": [
            "e455ad78950a4eaf8d513f7d3e667921",
            "d75bf86f69a1497e88346ac3e42c81cd",
            "e64f7023364d4a258968ef049930008c",
            "784ff4ef0de6425d95025e89eb137ff9",
            "60351791ad3d43f2b8e0a176649bb3ef",
            "fbd4171152f747e1ba51f87260297aac",
            "18de0bbd4423471d96920739f46aa611",
            "a4d11aa48d774439bb381fbd573f5b72",
            "5d9d10ce08864a3198cdbc3c6763e6b7",
            "a4dd554db7794184ad2a86810b9950e0",
            "0f65f2af276343838d68e890c9616ae0"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using custom data configuration PAN-X.de-data_dir=data\n",
            "Reusing dataset xtreme (/root/.cache/huggingface/datasets/xtreme/PAN-X.de-data_dir=data/1.0.0/2fc6b63c5326cc0d1f73060649612889b3a7ed8a6605c91cecdbd228a7158b17)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e455ad78950a4eaf8d513f7d3e667921",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    validation: Dataset({\n",
              "        features: ['tokens', 'ner_tags', 'langs'],\n",
              "        num_rows: 10000\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['tokens', 'ner_tags', 'langs'],\n",
              "        num_rows: 10000\n",
              "    })\n",
              "    train: Dataset({\n",
              "        features: ['tokens', 'ner_tags', 'langs'],\n",
              "        num_rows: 20000\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this case, `load_dataset` returns a `DatasetDict` where each key corresponds to one of the splits, and each\n",
        "value is a `Dataset` object with `features` and `num_rows` attributes.\n",
        "\n",
        "To keep track of each language, let’s create a Python `defaultdict` that stores the language code as the key and\n",
        "a PAN-X corpus of type `DatasetDict` as the value:"
      ],
      "metadata": {
        "id": "auhJfETdz2Mi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "languages = [\"de\", \"fr\", \"it\", \"en\"]\n",
        "fractions = [0.629, 0.229, 0.084, 0.059]\n",
        "\n",
        "# return a DatasetDict if a key doesn't exist\n",
        "panx_ch = defaultdict(DatasetDict)\n",
        "\n",
        "for lang, frac in zip(languages, fractions):\n",
        "  # load monolingual corpus\n",
        "  ds = load_dataset(\"xtreme\", f\"PAN-X.{lang}\", data_dir=\"data\")\n",
        "  # shuffle and downsample each split according to spoken proportion\n",
        "  for split in ds.keys():\n",
        "    panx_ch[lang][split] = (ds[split].shuffle(seed=0).select(range(int(frac * ds[split].num_rows))))"
      ],
      "metadata": {
        "id": "VzInvqNT0HU7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we’ve used the `Dataset.shuffle` function to make sure we don’t accidentally bias our dataset splits,\n",
        "while `Dataset.select` allows us to downsample each corpus according to the values in fracs. \n",
        "\n",
        "Let’s have a\n",
        "look at how many examples we have per language in the training sets by accessing the `Dataset.num_rows`\n",
        "attribute:"
      ],
      "metadata": {
        "id": "eebqOoNH2Rxk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame({lang:[panx_ch[lang][\"train\"].num_rows] for lang in languages}, index=[\"Number of training examples\"])"
      ],
      "metadata": {
        "id": "4CNTHUkq2Wd6",
        "outputId": "1e40eb80-bea5-402c-f2ed-5e66217e98b3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-e6998644-ab63-4bae-a0ca-b162e8ce58d1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>de</th>\n",
              "      <th>fr</th>\n",
              "      <th>it</th>\n",
              "      <th>en</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Number of training examples</th>\n",
              "      <td>12580</td>\n",
              "      <td>4580</td>\n",
              "      <td>1680</td>\n",
              "      <td>1180</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-e6998644-ab63-4bae-a0ca-b162e8ce58d1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-e6998644-ab63-4bae-a0ca-b162e8ce58d1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-e6998644-ab63-4bae-a0ca-b162e8ce58d1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                de    fr    it    en\n",
              "Number of training examples  12580  4580  1680  1180"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let’s inspect one of the examples in the German corpus\n",
        "panx_ch[\"de\"][\"train\"][0]"
      ],
      "metadata": {
        "id": "xbKa3xjx4FDJ",
        "outputId": "523ce1b2-11e1-4d3b-f4f6-ee9d8904ba48",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'langs': ['de',\n",
              "  'de',\n",
              "  'de',\n",
              "  'de',\n",
              "  'de',\n",
              "  'de',\n",
              "  'de',\n",
              "  'de',\n",
              "  'de',\n",
              "  'de',\n",
              "  'de',\n",
              "  'de'],\n",
              " 'ner_tags': [0, 0, 0, 0, 5, 6, 0, 0, 5, 5, 6, 0],\n",
              " 'tokens': ['2.000',\n",
              "  'Einwohnern',\n",
              "  'an',\n",
              "  'der',\n",
              "  'Danziger',\n",
              "  'Bucht',\n",
              "  'in',\n",
              "  'der',\n",
              "  'polnischen',\n",
              "  'Woiwodschaft',\n",
              "  'Pommern',\n",
              "  '.']}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In particular, we see that the `ner_tags` column corresponds to the mapping of each entity to an integer. This is a bit cryptic to the human eye,\n",
        "so let’s create a new column with the familiar `LOC, PER`, and `ORG` tags. \n",
        "\n",
        "To do this, the first thing to notice is that\n",
        "our `Dataset` object has a `features` attribute that specifies the underlying data types associated with each\n",
        "column:"
      ],
      "metadata": {
        "id": "7j5A6aGF4eGg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "panx_ch[\"de\"][\"train\"].features"
      ],
      "metadata": {
        "id": "iC50G_s24rBE",
        "outputId": "42427aea-7a0c-4542-e4df-b1508d74186d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'langs': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None),\n",
              " 'ner_tags': Sequence(feature=ClassLabel(num_classes=7, names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC'], names_file=None, id=None), length=-1, id=None),\n",
              " 'tokens': Sequence(feature=Value(dtype='string', id=None), length=-1, id=None)}"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `Sequence` class specifies that the field contains a list of features, which in the case of `ner_tags`\n",
        "corresponds to a list of ClassLabel `features`. \n",
        "\n",
        "Let’s pick out this feature from the training set as follows:"
      ],
      "metadata": {
        "id": "vP3N9iiQ5Fet"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tags = panx_ch[\"de\"][\"train\"].features[\"ner_tags\"].feature\n",
        "tags"
      ],
      "metadata": {
        "id": "R1zLCuLd5NbJ",
        "outputId": "49999b82-ddc4-4cd4-8202-9ad84b0ad635",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ClassLabel(num_classes=7, names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC'], names_file=None, id=None)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "langs = panx_ch[\"de\"][\"train\"].features[\"langs\"].feature\n",
        "langs"
      ],
      "metadata": {
        "id": "cJ-mHc905kxv",
        "outputId": "f4e15c01-67f2-4dfc-8ea8-3ea6c5659bf5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Value(dtype='string', id=None)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = panx_ch[\"de\"][\"train\"].features[\"tokens\"].feature\n",
        "tokens"
      ],
      "metadata": {
        "id": "0s48UN_j5vYH",
        "outputId": "bdbbc731-4221-44ca-c511-dde743454922",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Value(dtype='string', id=None)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "One handy property of the `ClassLabel` feature is that it has conversion methods to convert from the class name\n",
        "to an integer and vice versa. \n",
        "\n",
        "For example, we can find the integer associated with the `B-PER` tag by using the `ClassLabel.str2int` function as follows:"
      ],
      "metadata": {
        "id": "bH-QFkQ_555A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tags.str2int(\"B-PER\")"
      ],
      "metadata": {
        "id": "7du04g8J5_cY",
        "outputId": "b8500d2d-e308-4749-e981-f02840874018",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tags.str2int(\"I-PER\")"
      ],
      "metadata": {
        "id": "Ol0LgsLp6HNN",
        "outputId": "93728bb6-7a3a-489c-f102-5102d582b95c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Similarly, we can map back from an integer to the corresponding class name:"
      ],
      "metadata": {
        "id": "ZLJMDoar6O4J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tags.int2str(1)"
      ],
      "metadata": {
        "id": "aX4WP3G46Ps1",
        "outputId": "a520c617-ede2-4c3f-ea08-34cbeac46df0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'B-PER'"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tags.int2str(3)"
      ],
      "metadata": {
        "id": "GydnOv9o6T27",
        "outputId": "74683368-f98d-4f68-9ff1-943fdfcf92b7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'B-ORG'"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s use the `ClassLabel.int2str` function to create a new column in our training set with class names for\n",
        "each tag. \n",
        "\n",
        "We’ll use the `Dataset.map` function to return a dict with the key corresponding to the new column\n",
        "name and the value as a list of class names:"
      ],
      "metadata": {
        "id": "LcQJg5lw7HT7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_tag_names(batch):\n",
        "  return {\"ner_tags_str\": [tags.int2str(idx) for idx in batch[\"ner_tags\"]]}"
      ],
      "metadata": {
        "id": "aeZ-GwAD7LGe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "panx_de = panx_ch[\"de\"].map(create_tag_names)"
      ],
      "metadata": {
        "id": "CJQYPVQx7e-3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "panx_de[\"train\"][0]"
      ],
      "metadata": {
        "id": "0oC72KTh7n3r",
        "outputId": "d8b3a521-7a69-4573-800f-54c1c0db2046",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'langs': ['de',\n",
              "  'de',\n",
              "  'de',\n",
              "  'de',\n",
              "  'de',\n",
              "  'de',\n",
              "  'de',\n",
              "  'de',\n",
              "  'de',\n",
              "  'de',\n",
              "  'de',\n",
              "  'de'],\n",
              " 'ner_tags': [0, 0, 0, 0, 5, 6, 0, 0, 5, 5, 6, 0],\n",
              " 'ner_tags_str': ['O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'O',\n",
              "  'B-LOC',\n",
              "  'I-LOC',\n",
              "  'O',\n",
              "  'O',\n",
              "  'B-LOC',\n",
              "  'B-LOC',\n",
              "  'I-LOC',\n",
              "  'O'],\n",
              " 'tokens': ['2.000',\n",
              "  'Einwohnern',\n",
              "  'an',\n",
              "  'der',\n",
              "  'Danziger',\n",
              "  'Bucht',\n",
              "  'in',\n",
              "  'der',\n",
              "  'polnischen',\n",
              "  'Woiwodschaft',\n",
              "  'Pommern',\n",
              "  '.']}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have our tags in human-readable format, let’s see how the tokens and tags align for the first example in the training set:"
      ],
      "metadata": {
        "id": "7oEDlzsY9PjS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "de_example = panx_de[\"train\"][0]\n",
        "df = pd.DataFrame([de_example[\"tokens\"], de_example[\"ner_tags_str\"]], [\"Tokens\", \"Tags\"])\n",
        "display_df(df, header=None)"
      ],
      "metadata": {
        "id": "0cz6q-129TE7",
        "outputId": "ff22f721-f96f-4cbb-ea55-f4d4bafecb94",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Tokens</th>\n",
              "      <td>2.000</td>\n",
              "      <td>Einwohnern</td>\n",
              "      <td>an</td>\n",
              "      <td>der</td>\n",
              "      <td>Danziger</td>\n",
              "      <td>Bucht</td>\n",
              "      <td>in</td>\n",
              "      <td>der</td>\n",
              "      <td>polnischen</td>\n",
              "      <td>Woiwodschaft</td>\n",
              "      <td>Pommern</td>\n",
              "      <td>.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Tags</th>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>B-LOC</td>\n",
              "      <td>I-LOC</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>B-LOC</td>\n",
              "      <td>B-LOC</td>\n",
              "      <td>I-LOC</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As a sanity check that we don’t have any unusual imbalance in the tags, let’s calculate the frequencies of each\n",
        "entity across each split:"
      ],
      "metadata": {
        "id": "D2BDepCm99Pb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "split2freqs = {}\n",
        "\n",
        "for split in panx_de.keys():\n",
        "  tag_names = []\n",
        "  for row in panx_de[split][\"ner_tags_str\"]:\n",
        "    tag_names.append([t.split(\"-\")[1] for t in row if t.startswith(\"B\")])\n",
        "  \n",
        "  split2freqs[split] = Counter(chain.from_iterable(tag_names))\n",
        "\n",
        "pd.DataFrame.from_dict(split2freqs, orient=\"index\")"
      ],
      "metadata": {
        "id": "0Bbkg4QJ99zW",
        "outputId": "fe2fc99a-c791-48fa-acaf-a9c4fce0224a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-9033dea8-70f5-4b66-b48c-096fced2f251\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ORG</th>\n",
              "      <th>LOC</th>\n",
              "      <th>PER</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>validation</th>\n",
              "      <td>2683</td>\n",
              "      <td>3172</td>\n",
              "      <td>2893</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>test</th>\n",
              "      <td>2573</td>\n",
              "      <td>3180</td>\n",
              "      <td>3071</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>train</th>\n",
              "      <td>5366</td>\n",
              "      <td>6186</td>\n",
              "      <td>5810</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9033dea8-70f5-4b66-b48c-096fced2f251')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9033dea8-70f5-4b66-b48c-096fced2f251 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9033dea8-70f5-4b66-b48c-096fced2f251');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "             ORG   LOC   PER\n",
              "validation  2683  3172  2893\n",
              "test        2573  3180  3071\n",
              "train       5366  6186  5810"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This looks good - the distribution of the `PER, LOC`, and `ORG` frequencies are roughly the same for each split, so\n",
        "the validation and test sets should provide a good measure of our `NER` tagger’s ability to generalize."
      ],
      "metadata": {
        "id": "dOExucIm_EI8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Training a Named Entity Recognition Tagger"
      ],
      "metadata": {
        "id": "K5bC4fAi_KQ6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We know that for text classification, BERT uses the special `[CLS]` token to represent an entire sequence of text.\n",
        "\n",
        "This representation is then fed through a fully connected\n",
        "or dense layer to output the distribution of all the discrete label values.\n",
        "\n",
        "BERT and other encoder\n",
        "Transformers take a similar approach for NER, except that the representation of every input token is fed into the\n",
        "same fully-connected layer to output the entity of the token.\n",
        "\n",
        "For this reason, NER is often framed as a token\n",
        "classification task.\n",
        "\n",
        "<img src='https://github.com/rahiakela/transformers-research-and-practice/blob/main/natural-language-processing-with-transformers/04-multilingual-ner/images/1.png?raw=1' width='600'/>\n",
        "\n",
        "So far, so good, but how should we handle subwords in a token classification task?\n",
        "\n",
        "For example, the last name `Sparrow` is tokenized by WordPiece into the subwords `Spa` and `##rrow`, so which one (or both)\n",
        "should be assigned the `I-PER` label?\n",
        "\n",
        "Although we could have chosen to include the representation from the `##rrow`\n",
        "subword by assigning it a copy of the `I-LOC` label, this introduces extra complexity when subwords are associated\n",
        "with a `B-entity` because then we need to copy these tags and this violates the `IOB2` format.\n",
        "\n",
        "Fortunately, all this intuition from `BERT` carries over to `XLM-R` since the architecture is based on `RoBERTa`,\n",
        "which is identical to `BERT`! However, there are some slight differences, especially around the choice of tokenizer."
      ],
      "metadata": {
        "id": "FYewOAqF_SJo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###SentencePiece Tokenization"
      ],
      "metadata": {
        "id": "x3QnT0vYgor1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instead of using a WordPiece tokenizer, XLM-R uses a tokenizer called SentencePiece that is trained on the raw\n",
        "text of all 100 languages. The SentencePiece tokenizer is based on a type of subword segmentation called Unigram\n",
        "and encodes input text as a sequence of Unicode characters. \n",
        "\n",
        "This last feature is especially useful for multilingual\n",
        "corpora since it allows SentencePiece to be agnostic about accents, punctuation, and the fact that many languages\n",
        "like Japanese do not have whitespace characters.\n",
        "\n",
        "To get a feel for how `SentencePiece` compares to `WordPiece`, let’s load the BERT and `XLM-R` tokenizers in the\n",
        "usual way with `Transformers`:"
      ],
      "metadata": {
        "id": "F73slUmQgpmM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bert_model_name = \"bert-base-cased\"\n",
        "xlmr_model_name = \"xlm-roberta-base\"\n",
        "\n",
        "bert_tokenizer = AutoTokenizer.from_pretrained(bert_model_name)\n",
        "xlmr_tokenizer = AutoTokenizer.from_pretrained(xlmr_model_name)"
      ],
      "metadata": {
        "id": "bBnVP4BthVwG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "By encoding a small sequence of text we can also retrieve the special tokens that each model used during\n",
        "pretraining:"
      ],
      "metadata": {
        "id": "R6pe8Y-9h9zR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Jack Sparrow loves New York!\"\n",
        "bert_tokens = bert_tokenizer(text).tokens()\n",
        "xmlr_tokens = xlmr_tokenizer(text).tokens()"
      ],
      "metadata": {
        "id": "cb72SFjYh-Wy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame([bert_tokens, xmlr_tokens], [\"BERT\", \"XLM-R\"])\n",
        "display_df(df, header=None)"
      ],
      "metadata": {
        "id": "b0bR5QFPihUL",
        "outputId": "7e0c6f80-dd96-416d-d97f-da0f2ca05aa1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>BERT</th>\n",
              "      <td>[CLS]</td>\n",
              "      <td>Jack</td>\n",
              "      <td>Spa</td>\n",
              "      <td>##rrow</td>\n",
              "      <td>loves</td>\n",
              "      <td>New</td>\n",
              "      <td>York</td>\n",
              "      <td>!</td>\n",
              "      <td>[SEP]</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>XLM-R</th>\n",
              "      <td>&lt;s&gt;</td>\n",
              "      <td>▁Jack</td>\n",
              "      <td>▁Spar</td>\n",
              "      <td>row</td>\n",
              "      <td>▁love</td>\n",
              "      <td>s</td>\n",
              "      <td>▁New</td>\n",
              "      <td>▁York</td>\n",
              "      <td>!</td>\n",
              "      <td>&lt;/s&gt;</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we see that instead of the `[CLS]` and `[SEP]` tokens that BERT uses for sentence classification tasks, XLMR\n",
        "uses `<s>` and `<\\s>` to denote the start and end of a sequence.\n",
        "\n",
        "Another special feature of SentencePiece is that it\n",
        "treats raw text as a sequence of Unicode characters, with whitespace given the Unicode symbol `U+2581` or `_`\n",
        "character. By assigning a special symbol for whitespace, SentencePiece is able to detokenize a sequence without\n",
        "ambiguities.\n",
        "\n",
        "We can see that WordPiece has lost the information that there is no whitespace\n",
        "between `York` and `!`. \n",
        "\n",
        "By contrast, SentencePiece preserves the whitespace in the tokenized text so we can\n",
        "convert back to the raw text without ambiguity:"
      ],
      "metadata": {
        "id": "TXYeixbkmWtR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\".join(xmlr_tokens).replace(\"▁\", \" \")"
      ],
      "metadata": {
        "id": "9CQx2E3KogOp",
        "outputId": "23e58015-9c47-4214-8452-639690d0bcf2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'<s> Jack Sparrow loves New York!</s>'"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Transformers Model Class Anatomy"
      ],
      "metadata": {
        "id": "YZAB5-xBpLbW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Transformers library is organized around dedicated classes for each\n",
        "architecture and task:\n",
        "\n",
        "* Sequence classification\n",
        "* Extractive question answering\n",
        "* Language modeling\n",
        "* Named entity recognition\n",
        "* Summarization\n",
        "* Translation\n",
        "\n",
        "and the associated classes are named according to a `ModelNameForTask` convention. Most of the time, we load\n",
        "these models using the `ModelNameForTask.from_pretrained` function and since the architecture can\n",
        "usually be guessed from the name alone (e.g. `bert-base-uncased`), Transformers provides a convenient set of AutoClasses to automatically load the relevant configuration, vocabulary, or weights. \n",
        "\n",
        "In practice, these\n",
        "`AutoClasses` are extremely useful because it means that we can switch to a completely different architecture in our\n",
        "experiments by simply changing the model name!"
      ],
      "metadata": {
        "id": "tcH6UomnpMYp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###XLM-R Model for Token Classification"
      ],
      "metadata": {
        "id": "GWfxlylE3kDk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The separation of bodies and heads allows us to build a custom head for any task and just mount it on top of a\n",
        "pretrained model!\n",
        "\n",
        "Let’s go through the exercise of building a a custom token classification head for `XLM-R`. Since\n",
        "`XLM-R` uses the same model architecture as `RoBERTa`, we will use `RoBERTa` as the base model, but augmented\n",
        "with settings specific to `XLM-R`.\n",
        "\n",
        "To get started we need a data structure that will represent our `XLM-R` NER tagger.\n",
        "\n",
        "As a first guess, we’ll need a\n",
        "configuration file to initialize the model and a `forward` function to generate the outputs. \n",
        "\n",
        "With these\n",
        "considerations, let’s go ahead and build our `XLM-R` class for token classification:\n",
        "\n"
      ],
      "metadata": {
        "id": "E7MGxxTu3k1g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class XLMRobertaForTokenClassification(RobertaPreTrainedModel):\n",
        "  config_class = XLMRobertaConfig\n",
        "\n",
        "  def __init__(self, config):\n",
        "    super().__init__(config)\n",
        "\n",
        "    self.num_labels = config.num_labels\n",
        "    # load model body\n",
        "    self.roberta = RobertaModel(config, add_pooling_layer=False)\n",
        "    # setup token classification head\n",
        "    self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
        "    self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
        "    # load and initialize weights\n",
        "    self.init_weights()\n",
        "\n",
        "  def forward(self, input_ids=None, attention_mask=None, token_type_ids=None, labels=None, **kwargs):\n",
        "    pass"
      ],
      "metadata": {
        "id": "-Xvbo5WJ5NqW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The only thing left to do is to define what the model should do in a forward pass. \n",
        "\n",
        "We define the following behavior\n",
        "in the `forward` function:"
      ],
      "metadata": {
        "id": "3F-Q4TN569jw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def forward(self, input_ids=None, attention_mask=None, token_type_ids=None, labels=None, **kwargs):\n",
        "    # use model body to get encoder representations\n",
        "    outputs = self.roberta(input_ids, attention_mask=attention_mask, token_type_ids=token_type_ids, **kwargs)\n",
        "    # apply classifier to encoder representation\n",
        "    sequence_output = self.dropout(outputs[0])\n",
        "    logits = self.classifier(sequence_output)\n",
        "    # calculate losses\n",
        "    loss = None\n",
        "    if labels is not None:\n",
        "      loss_fct = nn.CrossEntropyLoss()\n",
        "      loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
        "    # return model output object\n",
        "    return TokenClassifierOutput(loss=loss, logits=logits, hidden_states=outputs.hidden_states, attentions=outputs.attentions)"
      ],
      "metadata": {
        "id": "bki-ZBrT7ADZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The only thing left to do is updating the placeholder function in the model class with our freshly baked functions:"
      ],
      "metadata": {
        "id": "WKjiyvpR-tDK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "XLMRobertaForTokenClassification.forward = forward"
      ],
      "metadata": {
        "id": "3hNc1kXl-tjQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Loading a Custom Model"
      ],
      "metadata": {
        "id": "BUGOTkK4-_Sr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we are ready to load our token classification model. Here we need to provide some additional information\n",
        "beyond the model name, including the tags that we will use to label each entity and the mapping of each tag to an\n",
        "ID and vice versa. \n",
        "\n",
        "All of this information can be derived from our `tags` variable, which as a `ClassLabel` object has a names attribute that we can use to derive the mapping:"
      ],
      "metadata": {
        "id": "5zbJR9in_AIQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index2tag = {idx: tag for idx, tag in enumerate(tags.names)}\n",
        "tag2index = {tag: idx for idx, tag in enumerate(tags.names)}"
      ],
      "metadata": {
        "id": "9hXn9EtEAkug"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "With this information and the `ClassLabel.num_classes` attribute, we can load the XLM-R configuration for\n",
        "NER as follows:"
      ],
      "metadata": {
        "id": "sjprBBb1BAnf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xlmr_config = AutoConfig.from_pretrained(xlmr_model_name, \n",
        "                                         num_labels=tags.num_classes,\n",
        "                                         id2label=index2tag,\n",
        "                                         label2id=tag2index)"
      ],
      "metadata": {
        "id": "rvKAne9DBCvn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we can load the model weights as usual with the `from_pretrained ` function. \n",
        "\n",
        "Note that we did not\n",
        "implement this ourselves; we get this for free by inheriting from `RobertaPreTrainedModel`:"
      ],
      "metadata": {
        "id": "ajxqMh7LBkM6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "xlmr_model = (XLMRobertaForTokenClassification.from_pretrained(xlmr_model_name, config=xlmr_config).to(device))"
      ],
      "metadata": {
        "id": "TVwMjixjBpQq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As a sanity check that we have initialized the tokenizer and model correctly.\n",
        "\n",
        "Let’s test the predictions on our small\n",
        "sequence of known entities:"
      ],
      "metadata": {
        "id": "zuvCBz2AC66z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = xlmr_tokenizer.encode(text, return_tensors=\"pt\")\n",
        "\n",
        "df = pd.DataFrame([xmlr_tokens, input_ids[0].numpy()], [\"Tokens\", \"Inpud IDs\"])\n",
        "display_df(df, header=None)"
      ],
      "metadata": {
        "id": "KlUM0c6YC9JI",
        "outputId": "a3bc9b0f-fc30-43d6-d0a2-319161d2cbcf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Tokens</th>\n",
              "      <td>&lt;s&gt;</td>\n",
              "      <td>▁Jack</td>\n",
              "      <td>▁Spar</td>\n",
              "      <td>row</td>\n",
              "      <td>▁love</td>\n",
              "      <td>s</td>\n",
              "      <td>▁New</td>\n",
              "      <td>▁York</td>\n",
              "      <td>!</td>\n",
              "      <td>&lt;/s&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Inpud IDs</th>\n",
              "      <td>0</td>\n",
              "      <td>21763</td>\n",
              "      <td>37456</td>\n",
              "      <td>15555</td>\n",
              "      <td>5161</td>\n",
              "      <td>7</td>\n",
              "      <td>2356</td>\n",
              "      <td>5753</td>\n",
              "      <td>38</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see, the start `<s>` and end `</s>` tokens are given the IDs 0 and 2 respectively. \n",
        "\n",
        "For reference we can\n",
        "find the mappings of the other special characters via the `all_special_ids` and `all_special_tokens`\n",
        "attributes of `xlmr_tokenizer`:"
      ],
      "metadata": {
        "id": "dwuYRyLWERev"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame([xlmr_tokenizer.all_special_tokens, xlmr_tokenizer.all_special_ids], index=[\"Special Token\", \"Special Token ID\"])\n",
        "display_df(df, header=None)"
      ],
      "metadata": {
        "id": "MhCVg7nJEWpj",
        "outputId": "3bda1045-444e-446d-a2b8-d769aa54cf32",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Special Token</th>\n",
              "      <td>&lt;s&gt;</td>\n",
              "      <td>&lt;/s&gt;</td>\n",
              "      <td>&lt;unk&gt;</td>\n",
              "      <td>&lt;pad&gt;</td>\n",
              "      <td>&lt;mask&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Special Token ID</th>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>250001</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we need to pass the inputs to the model and extract the predictions by taking the `argmax` to get the most\n",
        "likely class per token:"
      ],
      "metadata": {
        "id": "Gnv3_gzfE9J2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "outputs = xlmr_model(input_ids.to(device)).logits\n",
        "predictions = torch.argmax(outputs, dim=1)\n",
        "\n",
        "print(f\"Number of tokens in sequence: {len(xmlr_tokens)}\")\n",
        "print(f\"Shape of outputs: {outputs.shape}\")"
      ],
      "metadata": {
        "id": "eWVZpoEmE_DB",
        "outputId": "39cab604-73dc-41a2-d590-2e15518f5dd7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of tokens in sequence: 10\n",
            "Shape of outputs: torch.Size([1, 10, 7])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we see that the logits have the shape `[batch_size, num_tokens, num_tags]`, with each token\n",
        "given a logit among the 7 possible NER tags. \n",
        "\n",
        "By enumerating over the sequence, we can quickly see what the\n",
        "pretrained model predicts:"
      ],
      "metadata": {
        "id": "O4O1-7kQF0US"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tags.names"
      ],
      "metadata": {
        "id": "Av6JB_VHErV_",
        "outputId": "52b6492c-4197-47d6-f0d7-1ffc9f7bc3ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC']"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions[0].cpu().numpy()"
      ],
      "metadata": {
        "id": "Ofg3oc83EvAq",
        "outputId": "fd7260cc-ea48-4413-ac4d-e768faaebdbe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 6, 0, 3, 8, 9, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#preds = [tags.names[p] for p in predictions[0].cpu().numpy()]\n",
        "#df = pd.DataFrame([xmlr_tokens, preds], [\"Tokens\", \"Tags\"])\n",
        "#display_df(df, header=None)"
      ],
      "metadata": {
        "id": "N3JyfzDQF3Wp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "```log\n",
        "IndexError: list index out of range\n",
        "```"
      ],
      "metadata": {
        "id": "54fqA0TTHYfv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Unsurprisingly, our token classification layer with random weights leaves a lot to be desired; let’s fine-tune on\n",
        "some labeled data to make it better! \n",
        "\n",
        "Before doing so, let’s wrap the above steps into a helper function for later use:"
      ],
      "metadata": {
        "id": "-HH1MxCrE6lp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tag_text(text, tags, model, tokenizer):\n",
        "  # get tokens with special characters\n",
        "  tokens = tokenizer.tokenize(tokenizer.decode(tokenizer.encode(text)))\n",
        "  # encode the sequence into IDs\n",
        "  inputs = tokenizer.encode(text, return_tensors=\"pt\").to(device)\n",
        "  # get predictions as distribution over 7 possible classes\n",
        "  outputs = model(inputs)[0]\n",
        "  # take argmax to get most likely class per token\n",
        "  predictions = torch.argmax(outputs, dim=2)\n",
        "  # convert to DataFrame\n",
        "  preds = [tags.names[p] for p in predictions[0].cpu().numpy()]\n",
        "  df = pd.DataFrame([tokens, preds], [\"Tokens\", \"Tags\"])\n",
        "  display_df(df, header=None)"
      ],
      "metadata": {
        "id": "v8cYt6wNE7r1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tag_text(text, tags, xlmr_model, xlmr_tokenizer)"
      ],
      "metadata": {
        "id": "fFDXR4JsHDQ9",
        "outputId": "c51acb5b-4ecf-4065-db8b-1efa1837f811",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Tokens</th>\n",
              "      <td>&lt;s&gt;</td>\n",
              "      <td>▁Jack</td>\n",
              "      <td>▁Spar</td>\n",
              "      <td>row</td>\n",
              "      <td>▁love</td>\n",
              "      <td>s</td>\n",
              "      <td>▁New</td>\n",
              "      <td>▁York</td>\n",
              "      <td>!</td>\n",
              "      <td>&lt;/s&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Tags</th>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Tokenizing and Encoding the Texts"
      ],
      "metadata": {
        "id": "7sII77smHm1v"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our next step is to tokenize\n",
        "the whole dataset so that we can pass it to the XLM-R model for fine-tuning.\n",
        "\n",
        "As we know, Datasets provides a fast way to tokenize a Dataset object with the `Dataset.map` operation. \n",
        "\n",
        "To achieve this, recall that\n",
        "we first need to define a function with the minimal signature.\n",
        "\n",
        "```python\n",
        "function(examples: Dict[str, List]) -> Dict[str, List]\n",
        "```\n",
        "\n",
        "where examples is equivalent to a slice of a Dataset, e.g. `panx_de['train'][:10]`.\n",
        "\n",
        "Since the XLM-R\n",
        "tokenizer returns the input IDs for the model’s inputs, we just need to augment this information with the attention\n",
        "mask and the label IDs that encode the information about which token is associated with each NER tag.\n",
        "\n",
        "let’s look at how this works with our single\n",
        "German example by first collecting the words and tags as ordinary lists:"
      ],
      "metadata": {
        "id": "WbzRqQTKHnrU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "words, labels = de_example[\"tokens\"], de_example[\"ner_tags\"]"
      ],
      "metadata": {
        "id": "XhOeh_jrKUHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we tokenize each word and use the `is_split_words` argument to tell the tokenizer that our input\n",
        "sequence has already been split into words:"
      ],
      "metadata": {
        "id": "werQ0SgZKhNz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_input = xlmr_tokenizer(de_example[\"tokens\"], is_split_into_words=True)\n",
        "tokens = xlmr_tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\n",
        "df = pd.DataFrame([tokens], [\"Tokens\"])\n",
        "display_df(df, header=None)"
      ],
      "metadata": {
        "id": "TZDi_4L8KjJ4",
        "outputId": "e1ab949a-0f2d-438b-f1e0-9e65c90d74d1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Tokens</th>\n",
              "      <td>&lt;s&gt;</td>\n",
              "      <td>▁2.000</td>\n",
              "      <td>▁Einwohner</td>\n",
              "      <td>n</td>\n",
              "      <td>▁an</td>\n",
              "      <td>▁der</td>\n",
              "      <td>▁Dan</td>\n",
              "      <td>...</td>\n",
              "      <td>schaft</td>\n",
              "      <td>▁Po</td>\n",
              "      <td>mmer</td>\n",
              "      <td>n</td>\n",
              "      <td>▁</td>\n",
              "      <td>.</td>\n",
              "      <td>&lt;/s&gt;</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this example we can see that the tokenizer has split “Einwohnern” into two subwords \"Einwohner” and “n”.\n",
        "Since we’re following the convention that only “_Einwohner” should be associated with the `_B-LOC` label.\n",
        "\n",
        "we need a way to mask the subword representations after the first\n",
        "subword. Fortunately, `tokenized_input` is a class that contains a `word_ids` function that can help us\n",
        "achieve this:"
      ],
      "metadata": {
        "id": "BRG3Gfr2LjJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_ids = tokenized_input.word_ids()\n",
        "df = pd.DataFrame([tokens, word_ids], [\"Tokens\", \"Word IDs\"])\n",
        "display_df(df, header=None)"
      ],
      "metadata": {
        "id": "xd5Sf3tfLsHD",
        "outputId": "105be4e7-800f-4ba4-aff1-ab5deeca6dd7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Tokens</th>\n",
              "      <td>&lt;s&gt;</td>\n",
              "      <td>▁2.000</td>\n",
              "      <td>▁Einwohner</td>\n",
              "      <td>n</td>\n",
              "      <td>▁an</td>\n",
              "      <td>▁der</td>\n",
              "      <td>▁Dan</td>\n",
              "      <td>...</td>\n",
              "      <td>schaft</td>\n",
              "      <td>▁Po</td>\n",
              "      <td>mmer</td>\n",
              "      <td>n</td>\n",
              "      <td>▁</td>\n",
              "      <td>.</td>\n",
              "      <td>&lt;/s&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Word IDs</th>\n",
              "      <td>None</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s set `-100` as the label for these special tokens and the subwords we wish to mask during training:"
      ],
      "metadata": {
        "id": "zIetSIkwMJmd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "previous_word_idx = None,\n",
        "label_ids = []\n",
        "\n",
        "for word_idx in word_ids:\n",
        "  if word_idx is None or word_idx == previous_word_idx:\n",
        "    label_ids.append(-100)\n",
        "  elif word_idx !=previous_word_idx:\n",
        "    label_ids.append(labels[word_idx])\n",
        "  previous_word_idx = word_idx\n",
        "\n",
        "labels = [index2tag[label] if label != -100 else \"IGN\" for label in label_ids]\n",
        "df_index = [\"Tokens\", \"Word IDs\", \"Label IDs\", \"Labels\"]\n",
        "df = pd.DataFrame([tokens, word_ids, label_ids, labels], index=df_index)\n",
        "display_df(df, header=None)"
      ],
      "metadata": {
        "id": "0C2eMbHRMJDx",
        "outputId": "891310d4-b965-47c9-f281-b79d66d468da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Tokens</th>\n",
              "      <td>&lt;s&gt;</td>\n",
              "      <td>▁2.000</td>\n",
              "      <td>▁Einwohner</td>\n",
              "      <td>n</td>\n",
              "      <td>▁an</td>\n",
              "      <td>▁der</td>\n",
              "      <td>▁Dan</td>\n",
              "      <td>...</td>\n",
              "      <td>schaft</td>\n",
              "      <td>▁Po</td>\n",
              "      <td>mmer</td>\n",
              "      <td>n</td>\n",
              "      <td>▁</td>\n",
              "      <td>.</td>\n",
              "      <td>&lt;/s&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Word IDs</th>\n",
              "      <td>None</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>9</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>10</td>\n",
              "      <td>11</td>\n",
              "      <td>11</td>\n",
              "      <td>None</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Label IDs</th>\n",
              "      <td>-100</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>-100</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>...</td>\n",
              "      <td>-100</td>\n",
              "      <td>6</td>\n",
              "      <td>-100</td>\n",
              "      <td>-100</td>\n",
              "      <td>0</td>\n",
              "      <td>-100</td>\n",
              "      <td>-100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Labels</th>\n",
              "      <td>IGN</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>IGN</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>B-LOC</td>\n",
              "      <td>...</td>\n",
              "      <td>IGN</td>\n",
              "      <td>I-LOC</td>\n",
              "      <td>IGN</td>\n",
              "      <td>IGN</td>\n",
              "      <td>O</td>\n",
              "      <td>IGN</td>\n",
              "      <td>IGN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ">Why did we choose -100 as the ID to mask subword representations? The reason is that in PyTorch the cross entropy loss class\n",
        "`torch.nn.CrossEntropyLoss` has an attribute called ignore_index whose value is -100. This index is ignored during training\n",
        "and so we can use it to ignore the tokens associated with consecutive subwords.\n",
        "\n",
        "So let’s scale this out to the whole dataset\n",
        "by defining a single function that wraps all the logic:"
      ],
      "metadata": {
        "id": "DqlmdxbtOC1-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_and_align_labels(examples):\n",
        "  tokenized_inputs = xlmr_tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n",
        "  labels = []\n",
        "  for idx, label in enumerate(examples[\"ner_tags\"]):\n",
        "    word_ids = tokenized_inputs.word_ids(batch_index=idx)\n",
        "    previous_word_idx = None\n",
        "    label_ids = []\n",
        "    for word_idx in  word_ids:\n",
        "      if word_idx is None or word_idx == previous_word_idx:\n",
        "        label_ids.append(-100)\n",
        "      else:\n",
        "        label_ids.append(label[word_idx])\n",
        "      previous_word_idx = word_idx\n",
        "    labels.append(label_ids)\n",
        "  tokenized_inputs[\"labels\"] = labels\n",
        "  return tokenized_inputs"
      ],
      "metadata": {
        "id": "VOWJ7WwhOMQe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next let’s verify whether our function works as expected on a single training example:"
      ],
      "metadata": {
        "id": "2fwSfe-4QUkz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "single_sample = panx_de[\"train\"].select(range(1))\n",
        "single_sample_encoded = single_sample.map(tokenize_and_align_labels, batched=True)"
      ],
      "metadata": {
        "id": "W5_2I11LQU8_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "First, we should be able to decode the training example from the `input_ids`:"
      ],
      "metadata": {
        "id": "-yu9QM37Qzlr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\" \".join(token for token in single_sample[0][\"tokens\"]))\n",
        "print(xlmr_tokenizer.decode(single_sample_encoded[\"input_ids\"][0]))"
      ],
      "metadata": {
        "id": "8CCDnLiXQ1Zg",
        "outputId": "0bf3f7ba-0534-4f79-d0d8-c58620bd8679",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.000 Einwohnern an der Danziger Bucht in der polnischen Woiwodschaft Pommern .\n",
            "<s> 2.000 Einwohnern an der Danziger Bucht in der polnischen Woiwodschaft Pommern.</s>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Good, the decoded output from the tokenizer makes sense and we can see the appearance of the special tokens\n",
        "`<s>` and `</s>` for the start and end of the sentence. \n",
        "\n",
        "Next let’s check that the label IDs are implemented correctly\n",
        "by filtering out the padding label IDs and mapping back from ID to tag:"
      ],
      "metadata": {
        "id": "zYNmIHfoRcyF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "original_labels = single_sample[\"ner_tags_str\"][0]\n",
        "reconstructed_labels = [index2tag[idx] for idx in single_sample_encoded[\"labels\"][0] if idx != -100]\n",
        "\n",
        "df = pd.DataFrame([original_labels, reconstructed_labels], [\"Original Labels\", \"Reconstructed Labels\"])\n",
        "display_df(df, header=None)"
      ],
      "metadata": {
        "id": "20HNeF30RgTT",
        "outputId": "540ffab7-9900-47e7-980c-1d9f2bcc23eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Original Labels</th>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>B-LOC</td>\n",
              "      <td>I-LOC</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>B-LOC</td>\n",
              "      <td>B-LOC</td>\n",
              "      <td>I-LOC</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Reconstructed Labels</th>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>B-LOC</td>\n",
              "      <td>I-LOC</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>B-LOC</td>\n",
              "      <td>B-LOC</td>\n",
              "      <td>I-LOC</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now have all the ingredients we need to encode each split, so let’s write a function we can iterate over:"
      ],
      "metadata": {
        "id": "3PS_DhXWSKAD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def encode_panx_dataset(corpus):\n",
        "  return corpus.map(tokenize_and_align_labels, batched=True, remove_columns=[\"langs\", \"ner_tags\", \"tokens\"])"
      ],
      "metadata": {
        "id": "hlanjvHVSKbW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "By applying this function to a `DatasetDict` object, we get an encoded `Dataset` object per split. \n",
        "\n",
        "Let’s use this\n",
        "to encode our German corpus:"
      ],
      "metadata": {
        "id": "abMFWrnGSjWE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "panx_de_encoded = encode_panx_dataset(panx_ch[\"de\"])\n",
        "panx_de_encoded[\"train\"]"
      ],
      "metadata": {
        "id": "9pjL_yksSnTf",
        "outputId": "ac11cd69-35a0-4896-b0fe-ea417f11b5c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173,
          "referenced_widgets": [
            "2d12ca22390445308f217c454cd893a0",
            "af99a139fcf545d7b612aca14bfd0346",
            "8d3de88dd0e242d69b802234471bf6af",
            "bcabab9608b0424aa6b9026195b9d8c6",
            "d5ad3d8ac43142658408243a1fe1c37a",
            "6f941fb6524d4f4489ff7174f66f240e",
            "25b785411c3646fd8206cfde359f1564",
            "82ba9c7ed338488ea2950d033c5b6e6a",
            "6bd629e1b1a742829d3355a955e42c16",
            "d444cb00c7f74a6b98f93f0b238ee7e0",
            "4a3b4e0f9f684a1da38dd6c2f1641ae5"
          ]
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2d12ca22390445308f217c454cd893a0",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/7 [00:00<?, ?ba/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/xtreme/PAN-X.de-data_dir=data/1.0.0/2fc6b63c5326cc0d1f73060649612889b3a7ed8a6605c91cecdbd228a7158b17/cache-169a2d04705e6978.arrow\n",
            "Loading cached processed dataset at /root/.cache/huggingface/datasets/xtreme/PAN-X.de-data_dir=data/1.0.0/2fc6b63c5326cc0d1f73060649612889b3a7ed8a6605c91cecdbd228a7158b17/cache-bdd91157450b0191.arrow\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['input_ids', 'attention_mask', 'labels'],\n",
              "    num_rows: 12580\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Performance Measures"
      ],
      "metadata": {
        "id": "XjCgrp1QTDcs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluating a NER model is similar to evaluating a text classification model,\n",
        "and it is common to report results for precision, recall, and F -score. The\n",
        "only subtlety is that all words of an entity need to be predicted correctly in\n",
        "order for a prediction to be counted as correct.\n",
        "\n",
        "Fortunately, there is a nifty\n",
        "library called [seqeval](https://github.com/chakki-works/seqeval) that is designed for these kinds of tasks.\n",
        "\n",
        "For example,\n",
        "given some placeholder NER tags and model predictions, we can compute\n",
        "the metrics via seqeval’s `classification_report()` function:\n",
        "\n"
      ],
      "metadata": {
        "id": "qOj76QIRTEU0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_true = [\n",
        "   [\"O\", \"O\", \"O\", \"B-MISC\", \"I-MISC\", \"I-MISC\", \"O\"],\n",
        "   [\"B-PER\", \"I-PER\", \"O\"]       \n",
        "]\n",
        "\n",
        "y_pred = [\n",
        "   [\"O\", \"O\", \"B-MISC\", \"I-MISC\", \"I-MISC\", \"I-MISC\", \"O\"],\n",
        "   [\"B-PER\", \"I-PER\", \"O\"]\n",
        "]\n",
        "\n",
        "print(classification_report(y_true, y_pred))"
      ],
      "metadata": {
        "id": "V1oeWKt8eOw5",
        "outputId": "6c64c306-f665-4afa-8201-73178464f136",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        MISC       0.00      0.00      0.00         1\n",
            "         PER       1.00      1.00      1.00         1\n",
            "\n",
            "   micro avg       0.50      0.50      0.50         2\n",
            "   macro avg       0.50      0.50      0.50         2\n",
            "weighted avg       0.50      0.50      0.50         2\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To integrate these metrics during training, we need a function that can\n",
        "take the outputs of the model and convert them into the lists that seqeval\n",
        "expects. \n",
        "\n",
        "The following does the trick by ensuring we ignore the label IDs\n",
        "associated with subsequent subwords:"
      ],
      "metadata": {
        "id": "-HfwpKeJgSKj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def align_predictions(predictions, label_ids):\n",
        "  preds = np.argmax(predictions, axis=2)\n",
        "  batch_size, seq_len = preds.shape\n",
        "  labels_list, preds_list = [], []\n",
        "\n",
        "  for batch_idx in range(batch_size):\n",
        "    example_labels, example_preds = [], []\n",
        "    for seq_idx in range(seq_len):\n",
        "      # Ignore label IDs = -100\n",
        "      if label_ids[batch_idx, seq_idx] != -100:\n",
        "        example_labels.append(index2tag[label_ids[batch_idx][seq_idx]])\n",
        "        example_preds.append(index2tag[preds[batch_idx][seq_idx]])\n",
        "    \n",
        "    labels_list.append(example_labels)\n",
        "    preds_list.append(example_preds)\n",
        "  return preds_list, labels_list"
      ],
      "metadata": {
        "id": "hYevEnw-gTp3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Equipped with a performance metric, we can move on to actually training the\n",
        "model."
      ],
      "metadata": {
        "id": "UNnrmQOYjW2y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Fine-Tuning XLM-RoBERTa"
      ],
      "metadata": {
        "id": "oQPncaaQjXd4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our first strategy\n",
        "will be to fine-tune our base model on the German subset of PAN-X and then\n",
        "evaluate its zero-shot cross-lingual performance on French, Italian, and\n",
        "English. \n",
        "\n",
        "As usual, we’ll use the Transformers `Trainer` to handle our training loop, so first we need to define the training attributes using the\n",
        "`TrainingArguments` class:"
      ],
      "metadata": {
        "id": "1Bp0TCK2jq4G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_epochs = 3\n",
        "batch_size = 24\n",
        "logging_steps = len(panx_de_encoded[\"train\"]) // batch_size\n",
        "model_name = f\"{xlmr_model_name}-finetuned-panx-de\"\n",
        "\n",
        "training_args = TrainingArguments(output_dir=model_name,\n",
        "                                  log_level=\"error\",\n",
        "                                  num_train_epochs=num_epochs,\n",
        "                                  per_device_train_batch_size=batch_size,\n",
        "                                  per_device_eval_batch_size=batch_size,\n",
        "                                  evaluation_strategy=\"epoch\",\n",
        "                                  save_steps=1e6, weight_decay=0.01,\n",
        "                                  disable_tqdm=False, logging_steps=logging_steps)"
      ],
      "metadata": {
        "id": "H8PptOzHkIal"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We also need to tell the Trainer how to compute metrics on the validation set, so here we can use the\n",
        "`align_predictions` function that we defined earlier to extract the predictions and labels in the format needed\n",
        "by `seqeval` to calculate the `F1-score`:"
      ],
      "metadata": {
        "id": "iU9Murp0lqTf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(eval_pred):\n",
        "  y_pred, y_true = align_predictions(eval_pred.predictions, eval_pred.label_ids)\n",
        "  return {\"f1\": f1_score(y_true, y_pred)}"
      ],
      "metadata": {
        "id": "l4X7tZkClz5O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The final step is to define a data collator so we can pad each input sequence\n",
        "to the largest sequence length in a batch. \n",
        "\n",
        "Transformers provides a\n",
        "dedicated data collator for token classification that will pad the labels along\n",
        "with the inputs:"
      ],
      "metadata": {
        "id": "-rGhLKNAqGet"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data_collator = DataCollatorForTokenClassification(xlmr_tokenizer)"
      ],
      "metadata": {
        "id": "xUfP9ohkqIFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Padding the labels is necessary because, unlike in a text classification task,\n",
        "the labels are also sequences.\n",
        "\n",
        "We will train several models, so we’ll avoid\n",
        "initializing a new model for every Trainer by creating a model_init()\n",
        "method."
      ],
      "metadata": {
        "id": "GS0luz3OtVrn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def model_init():\n",
        "  return (XLMRobertaForTokenClassification.from_pretrained(xlmr_model_name, config=xlmr_config).to(device))"
      ],
      "metadata": {
        "id": "-fdsxQzPtmSW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s pass all this information together with the encoded encoded datasets to the Trainer:"
      ],
      "metadata": {
        "id": "PAJqiLiBruE2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(model_init=model_init,\n",
        "                  args=training_args,\n",
        "                  data_collator=data_collator,\n",
        "                  compute_metrics=compute_metrics,\n",
        "                  train_dataset=panx_de_encoded[\"train\"],\n",
        "                  eval_dataset=panx_de_encoded[\"validation\"],\n",
        "                  tokenizer=xlmr_tokenizer)"
      ],
      "metadata": {
        "id": "BD3mVNihru5M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "and then run the training loop as follows:"
      ],
      "metadata": {
        "id": "koqcnE3WuxyG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.train()"
      ],
      "metadata": {
        "id": "MtiipOrGuySM",
        "outputId": "06bb381e-be89-4fd6-c27f-26d0a325e664",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use thePyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1575' max='1575' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1575/1575 16:01, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.257000</td>\n",
              "      <td>0.151203</td>\n",
              "      <td>0.830240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.130500</td>\n",
              "      <td>0.140132</td>\n",
              "      <td>0.844654</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.081700</td>\n",
              "      <td>0.135171</td>\n",
              "      <td>0.859126</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1575, training_loss=0.15635196265720186, metrics={'train_runtime': 962.5189, 'train_samples_per_second': 39.21, 'train_steps_per_second': 1.636, 'total_flos': 862655119377480.0, 'train_loss': 0.15635196265720186, 'epoch': 3.0})"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame(trainer.state.log_history)[[\"epoch\", \"loss\", \"eval_loss\", \"eval_f1\"]]\n",
        "df = df.rename(columns={\"epoch\": \"Epoch\", \"loss\": \"Training Loss\", \"eval_loss\": \"Validation Loss\", \"eval_f1\": \"F1\"})\n",
        "\n",
        "df[\"Epoch\"] = df[\"Epoch\"].apply(lambda x: round(x))\n",
        "df[\"Training Loss\"] = df[\"Training Loss\"].ffill()\n",
        "df[[\"Validation Loss\", \"F1\"]] = df[[\"Validation Loss\", \"F1\"]].bfill().ffill()\n",
        "df.drop_duplicates()"
      ],
      "metadata": {
        "id": "hYfbx2GrvjaS",
        "outputId": "0d164a38-cd3d-4053-cf9b-00cf90bd4d06",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-a56abd5d-2c08-4d71-b4e7-d9756508ff3d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0.2570</td>\n",
              "      <td>0.151203</td>\n",
              "      <td>0.830240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.1305</td>\n",
              "      <td>0.140132</td>\n",
              "      <td>0.844654</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>0.0817</td>\n",
              "      <td>0.135171</td>\n",
              "      <td>0.859126</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a56abd5d-2c08-4d71-b4e7-d9756508ff3d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a56abd5d-2c08-4d71-b4e7-d9756508ff3d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a56abd5d-2c08-4d71-b4e7-d9756508ff3d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   Epoch  Training Loss  Validation Loss        F1\n",
              "0      1         0.2570         0.151203  0.830240\n",
              "2      2         0.1305         0.140132  0.844654\n",
              "4      3         0.0817         0.135171  0.859126"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "These F1 scores are quite good for a NER model."
      ],
      "metadata": {
        "id": "zP6GiNDNvqHh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To confirm that our model\n",
        "works as expected, let’s test it on the German translation of our simple\n",
        "example:"
      ],
      "metadata": {
        "id": "caQt8HHdvNVW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_de = \"Jeff Dean ist ein Informatiker bei Google in Kalifornien\"\n",
        "tag_text(text_de, tags, trainer.model, xlmr_tokenizer)"
      ],
      "metadata": {
        "id": "J9KSTCjkvN--",
        "outputId": "bce7df2e-2570-4f95-f57f-8d0b4afa6e33",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Tokens</th>\n",
              "      <td>&lt;s&gt;</td>\n",
              "      <td>▁Jeff</td>\n",
              "      <td>▁De</td>\n",
              "      <td>an</td>\n",
              "      <td>▁ist</td>\n",
              "      <td>▁ein</td>\n",
              "      <td>▁Informati</td>\n",
              "      <td>ker</td>\n",
              "      <td>▁bei</td>\n",
              "      <td>▁Google</td>\n",
              "      <td>▁in</td>\n",
              "      <td>▁Kaliforni</td>\n",
              "      <td>en</td>\n",
              "      <td>&lt;/s&gt;</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Tags</th>\n",
              "      <td>O</td>\n",
              "      <td>B-PER</td>\n",
              "      <td>I-PER</td>\n",
              "      <td>I-PER</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>O</td>\n",
              "      <td>B-ORG</td>\n",
              "      <td>O</td>\n",
              "      <td>B-LOC</td>\n",
              "      <td>I-LOC</td>\n",
              "      <td>O</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It works! But we should never get too confident about performance based on\n",
        "a single example. Instead, we should conduct a proper and thorough\n",
        "investigation of the model’s errors."
      ],
      "metadata": {
        "id": "_zuOX_-NyEBh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Error Analysis"
      ],
      "metadata": {
        "id": "zilYbC1NyTc5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A thorough error analysis of your model is one of the most important aspects\n",
        "when training and debugging transformers (and machine learning models in\n",
        "general). There are several failure modes where it might look like the model\n",
        "is performing well, while in practice it has some serious flaws.\n",
        "\n",
        "Examples\n",
        "where training can fail include:\n",
        "\n",
        "* We might accidentally mask too many tokens and also mask some of\n",
        "our labels to get a really promising loss drop.\n",
        "* The `compute_metrics()` function might have a bug that\n",
        "overestimates the true performance.\n",
        "* We might include the zero class or O entity in NER as a normal\n",
        "class, which will heavily skew the accuracy and F -score since it is\n",
        "the majority class by a large margin.\n",
        "\n",
        "When the model performs much worse than expected, looking at the errors\n",
        "can yield useful insights and reveal bugs that would be hard to spot by just\n",
        "looking at the code. And even if the model performs well and there are no\n",
        "bugs in the code, error analysis is still a useful tool to understand the model’s\n",
        "strengths and weaknesses. \n",
        "\n",
        "These are aspects we always need to keep in mind\n",
        "when we deploy a model in a production environment.\n",
        "\n",
        "Let’s define a method that we can apply to the validation set:"
      ],
      "metadata": {
        "id": "J6JNF2AOyaI8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def forward_pass_with_label(batch):\n",
        "  # Convert dict of lists to list of dicts suitable for data collator\n",
        "  features = [dict(zip(batch, t)) for t in zip(*batch.values())]\n",
        "  # Pad inputs and labels and put all tensors on device\n",
        "  batch = data_collator(features)\n",
        "  input_ids = batch[\"input_ids\"].to(device)\n",
        "  attention_mask = batch[\"attention_mask\"].to(device)\n",
        "  labels = batch[\"labels\"].to(device)\n",
        "\n",
        "  with torch.no_grad():\n",
        "    # Pass data through model\n",
        "    output = trainer.model(input_ids, attention_mask)\n",
        "    # Logit.size: [batch_size, sequence_length, classes]\n",
        "    # Predict class with largest logit value on classes axis\n",
        "    predicted_label = torch.argmax(output.logits, axis=-1).cpu().numpy()\n",
        "  \n",
        "  # Calculate loss per token after flattening batch dimension with view\n",
        "  loss = cross_entropy(output.logits.view(-1, 7), labels.view(-1), reduction=\"none\")\n",
        "  # Unflatten batch dimension and convert to numpy array\n",
        "  loss = loss.view(len(input_ids), -1).cpu().numpy()\n",
        "\n",
        "  return {\"loss\": loss, \"predicted_label\": predicted_label}"
      ],
      "metadata": {
        "id": "vx7Rn6nKqoBn"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now apply this function to the whole validation set using `map()` and\n",
        "load all the data into a DataFrame for further analysis:"
      ],
      "metadata": {
        "id": "ok4TJ4r6t-u0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "valid_set = panx_de_encoded[\"validation\"]\n",
        "valid_set = valid_set.map(forward_pass_with_label, batched=True, batch_size=32)\n",
        "\n",
        "df = valid_set.to_pandas()"
      ],
      "metadata": {
        "id": "C7oc7bZeuAqB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The tokens and the labels are still encoded with their IDs, so let’s map the\n",
        "tokens and labels back to strings to make it easier to read the results. For the\n",
        "padding tokens with label –100 we assign a special label, IGN, so we can\n",
        "filter them later."
      ],
      "metadata": {
        "id": "Lbs7_W11uT7W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "index2tag[-100] = \"IGN\"\n",
        "\n",
        "df[\"input_tokens\"] = df[\"input_ids\"].apply(lambda x: xlmr_tokenizer.convert_ids_to_tokens(x))\n",
        "df[\"predicted_label\"] = df[\"predicted_label\"].apply(lambda x: [index2tag[i] for i in x])\n",
        "df[\"labels\"] = df[\"labels\"].apply(lambda x: [index2tag[i] for i in x])\n",
        "\n",
        "df[\"loss\"] = df.apply(lambda x: x[\"loss\"][:len(x[\"input_ids\"])], axis=1)\n",
        "df[\"predicted_label\"] = df.apply(lambda x: x[\"predicted_label\"][:len(x[\"input_ids\"])], axis=1)\n",
        "\n",
        "df.head(1)"
      ],
      "metadata": {
        "id": "Z57-vejNuhZQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s have a look at the tokens individually by unpacking these\n",
        "lists. The `pandas.Series.explode()` function allows us to do exactly that\n",
        "in one line by creating a row for each element in the original rows list. \n",
        "\n",
        "Since\n",
        "all the lists in one row have the same length, we can do this in parallel for all\n",
        "columns. We also drop the padding tokens we named IGN, since their loss is\n",
        "zero anyway. \n",
        "\n",
        "Finally, we cast the losses, which are still `numpy.Array`\n",
        "objects, to standard floats:"
      ],
      "metadata": {
        "id": "QD8xRhqJyVk7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_tokens = df.apply(pd.Series.explode)\n",
        "df_tokens = df_tokens.query(\"labels != 'IGN'\")\n",
        "df_tokens[\"loss\"] = df_tokens[\"loss\"].astype(float).round(2)\n",
        "df_tokens.head(7)"
      ],
      "metadata": {
        "id": "CWweLTyHyafQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "With the data in this shape, we can now group it by the input tokens and\n",
        "aggregate the losses for each token with the count, mean, and sum. \n",
        "\n",
        "Finally,\n",
        "we sort the aggregated data by the sum of the losses and see which tokens\n",
        "have accumulated the most loss in the validation set:"
      ],
      "metadata": {
        "id": "Kt2q0RSDzF45"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(\n",
        "    df_tokens.groupby(\"input_tokens\")[[\"loss\"]]\n",
        "             .agg([\"count\", \"mean\", \"sum\"])\n",
        "             .droplevel(level=0, axis=1)  # Get rid of multi-level columns\n",
        "             .sort_values(by=\"sum\", ascending=False)\n",
        "             .reset_index()\n",
        "             .round(2)\n",
        "             .head(10)\n",
        "             .T\n",
        ")"
      ],
      "metadata": {
        "id": "CmTe5tuJzHTy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can observe several patterns in this list:\n",
        "* The whitespace token has the highest total loss, which is not\n",
        "surprising since it is also the most common token in the list.\n",
        "However, its mean loss is much lower than the other tokens in the\n",
        "list. This means that the model doesn’t struggle to classify it.\n",
        "* Words like “in”, “von”, “der”, and “und” appear relatively\n",
        "frequently. They often appear together with named entities and are\n",
        "sometimes part of them, which explains why the model might mix\n",
        "them up.\n",
        "* Parentheses, slashes, and capital letters at the beginning of words\n",
        "are rarer but have a relatively high average loss. We will investigate\n",
        "them further.\n",
        "* At the end of list we see some subwords that appear rarely but have a very high average loss. \n",
        "\n",
        "For example\n",
        "`_West` shows that these tokens appear in almost any class, and thus pose a classification challenge to the\n",
        "model:\n"
      ],
      "metadata": {
        "id": "M7-11piE0mvz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_tokens.query(\"input_tokens == '_West'\")[\"labels\"].value_counts()"
      ],
      "metadata": {
        "id": "knzwBFS13JUt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also group the label IDs and look at the losses for each class:"
      ],
      "metadata": {
        "id": "KAfbPEkE3Jl5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(\n",
        "    df_tokens.groupby(\"labels\")[[\"loss\"]]\n",
        "             .agg([\"count\", \"mean\", \"sum\"])\n",
        "             .droplevel(level=0, axis=1)  # Get rid of multi-level columns\n",
        "             .sort_values(by=\"mean\", ascending=False)\n",
        "             .reset_index()\n",
        "             .round(2)\n",
        "             .head(10)\n",
        "             .T\n",
        ")"
      ],
      "metadata": {
        "id": "cHgvGKCG0nI_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see that B - ORG has the highest average loss, which means that determining\n",
        "the beginning of an organization poses a challenge to our model.\n",
        "\n"
      ],
      "metadata": {
        "id": "ax6zOs0s071X"
      }
    }
  ]
}