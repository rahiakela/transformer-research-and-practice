{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02-text-classification-using-fine-tuning.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMGo001pgutwrk/znALaFmz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/transformers-research-and-practice/blob/main/natural-language-processing-with-transformers/02-text-classification/02_text_classification_using_fine_tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Text Classification using Fine-tuning"
      ],
      "metadata": {
        "id": "PfCJmxSiZ8Bd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Text classification is one of the most common tasks in NLP and can be used for applications\n",
        "such as tagging customer feedback into categories or routing support tickets according to their\n",
        "language. Chances are that your email’s spam filter is using text classification to protect your\n",
        "inbox from a deluge of unwanted junk!\n",
        "\n",
        "Another common type of text classification is sentiment analysis, which aims to identify the\n",
        "polarity of a given text.\n",
        "\n",
        "Now imagine that you are a data scientist who needs to build a system that can automatically\n",
        "identify emotional states such as “anger” or “joy” that people express towards your company’s\n",
        "product on Twitter. \n",
        "\n",
        "Until 2018, the deep learning approach to this problem typically involved\n",
        "finding a suitable neural architecture for the task and training it from scratch on a dataset of\n",
        "labeled tweets. This approach suffered from three major drawbacks:\n",
        "\n",
        "- You needed a lot of labeled data to train accurate models like recurrent or\n",
        "convolutional neural networks.\n",
        "- Training these models from scratch was time consuming and expensive.\n",
        "- The trained model could not be easily adapted to a new task, e.g. with a different set of labels.\n",
        "\n",
        "Nowadays, these limitations are largely overcome via transfer learning, where typically a\n",
        "Transformer-based architecture is pretrained on a generic task such as language modeling and\n",
        "then reused for a wide variety of downstream tasks."
      ],
      "metadata": {
        "id": "0O5UwNeIZ8op"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Setup"
      ],
      "metadata": {
        "id": "NmjXzjlJaZVE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install transformers[sentencepiece]\n",
        "!pip -q install datasets"
      ],
      "metadata": {
        "id": "TbIsiaFwaaky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install umap-learn"
      ],
      "metadata": {
        "id": "KuO4afypo7-T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "from transformers import set_seed\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import AutoModel\n",
        "from transformers import AutoModelForSequenceClassification\n",
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "from datasets import list_datasets, load_dataset\n",
        "\n",
        "import torch\n",
        "from torch.nn.functional import cross_entropy\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.dummy import DummyClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score, f1_score, plot_confusion_matrix, confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import umap.umap_ as umap\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "Kl_TTiiIaeLG"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "3wiDc664MCDa"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##The Dataset"
      ],
      "metadata": {
        "id": "FE-e_1EIaa1F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To build our emotion detector we’ll use a great dataset from an article that explored how\n",
        "emotions are represented in English Twitter messages. \n",
        "\n",
        "Unlike most sentiment analysis datasets\n",
        "that involve just “positive” and “negative” polarities, this dataset contains six basic emotions:\n",
        "anger, disgust, fear, joy, sadness, and surprise. \n",
        "\n",
        "\n",
        "Given a tweet, our task will be to train a model\n",
        "that can classify it into one of these emotions!"
      ],
      "metadata": {
        "id": "8-2ciOUGayjC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Overview of Datasets"
      ],
      "metadata": {
        "id": "s1hPKMSVhT_J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We can use the list_datasets function to see what datasets are available in the Hub:\n",
        "datasets = list_datasets()\n",
        "\n",
        "print(f\"There are {len(datasets)} datasets currently available on the Hub.\")\n",
        "print(f\"The first 10 are: {datasets[:10]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjvtlOmQbdG0",
        "outputId": "ed9ec72b-6f1c-4621-aa12-55c63b04edbc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 3316 datasets currently available on the Hub.\n",
            "The first 10 are: ['assin', 'ar_res_reviews', 'ambig_qa', 'bianet', 'ag_news', 'ajgt_twitter_ar', 'aeslc', 'bc2gm_corpus', 'air_dialogue', 'acronym_identification']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see that each dataset is given a name, so let’s inspect the metadata associated with the\n",
        "emotion dataset:"
      ],
      "metadata": {
        "id": "Ns2dh4xdbyIm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metadata = list_datasets(with_details=True)[datasets.index(\"emotion\")]\n",
        "\n",
        "# Show dataset description\n",
        "print(\"Description:\", metadata.description, \"\\n\")\n",
        "# Show first 8 lines of the citation string\n",
        "print(\"Citation:\", \"\\n\".join(metadata.citation.split(\"\\n\")[:8]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WE2INspybyz1",
        "outputId": "29cd89b2-37dc-4232-c5af-caf4151e1522"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Description: Emotion is a dataset of English Twitter messages with six basic emotions: anger, fear, joy, love, sadness, and surprise. For more detailed information please refer to the paper. \n",
            "\n",
            "Citation: @inproceedings{saravia-etal-2018-carer,\n",
            "    title = \"{CARER}: Contextualized Affect Representations for Emotion Recognition\",\n",
            "    author = \"Saravia, Elvis  and\n",
            "      Liu, Hsien-Chi Toby  and\n",
            "      Huang, Yen-Hao  and\n",
            "      Wu, Junlin  and\n",
            "      Chen, Yi-Shin\",\n",
            "    booktitle = \"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing\",\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This looks like the dataset we’re after, so next we can load it with the `load_dataset` function from Datasets:"
      ],
      "metadata": {
        "id": "TFwzYC8Zdm-P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "emotions = load_dataset(\"emotion\")"
      ],
      "metadata": {
        "id": "pPaEqtbZdoj4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZ1KLuRdeQnh",
        "outputId": "427acb5d-2dd2-4e53-9017-48d885397c88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 16000\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 2000\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 2000\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "we see it is similar to a Python dictionary, with each key corresponding to a different split. \n",
        "\n",
        "And just like any dictionary, we can access an individual split as usual"
      ],
      "metadata": {
        "id": "SGOtUtiMebHD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = emotions[\"train\"]\n",
        "train_ds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDGm5pQledFm",
        "outputId": "ebb79aa5-13bd-49d8-a140-7e2d3f92e471"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text', 'label'],\n",
              "    num_rows: 16000\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This object behaves like an\n",
        "ordinary Python container, so we can query its length"
      ],
      "metadata": {
        "id": "leozYrtJeqo6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvDZesbXerQ0",
        "outputId": "b8c28757-7fdf-47da-895d-8f29898eb35a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16000"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "or access a single example by its index"
      ],
      "metadata": {
        "id": "RECvP-DqexU5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ev1O0vYSexxU",
        "outputId": "c90495f2-4f08-483a-9061-3d0819414488"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'label': 0, 'text': 'i didnt feel humiliated'}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we see that a single row is represented as a\n",
        "dictionary, where the keys correspond to the column names"
      ],
      "metadata": {
        "id": "xfD3nZkbe7n1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds.column_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xR7VRirHe8Qj",
        "outputId": "609aa76c-42dc-400c-9c97-a9124069469f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['text', 'label']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This reflects the fact that Datasets is\n",
        "based on Apache Arrow, which defines a typed columnar format that is more memory efficient\n",
        "than native Python. \n",
        "\n",
        "We can see what data types are being used under the hood by accessing the\n",
        "features attribute of a Dataset object:"
      ],
      "metadata": {
        "id": "zOGbQFIrfGyD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds.features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXFN6Y1MfKuf",
        "outputId": "718dfe4a-9f8f-4cb3-a5c3-dc81a7e061e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'label': ClassLabel(num_classes=6, names=['sadness', 'joy', 'love', 'anger', 'fear', 'surprise'], names_file=None, id=None),\n",
              " 'text': Value(dtype='string', id=None)}"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also access several rows with a slice"
      ],
      "metadata": {
        "id": "3fpWX3D1fayp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds[:6]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ji3TnXWfZl3",
        "outputId": "3089fd4c-9c33-4198-bebf-9caec7f6542f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'label': [0, 0, 3, 2, 3, 0],\n",
              " 'text': ['i didnt feel humiliated',\n",
              "  'i can go from feeling so hopeless to so damned hopeful just from being around someone who cares and is awake',\n",
              "  'im grabbing a minute to post i feel greedy wrong',\n",
              "  'i am ever feeling nostalgic about the fireplace i will know that it is still on the property',\n",
              "  'i am feeling grouchy',\n",
              "  'ive been feeling a little burdened lately wasnt sure why that was']}"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "or get the full column by name"
      ],
      "metadata": {
        "id": "r7Urq-NifloZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds[\"text\"][:6]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47yK6jLAfmN4",
        "outputId": "16103e09-73cb-4f70-edb7-d2a29ac82935"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i didnt feel humiliated',\n",
              " 'i can go from feeling so hopeless to so damned hopeful just from being around someone who cares and is awake',\n",
              " 'im grabbing a minute to post i feel greedy wrong',\n",
              " 'i am ever feeling nostalgic about the fireplace i will know that it is still on the property',\n",
              " 'i am feeling grouchy',\n",
              " 'ive been feeling a little burdened lately wasnt sure why that was']"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In each case the resulting data structure depends on the type of query; although this may feel\n",
        "strange at first, it’s part of the secret sauce that makes Datasets so flexible!"
      ],
      "metadata": {
        "id": "pqLCZbrwf3Eb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###From Datasets to DataFrames"
      ],
      "metadata": {
        "id": "P5m7jqyif3ug"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Although Datasets provides a lot of low-level functionality to slice and dice our data, it is often\n",
        "convenient to convert a Dataset object to a Pandas DataFrame so we can access highlevel\n",
        "APIs for data visualization. \n",
        "\n",
        "To enable the conversion, Datasets provides a\n",
        "`Dataset.set_format` function that allow us to change the output format of the Dataset.\n",
        "\n",
        "This does not change the underlying data format which is Apache Arrow and you can switch to\n",
        "another format later if needed:"
      ],
      "metadata": {
        "id": "xqyQ0Xhsf6OL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "emotions.set_format(type=\"pandas\")\n",
        "\n",
        "df = emotions[\"train\"][:]\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "aDDPc_8AgTBQ",
        "outputId": "5eae34fc-7464-4c73-fc8d-63130558e5e9"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-4723e743-2ffc-43e0-a25e-701c6ba8378a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i didnt feel humiliated</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>i can go from feeling so hopeless to so damned...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i am feeling grouchy</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4723e743-2ffc-43e0-a25e-701c6ba8378a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4723e743-2ffc-43e0-a25e-701c6ba8378a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4723e743-2ffc-43e0-a25e-701c6ba8378a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                text  label\n",
              "0                            i didnt feel humiliated      0\n",
              "1  i can go from feeling so hopeless to so damned...      0\n",
              "2   im grabbing a minute to post i feel greedy wrong      3\n",
              "3  i am ever feeling nostalgic about the fireplac...      2\n",
              "4                               i am feeling grouchy      3"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see, the column headers have been preserved and the first few rows match our\n",
        "previous views of the data. \n",
        "\n",
        "However, the labels are represented as integers so let’s use the\n",
        "`ClassLabel.int2str` function to create a new column in our DataFrame with the\n",
        "corresponding label names:"
      ],
      "metadata": {
        "id": "wxNAZtVOhvUa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def label_int2str(row, split):\n",
        "  return emotions[split].features[\"label\"].int2str(row)"
      ],
      "metadata": {
        "id": "_UienA5Chx-U"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"label_name\"] = df[\"label\"].apply(label_int2str, split=\"train\")\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "nQ3XTyNlh_jE",
        "outputId": "4a83b40e-bb90-4685-d19c-ef81ab63bb91"
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-cd0f20c2-7953-4fdb-993f-f8ab83b6548e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>label_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i didnt feel humiliated</td>\n",
              "      <td>0</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>i can go from feeling so hopeless to so damned...</td>\n",
              "      <td>0</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
              "      <td>3</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
              "      <td>2</td>\n",
              "      <td>love</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i am feeling grouchy</td>\n",
              "      <td>3</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-cd0f20c2-7953-4fdb-993f-f8ab83b6548e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-cd0f20c2-7953-4fdb-993f-f8ab83b6548e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-cd0f20c2-7953-4fdb-993f-f8ab83b6548e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                text  label label_name\n",
              "0                            i didnt feel humiliated      0    sadness\n",
              "1  i can go from feeling so hopeless to so damned...      0    sadness\n",
              "2   im grabbing a minute to post i feel greedy wrong      3      anger\n",
              "3  i am ever feeling nostalgic about the fireplac...      2       love\n",
              "4                               i am feeling grouchy      3      anger"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Look at the Class Distribution"
      ],
      "metadata": {
        "id": "cvyIeZcLkGNW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Whenever you are working on text classification problems, it is a good idea to examine the\n",
        "distribution of examples among each class. \n",
        "\n",
        "For example, a dataset with a skewed class\n",
        "distribution might require a different treatment in terms of the training loss and evaluation\n",
        "metrics than a balanced one.\n",
        "\n",
        "With Pandas and the visualisation library Matplotlib we can quickly visualize this as follows:"
      ],
      "metadata": {
        "id": "TL6_McSRkG8H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"label_name\"].value_counts(ascending=True).plot.barh()\n",
        "plt.title(\"Category Counts\");"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "NrrK740UkwXQ",
        "outputId": "917e4349-cce2-4e38-c4ff-a3fbb87c49cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that the dataset is heavily imbalanced; the joy and sadness classes appear\n",
        "frequently whereas love and sadness are about 5-10 times rarer.\n",
        "\n",
        "There are several ways to\n",
        "deal with imbalanced data such as resampling the minority or majority classes.\n",
        "\n",
        "Alternatively, we can also weight the loss function to account for the underrepresented classes."
      ],
      "metadata": {
        "id": "zrzFOJU1lah_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###How Long Are Our Tweets?"
      ],
      "metadata": {
        "id": "8XYTrTFoloGX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transformer models have a maximum input sequence length that is referred to as the maximum context size. \n",
        "\n",
        "For most applications with BERT, the maximum context size is 512 tokens, where\n",
        "a token is defined by the choice of tokenizer and can be a word, subword, or character. \n",
        "\n",
        "Let’s make a rough estimate of our tweet lengths per emotion by looking at the distribution of words per tweet:"
      ],
      "metadata": {
        "id": "c-ay6PU2lo6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Words Per Tweet\"] = df[\"text\"].str.split().apply(len)\n",
        "\n",
        "df.boxplot(\"Words Per Tweet\", by=\"label_name\", grid=False, showfliers=False, color=\"red\", )\n",
        "plt.suptitle(\"\")\n",
        "plt.xlabel(\"\");"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 335
        },
        "id": "hCjuEu9Tl_nS",
        "outputId": "37cb3067-4b9a-41be-8ed4-1727dce55af1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/matplotlib/cbook/__init__.py:1376: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
            "  X = np.atleast_1d(X.T if isinstance(X, np.ndarray) else np.asarray(X))\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the plot we see that for each emotion, most tweets are around 15 words long and the\n",
        "longest tweets are well below BERT’s maximum context size of 512 tokens. \n",
        "\n",
        "Texts that are\n",
        "longer than a model’s context window need to be truncated, which can lead to a loss in\n",
        "performance if the truncated text contains crucial information. \n",
        "\n",
        "Let’s now figure out how we can\n",
        "convert these raw texts into a format suitable for Transformers!\n",
        "\n",
        "Now let’s also reset the output\n",
        "format of our dataset since we don’t need the DataFrame format anymore:"
      ],
      "metadata": {
        "id": "K7OzrHh-m6_Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "emotions.reset_format()"
      ],
      "metadata": {
        "id": "fgbD_xA2tTAN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Tokenization"
      ],
      "metadata": {
        "id": "AcJYRsUunEVs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transformer models like BERT cannot receive raw strings as input; instead they assume the\n",
        "text has been tokenized into numerical vectors. Tokenization is the step of breaking down a\n",
        "string into the atomic units used in the model. \n",
        "\n",
        "There are several tokenization strategies one can\n",
        "adopt and the optimal splitting of words in sub-units is usually learned from the corpus.\n",
        "\n",
        "Before\n",
        "looking at the tokenizer used for BERT, let’s motivate it by looking at two extreme cases:\n",
        "character and word tokenizers."
      ],
      "metadata": {
        "id": "95kJmltPnHwi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Character Tokenization"
      ],
      "metadata": {
        "id": "6BbVhz19xukw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The simplest tokenization scheme is to feed each character individually to the model. \n",
        "\n",
        "In Python, str objects are really arrays under the hood which allows us to quickly implement character-level tokenization with just one line of code:"
      ],
      "metadata": {
        "id": "p0ubSXmKxvWh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Tokenizing text is a core task of NLP.\"\n",
        "tokenized_text = list(text)\n",
        "print(tokenized_text)"
      ],
      "metadata": {
        "id": "zMNBTepTyE2X",
        "outputId": "43732f9c-16c4-4b8c-be21-9c21c622541b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['T', 'o', 'k', 'e', 'n', 'i', 'z', 'i', 'n', 'g', ' ', 't', 'e', 'x', 't', ' ', 'i', 's', ' ', 'a', ' ', 'c', 'o', 'r', 'e', ' ', 't', 'a', 's', 'k', ' ', 'o', 'f', ' ', 'N', 'L', 'P', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a good start but we are not yet done because our model expects each character to be\n",
        "converted to an integer, a process called numericalization. \n",
        "\n",
        "One simple way to do this is by\n",
        "encoding each unique token (which are characters in this case) with a unique integer:"
      ],
      "metadata": {
        "id": "E3QhW_TK5sST"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "token2idx = {}\n",
        "for idx, unique_char in enumerate(set(tokenized_text)):\n",
        "  token2idx[unique_char] = idx\n",
        "\n",
        "print(token2idx)"
      ],
      "metadata": {
        "id": "ZBnWs2365xzo",
        "outputId": "029be5ab-260e-4015-f0de-a086f8e7d1f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'t': 0, 'o': 1, 'e': 2, 'T': 3, 'c': 4, 'L': 5, '.': 6, 's': 7, 'f': 8, 'z': 9, 'i': 10, 'x': 11, 'g': 12, 'k': 13, 'r': 14, ' ': 15, 'a': 16, 'P': 17, 'N': 18, 'n': 19}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token2idx[\"e\"]"
      ],
      "metadata": {
        "id": "7tZ4JOXB6uVf",
        "outputId": "fd881f55-5ea9-4336-f533-0686c7af88d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token2idx[\"c\"]"
      ],
      "metadata": {
        "id": "0KJjBdLR60SX",
        "outputId": "d076fbcf-2adb-4b32-a17e-22a1000234aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This gives us a mapping from each character in our vocabulary to a unique integer, so we can\n",
        "now use token2idx to transform the tokenized text to a list of integers:"
      ],
      "metadata": {
        "id": "Tt92jUYE6XHd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = [token2idx[token] for token in tokenized_text]\n",
        "print(input_ids)"
      ],
      "metadata": {
        "id": "iggW90zK6YnO",
        "outputId": "31deaaed-a9e2-47c2-91bc-bfc5b822eb85",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[3, 1, 13, 2, 19, 10, 9, 10, 19, 12, 15, 0, 2, 11, 0, 15, 10, 7, 15, 16, 15, 4, 1, 14, 2, 15, 0, 16, 7, 13, 15, 1, 8, 15, 18, 5, 17, 6]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are almost done! Each token has been mapped to a unique, numerical identifier, hence the name `input_ids`.\n",
        "\n",
        "The last step is to convert `input_ids` into a 2d tensor of one-hot vectors\n",
        "which are better suited for neural networks than the categorical representation of `input_ids`.\n",
        "\n",
        "The reason for this is that the elements of `input_ids` create an ordinal scale, so adding or subtracting two IDs is a meaningless operation since the result in a new ID that represents another random token.\n",
        "\n",
        "On the other hand, the result of the adding two one-hot encodings can be\n",
        "easily interpreted: the two entries that are “hot” indicate that the corresponding two tokens cooccur.\n",
        "Each one-hot vector will have a length the size of the vocabulary and a “1” entry at the\n",
        "position of each ID, with zeros everywhere else.\n",
        "\n",
        "We can do this directly in PyTorch by converting `input_ids` to a `torch.Tensor`:"
      ],
      "metadata": {
        "id": "NxkX3miV7cLu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = torch.tensor(input_ids)\n",
        "\n",
        "one_hot_encodings = torch.nn.functional.one_hot(input_ids)\n",
        "one_hot_encodings.shape"
      ],
      "metadata": {
        "id": "c0bB4Ea78afY",
        "outputId": "a6f6a3b9-544c-45a8-ed24-8e5b9006988c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([38, 20])"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For each of the 38 input tokens we now have a one-hot vector of dimension 20 since our vocabularly consists of 20 unique characters.\n",
        "\n",
        "By examining the first vector, we can verify that a\n",
        "1 appears in the location indicated by `input_ids[0]`:"
      ],
      "metadata": {
        "id": "7Fnqc0Kc9Pay"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Token: {tokenized_text[0]}\")\n",
        "print(f\"Tensor index: {input_ids[0]}\")\n",
        "print(f\"One-hot vector: {one_hot_encodings[0]}\")"
      ],
      "metadata": {
        "id": "o0dQyrkB9TdW",
        "outputId": "47602578-50f9-4fa0-a7f7-f4319f8fc479",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token: T\n",
            "Tensor index: 3\n",
            "One-hot vector: tensor([0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Token: {tokenized_text[3]}\")\n",
        "print(f\"Tensor index: {input_ids[3]}\")\n",
        "print(f\"One-hot vector: {one_hot_encodings[3]}\")"
      ],
      "metadata": {
        "id": "wAwQ9t4f9w4v",
        "outputId": "4b0ba125-1aa1-44e8-ebd5-2d38e64d643a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token: e\n",
            "Tensor index: 2\n",
            "One-hot vector: tensor([0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From our simple example, we can see that character-level tokenization ignores any structure in the texts such as words and treats them just as streams of characters. Although this helps deal with misspellings and rare words, the main drawback is that linguistic structures such as words\n",
        "need to be learned, and that process requires significant compute and memory.\n",
        "\n",
        "For this reason, character tokenization is rarely used in practice. Instead, some structure of the text such as\n",
        "words is preserved during the tokenization step."
      ],
      "metadata": {
        "id": "pSUMdeBO_AOY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Word Tokenization"
      ],
      "metadata": {
        "id": "vwTX9OJk_MIf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instead of splitting the text into characters, we can split it into words and map each word to an\n",
        "integer. By using words from the outset, the model can skip the step of learning words from\n",
        "characters and thereby eliminate complexity from the training process.\n",
        "\n",
        "One simple class of word tokenizers uses whitespaces to tokenize the text. We can do this by\n",
        "applying Python’s split function directly on the raw text:"
      ],
      "metadata": {
        "id": "lRmigE9s_S7h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_text = text.split()\n",
        "print(tokenized_text)"
      ],
      "metadata": {
        "id": "XxSp1zecOKXv",
        "outputId": "b6c89dd6-cb79-4951-821e-45a13171a91c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Tokenizing', 'text', 'is', 'a', 'core', 'task', 'of', 'NLP.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "However, we can already see one potential problem with this\n",
        "tokenization scheme; punctuation is not accounted for, so NLP. is treated as a single token.\n",
        "Given that words can include declinations, conjugations, or misspellings, the size of the\n",
        "vocabulary can easily grow into the millions!\n",
        "\n",
        "Words that are not part of the vocabulary are classified as “unknown” and\n",
        "mapped to a shared UNK token. This means that we lose some potentially important information\n",
        "in the process of word tokenization since the model has no information about which words\n",
        "were associated with the UNK tokens.\n",
        "\n",
        "Wouldn’t it be nice if there was a compromise between character and word tokenization that\n",
        "preserves all input information and some of the input structure?"
      ],
      "metadata": {
        "id": "6r2xX0zrOrZ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Subword Tokenization"
      ],
      "metadata": {
        "id": "U4O6LxG5PZ4e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The idea behind subword tokenization is to take the best of both worlds from character and\n",
        "word tokenization. On one hand, we want to use characters since they allow the model to deal\n",
        "with rare character combinations and misspellings. On the other hand, we want to keep frequent\n",
        "words and word parts as unique entities.\n",
        "\n",
        "There are several subword tokenization algorithms such as Byte-Pair-Encoding, WordPiece,\n",
        "Unigram, and SentencePiece.\n",
        "\n",
        "The main distinguishing feature of subword tokenization (as well as word\n",
        "tokenization) is that it is learned from the corpus used for pretraining.\n"
      ],
      "metadata": {
        "id": "r5MbwQnWPcN4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Transformers library provides a convenient\n",
        "`from_pretrained` function that can be used to load both objects, either from the Hugging Face Model Hub or from a local path.\n",
        "\n",
        "Let’s get started by loading the tokenizer for the DistilBERT model."
      ],
      "metadata": {
        "id": "pjS47tMWSTjS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"distilbert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "u8Wank0tTsM1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can examine a few attributes of the tokenizer such as the vocabulary size:"
      ],
      "metadata": {
        "id": "TrCVX20XUG-e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.vocab_size"
      ],
      "metadata": {
        "id": "oH6fi04CUHa0",
        "outputId": "fcccf114-d9c2-4a54-aad5-e0c96a20f5a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30522"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also look at the special tokens used by the tokenizer, which differ from model to model.\n",
        "\n",
        "For example, BERT uses the `[MASK]` token for the primary objective of masked language\n",
        "modeling and the `[CLS]` and `[SEP]` tokens for the secondary pretraining objective of\n",
        "predicting if two sentences are consecutive:"
      ],
      "metadata": {
        "id": "pJrNRmAZUdkK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.special_tokens_map"
      ],
      "metadata": {
        "id": "sO837NxFUkvz",
        "outputId": "b3050ae1-77d1-4e4b-bf22-7de45941ac24",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'cls_token': '[CLS]',\n",
              " 'mask_token': '[MASK]',\n",
              " 'pad_token': '[PAD]',\n",
              " 'sep_token': '[SEP]',\n",
              " 'unk_token': '[UNK]'}"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Furthermore, the tokenizer stores the information of the corresponding model’s maximum\n",
        "context sizes:"
      ],
      "metadata": {
        "id": "eGt9oLXpUxeT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.model_max_length"
      ],
      "metadata": {
        "id": "1iFI3vCwUx8o",
        "outputId": "e87a01ce-cb64-47d2-e12a-2aaab59a6f4f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "512"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets examine how the encoding and decoding of strings works in practice by first encoding a\n",
        "test string:"
      ],
      "metadata": {
        "id": "rKsTAXGPU6lV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Tokenizing text is a core task of NLP.\"\n",
        "encoded_text = tokenizer(text)\n",
        "encoded_text"
      ],
      "metadata": {
        "id": "xDlB8n3HU7Bz",
        "outputId": "b949d626-0146-471b-87a8-ea0ee24c3c23",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [101, 19204, 6026, 3793, 2003, 1037, 4563, 4708, 1997, 17953, 2361, 1012, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have the\n",
        "`input_ids`, we can convert them back into tokens by using the tokenizer’s\n",
        "`convert_ids_to_tokens()` method:"
      ],
      "metadata": {
        "id": "Wy8DKKxyWXZH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokens = tokenizer.convert_ids_to_tokens(encoded_text.input_ids)\n",
        "print(tokens)"
      ],
      "metadata": {
        "id": "lR2x6uB5WaeQ",
        "outputId": "c87a4fb7-dabb-4f75-bc37-5250775d7182",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['[CLS]', 'token', '##izing', 'text', 'is', 'a', 'core', 'task', 'of', 'nl', '##p', '.', '[SEP]']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The AutoTokenizer class has a `convert_tokens_to_string()` method for\n",
        "remove the prefix etc., so let’s apply it to our tokens:"
      ],
      "metadata": {
        "id": "pc7PWTt8Wu_F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.convert_tokens_to_string(tokens))"
      ],
      "metadata": {
        "id": "gwaSgK8MW0z7",
        "outputId": "915231b1-3b72-4d55-87a4-7ad778b77605",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLS] tokenizing text is a core task of nlp. [SEP]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Tokenizing the Whole Dataset"
      ],
      "metadata": {
        "id": "8sPKGaA3yFdm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To tokenize the whole corpus, we'll use the `map()` method of our `DatasetDict` object. We'll encounter this method many times throughout this book, as it provides a convenient way to apply a processing function to each element in a dataset. As we'll soon see, the `map()` method can also be used to create new rows and columns.\n",
        "\n",
        "To get started, the first thing we need is a processing function to tokenize our examples with:"
      ],
      "metadata": {
        "id": "ptyo7kkgyIQU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(batch):\n",
        "  return tokenizer(batch[\"text\"], padding=True, truncation=True)"
      ],
      "metadata": {
        "id": "ygQ5EKEQrsDJ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function applies the tokenizer to a batch of examples; `padding=True` will pad the examples with zeros to the size of the longest one in a batch, and `truncation=True` will truncate the examples to the model's maximum context size. \n",
        "\n",
        "To see `tokenize()` in action, let's pass a batch of two examples from the training set:"
      ],
      "metadata": {
        "id": "UhuJoyTtsASM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenize(emotions[\"train\"][:2]))"
      ],
      "metadata": {
        "id": "YCHqR8RDsB-8",
        "outputId": "c23bb3d7-fb15-4fe5-94bd-34ba645c31fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': [[101, 1045, 2134, 2102, 2514, 26608, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1045, 2064, 2175, 2013, 3110, 2061, 20625, 2000, 2061, 9636, 17772, 2074, 2013, 2108, 2105, 2619, 2040, 14977, 1998, 2003, 8300, 102]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we can see the result of padding: the first element of `input_ids` is shorter than the second, so zeros have been added to that element to make them the same length. \n",
        "\n",
        "These zeros have a corresponding `[PAD]` token in the vocabulary, and the set of special tokens also includes the `[CLS]` and `[SEP]` tokens that we encountered earlier:"
      ],
      "metadata": {
        "id": "PKovGtKAuXLq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokens2ids = list(zip(tokenizer.all_special_tokens, tokenizer.all_special_ids))\n",
        "data = sorted(tokens2ids, key=lambda x: x[-1])\n",
        "df = pd.DataFrame(data, columns=[\"Special Token\", \"Special Token ID\"])\n",
        "df.T"
      ],
      "metadata": {
        "id": "AYvdR1ELuZCL",
        "outputId": "ccfecde5-1cb1-4daa-8186-4c9f7c585b9c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        }
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-3c4a32cc-9530-41fe-8b7e-43c1dac06945\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Special Token</th>\n",
              "      <td>[PAD]</td>\n",
              "      <td>[UNK]</td>\n",
              "      <td>[CLS]</td>\n",
              "      <td>[SEP]</td>\n",
              "      <td>[MASK]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Special Token ID</th>\n",
              "      <td>0</td>\n",
              "      <td>100</td>\n",
              "      <td>101</td>\n",
              "      <td>102</td>\n",
              "      <td>103</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3c4a32cc-9530-41fe-8b7e-43c1dac06945')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3c4a32cc-9530-41fe-8b7e-43c1dac06945 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3c4a32cc-9530-41fe-8b7e-43c1dac06945');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                      0      1      2      3       4\n",
              "Special Token     [PAD]  [UNK]  [CLS]  [SEP]  [MASK]\n",
              "Special Token ID      0    100    101    102     103"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Also note that in addition to returning the encoded tweets as `input_ids`, the tokenizer returns a list of `attention_mask` arrays. This is because we do not want the model to get confused by the additional padding tokens: the attention mask allows the model to ignore the padded parts of the input. It provides a visual explanation of how the input IDs and attention masks are padded.\n",
        "\n",
        "<img alt=\"attention-mask\" caption=\"For each batch, the input sequences are padded to the maximum sequence length in the batch; the attention mask is used in the model to ignore the padded areas of the input tensors\" src=\"https://github.com/rahiakela/transformers-research-and-practice/blob/main/natural-language-processing-with-transformers/02-text-classification/images/chapter02_attention-mask.png?raw=1\" id=\"attention-mask\"/> \n",
        "\n",
        "Once we've defined a processing function, we can apply it across all the splits in the corpus in a single line of code:"
      ],
      "metadata": {
        "id": "hSttLMuAvEqf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "emotions_encoded = emotions.map(tokenize, batched=True, batch_size=None)"
      ],
      "metadata": {
        "id": "prEOtcGO3O0-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "By default, the `map()` method operates individually on every example in the corpus, so setting `batched=True` will encode the tweets in batches. Because we've set `batch_size=None`, our `tokenize()` function will be applied on the full dataset as a single batch. \n",
        "\n",
        "This ensures that the input tensors and attention masks have the same shape globally, and we can see that this operation has added new `input_ids` and `attention_mask` columns to the dataset:"
      ],
      "metadata": {
        "id": "rL1pjzl83oKI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(emotions_encoded[\"train\"].column_names)"
      ],
      "metadata": {
        "id": "2hPf5SaI3qI5",
        "outputId": "1417cf6f-8279-4b47-d0f5-f776ed72a7c5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['text', 'label', 'input_ids', 'attention_mask']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> Note: Later, we'll see how _data collators_ can be used to dynamically pad the tensors in each batch. Padding globally will come in handy in the next section, where we extract a feature matrix from the whole corpus."
      ],
      "metadata": {
        "id": "2pMoYIKA35Ho"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Fine-tuning Transformers"
      ],
      "metadata": {
        "id": "O8-EPEmTXMQ5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As know, models like DistilBERT are pretrained to predict masked words in a sequence of text. However, we can't use these language models directly for text classification; we need to modify them slightly. To understand what modifications are necessary, let's take a look at the architecture of an encoder-based model like DistilBERT.\n",
        "\n",
        "<img src='https://github.com/rahiakela/transformers-research-and-practice/blob/main/natural-language-processing-with-transformers/02-text-classification/images/chapter02_encoder-classifier.png?raw=1'/>\n",
        "\n",
        "First, the text is tokenized and represented as one-hot vectors whose dimension is the size of\n",
        "the tokenizer vocabulary, usually consisting of 50k-100k unique tokens. \n",
        "\n",
        "Next, these token\n",
        "encodings are embedded in lower dimensions and passed through the encoder block layers to\n",
        "yield a hidden state for each input token. \n",
        "\n",
        "For the pretraining objective of language modeling,\n",
        "each hidden state is connected to a layer that predicts the token for the input token, which is\n",
        "only non-trivial if the input token was masked. \n",
        "\n",
        "For the classification task, we replace the\n",
        "language modeling layer with a classification layer. BERT sequences always start with a\n",
        "classification token `[CLS]`, therefore we use the hidden state for the classification token as\n",
        "input for our classification layer.\n",
        "\n",
        "We have two options to train such a model on our Twitter dataset:\n",
        "- **Feature extraction**\n",
        "  - We use the hidden states as features and just train a classifier on them.\n",
        "- **Fine-tuning**\n",
        "  - We train the whole model end-to-end, which also updates the parameters of the pretrained BERT model.\n",
        "\n",
        "In this section we explore both options for DistilBert and examine their trade-offs."
      ],
      "metadata": {
        "id": "zLPTXZ6OXM4r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s now explore what it takes to fine-tune a Transformer end-to-end. **With the fine-tuning approach we do not use the hidden states as fixed features**, but instead train them as shown.\n",
        "\n",
        "<img src='https://github.com/rahiakela/transformers-research-and-practice/blob/main/natural-language-processing-with-transformers/02-text-classification/images/5.png?raw=1' width='800'/>\n",
        "\n",
        "**This requires the classification head to be differentiable, which is why this method usually uses a neural network for classification**. \n",
        "\n",
        "Since we retrain all the DistilBERT parameters,\n",
        "this approach requires much more compute than the feature extraction approach and typically\n",
        "requires a GPU.\n",
        "\n",
        "Training the hidden states that serve as inputs to the classification model will help us avoid the problem of working with data that may not be well suited for the classification task. Instead, the initial hidden states adapt during training to decrease the model loss and thus increase its performance.\n",
        "\n",
        "We'll be using the `Trainer` API from image:images/logo.png[hf,13,13] Transformers to simplify the training loop. Let's look at the ingredients we need to set one up!"
      ],
      "metadata": {
        "id": "neMUtYZByrbQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Loading a Pretrained Model"
      ],
      "metadata": {
        "id": "LtEateZ0yq3W"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first thing we need is a pretrained `DistilBERT` model like the one we used in the featurebased approach. The only slight modification is that we use the\n",
        "`AutoModelForSequenceClassification` model instead of `AutoModel`. \n",
        "\n",
        "**The difference is that the `AutoModelForSequenceClassification` model has a\n",
        "classification head on top of the model outputs which can be easily trained with the base model**.\n",
        "\n",
        "We just need to specify how many labels the model has to predict (six in our case), since this dictates the number of outputs the classification head has:"
      ],
      "metadata": {
        "id": "TJhNcumVyrpC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_labels = 6\n",
        "\n",
        "model = (AutoModelForSequenceClassification.from_pretrained(model_name, num_labels=num_labels).to(device))"
      ],
      "metadata": {
        "id": "rV9B-TGB11I6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "You will probably see a warning that some parts of the models are randomly initialized. This is\n",
        "normal since the classification head has not yet been trained."
      ],
      "metadata": {
        "id": "aiSrnFjB2RDh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Define the Performance Metrics"
      ],
      "metadata": {
        "id": "09ZJGyMG3Km9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "To monitor metrics during training, we need to define a `compute_metrics()` function for the `Trainer`.  This function receives an `EvalPrediction` object (which is a named tuple with `predictions` and `label_ids` attributes) and needs to return a dictionary that maps each metric's name to its value. \n",
        "\n",
        "For our application, we'll compute the $F_1$-score and the accuracy of the model as follows:"
      ],
      "metadata": {
        "id": "7hZidsx23LeS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(pred):\n",
        "  labels = pred.label_ids\n",
        "  preds = pred.predictions.argmax(-1)\n",
        "  f1 = f1_score(labels, preds, average=\"weighted\")\n",
        "  acc = accuracy_score(labels, preds)\n",
        "\n",
        "  return {\"accuracy\": acc, \"f1\": f1}"
      ],
      "metadata": {
        "id": "WxiP1Ri33bMD"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Training the Model"
      ],
      "metadata": {
        "id": "640GkDBW4CLe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To define the training parameters, we use the `TrainingArguments` class. This class stores a lot of information and gives you fine-grained control over the training and evaluation. The most important argument to specify is `output_dir`, which is where all the artifacts from training are stored. \n",
        "\n",
        "Here is an example of `TrainingArguments` in all its glory:"
      ],
      "metadata": {
        "id": "hkaeesq-4DBF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "logging_steps = len(emotions_encoded[\"train\"]) // batch_size\n",
        "model_name = f\"{model_name}-finetuned-emotion\"\n",
        "training_args = TrainingArguments(output_dir=\"results\",\n",
        "                                  num_train_epochs=2,\n",
        "                                  learning_rate=2e-5,\n",
        "                                  per_device_train_batch_size=batch_size,\n",
        "                                  per_device_eval_batch_size=batch_size,\n",
        "                                  weight_decay=0.01,\n",
        "                                  evaluation_strategy=\"epoch\",\n",
        "                                  disable_tqdm=False,\n",
        "                                  logging_steps=logging_steps,\n",
        "                                  log_level=\"error\")"
      ],
      "metadata": {
        "id": "--VlMc924Tk0"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we also set the batch size, learning rate, and number of epochs, and specify to load the best model at the end of the training run. \n",
        "\n",
        "With this final ingredient, we can instantiate and fine-tune our model with the `Trainer`: "
      ],
      "metadata": {
        "id": "ut1v7LAq7b0p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(model=model, args=training_args,\n",
        "                  compute_metrics=compute_metrics,\n",
        "                  train_dataset=emotions_encoded[\"train\"],\n",
        "                  eval_dataset=emotions_encoded[\"validation\"],\n",
        "                  tokenizer=tokenizer)\n",
        "trainer.train();"
      ],
      "metadata": {
        "id": "1HyJNsTE7drI",
        "outputId": "d0052bf4-57c7-4e60-937d-3312b6216e2d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='500' max='500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [500/500 03:53, Epoch 2/2]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.859000</td>\n",
              "      <td>0.328427</td>\n",
              "      <td>0.902000</td>\n",
              "      <td>0.898507</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.256000</td>\n",
              "      <td>0.226478</td>\n",
              "      <td>0.921500</td>\n",
              "      <td>0.921977</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looking at the logs, we can see that our model has an $F_1$-score on the validation set of around 92% - this is a significant improvement over the feature-based approach!\n",
        "\n",
        "We can also see that\n",
        "the best model was saved by running the evaluate method:"
      ],
      "metadata": {
        "id": "1ipYE-C4WgDi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results = trainer.evaluate()"
      ],
      "metadata": {
        "id": "ob4C2hojWolO",
        "outputId": "8784b16e-0378-4803-f36d-6e9700b52622",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='32' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [32/32 00:04]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BLYJkoVEWu7i",
        "outputId": "20be5869-86b1-42a5-e7b4-e92f808643b5"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'epoch': 2.0,\n",
              " 'eval_accuracy': 0.9215,\n",
              " 'eval_f1': 0.92197668896163,\n",
              " 'eval_loss': 0.2264777570962906,\n",
              " 'eval_runtime': 4.7584,\n",
              " 'eval_samples_per_second': 420.311,\n",
              " 'eval_steps_per_second': 6.725}"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "We can take a more detailed look at the training metrics by calculating the confusion matrix. To visualize the confusion matrix, we first need to get the predictions on the validation set. The `predict()` method of the `Trainer` class returns several useful objects we can use for evaluation:"
      ],
      "metadata": {
        "id": "yl3dZ45d8K25"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preds_output = trainer.predict(emotions_encoded[\"validation\"])"
      ],
      "metadata": {
        "id": "xwLI0Xh08RnY",
        "outputId": "a8f8761f-c600-4614-99a5-a068aff65da9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='64' max='32' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [32/32 00:09]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The output of the `predict()` method is a `PredictionOutput` object that contains arrays of `predictions` and `label_ids`, along with the metrics we passed to the trainer. \n",
        "\n",
        "For example, the metrics on the validation set can be accessed as follows:"
      ],
      "metadata": {
        "id": "IOM7E8PWUsm4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preds_output.metrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7bZhGfMhUtBW",
        "outputId": "0a092c80-cd29-4a99-d4ac-90e66d2015ee"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'test_accuracy': 0.9215,\n",
              " 'test_f1': 0.92197668896163,\n",
              " 'test_loss': 0.2264777570962906,\n",
              " 'test_runtime': 4.8723,\n",
              " 'test_samples_per_second': 410.484,\n",
              " 'test_steps_per_second': 6.568}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It also contains the raw predictions for each class. We can decode the predictions greedily using `np.argmax()`. This yields the predicted labels and has the same format as the labels returned by the Scikit-Learn models in the feature-based approach:"
      ],
      "metadata": {
        "id": "aiqD4SaoU2Se"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_preds = np.argmax(preds_output.predictions, axis=1)"
      ],
      "metadata": {
        "id": "LqNGj1TYU3YB"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s have a more detailed look at the training metrics by calculating the confusion matrix."
      ],
      "metadata": {
        "id": "S8tiA-te8vDD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Visualize the Confusion Matrix"
      ],
      "metadata": {
        "id": "VJHzyNw78hBY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "With the predictions, we can plot the confusion matrix again:"
      ],
      "metadata": {
        "id": "bixI80Bf8iRd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_train = np.array(emotions_encoded[\"train\"][\"label\"])\n",
        "y_valid = np.array(emotions_encoded[\"validation\"][\"label\"])\n",
        "labels= emotions_encoded[\"train\"].features[\"label\"]\n",
        "labels.names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tNHOChZVWxI9",
        "outputId": "f6d80b80-5100-4363-cd89-d712c7449215"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['sadness', 'joy', 'love', 'anger', 'fear', 'surprise']"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_confusion_matrix(y_preds, y_true, labels):\n",
        "    cm = confusion_matrix(y_true, y_preds, normalize=\"true\")\n",
        "    fig, ax = plt.subplots(figsize=(6, 6))\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
        "    disp.plot(cmap=\"Blues\", values_format=\".2f\", ax=ax, colorbar=False)\n",
        "    plt.title(\"Normalized confusion matrix\")\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "C5rh2AsLb6Qs"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_confusion_matrix(y_preds, y_valid, labels.names)"
      ],
      "metadata": {
        "id": "AA8Qpz_qVZ13",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 404
        },
        "outputId": "89a1a644-64c4-47c4-9505-65de7fcf52d1"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is much closer to the ideal diagonal confusion matrix.  The `love` category is still often confused with `joy`, which seems natural. `surprise` is also frequently mistaken for `joy`, or confused with `fear`.\n",
        "\n",
        "Overall the performance of the model seems quite good, but before we call it a day, let's dive a little deeper into the types of errors our model is likely to make.\n",
        "\n",
        "Also, looking at the classification report reveals that the model is also performing much better\n",
        "for minority classes like surprise."
      ],
      "metadata": {
        "id": "M14ODYT6XGiY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(classification_report(y_valid, y_preds, target_names=labels.names))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m5XIpbaUXGqi",
        "outputId": "3e8c92bb-bf71-4f0d-d2b1-018809ca05c9"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     sadness       0.94      0.96      0.95       550\n",
            "         joy       0.96      0.92      0.94       704\n",
            "        love       0.79      0.89      0.84       178\n",
            "       anger       0.93      0.93      0.93       275\n",
            "        fear       0.86      0.90      0.88       212\n",
            "    surprise       0.88      0.79      0.83        81\n",
            "\n",
            "    accuracy                           0.92      2000\n",
            "   macro avg       0.89      0.90      0.90      2000\n",
            "weighted avg       0.92      0.92      0.92      2000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Making Predictions"
      ],
      "metadata": {
        "id": "UmCnELHqXX5Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also use the fine-tuned model to make predictions on new tweets. \n",
        "\n",
        "First, we need to\n",
        "tokenize the text, pass the tensor through the model, and extract the logits:"
      ],
      "metadata": {
        "id": "Lv75ZON8XZR9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "custom_tweet = \"i saw a movie today and it was really good.\"\n",
        "input_tensor = tokenizer.encode(custom_tweet, return_tensors=\"pt\").to(device)\n",
        "logits = model(input_tensor).logits"
      ],
      "metadata": {
        "id": "XdkMlZZ7dO00"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The model predictions are not normalized meaning that they are not a probability distribution\n",
        "but the raw outputs before the softmax layer:"
      ],
      "metadata": {
        "id": "P_57GKkldwXc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logits"
      ],
      "metadata": {
        "id": "_Gjpi-dFdvpY",
        "outputId": "8c6f095f-c839-4320-fa5a-27ef1d9c228c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.6723,  3.6753, -0.8213, -1.1042, -1.3242, -1.2927]],\n",
              "       device='cuda:0', grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can easily make the predictions a probability distribution by applying a softmax function to\n",
        "them. \n",
        "\n",
        "Since we have a batch size of 1, we can get rid of the first dimension and convert the\n",
        "tensor to a NumPy array for processing on the CPU:"
      ],
      "metadata": {
        "id": "jYmGg4Bid5k9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "softmax = torch.nn.Softmax(dim=1)\n",
        "probs = softmax(logits)[0]\n",
        "probs = probs.cpu().detach().numpy()"
      ],
      "metadata": {
        "id": "adaw2uXNd6v-"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "probs"
      ],
      "metadata": {
        "id": "iPpq9kFOf1aO",
        "outputId": "b17242d3-7346-44fb-9cf9-5f9db54bc03a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.01236612, 0.95585734, 0.01065474, 0.00802863, 0.00644343,\n",
              "       0.00664967], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we can plot the probability for each class in a bar plot. \n",
        "\n",
        "Clearly, the model estimates that\n",
        "the most likely class is joy, which appears to be reasonable given the tweet."
      ],
      "metadata": {
        "id": "rhj61Bfif6P1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labels"
      ],
      "metadata": {
        "id": "1TIsk6Ulgf4E",
        "outputId": "618a14c3-a2b2-435b-d785-0ae2bf9f574c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ClassLabel(num_classes=6, names=['sadness', 'joy', 'love', 'anger', 'fear', 'surprise'], names_file=None, id=None)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.bar(labels.names, 100 * probs, color=\"C0\")\n",
        "plt.title(f\"Prediction for : '{custom_tweet}'\")\n",
        "plt.ylabel(\"Class probability (%)\")"
      ],
      "metadata": {
        "id": "zYC4y1uTf7U7",
        "outputId": "9ba27d85-b762-4c27-c9b6-cff34e6c6ad6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0, 0.5, 'Class probability (%)')"
            ]
          },
          "metadata": {},
          "execution_count": 35
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Error Analysis"
      ],
      "metadata": {
        "id": "l4dnQOclgrmm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A simple, yet\n",
        "powerful tool is to sort the validation samples by the model loss. When passing the label during\n",
        "the forward pass, the loss is automatically calculated and returned. \n",
        "\n",
        "Below is a function that\n",
        "returns the loss along with the predicted label."
      ],
      "metadata": {
        "id": "qb6ZndErgsnd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def forward_pass_with_label(batch):\n",
        "  # Place all input tensors on the same device as the model\n",
        "  inputs = {k: v.to(device) for k, v in batch.items() if k in tokenizer.model_input_names}\n",
        "\n",
        "  with torch.no_grad():\n",
        "    output = model(**inputs)\n",
        "    pred_label = torch.argmax(output.logits, axis=-1)\n",
        "    loss = cross_entropy(output.logits, batch[\"label\"].to(device), reduction=\"none\")\n",
        "\n",
        "  # Place outputs on CPU for compatibility with other dataset columns   \n",
        "  return {\"loss\": loss.cpu().numpy(), \"predicted_label\": pred_label.cpu().numpy()}"
      ],
      "metadata": {
        "id": "iDrRf6n_g0JJ"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the `DatasetDict.map` function once more, we apply the function to get the losses for\n",
        "all the samples:"
      ],
      "metadata": {
        "id": "P3A4ryC6iCxy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert our dataset back to PyTorch tensors\n",
        "emotions_encoded.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
        "# Compute loss values\n",
        "emotions_encoded[\"validation\"] = emotions_encoded[\"validation\"].map(forward_pass_with_label, batched=True, batch_size=16)"
      ],
      "metadata": {
        "id": "4dmH0HVViEj_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we create a DataFrame with the texts, losses, and the predicted/true labels."
      ],
      "metadata": {
        "id": "6dik4CKXii9N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "emotions_encoded.set_format(\"pandas\")\n",
        "\n",
        "cols = [\"text\", \"label\", \"predicted_label\", \"loss\"]\n",
        "df_test = emotions_encoded[\"validation\"][:][cols]\n",
        "df_test[\"label\"] = df_test[\"label\"].apply(label_int2str, split=\"test\")\n",
        "df_test[\"predicted_label\"] = (df_test[\"predicted_label\"].apply(label_int2str, split=\"test\"))"
      ],
      "metadata": {
        "id": "nFSXhQlXjmK2"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test.head()"
      ],
      "metadata": {
        "id": "2qmqy77imHMm",
        "outputId": "cc9c5f84-dfca-4541-91d7-3cd65e0e195d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-517c7d20-c37b-478f-aa9b-1589809debdd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>predicted_label</th>\n",
              "      <th>loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>im feeling quite sad and sorry for myself but ...</td>\n",
              "      <td>sadness</td>\n",
              "      <td>sadness</td>\n",
              "      <td>0.022399</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>i feel like i am still looking at a blank canv...</td>\n",
              "      <td>sadness</td>\n",
              "      <td>sadness</td>\n",
              "      <td>0.025774</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>i feel like a faithful servant</td>\n",
              "      <td>love</td>\n",
              "      <td>love</td>\n",
              "      <td>0.356216</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>i am just feeling cranky and blue</td>\n",
              "      <td>anger</td>\n",
              "      <td>anger</td>\n",
              "      <td>0.038201</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i can have for a treat or if i am feeling festive</td>\n",
              "      <td>joy</td>\n",
              "      <td>joy</td>\n",
              "      <td>0.023161</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-517c7d20-c37b-478f-aa9b-1589809debdd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-517c7d20-c37b-478f-aa9b-1589809debdd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-517c7d20-c37b-478f-aa9b-1589809debdd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                text    label predicted_label  \\\n",
              "0  im feeling quite sad and sorry for myself but ...  sadness         sadness   \n",
              "1  i feel like i am still looking at a blank canv...  sadness         sadness   \n",
              "2                     i feel like a faithful servant     love            love   \n",
              "3                  i am just feeling cranky and blue    anger           anger   \n",
              "4  i can have for a treat or if i am feeling festive      joy             joy   \n",
              "\n",
              "       loss  \n",
              "0  0.022399  \n",
              "1  0.025774  \n",
              "2  0.356216  \n",
              "3  0.038201  \n",
              "4  0.023161  "
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now easily sort `emotions_encoded` by the losses in either ascending or descending order. The goal of this exercise is to detect one of the following:\n",
        "\n",
        "- _Wrong labels_:: Every process that adds labels to data can be flawed. Annotators can make mistakes or disagree, while labels that are inferred from other features can be wrong. If it was easy to automatically annotate data, then we would not need a model to do it. Thus, it is normal that there are some wrongly labeled examples. With this approach, we can quickly find and correct them.\n",
        "\n",
        "- _Quirks of the dataset_:: Datasets in the real world are always a bit messy. When working with text, special characters or strings in the inputs can have a big impact on the model's predictions. Inspecting the model's weakest predictions can help identify such features, and cleaning the data or injecting similar examples can make the model more robust.\n",
        "\n",
        "Let's first have a look at the data samples with the highest losses:"
      ],
      "metadata": {
        "id": "dcZDRunx7tVo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now easily sort the DataFrame by the losses in either ascending or descending order."
      ],
      "metadata": {
        "id": "VGcyQUMRl-80"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_test.sort_values(by=[\"loss\"], ascending=False).head(10)"
      ],
      "metadata": {
        "id": "OTLwegMXlr_J",
        "outputId": "e7f6896a-f890-492f-9526-ef4404ff2de6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-f95bca47-de47-4353-9371-f229e7b96e4c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>predicted_label</th>\n",
              "      <th>loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>882</th>\n",
              "      <td>i feel badly about reneging on my commitment t...</td>\n",
              "      <td>love</td>\n",
              "      <td>sadness</td>\n",
              "      <td>5.930562</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1963</th>\n",
              "      <td>i called myself pro life and voted for perry w...</td>\n",
              "      <td>joy</td>\n",
              "      <td>sadness</td>\n",
              "      <td>5.470693</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1274</th>\n",
              "      <td>i am going to several holiday parties and i ca...</td>\n",
              "      <td>joy</td>\n",
              "      <td>sadness</td>\n",
              "      <td>5.356759</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1801</th>\n",
              "      <td>i feel that he was being overshadowed by the s...</td>\n",
              "      <td>love</td>\n",
              "      <td>sadness</td>\n",
              "      <td>5.250397</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1870</th>\n",
              "      <td>i guess i feel betrayed because i admired him ...</td>\n",
              "      <td>joy</td>\n",
              "      <td>sadness</td>\n",
              "      <td>5.159094</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1509</th>\n",
              "      <td>i guess this is a memoir so it feels like that...</td>\n",
              "      <td>joy</td>\n",
              "      <td>fear</td>\n",
              "      <td>4.965000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1500</th>\n",
              "      <td>i guess we would naturally feel a sense of lon...</td>\n",
              "      <td>anger</td>\n",
              "      <td>sadness</td>\n",
              "      <td>4.912658</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>405</th>\n",
              "      <td>i have been feeling extraordinarily indecisive...</td>\n",
              "      <td>fear</td>\n",
              "      <td>joy</td>\n",
              "      <td>4.908146</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1950</th>\n",
              "      <td>i as representative of everything thats wrong ...</td>\n",
              "      <td>surprise</td>\n",
              "      <td>sadness</td>\n",
              "      <td>4.846525</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>318</th>\n",
              "      <td>i felt ashamed of these feelings and was scare...</td>\n",
              "      <td>fear</td>\n",
              "      <td>sadness</td>\n",
              "      <td>4.767237</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f95bca47-de47-4353-9371-f229e7b96e4c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f95bca47-de47-4353-9371-f229e7b96e4c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f95bca47-de47-4353-9371-f229e7b96e4c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                   text     label  \\\n",
              "882   i feel badly about reneging on my commitment t...      love   \n",
              "1963  i called myself pro life and voted for perry w...       joy   \n",
              "1274  i am going to several holiday parties and i ca...       joy   \n",
              "1801  i feel that he was being overshadowed by the s...      love   \n",
              "1870  i guess i feel betrayed because i admired him ...       joy   \n",
              "1509  i guess this is a memoir so it feels like that...       joy   \n",
              "1500  i guess we would naturally feel a sense of lon...     anger   \n",
              "405   i have been feeling extraordinarily indecisive...      fear   \n",
              "1950  i as representative of everything thats wrong ...  surprise   \n",
              "318   i felt ashamed of these feelings and was scare...      fear   \n",
              "\n",
              "     predicted_label      loss  \n",
              "882          sadness  5.930562  \n",
              "1963         sadness  5.470693  \n",
              "1274         sadness  5.356759  \n",
              "1801         sadness  5.250397  \n",
              "1870         sadness  5.159094  \n",
              "1509            fear  4.965000  \n",
              "1500         sadness  4.912658  \n",
              "405              joy  4.908146  \n",
              "1950         sadness  4.846525  \n",
              "318          sadness  4.767237  "
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can clearly see that the model predicted some of the labels wrong. On the other hand it\n",
        "seems that there are quite a few examples with no clear class which might be either mislabelled\n",
        "or require an new class altogether. \n",
        "\n",
        "In particular, joy seems to be mislabelled several times. With\n",
        "this information we can refine the dataset which often can lead to as much or more performance\n",
        "gain as having more data or larger models!"
      ],
      "metadata": {
        "id": "iZasWdGTnXXp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_test.sort_values(by=[\"loss\"], ascending=True).head(10)"
      ],
      "metadata": {
        "id": "xYN8mbmPoAnQ",
        "outputId": "27a29c44-5ed2-40a2-a07b-f2dc9843a0f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-6a09ef31-ddf1-458c-a35b-c9a38e573786\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>predicted_label</th>\n",
              "      <th>loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>133</th>\n",
              "      <td>i and feel quite ungrateful for it but i m loo...</td>\n",
              "      <td>sadness</td>\n",
              "      <td>sadness</td>\n",
              "      <td>0.017308</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>i feel try to tell me im ungrateful tell me im...</td>\n",
              "      <td>sadness</td>\n",
              "      <td>sadness</td>\n",
              "      <td>0.017643</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1601</th>\n",
              "      <td>i feel so ungrateful when thinking saying thes...</td>\n",
              "      <td>sadness</td>\n",
              "      <td>sadness</td>\n",
              "      <td>0.017714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1140</th>\n",
              "      <td>i do think about certain people i feel a bit d...</td>\n",
              "      <td>sadness</td>\n",
              "      <td>sadness</td>\n",
              "      <td>0.017773</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1502</th>\n",
              "      <td>i feel ungrateful for stupid shit like</td>\n",
              "      <td>sadness</td>\n",
              "      <td>sadness</td>\n",
              "      <td>0.017839</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1466</th>\n",
              "      <td>i feel so ungrateful to be wishing this pregna...</td>\n",
              "      <td>sadness</td>\n",
              "      <td>sadness</td>\n",
              "      <td>0.017847</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1310</th>\n",
              "      <td>i feel like an ungrateful asshole</td>\n",
              "      <td>sadness</td>\n",
              "      <td>sadness</td>\n",
              "      <td>0.017931</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1663</th>\n",
              "      <td>i feel idiotic calling again though</td>\n",
              "      <td>sadness</td>\n",
              "      <td>sadness</td>\n",
              "      <td>0.018416</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>i have no extra money im worried all of the ti...</td>\n",
              "      <td>sadness</td>\n",
              "      <td>sadness</td>\n",
              "      <td>0.018422</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1452</th>\n",
              "      <td>i always feel guilty and come to one conclusio...</td>\n",
              "      <td>sadness</td>\n",
              "      <td>sadness</td>\n",
              "      <td>0.018494</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6a09ef31-ddf1-458c-a35b-c9a38e573786')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6a09ef31-ddf1-458c-a35b-c9a38e573786 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6a09ef31-ddf1-458c-a35b-c9a38e573786');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                   text    label  \\\n",
              "133   i and feel quite ungrateful for it but i m loo...  sadness   \n",
              "21    i feel try to tell me im ungrateful tell me im...  sadness   \n",
              "1601  i feel so ungrateful when thinking saying thes...  sadness   \n",
              "1140  i do think about certain people i feel a bit d...  sadness   \n",
              "1502             i feel ungrateful for stupid shit like  sadness   \n",
              "1466  i feel so ungrateful to be wishing this pregna...  sadness   \n",
              "1310                  i feel like an ungrateful asshole  sadness   \n",
              "1663                i feel idiotic calling again though  sadness   \n",
              "69    i have no extra money im worried all of the ti...  sadness   \n",
              "1452  i always feel guilty and come to one conclusio...  sadness   \n",
              "\n",
              "     predicted_label      loss  \n",
              "133          sadness  0.017308  \n",
              "21           sadness  0.017643  \n",
              "1601         sadness  0.017714  \n",
              "1140         sadness  0.017773  \n",
              "1502         sadness  0.017839  \n",
              "1466         sadness  0.017847  \n",
              "1310         sadness  0.017931  \n",
              "1663         sadness  0.018416  \n",
              "69           sadness  0.018422  \n",
              "1452         sadness  0.018494  "
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now know that the joy is sometimes mislabelled and that the model is most confident about\n",
        "giving the label sadness. With this information we can make targeted improvements to our dataset and also keep an eye on the class the model seems to be very confident about."
      ],
      "metadata": {
        "id": "KU7TcAlgoQDJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df_test.sort_values(by=[\"label\"], ascending=True).head(10)"
      ],
      "metadata": {
        "id": "z7C2UkF8mkOH",
        "outputId": "ef575881-7bfe-4121-9295-be86272671cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        }
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-f690933f-4a01-434b-a6f9-23c9fdb09e61\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>predicted_label</th>\n",
              "      <th>loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1447</th>\n",
              "      <td>i feeling so agitated right now</td>\n",
              "      <td>anger</td>\n",
              "      <td>fear</td>\n",
              "      <td>0.894044</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1290</th>\n",
              "      <td>ive spent the last several days feeling irrita...</td>\n",
              "      <td>anger</td>\n",
              "      <td>anger</td>\n",
              "      <td>0.034819</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1289</th>\n",
              "      <td>im feeling very distracted today</td>\n",
              "      <td>anger</td>\n",
              "      <td>anger</td>\n",
              "      <td>0.064907</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1287</th>\n",
              "      <td>i feel resentful in that i sacrificed alot for...</td>\n",
              "      <td>anger</td>\n",
              "      <td>anger</td>\n",
              "      <td>0.043077</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1284</th>\n",
              "      <td>i look in my wallet and i feel a cold chill</td>\n",
              "      <td>anger</td>\n",
              "      <td>anger</td>\n",
              "      <td>0.062392</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1279</th>\n",
              "      <td>i am feeling so violent i just fucking shudder...</td>\n",
              "      <td>anger</td>\n",
              "      <td>anger</td>\n",
              "      <td>0.050914</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>234</th>\n",
              "      <td>im feeling less grumpy after that</td>\n",
              "      <td>anger</td>\n",
              "      <td>anger</td>\n",
              "      <td>0.035269</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1277</th>\n",
              "      <td>i will just say that i feel jealous and angry</td>\n",
              "      <td>anger</td>\n",
              "      <td>anger</td>\n",
              "      <td>0.042470</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1683</th>\n",
              "      <td>i had applied for a job and they had assured m...</td>\n",
              "      <td>anger</td>\n",
              "      <td>joy</td>\n",
              "      <td>4.345836</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1275</th>\n",
              "      <td>i wake up every morning excited about breakfas...</td>\n",
              "      <td>anger</td>\n",
              "      <td>anger</td>\n",
              "      <td>0.045055</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f690933f-4a01-434b-a6f9-23c9fdb09e61')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f690933f-4a01-434b-a6f9-23c9fdb09e61 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f690933f-4a01-434b-a6f9-23c9fdb09e61');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                   text  label  \\\n",
              "1447                    i feeling so agitated right now  anger   \n",
              "1290  ive spent the last several days feeling irrita...  anger   \n",
              "1289                   im feeling very distracted today  anger   \n",
              "1287  i feel resentful in that i sacrificed alot for...  anger   \n",
              "1284        i look in my wallet and i feel a cold chill  anger   \n",
              "1279  i am feeling so violent i just fucking shudder...  anger   \n",
              "234                   im feeling less grumpy after that  anger   \n",
              "1277      i will just say that i feel jealous and angry  anger   \n",
              "1683  i had applied for a job and they had assured m...  anger   \n",
              "1275  i wake up every morning excited about breakfas...  anger   \n",
              "\n",
              "     predicted_label      loss  \n",
              "1447            fear  0.894044  \n",
              "1290           anger  0.034819  \n",
              "1289           anger  0.064907  \n",
              "1287           anger  0.043077  \n",
              "1284           anger  0.062392  \n",
              "1279           anger  0.050914  \n",
              "234            anger  0.035269  \n",
              "1277           anger  0.042470  \n",
              "1683             joy  4.345836  \n",
              "1275           anger  0.045055  "
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# selecting the true and pred mismatch labels\n",
        "true_pred_labels_mismatch = df_test[df_test[\"label\"] != df_test[\"predicted_label\"]]"
      ],
      "metadata": {
        "id": "8EKQCsnnqcji"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "true_pred_labels_mismatch"
      ],
      "metadata": {
        "id": "EAEmY5Guq_1Y",
        "outputId": "13137cdb-fbad-496b-9449-7d9539e2488c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-3d4589ae-81c1-4a52-9d93-2904b286b2a4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>predicted_label</th>\n",
              "      <th>loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>i know what it feels like he stressed glaring ...</td>\n",
              "      <td>anger</td>\n",
              "      <td>sadness</td>\n",
              "      <td>1.198635</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>i feel as if i am the beloved preparing hersel...</td>\n",
              "      <td>joy</td>\n",
              "      <td>love</td>\n",
              "      <td>1.772280</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>i am feeling very blessed today that they shar...</td>\n",
              "      <td>joy</td>\n",
              "      <td>love</td>\n",
              "      <td>1.236907</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>i didn t feel accepted</td>\n",
              "      <td>joy</td>\n",
              "      <td>love</td>\n",
              "      <td>0.806654</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>i feel that this is important in itself the fa...</td>\n",
              "      <td>joy</td>\n",
              "      <td>sadness</td>\n",
              "      <td>1.316638</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1963</th>\n",
              "      <td>i called myself pro life and voted for perry w...</td>\n",
              "      <td>joy</td>\n",
              "      <td>sadness</td>\n",
              "      <td>5.279847</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1964</th>\n",
              "      <td>i feel vaguely cheated and a little amused</td>\n",
              "      <td>joy</td>\n",
              "      <td>anger</td>\n",
              "      <td>3.938705</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1987</th>\n",
              "      <td>i feel im supposed to hate dams amp all the co...</td>\n",
              "      <td>joy</td>\n",
              "      <td>anger</td>\n",
              "      <td>1.259942</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1993</th>\n",
              "      <td>i feel so tortured by it</td>\n",
              "      <td>anger</td>\n",
              "      <td>fear</td>\n",
              "      <td>0.855164</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1998</th>\n",
              "      <td>i truly feel that if you are passionate enough...</td>\n",
              "      <td>joy</td>\n",
              "      <td>love</td>\n",
              "      <td>1.002115</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>150 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3d4589ae-81c1-4a52-9d93-2904b286b2a4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3d4589ae-81c1-4a52-9d93-2904b286b2a4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3d4589ae-81c1-4a52-9d93-2904b286b2a4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                   text  ...      loss\n",
              "17    i know what it feels like he stressed glaring ...  ...  1.198635\n",
              "27    i feel as if i am the beloved preparing hersel...  ...  1.772280\n",
              "35    i am feeling very blessed today that they shar...  ...  1.236907\n",
              "55                               i didn t feel accepted  ...  0.806654\n",
              "72    i feel that this is important in itself the fa...  ...  1.316638\n",
              "...                                                 ...  ...       ...\n",
              "1963  i called myself pro life and voted for perry w...  ...  5.279847\n",
              "1964         i feel vaguely cheated and a little amused  ...  3.938705\n",
              "1987  i feel im supposed to hate dams amp all the co...  ...  1.259942\n",
              "1993                           i feel so tortured by it  ...  0.855164\n",
              "1998  i truly feel that if you are passionate enough...  ...  1.002115\n",
              "\n",
              "[150 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "true_pred_labels_mismatch.shape"
      ],
      "metadata": {
        "id": "95Tc15P5roCy",
        "outputId": "836dd097-2420-4ea0-c26b-a21a14fe6fca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(157, 4)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(true_pred_labels_mismatch)"
      ],
      "metadata": {
        "id": "yZiU_UFOsEq_",
        "outputId": "3a6c8714-fbfc-4692-a63e-d5b158b1e0c6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "157"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So, we have 150 samples that are misclassified."
      ],
      "metadata": {
        "id": "IpTD_cQosHQn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# selecting the true and pred mismatch labels\n",
        "true_pred_labels_mismatch = df_test.loc[df_test[\"label\"] != df_test[\"predicted_label\"]]\n",
        "true_pred_labels_mismatch"
      ],
      "metadata": {
        "id": "b6wV8DuuwFRp",
        "outputId": "e95f35d6-ca50-41e9-f428-b89a31d0a561",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        }
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-be178b78-a8cb-4655-b0c0-bf62cf5f1d0a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>predicted_label</th>\n",
              "      <th>loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>i feel as if i am the beloved preparing hersel...</td>\n",
              "      <td>joy</td>\n",
              "      <td>love</td>\n",
              "      <td>1.702191</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>i am feeling very blessed today that they shar...</td>\n",
              "      <td>joy</td>\n",
              "      <td>love</td>\n",
              "      <td>1.012860</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>i didn t feel accepted</td>\n",
              "      <td>joy</td>\n",
              "      <td>love</td>\n",
              "      <td>0.799338</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>i feel that this is important in itself the fa...</td>\n",
              "      <td>joy</td>\n",
              "      <td>sadness</td>\n",
              "      <td>2.198458</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91</th>\n",
              "      <td>i feel like the people i know are really gener...</td>\n",
              "      <td>joy</td>\n",
              "      <td>love</td>\n",
              "      <td>1.399380</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1964</th>\n",
              "      <td>i feel vaguely cheated and a little amused</td>\n",
              "      <td>joy</td>\n",
              "      <td>sadness</td>\n",
              "      <td>3.449615</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1981</th>\n",
              "      <td>i spent a lot of time feeling overwhelmed with...</td>\n",
              "      <td>fear</td>\n",
              "      <td>surprise</td>\n",
              "      <td>0.969145</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1990</th>\n",
              "      <td>i just feel too overwhelmed i can t see the fo...</td>\n",
              "      <td>fear</td>\n",
              "      <td>surprise</td>\n",
              "      <td>0.892993</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1993</th>\n",
              "      <td>i feel so tortured by it</td>\n",
              "      <td>anger</td>\n",
              "      <td>fear</td>\n",
              "      <td>1.132467</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1998</th>\n",
              "      <td>i truly feel that if you are passionate enough...</td>\n",
              "      <td>joy</td>\n",
              "      <td>love</td>\n",
              "      <td>1.062563</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>157 rows × 4 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-be178b78-a8cb-4655-b0c0-bf62cf5f1d0a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-be178b78-a8cb-4655-b0c0-bf62cf5f1d0a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-be178b78-a8cb-4655-b0c0-bf62cf5f1d0a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                   text  label  \\\n",
              "27    i feel as if i am the beloved preparing hersel...    joy   \n",
              "35    i am feeling very blessed today that they shar...    joy   \n",
              "55                               i didn t feel accepted    joy   \n",
              "72    i feel that this is important in itself the fa...    joy   \n",
              "91    i feel like the people i know are really gener...    joy   \n",
              "...                                                 ...    ...   \n",
              "1964         i feel vaguely cheated and a little amused    joy   \n",
              "1981  i spent a lot of time feeling overwhelmed with...   fear   \n",
              "1990  i just feel too overwhelmed i can t see the fo...   fear   \n",
              "1993                           i feel so tortured by it  anger   \n",
              "1998  i truly feel that if you are passionate enough...    joy   \n",
              "\n",
              "     predicted_label      loss  \n",
              "27              love  1.702191  \n",
              "35              love  1.012860  \n",
              "55              love  0.799338  \n",
              "72           sadness  2.198458  \n",
              "91              love  1.399380  \n",
              "...              ...       ...  \n",
              "1964         sadness  3.449615  \n",
              "1981        surprise  0.969145  \n",
              "1990        surprise  0.892993  \n",
              "1993            fear  1.132467  \n",
              "1998            love  1.062563  \n",
              "\n",
              "[157 rows x 4 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Saving the Model"
      ],
      "metadata": {
        "id": "ZRJNfobDoeJv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we want to save the model so we can reuse it in another session or later if we want to\n",
        "put it in production. \n",
        "\n",
        "We can save the model together with the right tokenizer in the same folder:"
      ],
      "metadata": {
        "id": "KIbleC4yoe00"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainer.save_model(\"models/distilbert-emotion\")"
      ],
      "metadata": {
        "id": "zMcd0BfYoloi",
        "outputId": "c1ebd24b-da36-4c1a-ba16-d61f37670bb1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to models/distilbert-emotion\n",
            "Configuration saved in models/distilbert-emotion/config.json\n",
            "Model weights saved in models/distilbert-emotion/pytorch_model.bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.save_pretrained(\"models/distilbert-emotion\")"
      ],
      "metadata": {
        "id": "bWk3pjWRovyB",
        "outputId": "11901fc8-3e47-4fed-ee19-70e718162199",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "tokenizer config file saved in models/distilbert-emotion/tokenizer_config.json\n",
            "Special tokens file saved in models/distilbert-emotion/special_tokens_map.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('models/distilbert-emotion/tokenizer_config.json',\n",
              " 'models/distilbert-emotion/special_tokens_map.json',\n",
              " 'models/distilbert-emotion/vocab.txt',\n",
              " 'models/distilbert-emotion/added_tokens.json',\n",
              " 'models/distilbert-emotion/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The NLP community benefits greatly from sharing pretrained and fine-tuned models, and\n",
        "everybody can share their models with others via the Hugging Face Model Hub."
      ],
      "metadata": {
        "id": "4vS305dlpA43"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Conclusion"
      ],
      "metadata": {
        "id": "xpJ9ZT1t8QPa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Congratulations, you now know how to train a transformer model to classify the emotions in tweets! We have seen two complementary approaches based on features and fine-tuning, and investigated their strengths and weaknesses. \n",
        "\n",
        "However, this is just the first step in building a real-world application with transformer models, and we have a lot more ground to cover. Here's a list of challenges you're likely to experience in your NLP journey:\n",
        "\n",
        "My boss wants my model in production yesterday!::\n",
        "In most applications, your model doesn't just sit somewhere gathering dust - you want to make sure it's serving predictions! When a model is pushed to the Hub, an inference endpoint is automatically created that can be called with HTTP requests. We recommend checking out the [documentation](https://api-inference.huggingface.co/docs/python/html/index.html) of the Inference API if you want to learn more. \n",
        "\n",
        "My users want faster predictions!::\n",
        "\n",
        "We've already seen one approach to this problem: using DistilBERT. In <<chapter_compression>> we'll dive into knowledge distillation (the process by which DistilBERT was created), along with other tricks to speed up your transformer models.\n",
        "\n",
        "\n",
        "Can your model also do X?::\n",
        "\n",
        "As we've alluded to in this chapter, transformers are extremely versatile. In the rest of the book we will be exploring a range of tasks, like question answering and named entity recognition, all using the same basic architecture.\n",
        "\n",
        "None of my texts are in English!::\n",
        "\n",
        "It turns out that transformers also come in a multilingual variety, and we'll use them in <<chapter_ner>> to tackle several languages at once.\n",
        "\n",
        "I don't have any labels!::\n",
        "\n",
        "If there is very little labeled data available, fine-tuning may not be an option. In <<chapter_fewlabels>>, we'll explore some techniques to deal with this situation.\n",
        "\n",
        "Now that we've seen what's involved in training and sharing a transformer, in the next chapter we'll explore implementing our very own transformer model from scratch."
      ],
      "metadata": {
        "id": "RabF3ykc8QtC"
      }
    }
  ]
}