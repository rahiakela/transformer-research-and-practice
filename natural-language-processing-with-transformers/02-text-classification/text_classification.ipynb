{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "text-classification.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOMNNfQ9GCCXObQB6g+BUhQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cf7960614a71479794150e72870d1ccf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9d2a36e468064e6daa96981c441f0c05",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_61f6800b86f846b3ac848f3253d1f583",
              "IPY_MODEL_9812bda3566f41c3a1a9530e7fe5d8d7",
              "IPY_MODEL_2ab17062e37a46cba4b1747f5eed47e1"
            ]
          }
        },
        "9d2a36e468064e6daa96981c441f0c05": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "61f6800b86f846b3ac848f3253d1f583": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e36cc434711948ff97806f1004580fd0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a8a896a9acae47fa8f7beecd44b6e9e4"
          }
        },
        "9812bda3566f41c3a1a9530e7fe5d8d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4923c4ff92d64e9380451e0cff8bda40",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 28,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 28,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a3270593b7cc48df94d754aba5b03615"
          }
        },
        "2ab17062e37a46cba4b1747f5eed47e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_22c858159caf4dc3855ce1f38ac780c6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 28.0/28.0 [00:00&lt;00:00, 588B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9a2b26b43ac84fd59339c419329f5cc8"
          }
        },
        "e36cc434711948ff97806f1004580fd0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a8a896a9acae47fa8f7beecd44b6e9e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4923c4ff92d64e9380451e0cff8bda40": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a3270593b7cc48df94d754aba5b03615": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "22c858159caf4dc3855ce1f38ac780c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9a2b26b43ac84fd59339c419329f5cc8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5413f7c3c0f44d7991efd2f45b7d11fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1445d05a9c4e4fcd9ea95ddeb23cec26",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3aa83dc3a99f42599314f7931505a098",
              "IPY_MODEL_93a41c6fdc494312b08eed775f204c29",
              "IPY_MODEL_6ea43399fa2040a9856a6435ef801b00"
            ]
          }
        },
        "1445d05a9c4e4fcd9ea95ddeb23cec26": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3aa83dc3a99f42599314f7931505a098": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3af53bdc2a1f4b60a1e2e357b2bd05c8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ca1e22a243fa45ca84ad3aa66274f221"
          }
        },
        "93a41c6fdc494312b08eed775f204c29": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_06bd74dcd2dd45fe9509f12a0d190e6c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 483,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 483,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4e174def61fe4a0199b3e4188e8c1d5d"
          }
        },
        "6ea43399fa2040a9856a6435ef801b00": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_50dc2e87bf784142a3ca8b0054a12b48",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 483/483 [00:00&lt;00:00, 11.7kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9965cf77a2c94980aa3936c177926922"
          }
        },
        "3af53bdc2a1f4b60a1e2e357b2bd05c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ca1e22a243fa45ca84ad3aa66274f221": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "06bd74dcd2dd45fe9509f12a0d190e6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4e174def61fe4a0199b3e4188e8c1d5d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "50dc2e87bf784142a3ca8b0054a12b48": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9965cf77a2c94980aa3936c177926922": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "59f3b3b241e64a19ab9332436d6c0696": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_fa5b1b0847bb4eb590eff0ec01c100ed",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_440ddb31e8194da389b5702f4434d554",
              "IPY_MODEL_0de30715a7ea43c0b190246110f79504",
              "IPY_MODEL_421fdd2faa534637b5e73ed941c58c81"
            ]
          }
        },
        "fa5b1b0847bb4eb590eff0ec01c100ed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "440ddb31e8194da389b5702f4434d554": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d55517e4728a4a4aa840b9af69c2ed07",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a1549cabeaf6473cab78685db76dea78"
          }
        },
        "0de30715a7ea43c0b190246110f79504": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_dbc945b97abd48fc9147750690aa25b6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_95bd219cc7ac47f79b5b5e883e44ba60"
          }
        },
        "421fdd2faa534637b5e73ed941c58c81": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_fefe770cd9f1446ba2f5ae266fd71aca",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 226k/226k [00:00&lt;00:00, 399kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9acf2c022e0744ada07f04ef1e292a0c"
          }
        },
        "d55517e4728a4a4aa840b9af69c2ed07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a1549cabeaf6473cab78685db76dea78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dbc945b97abd48fc9147750690aa25b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "95bd219cc7ac47f79b5b5e883e44ba60": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fefe770cd9f1446ba2f5ae266fd71aca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9acf2c022e0744ada07f04ef1e292a0c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f0aa0d3c4d11465d8a16813e059516b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_921677de21644bbbb458d6b785701f92",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_8ea2a3e5d3f144ec9dff3c99330efb09",
              "IPY_MODEL_b501dacee4894bbd81cc5592dfa398a2",
              "IPY_MODEL_c38698443de64cf4b01943a19c76bf5f"
            ]
          }
        },
        "921677de21644bbbb458d6b785701f92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8ea2a3e5d3f144ec9dff3c99330efb09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6ef5a1b7d84a4393b880253c2d7c0f55",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a09c268e416e4cafa54e4e8ad25c83d9"
          }
        },
        "b501dacee4894bbd81cc5592dfa398a2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0169a0864a3043408e906d484d5cee2c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 466062,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 466062,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_17f79c95891545c0948b3cbb26f45fb0"
          }
        },
        "c38698443de64cf4b01943a19c76bf5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3c400f9608084825a9b82d8ced381636",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 455k/455k [00:00&lt;00:00, 1.28MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c45e12f6963b4172af8c9372ddbd5b49"
          }
        },
        "6ef5a1b7d84a4393b880253c2d7c0f55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a09c268e416e4cafa54e4e8ad25c83d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0169a0864a3043408e906d484d5cee2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "17f79c95891545c0948b3cbb26f45fb0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3c400f9608084825a9b82d8ced381636": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c45e12f6963b4172af8c9372ddbd5b49": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/transformers-research-and-practice/blob/main/natural-language-processing-with-transformers/02-text-classification/text_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Text Classification"
      ],
      "metadata": {
        "id": "PfCJmxSiZ8Bd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Text classification is one of the most common tasks in NLP and can be used for applications\n",
        "such as tagging customer feedback into categories or routing support tickets according to their\n",
        "language. Chances are that your email’s spam filter is using text classification to protect your\n",
        "inbox from a deluge of unwanted junk!\n",
        "\n",
        "Another common type of text classification is sentiment analysis, which aims to identify the\n",
        "polarity of a given text.\n",
        "\n",
        "Now imagine that you are a data scientist who needs to build a system that can automatically\n",
        "identify emotional states such as “anger” or “joy” that people express towards your company’s\n",
        "product on Twitter. \n",
        "\n",
        "Until 2018, the deep learning approach to this problem typically involved\n",
        "finding a suitable neural architecture for the task and training it from scratch on a dataset of\n",
        "labeled tweets. This approach suffered from three major drawbacks:\n",
        "\n",
        "- You needed a lot of labeled data to train accurate models like recurrent or\n",
        "convolutional neural networks.\n",
        "- Training these models from scratch was time consuming and expensive.\n",
        "- The trained model could not be easily adapted to a new task, e.g. with a different set of labels.\n",
        "\n",
        "Nowadays, these limitations are largely overcome via transfer learning, where typically a\n",
        "Transformer-based architecture is pretrained on a generic task such as language modeling and\n",
        "then reused for a wide variety of downstream tasks."
      ],
      "metadata": {
        "id": "0O5UwNeIZ8op"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Setup"
      ],
      "metadata": {
        "id": "NmjXzjlJaZVE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install transformers[sentencepiece]\n",
        "!pip -q install datasets"
      ],
      "metadata": {
        "id": "TbIsiaFwaaky"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "from transformers import set_seed\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import AutoModel\n",
        "from datasets import list_datasets, load_dataset\n",
        "\n",
        "import torch\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "Kl_TTiiIaeLG"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##The Dataset"
      ],
      "metadata": {
        "id": "FE-e_1EIaa1F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To build our emotion detector we’ll use a great dataset from an article that explored how\n",
        "emotions are represented in English Twitter messages. \n",
        "\n",
        "Unlike most sentiment analysis datasets\n",
        "that involve just “positive” and “negative” polarities, this dataset contains six basic emotions:\n",
        "anger, disgust, fear, joy, sadness, and surprise. \n",
        "\n",
        "\n",
        "Given a tweet, our task will be to train a model\n",
        "that can classify it into one of these emotions!"
      ],
      "metadata": {
        "id": "8-2ciOUGayjC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Overview of Datasets"
      ],
      "metadata": {
        "id": "s1hPKMSVhT_J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We can use the list_datasets function to see what datasets are available in the Hub:\n",
        "datasets = list_datasets()\n",
        "\n",
        "print(f\"There are {len(datasets)} datasets currently available on the Hub.\")\n",
        "print(f\"The first 10 are: {datasets[:10]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pjvtlOmQbdG0",
        "outputId": "75e28c86-8750-4556-876a-36dae10da11e"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "There are 2179 datasets currently available on the Hub.\n",
            "The first 10 are: ['0n1xus/codexglue', '0n1xus/pytorrent-standalone', 'AConsApart/anime_subtitles_DialoGPT', 'AI-Sweden/SuperLim', 'AI-it/korean-hate-speech', 'ARKseal/YFCC14M_subset_webdataset', 'ARTeLab/fanpage', 'ARTeLab/ilpost', 'ARTeLab/mlsum-it', 'Abdo1Kamr/Arabic_Hadith']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see that each dataset is given a name, so let’s inspect the metadata associated with the\n",
        "emotion dataset:"
      ],
      "metadata": {
        "id": "Ns2dh4xdbyIm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "metadata = list_datasets(with_details=True)[datasets.index(\"emotion\")]\n",
        "\n",
        "# Show dataset description\n",
        "print(\"Description:\", metadata.description, \"\\n\")\n",
        "# Show first 8 lines of the citation string\n",
        "print(\"Citation:\", \"\\n\".join(metadata.citation.split(\"\\n\")[:8]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WE2INspybyz1",
        "outputId": "ab37d60f-66ad-4c23-dc3a-c3bdd6944ed4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Description: Emotion is a dataset of English Twitter messages with six basic emotions: anger, fear, joy, love, sadness, and surprise. For more detailed information please refer to the paper. \n",
            "\n",
            "Citation: @inproceedings{saravia-etal-2018-carer,\n",
            "    title = \"{CARER}: Contextualized Affect Representations for Emotion Recognition\",\n",
            "    author = \"Saravia, Elvis  and\n",
            "      Liu, Hsien-Chi Toby  and\n",
            "      Huang, Yen-Hao  and\n",
            "      Wu, Junlin  and\n",
            "      Chen, Yi-Shin\",\n",
            "    booktitle = \"Proceedings of the 2018 Conference on Empirical Methods in Natural Language Processing\",\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This looks like the dataset we’re after, so next we can load it with the `load_dataset` function from Datasets:"
      ],
      "metadata": {
        "id": "TFwzYC8Zdm-P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "emotions = load_dataset(\"emotion\")"
      ],
      "metadata": {
        "id": "pPaEqtbZdoj4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "emotions"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UZ1KLuRdeQnh",
        "outputId": "5d19804c-12d8-4b4b-a73c-59a5be315e65"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 16000\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 2000\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['text', 'label'],\n",
              "        num_rows: 2000\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "we see it is similar to a Python dictionary, with each key corresponding to a different split. \n",
        "\n",
        "And just like any dictionary, we can access an individual split as usual"
      ],
      "metadata": {
        "id": "SGOtUtiMebHD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds = emotions[\"train\"]\n",
        "train_ds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iDGm5pQledFm",
        "outputId": "db72ae96-9dcc-41b4-9ac4-a7492fced36d"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['text', 'label'],\n",
              "    num_rows: 16000\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This object behaves like an\n",
        "ordinary Python container, so we can query its length"
      ],
      "metadata": {
        "id": "leozYrtJeqo6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_ds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvDZesbXerQ0",
        "outputId": "245d565d-440b-4479-df43-e3c3c53ee54d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16000"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "or access a single example by its index"
      ],
      "metadata": {
        "id": "RECvP-DqexU5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ev1O0vYSexxU",
        "outputId": "684e0fbf-811b-448d-f63b-34e2b5a2cb99"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'label': 0, 'text': 'i didnt feel humiliated'}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we see that a single row is represented as a\n",
        "dictionary, where the keys correspond to the column names"
      ],
      "metadata": {
        "id": "xfD3nZkbe7n1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds.column_names"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xR7VRirHe8Qj",
        "outputId": "1808ebb3-e98c-4015-cfe3-882fc0d69a1f"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['text', 'label']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This reflects the fact that Datasets is\n",
        "based on Apache Arrow, which defines a typed columnar format that is more memory efficient\n",
        "than native Python. \n",
        "\n",
        "We can see what data types are being used under the hood by accessing the\n",
        "features attribute of a Dataset object:"
      ],
      "metadata": {
        "id": "zOGbQFIrfGyD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds.features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZXFN6Y1MfKuf",
        "outputId": "e0f1ec64-d624-4a0e-8274-1640d7639473"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'label': ClassLabel(num_classes=6, names=['sadness', 'joy', 'love', 'anger', 'fear', 'surprise'], names_file=None, id=None),\n",
              " 'text': Value(dtype='string', id=None)}"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also access several rows with a slice"
      ],
      "metadata": {
        "id": "3fpWX3D1fayp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds[:6]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ji3TnXWfZl3",
        "outputId": "8ab65ab1-f232-4dd4-b7bc-09a89894820b"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'label': [0, 0, 3, 2, 3, 0],\n",
              " 'text': ['i didnt feel humiliated',\n",
              "  'i can go from feeling so hopeless to so damned hopeful just from being around someone who cares and is awake',\n",
              "  'im grabbing a minute to post i feel greedy wrong',\n",
              "  'i am ever feeling nostalgic about the fireplace i will know that it is still on the property',\n",
              "  'i am feeling grouchy',\n",
              "  'ive been feeling a little burdened lately wasnt sure why that was']}"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "or get the full column by name"
      ],
      "metadata": {
        "id": "r7Urq-NifloZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_ds[\"text\"][:6]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "47yK6jLAfmN4",
        "outputId": "55b40692-ec9f-4e0a-de1e-785151b3cf40"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['i didnt feel humiliated',\n",
              " 'i can go from feeling so hopeless to so damned hopeful just from being around someone who cares and is awake',\n",
              " 'im grabbing a minute to post i feel greedy wrong',\n",
              " 'i am ever feeling nostalgic about the fireplace i will know that it is still on the property',\n",
              " 'i am feeling grouchy',\n",
              " 'ive been feeling a little burdened lately wasnt sure why that was']"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In each case the resulting data structure depends on the type of query; although this may feel\n",
        "strange at first, it’s part of the secret sauce that makes Datasets so flexible!"
      ],
      "metadata": {
        "id": "pqLCZbrwf3Eb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###From Datasets to DataFrames"
      ],
      "metadata": {
        "id": "P5m7jqyif3ug"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Although Datasets provides a lot of low-level functionality to slice and dice our data, it is often\n",
        "convenient to convert a Dataset object to a Pandas DataFrame so we can access highlevel\n",
        "APIs for data visualization. \n",
        "\n",
        "To enable the conversion, Datasets provides a\n",
        "`Dataset.set_format` function that allow us to change the output format of the Dataset.\n",
        "\n",
        "This does not change the underlying data format which is Apache Arrow and you can switch to\n",
        "another format later if needed:"
      ],
      "metadata": {
        "id": "xqyQ0Xhsf6OL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "emotions.set_format(type=\"pandas\")\n",
        "\n",
        "df = emotions[\"train\"][:]\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "aDDPc_8AgTBQ",
        "outputId": "82cb0502-c636-40ac-b8b8-eed02ed395a5"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i didnt feel humiliated</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>i can go from feeling so hopeless to so damned...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i am feeling grouchy</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  label\n",
              "0                            i didnt feel humiliated      0\n",
              "1  i can go from feeling so hopeless to so damned...      0\n",
              "2   im grabbing a minute to post i feel greedy wrong      3\n",
              "3  i am ever feeling nostalgic about the fireplac...      2\n",
              "4                               i am feeling grouchy      3"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see, the column headers have been preserved and the first few rows match our\n",
        "previous views of the data. \n",
        "\n",
        "However, the labels are represented as integers so let’s use the\n",
        "`ClassLabel.int2str` function to create a new column in our DataFrame with the\n",
        "corresponding label names:"
      ],
      "metadata": {
        "id": "wxNAZtVOhvUa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def label_int2str(row, split):\n",
        "  return emotions[split].features[\"label\"].int2str(row)"
      ],
      "metadata": {
        "id": "_UienA5Chx-U"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"label_name\"] = df[\"label\"].apply(label_int2str, split=\"train\")\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "nQ3XTyNlh_jE",
        "outputId": "ba9056e4-b5de-4ca7-da59-7ee7d9218834"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>label</th>\n",
              "      <th>label_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>i didnt feel humiliated</td>\n",
              "      <td>0</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>i can go from feeling so hopeless to so damned...</td>\n",
              "      <td>0</td>\n",
              "      <td>sadness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>im grabbing a minute to post i feel greedy wrong</td>\n",
              "      <td>3</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>i am ever feeling nostalgic about the fireplac...</td>\n",
              "      <td>2</td>\n",
              "      <td>love</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>i am feeling grouchy</td>\n",
              "      <td>3</td>\n",
              "      <td>anger</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text  label label_name\n",
              "0                            i didnt feel humiliated      0    sadness\n",
              "1  i can go from feeling so hopeless to so damned...      0    sadness\n",
              "2   im grabbing a minute to post i feel greedy wrong      3      anger\n",
              "3  i am ever feeling nostalgic about the fireplac...      2       love\n",
              "4                               i am feeling grouchy      3      anger"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Look at the Class Distribution"
      ],
      "metadata": {
        "id": "cvyIeZcLkGNW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Whenever you are working on text classification problems, it is a good idea to examine the\n",
        "distribution of examples among each class. \n",
        "\n",
        "For example, a dataset with a skewed class\n",
        "distribution might require a different treatment in terms of the training loss and evaluation\n",
        "metrics than a balanced one.\n",
        "\n",
        "With Pandas and the visualisation library Matplotlib we can quickly visualize this as follows:"
      ],
      "metadata": {
        "id": "TL6_McSRkG8H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"label_name\"].value_counts(ascending=True).plot.barh()\n",
        "plt.title(\"Category Counts\");"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "NrrK740UkwXQ",
        "outputId": "a36dfc4b-5dc0-4cf4-cf40-611e8747587c"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that the dataset is heavily imbalanced; the joy and sadness classes appear\n",
        "frequently whereas love and sadness are about 5-10 times rarer.\n",
        "\n",
        "There are several ways to\n",
        "deal with imbalanced data such as resampling the minority or majority classes.\n",
        "\n",
        "Alternatively, we can also weight the loss function to account for the underrepresented classes."
      ],
      "metadata": {
        "id": "zrzFOJU1lah_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###How Long Are Our Tweets?"
      ],
      "metadata": {
        "id": "8XYTrTFoloGX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transformer models have a maximum input sequence length that is referred to as the maximum context size. \n",
        "\n",
        "For most applications with BERT, the maximum context size is 512 tokens, where\n",
        "a token is defined by the choice of tokenizer and can be a word, subword, or character. \n",
        "\n",
        "Let’s make a rough estimate of our tweet lengths per emotion by looking at the distribution of words per tweet:"
      ],
      "metadata": {
        "id": "c-ay6PU2lo6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"Words Per Tweet\"] = df[\"text\"].str.split().apply(len)\n",
        "\n",
        "df.boxplot(\"Words Per Tweet\", by=\"label_name\", grid=False, showfliers=False, color=\"red\", )\n",
        "plt.suptitle(\"\")\n",
        "plt.xlabel(\"\");"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "hCjuEu9Tl_nS",
        "outputId": "6bb3fc94-fbf6-4322-da8f-e65923f34d3e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the plot we see that for each emotion, most tweets are around 15 words long and the\n",
        "longest tweets are well below BERT’s maximum context size of 512 tokens. \n",
        "\n",
        "Texts that are\n",
        "longer than a model’s context window need to be truncated, which can lead to a loss in\n",
        "performance if the truncated text contains crucial information. \n",
        "\n",
        "Let’s now figure out how we can\n",
        "convert these raw texts into a format suitable for Transformers!"
      ],
      "metadata": {
        "id": "K7OzrHh-m6_Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Tokenization"
      ],
      "metadata": {
        "id": "AcJYRsUunEVs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transformer models like BERT cannot receive raw strings as input; instead they assume the\n",
        "text has been tokenized into numerical vectors. Tokenization is the step of breaking down a\n",
        "string into the atomic units used in the model. \n",
        "\n",
        "There are several tokenization strategies one can\n",
        "adopt and the optimal splitting of words in sub-units is usually learned from the corpus.\n",
        "\n",
        "Before\n",
        "looking at the tokenizer used for BERT, let’s motivate it by looking at two extreme cases:\n",
        "character and word tokenizers."
      ],
      "metadata": {
        "id": "95kJmltPnHwi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Character Tokenization"
      ],
      "metadata": {
        "id": "6BbVhz19xukw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The simplest tokenization scheme is to feed each character individually to the model. \n",
        "\n",
        "In Python, str objects are really arrays under the hood which allows us to quickly implement character-level tokenization with just one line of code:"
      ],
      "metadata": {
        "id": "p0ubSXmKxvWh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"Tokenizing text is a core task of NLP.\"\n",
        "tokenized_text = list(text)\n",
        "print(tokenized_text)"
      ],
      "metadata": {
        "id": "zMNBTepTyE2X",
        "outputId": "fc07f2c9-a69c-4858-eda7-dc1459db57ad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['T', 'o', 'k', 'e', 'n', 'i', 'z', 'i', 'n', 'g', ' ', 't', 'e', 'x', 't', ' ', 'i', 's', ' ', 'a', ' ', 'c', 'o', 'r', 'e', ' ', 't', 'a', 's', 'k', ' ', 'o', 'f', ' ', 'N', 'L', 'P', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This is a good start but we are not yet done because our model expects each character to be\n",
        "converted to an integer, a process called numericalization. \n",
        "\n",
        "One simple way to do this is by\n",
        "encoding each unique token (which are characters in this case) with a unique integer:"
      ],
      "metadata": {
        "id": "E3QhW_TK5sST"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "token2idx = {}\n",
        "for idx, unique_char in enumerate(set(tokenized_text)):\n",
        "  token2idx[unique_char] = idx\n",
        "\n",
        "print(token2idx)"
      ],
      "metadata": {
        "id": "ZBnWs2365xzo",
        "outputId": "a1df199a-8a48-4fbc-a28c-6a0821f5a3c9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'N': 0, 'i': 1, 'L': 2, 'c': 3, 'e': 4, 's': 5, 'n': 6, '.': 7, 'a': 8, 'f': 9, 't': 10, 'T': 11, 'k': 12, 'r': 13, 'z': 14, 'P': 15, 'o': 16, ' ': 17, 'x': 18, 'g': 19}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token2idx[\"e\"]"
      ],
      "metadata": {
        "id": "7tZ4JOXB6uVf",
        "outputId": "d439090b-26db-4084-eb45-a3677792939c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "token2idx[\"c\"]"
      ],
      "metadata": {
        "id": "0KJjBdLR60SX",
        "outputId": "37fca553-6ba8-494d-db71-99ec6f78b828",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This gives us a mapping from each character in our vocabulary to a unique integer, so we can\n",
        "now use token2idx to transform the tokenized text to a list of integers:"
      ],
      "metadata": {
        "id": "Tt92jUYE6XHd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = [token2idx[token] for token in tokenized_text]\n",
        "print(input_ids)"
      ],
      "metadata": {
        "id": "iggW90zK6YnO",
        "outputId": "f926cd88-cf91-4787-f851-4ca9718e90a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[11, 16, 12, 4, 6, 1, 14, 1, 6, 19, 17, 10, 4, 18, 10, 17, 1, 5, 17, 8, 17, 3, 16, 13, 4, 17, 10, 8, 5, 12, 17, 16, 9, 17, 0, 2, 15, 7]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are almost done! Each token has been mapped to a unique, numerical identifier, hence the name `input_ids`.\n",
        "\n",
        "The last step is to convert `input_ids` into a 2d tensor of one-hot vectors\n",
        "which are better suited for neural networks than the categorical representation of `input_ids`.\n",
        "\n",
        "The reason for this is that the elements of `input_ids` create an ordinal scale, so adding or subtracting two IDs is a meaningless operation since the result in a new ID that represents another random token.\n",
        "\n",
        "On the other hand, the result of the adding two one-hot encodings can be\n",
        "easily interpreted: the two entries that are “hot” indicate that the corresponding two tokens cooccur.\n",
        "Each one-hot vector will have a length the size of the vocabulary and a “1” entry at the\n",
        "position of each ID, with zeros everywhere else.\n",
        "\n",
        "We can do this directly in PyTorch by converting `input_ids` to a `torch.Tensor`:"
      ],
      "metadata": {
        "id": "NxkX3miV7cLu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_ids = torch.tensor(input_ids)\n",
        "\n",
        "one_hot_encodings = torch.nn.functional.one_hot(input_ids)\n",
        "one_hot_encodings.shape"
      ],
      "metadata": {
        "id": "c0bB4Ea78afY",
        "outputId": "bbf09b68-7ed7-419b-8522-9a452be24475",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([38, 20])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For each of the 38 input tokens we now have a one-hot vector of dimension 20 since our vocabularly consists of 20 unique characters.\n",
        "\n",
        "By examining the first vector, we can verify that a\n",
        "1 appears in the location indicated by `input_ids[0]`:"
      ],
      "metadata": {
        "id": "7Fnqc0Kc9Pay"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Token: {tokenized_text[0]}\")\n",
        "print(f\"Tensor index: {input_ids[0]}\")\n",
        "print(f\"One-hot vector: {one_hot_encodings[0]}\")"
      ],
      "metadata": {
        "id": "o0dQyrkB9TdW",
        "outputId": "133b3601-4af7-4929-e660-589708f64969",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token: T\n",
            "Tensor index: 11\n",
            "One-hot vector: tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Token: {tokenized_text[3]}\")\n",
        "print(f\"Tensor index: {input_ids[3]}\")\n",
        "print(f\"One-hot vector: {one_hot_encodings[3]}\")"
      ],
      "metadata": {
        "id": "wAwQ9t4f9w4v",
        "outputId": "de97cebb-3b73-4555-b4ec-fef4c1069c6a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Token: e\n",
            "Tensor index: 4\n",
            "One-hot vector: tensor([0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From our simple example, we can see that character-level tokenization ignores any structure in the texts such as words and treats them just as streams of characters. Although this helps deal with misspellings and rare words, the main drawback is that linguistic structures such as words\n",
        "need to be learned, and that process requires significant compute and memory.\n",
        "\n",
        "For this reason, character tokenization is rarely used in practice. Instead, some structure of the text such as\n",
        "words is preserved during the tokenization step."
      ],
      "metadata": {
        "id": "pSUMdeBO_AOY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Word Tokenization"
      ],
      "metadata": {
        "id": "vwTX9OJk_MIf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instead of splitting the text into characters, we can split it into words and map each word to an\n",
        "integer. By using words from the outset, the model can skip the step of learning words from\n",
        "characters and thereby eliminate complexity from the training process.\n",
        "\n",
        "One simple class of word tokenizers uses whitespaces to tokenize the text. We can do this by\n",
        "applying Python’s split function directly on the raw text:"
      ],
      "metadata": {
        "id": "lRmigE9s_S7h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized_text = text.split()\n",
        "print(tokenized_text)"
      ],
      "metadata": {
        "id": "XxSp1zecOKXv",
        "outputId": "e31f2a01-2a5e-4209-bcd4-51a3f9b7a416",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Tokenizing', 'text', 'is', 'a', 'core', 'task', 'of', 'NLP.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "However, we can already see one potential problem with this\n",
        "tokenization scheme; punctuation is not accounted for, so NLP. is treated as a single token.\n",
        "Given that words can include declinations, conjugations, or misspellings, the size of the\n",
        "vocabulary can easily grow into the millions!\n",
        "\n",
        "Words that are not part of the vocabulary are classified as “unknown” and\n",
        "mapped to a shared UNK token. This means that we lose some potentially important information\n",
        "in the process of word tokenization since the model has no information about which words\n",
        "were associated with the UNK tokens.\n",
        "\n",
        "Wouldn’t it be nice if there was a compromise between character and word tokenization that\n",
        "preserves all input information and some of the input structure?"
      ],
      "metadata": {
        "id": "6r2xX0zrOrZ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Subword Tokenization"
      ],
      "metadata": {
        "id": "U4O6LxG5PZ4e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The idea behind subword tokenization is to take the best of both worlds from character and\n",
        "word tokenization. On one hand, we want to use characters since they allow the model to deal\n",
        "with rare character combinations and misspellings. On the other hand, we want to keep frequent\n",
        "words and word parts as unique entities.\n",
        "\n",
        "There are several subword tokenization algorithms such as Byte-Pair-Encoding, WordPiece,\n",
        "Unigram, and SentencePiece. Most of them adopt a similar strategy:\n",
        "\n",
        "- Simple tokenization\n",
        "  The text corpus is split into words, usually according to whitespace and punctuation rules.\n",
        "- Counting\n",
        "  - All the words in the corpus are counted and the tally is stored.\n",
        "- Splitting\n",
        "  - The words in the tally are split into subwords. Initially these are characters.\n",
        "- Subword pairs counting\n",
        "  - Using the tally, the subword pairs are counted.\n",
        "-Merging\n",
        "  - Based on a rule, some of the subword pairs are merged in the corpus.\n",
        "- Stopping\n",
        "  - The process is stopped when a predefined vocabulary size is reached.\n",
        "\n",
        "The main distinguishing feature of subword tokenization (as well as word\n",
        "tokenization) is that it is learned from the corpus used for pretraining."
      ],
      "metadata": {
        "id": "r5MbwQnWPcN4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Using Pretrained Tokenizers"
      ],
      "metadata": {
        "id": "BWYtppgoSRXZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We’ve noted that loading the right pretrained tokenizer for a given pretrained model is crucial\n",
        "to getting sensible results. \n",
        "\n",
        "The Transformers library provides a convenient\n",
        "`from_pretrained` function that can be used to load both objects, either from the Hugging Face Model Hub or from a local path.\n",
        "\n",
        "To build our emotion detector we’ll use a BERT variant called DistilBERT, which is a\n",
        "downscaled version of the original BERT model. The main advantage of this model is that it\n",
        "achieves comparable performance to BERT while being significantly smaller and more\n",
        "efficient.\n",
        "\n",
        "Let’s get started by loading the tokenizer for the DistilBERT model."
      ],
      "metadata": {
        "id": "pjS47tMWSTjS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_name = \"distilbert-base-uncased\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)"
      ],
      "metadata": {
        "id": "u8Wank0tTsM1",
        "outputId": "83e39aff-7026-41f8-f250-e8ff6fb9e29d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0,
          "referenced_widgets": [
            "cf7960614a71479794150e72870d1ccf",
            "9d2a36e468064e6daa96981c441f0c05",
            "61f6800b86f846b3ac848f3253d1f583",
            "9812bda3566f41c3a1a9530e7fe5d8d7",
            "2ab17062e37a46cba4b1747f5eed47e1",
            "e36cc434711948ff97806f1004580fd0",
            "a8a896a9acae47fa8f7beecd44b6e9e4",
            "4923c4ff92d64e9380451e0cff8bda40",
            "a3270593b7cc48df94d754aba5b03615",
            "22c858159caf4dc3855ce1f38ac780c6",
            "9a2b26b43ac84fd59339c419329f5cc8",
            "5413f7c3c0f44d7991efd2f45b7d11fb",
            "1445d05a9c4e4fcd9ea95ddeb23cec26",
            "3aa83dc3a99f42599314f7931505a098",
            "93a41c6fdc494312b08eed775f204c29",
            "6ea43399fa2040a9856a6435ef801b00",
            "3af53bdc2a1f4b60a1e2e357b2bd05c8",
            "ca1e22a243fa45ca84ad3aa66274f221",
            "06bd74dcd2dd45fe9509f12a0d190e6c",
            "4e174def61fe4a0199b3e4188e8c1d5d",
            "50dc2e87bf784142a3ca8b0054a12b48",
            "9965cf77a2c94980aa3936c177926922",
            "59f3b3b241e64a19ab9332436d6c0696",
            "fa5b1b0847bb4eb590eff0ec01c100ed",
            "440ddb31e8194da389b5702f4434d554",
            "0de30715a7ea43c0b190246110f79504",
            "421fdd2faa534637b5e73ed941c58c81",
            "d55517e4728a4a4aa840b9af69c2ed07",
            "a1549cabeaf6473cab78685db76dea78",
            "dbc945b97abd48fc9147750690aa25b6",
            "95bd219cc7ac47f79b5b5e883e44ba60",
            "fefe770cd9f1446ba2f5ae266fd71aca",
            "9acf2c022e0744ada07f04ef1e292a0c",
            "f0aa0d3c4d11465d8a16813e059516b8",
            "921677de21644bbbb458d6b785701f92",
            "8ea2a3e5d3f144ec9dff3c99330efb09",
            "b501dacee4894bbd81cc5592dfa398a2",
            "c38698443de64cf4b01943a19c76bf5f",
            "6ef5a1b7d84a4393b880253c2d7c0f55",
            "a09c268e416e4cafa54e4e8ad25c83d9",
            "0169a0864a3043408e906d484d5cee2c",
            "17f79c95891545c0948b3cbb26f45fb0",
            "3c400f9608084825a9b82d8ced381636",
            "c45e12f6963b4172af8c9372ddbd5b49"
          ]
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cf7960614a71479794150e72870d1ccf",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5413f7c3c0f44d7991efd2f45b7d11fb",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/483 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "59f3b3b241e64a19ab9332436d6c0696",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/226k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f0aa0d3c4d11465d8a16813e059516b8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/455k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can examine a few attributes of the tokenizer such as the vocabulary size:"
      ],
      "metadata": {
        "id": "TrCVX20XUG-e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.vocab_size"
      ],
      "metadata": {
        "id": "oH6fi04CUHa0",
        "outputId": "49d98104-73f9-46c4-fe97-f57c32add0bd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30522"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also look at the special tokens used by the tokenizer, which differ from model to model.\n",
        "\n",
        "For example, BERT uses the `[MASK]` token for the primary objective of masked language\n",
        "modeling and the `[CLS]` and `[SEP]` tokens for the secondary pretraining objective of\n",
        "predicting if two sentences are consecutive:"
      ],
      "metadata": {
        "id": "pJrNRmAZUdkK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.special_tokens_map"
      ],
      "metadata": {
        "id": "sO837NxFUkvz",
        "outputId": "1d4db19e-0862-4d9a-e4f5-c605d5291cf7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'cls_token': '[CLS]',\n",
              " 'mask_token': '[MASK]',\n",
              " 'pad_token': '[PAD]',\n",
              " 'sep_token': '[SEP]',\n",
              " 'unk_token': '[UNK]'}"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Furthermore, the tokenizer stores the information of the corresponding model’s maximum\n",
        "context sizes:"
      ],
      "metadata": {
        "id": "eGt9oLXpUxeT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.model_max_length"
      ],
      "metadata": {
        "id": "1iFI3vCwUx8o",
        "outputId": "1cda571d-a16c-4e84-b720-b964254fa599",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "512"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lets examine how the encoding and decoding of strings works in practice by first encoding a\n",
        "test string:"
      ],
      "metadata": {
        "id": "rKsTAXGPU6lV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_str = tokenizer.encode(\"this is a complicatedtest\")\n",
        "encoded_str"
      ],
      "metadata": {
        "id": "xDlB8n3HU7Bz",
        "outputId": "17b89c4c-b43e-44f7-84b8-47726cf9786f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[101, 2023, 2003, 1037, 8552, 22199, 102]"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that the 4 input words have been mapped to seven integers. When we feed these\n",
        "values to the model, they are mapped into a one-hot vector in a manner. \n",
        "\n",
        "We can then translate the numerical tokens back using the\n",
        "decoder:"
      ],
      "metadata": {
        "id": "Wy8DKKxyWXZH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for token in encoded_str:\n",
        "  print(token, tokenizer.decode([token]))"
      ],
      "metadata": {
        "id": "lR2x6uB5WaeQ",
        "outputId": "ac95c3fd-c669-40cd-a91f-2e159a0932e9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "101 [CLS]\n",
            "2023 this\n",
            "2003 is\n",
            "1037 a\n",
            "8552 complicated\n",
            "22199 ##test\n",
            "102 [SEP]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can observe two things. First, the `[CLS]` and `[SEP]` tokens have been added\n",
        "automatically to the start and end of the sequence, and second, the long word\n",
        "`complicatedtest` has been split into two tokens. The `##` prefix in `##test` signifies that\n",
        "the preceding string is not a whitespace and that it should be merged with the previous token."
      ],
      "metadata": {
        "id": "pc7PWTt8Wu_F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_str = tokenizer.encode(\"this is a complicated test\")\n",
        "encoded_str"
      ],
      "metadata": {
        "id": "gwaSgK8MW0z7",
        "outputId": "3545b843-c298-4615-8a05-df498be53d9c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[101, 2023, 2003, 1037, 8552, 3231, 102]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for token in encoded_str:\n",
        "  print(token, tokenizer.decode([token]))"
      ],
      "metadata": {
        "id": "GP1wBgWfW7pl",
        "outputId": "3f4a1b93-7a7d-49ea-e340-a225d04bf4f0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "101 [CLS]\n",
            "2023 this\n",
            "2003 is\n",
            "1037 a\n",
            "8552 complicated\n",
            "3231 test\n",
            "102 [SEP]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Training a Text Classifier"
      ],
      "metadata": {
        "id": "O8-EPEmTXMQ5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "BERT models are pretrained to predict masked words in a sequence\n",
        "of text. However, we can’t use these language models directly for text classification, so instead\n",
        "we need to modify them slightly.\n",
        "\n",
        "<img src='https://github.com/rahiakela/transformers-research-and-practice/blob/main/natural-language-processing-with-transformers/02-text-classification/images/1.png?raw=1' width='800'/>\n",
        "\n",
        "First, the text is tokenized and represented as one-hot vectors whose dimension is the size of\n",
        "the tokenizer vocabulary, usually consisting of 50k-100k unique tokens. \n",
        "\n",
        "Next, these token\n",
        "encodings are embedded in lower dimensions and passed through the encoder block layers to\n",
        "yield a hidden state for each input token. \n",
        "\n",
        "For the pretraining objective of language modeling,\n",
        "each hidden state is connected to a layer that predicts the token for the input token, which is\n",
        "only non-trivial if the input token was masked. \n",
        "\n",
        "For the classification task, we replace the\n",
        "language modeling layer with a classification layer. BERT sequences always start with a\n",
        "classification token `[CLS]`, therefore we use the hidden state for the classification token as\n",
        "input for our classification layer.\n",
        "\n",
        "We have two options to train such a model on our Twitter dataset:\n",
        "- Feature extraction\n",
        "  - We use the hidden states as features and just train a classifier on them.\n",
        "- Fine-tuning\n",
        "  - We train the whole model end-to-end, which also updates the parameters of the pretrained BERT model.\n",
        "\n",
        "In this section we explore both options for DistilBert and examine their trade-offs."
      ],
      "metadata": {
        "id": "zLPTXZ6OXM4r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Transformers as Feature Extractors"
      ],
      "metadata": {
        "id": "H3ubA-LmZtoM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To use a Transformer as a feature extractor is fairly simple;we freeze\n",
        "the body’s weights during training and use the hidden states as features for the classifier. \n",
        "\n",
        "The advantage of this approach is that we can quickly train a small or shallow model. Such a model\n",
        "could be a neural classification layer or a method that does not rely on gradients such a Random Forest. \n",
        "\n",
        "This method is especially convenient if GPUs are unavailable since the hidden\n",
        "states can be computed relatively fast on a CPU.\n",
        "\n",
        "<img src='https://github.com/rahiakela/transformers-research-and-practice/blob/main/natural-language-processing-with-transformers/02-text-classification/images/2.png?raw=1' width='800'/>\n",
        "\n",
        "The feature-based method relies on the assumption that the hidden states capture all the\n",
        "information necessary for the classification task. However, if some information is not required\n",
        "for the pretraining task, it may not be encoded in the hidden state, even if it would be crucial\n",
        "for the classification task. \n",
        "\n",
        "In this case the classification model has to work with suboptimal\n",
        "data, and it is better to use the fine-tuning approach."
      ],
      "metadata": {
        "id": "37VM1KwmZxxE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Using Pretrained Models"
      ],
      "metadata": {
        "id": "t-jSca37hvyr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we want to avoid training a model from scratch we will also use the\n",
        "`from_pretrained` function from Transformers to load a pretrained DistilBERT model:"
      ],
      "metadata": {
        "id": "CtbAp2o7hwoI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = AutoModel.from_pretrained(model_name).to(device)"
      ],
      "metadata": {
        "id": "eTal_KxliCOm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `AutoModel` class corresponds to the input encoder that translates the one-hot vectors to\n",
        "embeddings with positional encodings and feeds them through the encoder stack to return the\n",
        "hidden states. \n",
        "\n",
        "The language model head that takes the hidden states and decodes them to the\n",
        "masked token prediction is excluded since it is only needed for pretraining. \n",
        "\n",
        "If you want to use\n",
        "that model head you can load the complete model with `AutoModelForMaskedLM`."
      ],
      "metadata": {
        "id": "XOpGCY3-jLA9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Extracting the Last Hidden States"
      ],
      "metadata": {
        "id": "DWdSpDUNjZyu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To warm up, let’s retrieve the last hidden states for a single string. To do that we first need to\n",
        "tokenize the string."
      ],
      "metadata": {
        "id": "JRmzyYa3japM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text = \"this is a test\"\n",
        "text_tensor = tokenizer.encode(text, return_tensors=\"pt\").to(device)"
      ],
      "metadata": {
        "id": "hfZzNpyqjesF"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The resulting tensor has the shape `[batch_size, n_tokens]`:"
      ],
      "metadata": {
        "id": "9_8YEsxQj3Fi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "text_tensor.shape"
      ],
      "metadata": {
        "id": "C-_PGg8wj42X",
        "outputId": "bd83ea4d-2d12-455e-cbc2-f5c73cefa536",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can now pass this tensor to the model to extract the hidden states. Depending on the model\n",
        "configuration, the output can contain several objects such as the hidden states, losses, or\n",
        "attentions, that are arranged in a class that is similar to a namedtuple in Python.\n",
        "\n",
        "In our\n",
        "example, the model output is a Python dataclass called BaseModelOutput, and like any\n",
        "class, we can access the attributes by name. Since the current model returns only one entry\n",
        "which is the last hidden state, let’s pass the encoded text and examine the outputs:"
      ],
      "metadata": {
        "id": "UbMLLf6Skjwd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "output = model(text_tensor)\n",
        "output.last_hidden_state.shape"
      ],
      "metadata": {
        "id": "EmWQ7lJOkw6-",
        "outputId": "cb9e492a-de0c-4ff9-9f38-7b01b19718be",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 6, 768])"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Looking at the hidden state tensor we see that it has the shape `[batch_size, n_tokens, hidden_dim]`. \n",
        "\n",
        "The way BERT works is that a hidden state is returned for each input, and the\n",
        "model uses these hidden states to predict masked tokens in the pretraining task. \n",
        "\n",
        "For\n",
        "classification tasks, it is common practice to use the hidden state associated with the `[CLS]`\n",
        "token as the input feature, which is located at the first position in the second dimension."
      ],
      "metadata": {
        "id": "tXHZsKB_lKEn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Tokenizing the Whole Dataset"
      ],
      "metadata": {
        "id": "shtT4Bj4lUB_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we know how to extract the hidden states for a single string, let’s tokenize the whole\n",
        "dataset! \n",
        "\n",
        "To do this, we can write a simple function that will tokenize our examples"
      ],
      "metadata": {
        "id": "Kdrpk38HlWrw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize(batch):\n",
        "  return tokenizer(batch[\"text\"], padding=True, truncation=True)"
      ],
      "metadata": {
        "id": "GdOcTdJLoIJU"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "where `padding=True` will pad the examples with zeroes to the longest one in a batch, and\n",
        "`truncation=True` will truncate the examples to the model’s maximum context size.\n",
        "\n",
        "Previously, we set the output format of the dataset to \"pandas\" so that the accessed data is\n",
        "returned as a DataFrame. \n",
        "\n",
        "We don’t need this output format anymore so we can now reset it\n",
        "as follows:"
      ],
      "metadata": {
        "id": "ER1JlJCwoaGt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "emotions.reset_format()"
      ],
      "metadata": {
        "id": "3zWH5GQtol1g"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "By applying the tokenize function on a small set of texts."
      ],
      "metadata": {
        "id": "o4W8yVHeorST"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenize(emotions[\"train\"][:3])"
      ],
      "metadata": {
        "id": "rDx3_qxPor8o",
        "outputId": "78f8bac3-61c0-499c-ced6-b3147ae67ef4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [[101, 1045, 2134, 2102, 2514, 26608, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [101, 1045, 2064, 2175, 2013, 3110, 2061, 20625, 2000, 2061, 9636, 17772, 2074, 2013, 2108, 2105, 2619, 2040, 14977, 1998, 2003, 8300, 102], [101, 10047, 9775, 1037, 3371, 2000, 2695, 1045, 2514, 20505, 3308, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]}"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "we see that the result is a dictionary, where each value is a list of lists generated by the\n",
        "tokenizer. In particular, each sequence in input_ids starts with 101 and ends with 102,\n",
        "followed by zeroes, corresponding to the `[CLS], [SEP]`, and `[PAD]` tokens respectively:\n",
        "\n",
        "<img src='https://github.com/rahiakela/transformers-research-and-practice/blob/main/natural-language-processing-with-transformers/02-text-classification/images/3.png?raw=1' width='800'/>\n",
        "\n",
        "Also note that in addition to returning the encoded tweets as input_ids, the tokenizer also\n",
        "returns list of attention_mask arrays. This is because we do not want the model to get\n",
        "confused by the additional padding tokens, so the attention mask allows the model to ignore the\n",
        "padded parts of the input.\n",
        "\n",
        "<img src='https://github.com/rahiakela/transformers-research-and-practice/blob/main/natural-language-processing-with-transformers/02-text-classification/images/4.png?raw=1' width='800'/>\n",
        "\n",
        ">For each batch, the input sequences are padded to the maximum sequence length in the batch. The attention mask is used in the model to ignore the padded areas of the input tensors.\n",
        "\n",
        "To apply our tokenize function to the whole emotions corpus, we’ll use the\n",
        "DatasetDict.map function. \n",
        "\n",
        "This will apply tokenize across all the splits in the corpus,\n",
        "so our training, validation and test data will be preprocessed in a single line of code:"
      ],
      "metadata": {
        "id": "mEE7AMU1pAbD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# batch_size=None applies our tokenize function in one single batch and ensures that the input tensors and attention masks have the same shape globally\n",
        "emotions_encoded = emotions.map(tokenize, batched=True, batch_size=None)"
      ],
      "metadata": {
        "id": "1gcxWkgdrzFs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "By default, `DatasetDict.map` operates individually on every example in the corpus, so setting `batched=True` will encode the tweets in batches, while `batch_size=None` applies our tokenize function in one single batch and ensures that the input tensors and attention masks have the same shape globally. \n",
        "\n",
        "We can see that this operation has added two new features to the dataset: `input_ids` and the `attention mask`."
      ],
      "metadata": {
        "id": "MwdkqczIsU8k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "emotions_encoded[\"train\"].features"
      ],
      "metadata": {
        "id": "GOobcJtBo_3Z",
        "outputId": "7a824c9d-d9d5-441a-a139-b4e2426eb3e3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'attention_mask': Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None),\n",
              " 'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None),\n",
              " 'label': ClassLabel(num_classes=6, names=['sadness', 'joy', 'love', 'anger', 'fear', 'surprise'], names_file=None, id=None),\n",
              " 'text': Value(dtype='string', id=None)}"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emotions_encoded[\"train\"].features[\"attention_mask\"]"
      ],
      "metadata": {
        "id": "DvKyMMTKtFKe",
        "outputId": "02e834c1-689e-47b6-eeb8-0583b21e56f4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequence(feature=Value(dtype='int8', id=None), length=-1, id=None)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emotions_encoded[\"train\"].features[\"input_ids\"]"
      ],
      "metadata": {
        "id": "EF0UsdCatJdW",
        "outputId": "bf2b21d9-59e5-4fe7-c8bb-1328a7978485",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None)"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emotions_encoded[\"train\"].features[\"label\"]"
      ],
      "metadata": {
        "id": "64MG2ANytMPV",
        "outputId": "545fee62-db0a-4b34-d63e-34199fea78c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ClassLabel(num_classes=6, names=['sadness', 'joy', 'love', 'anger', 'fear', 'surprise'], names_file=None, id=None)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "emotions_encoded[\"train\"].features[\"text\"]"
      ],
      "metadata": {
        "id": "cOrJJqjItPYH",
        "outputId": "41a8ed0c-6b12-4387-85b8-767e897bcad2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Value(dtype='string', id=None)"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####From Input IDs to Hidden States"
      ],
      "metadata": {
        "id": "U0CjD5M5tDUR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "PqTF5IH8tEVh"
      }
    }
  ]
}