{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "summarization.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMC5OvjvQjOiSNiQiMjcdRy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/transformers-research-and-practice/blob/main/natural-language-processing-with-transformers/06-summarization/summarization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Summarization"
      ],
      "metadata": {
        "id": "yec-35M4BWvO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Text summarization is a\n",
        "difficult task for neural language models, including transformers. Despite these challenges,\n",
        "text summarization offers the prospect for domain experts to significantly\n",
        "speed up their workflows and is used by enterprises to condense internal knowledge,\n",
        "summarize contracts, automatically generate content for social media releases,\n",
        "and more.\n",
        "\n",
        "Summarization is a classic\n",
        "sequence-to-sequence (seq2seq) task with an input text and a target text."
      ],
      "metadata": {
        "id": "dfFj2oRmBXpd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Setup"
      ],
      "metadata": {
        "id": "0jROG17wBazd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install transformers[sentencepiece]\n",
        "!pip -q install datasets\n",
        "!pip -q install sacrebleu\n",
        "!pip -q install rouge_score\n",
        "!pip -q install py7zr"
      ],
      "metadata": {
        "id": "ojHJ4FhvBb7V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline, set_seed\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "from transformers import DataCollatorForSeq2Seq\n",
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "from datasets import load_dataset, load_metric\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "dIrfRuBsBibh"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
      ],
      "metadata": {
        "id": "NAO6MfducoWT"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download(\"punkt\")"
      ],
      "metadata": {
        "id": "s7nIfW88cegm",
        "outputId": "e4419088-d607-4e26-a65b-815f61db71b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##CNN/DailyMail Dataset"
      ],
      "metadata": {
        "id": "qBE7AF9bD1Wx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The CNN/DailyMail dataset consists of around 300,000 pairs of news articles and\n",
        "their corresponding summaries, composed from the bullet points that CNN and the\n",
        "DailyMail attach to their articles.\n",
        "\n",
        "An important aspect of the dataset is that the summaries are abstractive and not extractive, which means that they consist of new\n",
        "sentences instead of simple excerpts.\n",
        "\n",
        "We’ll use version 3.0.0, which is a nonanonymized version set up for summarization."
      ],
      "metadata": {
        "id": "5IQkUfASD2Kw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"cnn_dailymail\", version=\"3.0.0\")"
      ],
      "metadata": {
        "id": "le4s8kDKEMwp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Features: {dataset['train'].column_names}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hlgyxXqHE5BQ",
        "outputId": "71f71011-ffe1-4b8c-a5c2-965c69a6deab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features: ['article', 'highlights', 'id']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s look at an excerpt from an article:"
      ],
      "metadata": {
        "id": "liZjNQ2KFA9w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample = dataset[\"train\"][1]\n",
        "\n",
        "print(f\"\"\"Article (excerpt of 500 characters, total length: {len(sample['article'])})\"\"\")\n",
        "print(sample[\"article\"])\n",
        "\n",
        "print(f\"\\nSummary (length: {len(sample['highlights'])})\")\n",
        "print(sample[\"highlights\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nKLCJt-wFC49",
        "outputId": "fe33fa7f-73c2-4e5c-88a4-e99ef77f66ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Article (excerpt of 500 characters, total length: 3192)\n",
            "(CNN) -- Usain Bolt rounded off the world championships Sunday by claiming his third gold in Moscow as he anchored Jamaica to victory in the men's 4x100m relay. The fastest man in the world charged clear of United States rival Justin Gatlin as the Jamaican quartet of Nesta Carter, Kemar Bailey-Cole, Nickel Ashmeade and Bolt won in 37.36 seconds. The U.S finished second in 37.56 seconds with Canada taking the bronze after Britain were disqualified for a faulty handover. The 26-year-old Bolt has now collected eight gold medals at world championships, equaling the record held by American trio Carl Lewis, Michael Johnson and Allyson Felix, not to mention the small matter of six Olympic titles. The relay triumph followed individual successes in the 100 and 200 meters in the Russian capital. \"I'm proud of myself and I'll continue to work to dominate for as long as possible,\" Bolt said, having previously expressed his intention to carry on until the 2016 Rio Olympics. Victory was never seriously in doubt once he got the baton safely in hand from Ashmeade, while Gatlin and the United States third leg runner Rakieem Salaam had problems. Gatlin strayed out of his lane as he struggled to get full control of their baton and was never able to get on terms with Bolt. Earlier, Jamaica's women underlined their dominance in the sprint events by winning the 4x100m relay gold, anchored by Shelly-Ann Fraser-Pryce, who like Bolt was completing a triple. Their quartet recorded a championship record of 41.29 seconds, well clear of France, who crossed the line in second place in 42.73 seconds. Defending champions, the United States, were initially back in the bronze medal position after losing time on the second handover between Alexandria Anderson and English Gardner, but promoted to silver when France were subsequently disqualified for an illegal handover. The British quartet, who were initially fourth, were promoted to the bronze which eluded their men's team. Fraser-Pryce, like Bolt aged 26, became the first woman to achieve three golds in the 100-200 and the relay. In other final action on the last day of the championships, France's Teddy Tamgho became the third man to leap over 18m in the triple jump, exceeding the mark by four centimeters to take gold. Germany's Christina Obergfoll finally took gold at global level in the women's javelin after five previous silvers, while Kenya's Asbel Kiprop easily won a tactical men's 1500m final. Kiprop's compatriot Eunice Jepkoech Sum was a surprise winner of the women's 800m. Bolt's final dash for golden glory brought the eight-day championship to a rousing finale, but while the hosts topped the medal table from the United States there was criticism of the poor attendances in the Luzhniki Stadium. There was further concern when their pole vault gold medalist Yelena Isinbayeva made controversial remarks in support of Russia's new laws, which make \"the propagandizing of non-traditional sexual relations among minors\" a criminal offense. She later attempted to clarify her comments, but there were renewed calls by gay rights groups for a boycott of the 2014 Winter Games in Sochi, the next major sports event in Russia.\n",
            "\n",
            "Summary (length: 180)\n",
            "Usain Bolt wins third gold of world championship .\n",
            "Anchors Jamaica to 4x100m relay victory .\n",
            "Eighth gold at the championships for Bolt .\n",
            "Jamaica double up in women's 4x100m relay .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see that the articles can be very long compared to the target summary; in this particular\n",
        "case the difference is 17-fold.\n",
        "\n",
        "Long articles pose a challenge to most transformer\n",
        "models since the context size is usually limited to 1,000 tokens or so, which is\n",
        "equivalent to a few paragraphs of text. The standard, yet crude way to deal with this\n",
        "for summarization is to simply truncate the texts beyond the model’s context size."
      ],
      "metadata": {
        "id": "I3uztDnPIwQN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Text Summarization Pipelines"
      ],
      "metadata": {
        "id": "PXn-s8xdI3n-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s see how a few of the most popular transformer models for summarization perform\n",
        "by first looking qualitatively at the outputs for the preceding example."
      ],
      "metadata": {
        "id": "AIIQn9SpI4V1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_text = dataset[\"train\"][1][\"article\"][:2000]  # restrict the input text to 2,000 characters\n",
        "\n",
        "# We'll collect the generated summaries of each model in a dictionary\n",
        "summaries = {}"
      ],
      "metadata": {
        "id": "KQoxjDP1buCn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's differentiate the end of a sentence\n",
        "from punctuation that occurs in abbreviations"
      ],
      "metadata": {
        "id": "MUPpd8ctcWbt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "string = \"The U.S. are a country. The U.N. is an organization.\"\n",
        "sent_tokenize(string)"
      ],
      "metadata": {
        "id": "rCISIlGjcXxg",
        "outputId": "ebe9b7df-bacb-45ff-93e7-b9da32509906",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The U.S. are a country.', 'The U.N. is an organization.']"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Summarization Baseline"
      ],
      "metadata": {
        "id": "F2uP4JYIcr19"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A common baseline for summarizing news articles is to simply take the first three\n",
        "sentences of the article."
      ],
      "metadata": {
        "id": "M8FG9t65ctFT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def three_sentence_summary(text):\n",
        "  return \"\\n\".join(sent_tokenize(text)[:3])"
      ],
      "metadata": {
        "id": "o1JLfDwzc08a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summaries[\"baseline\"] = three_sentence_summary(sample_text)"
      ],
      "metadata": {
        "id": "Db3V7AmodGMQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###GPT-2"
      ],
      "metadata": {
        "id": "zq4j04_NdRsB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "One of GPT-2’s surprising features is that we can also use it to generate summaries\n",
        "by simply appending `TL;DR` at the end of the input text. \n",
        "\n",
        "The expression `TL;DR` (too long; didn’t read) is often used on platforms like Reddit to indicate a short version\n",
        "of a long post."
      ],
      "metadata": {
        "id": "1XT8F5eadSc1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed(42)\n",
        "\n",
        "pipe = pipeline(\"text-generation\", model=\"gpt2\")\n",
        "\n",
        "gpt2_query = sample_text + \"\\nTL;DR:\\n\"\n",
        "pipe_out = pipe(gpt2_query, max_length=512, clean_up_tokenization_spaces=True)\n",
        "summaries[\"gpt2\"] = \"\\n\".join(sent_tokenize(pipe_out[0][\"generated_text\"][len(gpt2_query):]))"
      ],
      "metadata": {
        "id": "1003nJfrfCew",
        "outputId": "9cb2b80c-2431-4cef-93a8-75eba15894a9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###T5"
      ],
      "metadata": {
        "id": "ENKDRNdKgCkv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next let’s try the T5 transformer.\n",
        "\n",
        "The T5 checkpoints are trained on a mixture of unsupervised data (to\n",
        "reconstruct masked words) and supervised data for several tasks, including summarization.\n",
        "These checkpoints can thus be directly used to perform summarization\n",
        "without fine-tuning by using the same prompts used during pretraining.\n",
        "\n",
        "In this\n",
        "framework, the input format for the model to summarize a document is \"summarize:`<ARTICLE>`\", and for translation it looks like \"translate English to German:`<TEXT>`\"."
      ],
      "metadata": {
        "id": "2IQUpmWSgD2W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipeline(\"summarization\", model=\"t5-large\")\n",
        "\n",
        "pipe_out = pipe(sample_text)\n",
        "summaries[\"t5\"] = \"\\n\".join(sent_tokenize(pipe_out[0][\"summary_text\"]))"
      ],
      "metadata": {
        "id": "jRG5kmMRgj6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###BART"
      ],
      "metadata": {
        "id": "0mCTi_o0g502"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "BART also uses an encoder-decoder architecture and is trained to reconstruct corrupted inputs. It combines the pretraining schemes of BERT and GPT-2."
      ],
      "metadata": {
        "id": "DMA8SiSEg6qi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
        "\n",
        "pipe_out = pipe(sample_text)\n",
        "summaries[\"bart\"] = \"\\n\".join(sent_tokenize(pipe_out[0][\"summary_text\"]))"
      ],
      "metadata": {
        "id": "qJbRf5vthAtQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###PEGASUS"
      ],
      "metadata": {
        "id": "8bqGB7PuhOac"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Like BART, PEGASUS is an encoder-decoder transformer.its pretraining objective is to predict masked sentences in multisentence texts.\n",
        "\n",
        "The\n",
        "authors argue that the closer the pretraining objective is to the downstream task, the\n",
        "more effective it is. \n",
        "\n",
        "With the aim of finding a pretraining objective that is closer to\n",
        "summarization than general language modeling, they automatically identified, in a\n",
        "very large corpus, sentences containing most of the content of their surrounding\n",
        "paragraphs (using summarization evaluation metrics as a heuristic for content\n",
        "overlap) and pretrained the PEGASUS model to reconstruct these sentences, thereby\n",
        "obtaining a state-of-the-art model for text summarization.\n",
        "\n"
      ],
      "metadata": {
        "id": "32jotqkYhPMk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipeline(\"summarization\", model=\"google/pegasus-cnn_dailymail\")\n",
        "\n",
        "pipe_out = pipe(sample_text)\n",
        "summaries[\"pegasus\"] = pipe_out[0][\"summary_text\"].replace(\" .<n>\", \".\\n\")"
      ],
      "metadata": {
        "id": "imIO1Rdfiqe8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Comparing Different Summaries"
      ],
      "metadata": {
        "id": "r_VaWZ1bjFEc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have generated summaries with four different models, let’s compare the results.\n",
        "\n",
        "Keep in mind that one model has not been trained on the dataset at all\n",
        "(GPT-2), one model has been fine-tuned on this task among others (T5), and two\n",
        "models have exclusively been fine-tuned on this task (BART and PEGASUS).\n",
        "\n",
        "Let’s\n",
        "have a look at the summaries these models have generated:"
      ],
      "metadata": {
        "id": "6UBEAHomjH_e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"GROUND TRUTH\")\n",
        "print(dataset[\"train\"][1][\"highlights\"])\n",
        "print(\"\")\n",
        "\n",
        "for model_name in summaries:\n",
        "  print(model_name.upper())\n",
        "  print(\"-----------------------------------\")\n",
        "  print(summaries[model_name])\n",
        "  print(\"\")"
      ],
      "metadata": {
        "id": "fBv8k5aLmIcf",
        "outputId": "6b4221d3-b55d-4f23-86fa-391a742ea39a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GROUND TRUTH\n",
            "Usain Bolt wins third gold of world championship .\n",
            "Anchors Jamaica to 4x100m relay victory .\n",
            "Eighth gold at the championships for Bolt .\n",
            "Jamaica double up in women's 4x100m relay .\n",
            "\n",
            "BASELINE\n",
            "-----------------------------------\n",
            "(CNN) -- Usain Bolt rounded off the world championships Sunday by claiming his third gold in Moscow as he anchored Jamaica to victory in the men's 4x100m relay.\n",
            "The fastest man in the world charged clear of United States rival Justin Gatlin as the Jamaican quartet of Nesta Carter, Kemar Bailey-Cole, Nickel Ashmeade and Bolt won in 37.36 seconds.\n",
            "The U.S finished second in 37.56 seconds with Canada taking the bronze after Britain were disqualified for a faulty handover.\n",
            "\n",
            "GPT2\n",
            "-----------------------------------\n",
            "Usain Bolt triumphed after a difficult final, but then he got into trouble when Canada made him try to block.\n",
            "It's the last match he's held all of last year with the men, who were later picked in the third and fourth rounds of the men's 100m and 200m and at Rio-Gold.\n",
            "UPDATE - November 8 - Team USA won in 36.36,\n",
            "\n",
            "T5\n",
            "-----------------------------------\n",
            "usain bolt wins his third gold medal of the world championships in the men's 4x100m relay .\n",
            "the 26-year-old anchored Jamaica to victory in the event in the Russian capital .\n",
            "he has now collected eight gold medals at the championships, equaling the record .\n",
            "\n",
            "BART\n",
            "-----------------------------------\n",
            "Usain Bolt wins his third gold of the world championships in Moscow.\n",
            "Bolt anchors Jamaica to victory in the men's 4x100m relay.\n",
            "The 26-year-old has now won eight gold medals at world championships.\n",
            "Jamaica's women also win gold in the relay, beating France in the process.\n",
            "\n",
            "PEGASUS\n",
            "-----------------------------------\n",
            "Usain Bolt wins third gold of world championships.\n",
            "Anchors Jamaica to victory in men's 4x100m relay.\n",
            "Eighth gold at the championships for Bolt.\n",
            "Jamaica also win women's 4x100m relay .\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first thing we notice by looking at the model outputs is that the summary generated\n",
        "by GPT-2 is quite different from the others. Instead of giving a summary of the\n",
        "text, it summarizes the characters.\n",
        "\n",
        "Comparing the other three model summaries against the ground truth, we see that\n",
        "there is remarkable overlap, with PEGASUS’s output bearing the most striking\n",
        "resemblance.\n",
        "\n",
        "Now that we have inspected a few models, let’s try to decide which one we would use\n",
        "in a production setting.\n",
        "\n",
        "However, this\n",
        "is not a systematic way of determining the best model! Ideally, we would define a metric, measure it for all models on some benchmark dataset, and choose the one\n",
        "with the best performance.\n",
        "\n",
        "But how do you define a metric for text generation?\n",
        "\n",
        "The\n",
        "standard metrics that we’ve seen, like accuracy, recall, and precision, are not easy to\n",
        "apply to this task."
      ],
      "metadata": {
        "id": "ZTNXqw4am90z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Measuring the Quality of Generated Text"
      ],
      "metadata": {
        "id": "MT1h8LjunfYM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Good evaluation metrics are important, since we use them to measure the performance\n",
        "of models not only when we train them but also later, in production.\n",
        "\n",
        "Measuring performance on a text generation task is not as easy as with standard classification\n",
        "tasks such as sentiment analysis or named entity recognition.\n",
        "\n",
        "Two of the most common metrics used to evaluate generated text are **BLEU** and **ROUGE**."
      ],
      "metadata": {
        "id": "FMU9qi7wnfrS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###BLEU"
      ],
      "metadata": {
        "id": "uoeKCUCgzuH2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The idea of BLEU is simple: instead of looking at how many of the tokens in the generated texts are perfectly aligned with the reference text tokens, we look at words or n-grams. \n",
        "\n",
        "BLEU is a precision-based metric, which means that when we compare the\n",
        "two texts we count the number of words in the generation that occur in the reference and divide it by the length of the reference.\n",
        "\n",
        "The weakness of the BLEU metric is that it expects the text to already\n",
        "be tokenized. This can lead to varying results if the exact same method for text tokenization\n",
        "is not used. \n",
        "\n",
        "The SacreBLEU metric addresses this issue by internalizing the\n",
        "tokenization step; for this reason, it is the preferred metric for benchmarking."
      ],
      "metadata": {
        "id": "cD5vGy6BzvFS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bleu_metric = load_metric(\"sacrebleu\")"
      ],
      "metadata": {
        "id": "nqA3xhmv2_Wc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `bleu_metric` object is an instance of the Metric class, and works like an aggregator: you can add single instances with `add()` or whole batches via `add_batch()`."
      ],
      "metadata": {
        "id": "fcqa8LIW6pgc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bleu_metric.add(prediction=\"the the the the the the\", reference=[\"the cat is on the mat\"])\n",
        "\n",
        "results = bleu_metric.compute(smooth_method=\"floor\", smooth_value=0)\n",
        "results[\"precisions\"] = [np.round(p, 2) for p in results[\"precisions\"]]\n",
        "\n",
        "pd.DataFrame.from_dict(results, orient=\"index\", columns=[\"Value\"])"
      ],
      "metadata": {
        "id": "c0kTEETC6hrq",
        "outputId": "47ae10fb-019e-493b-d525-eef798dfc0e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                             Value\n",
              "score                          0.0\n",
              "counts                [2, 0, 0, 0]\n",
              "totals                [6, 5, 4, 3]\n",
              "precisions  [33.33, 0.0, 0.0, 0.0]\n",
              "bp                             1.0\n",
              "sys_len                          6\n",
              "ref_len                          6"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-34653454-65cd-4741-b833-1e7690572fce\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>score</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>counts</th>\n",
              "      <td>[2, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>totals</th>\n",
              "      <td>[6, 5, 4, 3]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>precisions</th>\n",
              "      <td>[33.33, 0.0, 0.0, 0.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bp</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sys_len</th>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ref_len</th>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-34653454-65cd-4741-b833-1e7690572fce')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-34653454-65cd-4741-b833-1e7690572fce button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-34653454-65cd-4741-b833-1e7690572fce');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see the precision of the 1-gram is indeed 2/6, whereas the precisions for the 2/3/4-grams are all 0.\n",
        "\n",
        "This means the geometric mean is zero, and\n",
        "thus also the BLEU score. \n",
        "\n",
        "Let’s look at another example where the prediction is\n",
        "almost correct:"
      ],
      "metadata": {
        "id": "BmIb2a_C71h0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bleu_metric.add(prediction=\"the cat is on mat\", reference=[\"the cat is on the mat\"])\n",
        "\n",
        "results = bleu_metric.compute(smooth_method=\"floor\", smooth_value=0)\n",
        "results[\"precisions\"] = [np.round(p, 2) for p in results[\"precisions\"]]\n",
        "\n",
        "pd.DataFrame.from_dict(results, orient=\"index\", columns=[\"Value\"])"
      ],
      "metadata": {
        "id": "OklcxZWU76p6",
        "outputId": "3c0a927d-0787-41fa-b977-805d3f64a0e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                 Value\n",
              "score                        57.893007\n",
              "counts                    [5, 3, 2, 1]\n",
              "totals                    [5, 4, 3, 2]\n",
              "precisions  [100.0, 75.0, 66.67, 50.0]\n",
              "bp                            0.818731\n",
              "sys_len                              5\n",
              "ref_len                              6"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9abffe9e-6750-4a54-bf40-3d791822d3f2\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>score</th>\n",
              "      <td>57.893007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>counts</th>\n",
              "      <td>[5, 3, 2, 1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>totals</th>\n",
              "      <td>[5, 4, 3, 2]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>precisions</th>\n",
              "      <td>[100.0, 75.0, 66.67, 50.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bp</th>\n",
              "      <td>0.818731</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sys_len</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ref_len</th>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9abffe9e-6750-4a54-bf40-3d791822d3f2')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9abffe9e-6750-4a54-bf40-3d791822d3f2 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9abffe9e-6750-4a54-bf40-3d791822d3f2');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We observe that the precision scores are much better. The 1-grams in the prediction\n",
        "all match, and only in the precision scores do we see that something is off.\n",
        "\n",
        "The BLEU score is widely used for evaluating text, especially in machine translation,\n",
        "since precise translations are usually favored over translations that include all possible\n",
        "and appropriate words.\n",
        "\n",
        "There are other applications, such as summarization, where the situation is different.\n",
        "There, we want all the important information in the generated text, so we favor high\n",
        "recall. \n",
        "\n",
        "This is where the ROUGE score is usually used."
      ],
      "metadata": {
        "id": "BgrOdLRu8OlZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###ROUGE"
      ],
      "metadata": {
        "id": "RdfWOsI48dwY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The ROUGE score was specifically developed for applications like summarization\n",
        "where high recall is more important than just precision.\n",
        "\n",
        "The approach is very similar\n",
        "to the BLEU score in that we look at different n-grams and compare their occurrences\n",
        "in the generated text and the reference texts. \n",
        "\n",
        "The difference is that with ROUGE we\n",
        "check how many n-grams in the reference text also occur in the generated text.\n",
        "\n",
        "In the Datasets implementation, two variations of ROUGE are calculated: \n",
        "\n",
        "* one calculates the score per sentence and averages it for the summaries (ROUGE-L)\n",
        "\n",
        "* the other calculates it directly over the whole summary (ROUGE-Lsum)."
      ],
      "metadata": {
        "id": "FfCQcp2j8fna"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rouge_metric = load_metric(\"rouge\")"
      ],
      "metadata": {
        "id": "cp5Qmm9nFR9s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s apply the ROUGE score to all the summaries generated by the models:"
      ],
      "metadata": {
        "id": "z2E0oTAQFd4G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reference = dataset[\"train\"][1][\"highlights\"]\n",
        "records = []\n",
        "rouge_names = [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"]\n",
        "\n",
        "for model_name in summaries:\n",
        "  rouge_metric.add(prediction=summaries[model_name], reference=reference)\n",
        "  score = rouge_metric.compute()\n",
        "  rouge_dict = dict((rn, score[rn].mid.fmeasure) for rn in rouge_names)\n",
        "  records.append(rouge_dict)\n",
        "\n",
        "pd.DataFrame.from_records(records, index=summaries.keys())"
      ],
      "metadata": {
        "id": "efVZNWdyH0OO",
        "outputId": "ef1b3dce-cecb-41c0-bbc5-e0352e621f8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            rouge1    rouge2    rougeL  rougeLsum\n",
              "baseline  0.303571  0.090909  0.214286   0.232143\n",
              "gpt2      0.212766  0.021739  0.127660   0.148936\n",
              "t5        0.486486  0.222222  0.378378   0.486486\n",
              "bart      0.582278  0.207792  0.455696   0.506329\n",
              "pegasus   0.866667  0.655172  0.800000   0.833333"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4fbeacf7-c949-408f-8720-bd1f87807054\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rouge1</th>\n",
              "      <th>rouge2</th>\n",
              "      <th>rougeL</th>\n",
              "      <th>rougeLsum</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>baseline</th>\n",
              "      <td>0.303571</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.214286</td>\n",
              "      <td>0.232143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gpt2</th>\n",
              "      <td>0.212766</td>\n",
              "      <td>0.021739</td>\n",
              "      <td>0.127660</td>\n",
              "      <td>0.148936</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>t5</th>\n",
              "      <td>0.486486</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>0.378378</td>\n",
              "      <td>0.486486</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bart</th>\n",
              "      <td>0.582278</td>\n",
              "      <td>0.207792</td>\n",
              "      <td>0.455696</td>\n",
              "      <td>0.506329</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pegasus</th>\n",
              "      <td>0.866667</td>\n",
              "      <td>0.655172</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.833333</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4fbeacf7-c949-408f-8720-bd1f87807054')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4fbeacf7-c949-408f-8720-bd1f87807054 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4fbeacf7-c949-408f-8720-bd1f87807054');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "These results are obviously not very reliable as we only looked at a single sample, but\n",
        "we can compare the quality of the summary for that one example.\n",
        "\n"
      ],
      "metadata": {
        "id": "HEbtaet9Jr-Q"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Evaluating PEGASUS"
      ],
      "metadata": {
        "id": "GAFmGcpjYtLC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We now have all the pieces in place to evaluate the model properly: we have a dataset\n",
        "with a test set from CNN/DailyMail, we have a metric with ROUGE, and we have a\n",
        "summarization model. We just need to put the pieces together.\n",
        "\n",
        "Let’s first evaluate the performance of the three-sentence baseline:"
      ],
      "metadata": {
        "id": "OzadUV6uYwqJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_summaries_baseline(dataset, metric, column_text=\"article\", column_summary=\"highlights\"):\n",
        "  summaries = [three_sentence_summary(text) for text in dataset[column_text]]\n",
        "  metric.add_batch(predictions=summaries, references=dataset[column_summary])\n",
        "  score = metric.compute()\n",
        "  return score"
      ],
      "metadata": {
        "id": "ASr3nlTaY8VL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since the test fraction of the\n",
        "CNN/DailyMail dataset consists of roughly 10,000 samples, generating summaries for\n",
        "all these articles takes a lot of time.\n",
        "\n",
        "For the purpose of keeping the calculations relatively\n",
        "fast, we’ll subsample the test set and run the evaluation on 1,000 samples\n",
        "instead. This should give us a much more stable score estimation while completing in\n",
        "less than one hour on a single GPU for the PEGASUS model:"
      ],
      "metadata": {
        "id": "vWyWdGQ1bfOA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_sampled = dataset[\"test\"].shuffle(seed=42).select(range(1000))\n",
        "\n",
        "score = evaluate_summaries_baseline(test_sampled, rouge_metric)\n",
        "rouge_dict = dict((rn, score[rn].mid.fmeasure) for rn in rouge_names)\n",
        "\n",
        "pd.DataFrame.from_dict(rouge_dict, orient=\"index\", columns=[\"baseline\"]).T"
      ],
      "metadata": {
        "id": "Rdk2CNjWblah",
        "outputId": "90e16c9e-86b1-47de-ce10-4276e0e3c85e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 118
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading cached shuffled indices for dataset at /root/.cache/huggingface/datasets/cnn_dailymail/default/3.0.0/3cb851bf7cf5826e45d49db2863f627cba583cbc32342df7349dfe6c38060234/cache-6ffd8e582e03c755.arrow\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            rouge1    rouge2    rougeL  rougeLsum\n",
              "baseline  0.388071  0.170554  0.247146   0.354972"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-52abb1b3-f681-4a89-b69b-f38a8c30364e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rouge1</th>\n",
              "      <th>rouge2</th>\n",
              "      <th>rougeL</th>\n",
              "      <th>rougeLsum</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>baseline</th>\n",
              "      <td>0.388071</td>\n",
              "      <td>0.170554</td>\n",
              "      <td>0.247146</td>\n",
              "      <td>0.354972</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-52abb1b3-f681-4a89-b69b-f38a8c30364e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-52abb1b3-f681-4a89-b69b-f38a8c30364e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-52abb1b3-f681-4a89-b69b-f38a8c30364e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The scores are mostly worse than on the previous example, but still better than those\n",
        "achieved by GPT-2! \n",
        "\n",
        "Now let’s implement the same evaluation function for evaluating\n",
        "the PEGASUS model:"
      ],
      "metadata": {
        "id": "Royf9Ov_cXH7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def chunks(list_of_elements, batch_size):\n",
        "  \"\"\"Yield successive batch-sized chunks from list_of_elements.\"\"\"\n",
        "  for i in range(0, len(list_of_elements), batch_size):\n",
        "      yield list_of_elements[i : i + batch_size]"
      ],
      "metadata": {
        "id": "Kc8hvj2rcYlD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_summaries_pegasus(dataset, metric, model, tokenizer, batch_size=16, device=device, column_text=\"article\", column_summary=\"highlights\"):\n",
        "  article_batches = list(chunks(dataset[column_text], batch_size))\n",
        "  target_batches = list(chunks(dataset[column_summary], batch_size))\n",
        "\n",
        "  for article_batch, target_batch in tqdm(zip(article_batches, target_batches), total=len(article_batches)):\n",
        "      \n",
        "      inputs = tokenizer(article_batch, max_length=1024,  truncation=True, padding=\"max_length\", return_tensors=\"pt\")\n",
        "      \n",
        "      summaries = model.generate(input_ids=inputs[\"input_ids\"].to(device),\n",
        "                                  attention_mask=inputs[\"attention_mask\"].to(device), \n",
        "                                  length_penalty=0.8, num_beams=8, max_length=128)\n",
        "      \n",
        "      decoded_summaries = [tokenizer.decode(s, skip_special_tokens=True, clean_up_tokenization_spaces=True) for s in summaries]\n",
        "      decoded_summaries = [d.replace(\"<n>\", \" \") for d in decoded_summaries]\n",
        "      metric.add_batch(predictions=decoded_summaries, references=target_batch)\n",
        "      \n",
        "  score = metric.compute()\n",
        "  return score"
      ],
      "metadata": {
        "id": "8FnNuAXwczlo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s now load the model again with the `AutoModelForSeq2SeqLM` class, used for `seq2seq` generation tasks, and evaluate it:"
      ],
      "metadata": {
        "id": "X7iLPhprdUTa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_ckpt = \"google/pegasus-cnn_dailymail\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(model_ckpt).to(device)"
      ],
      "metadata": {
        "id": "MSi6T8CfdYht"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "score = evaluate_summaries_pegasus(test_sampled, rouge_metric, model, tokenizer, batch_size=8)\n",
        "rouge_dict = dict((rn, score[rn].mid.fmeasure) for rn in rouge_names)\n",
        "\n",
        "pd.DataFrame.from_dict(rouge_dict, index=[\"pegasus\"])"
      ],
      "metadata": {
        "id": "pj92Vwe9drm_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "These numbers are very close to the published results. One thing to note here is that\n",
        "the loss and per-token accuracy are decoupled to some degree from the ROUGE\n",
        "scores. The loss is independent of the decoding strategy, whereas the ROUGE score is\n",
        "strongly coupled.\n",
        "\n",
        "Since ROUGE and BLEU correlate better with human judgment than loss or accuracy,\n",
        "we should focus on them and carefully explore and choose the decoding strategy\n",
        "when building text generation models. These metrics are far from perfect, however,\n",
        "and one should always consider human judgments as well."
      ],
      "metadata": {
        "id": "jSueNgvWeTfd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Training Summarization Model"
      ],
      "metadata": {
        "id": "JgkVmE-Ou-FF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let’s\n",
        "put this to use to train a custom text summarization model! For our application, we’ll\n",
        "use the [SAMSum dataset](https://huggingface.co/datasets/samsum) developed by Samsung, which consists of a collection of dialogues\n",
        "along with brief summaries.\n",
        "\n",
        "Let’s load it and look at an example:\n",
        "\n"
      ],
      "metadata": {
        "id": "baIW-lF-vABH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_samsum = load_dataset(\"samsum\")\n",
        "split_lengths = [len(dataset_samsum[split]) for split in dataset_samsum]\n",
        "\n",
        "print(f\"Split lengths: {split_lengths}\")\n",
        "print(f\"Features: {dataset_samsum['train'].column_names}\")\n",
        "print(f\"\\nDialogue:\")\n",
        "print(dataset_samsum[\"test\"][0][\"dialogue\"])\n",
        "print(f\"\\nSummary:\")\n",
        "print(dataset_samsum[\"test\"][0][\"summary\"])"
      ],
      "metadata": {
        "id": "epgHnqSyvyD2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The dialogues look like what you would expect from a chat via SMS or WhatsApp,\n",
        "including emojis and placeholders for GIFs. The dialogue field contains the full text\n",
        "and the summary the summarized dialogue.\n",
        "\n",
        "Could a model that was fine-tuned on the\n",
        "CNN/DailyMail dataset deal with that? \n",
        "\n",
        "Let’s find out!"
      ],
      "metadata": {
        "id": "tcQ4b8Rv0nBq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Evaluating PEGASUS on SAMSum"
      ],
      "metadata": {
        "id": "n7TKCryV0tY1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First we’ll run the same summarization pipeline with PEGASUS to see what the output\n",
        "looks like."
      ],
      "metadata": {
        "id": "S20dQgnu0uH4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipe_out = pipe(dataset_samsum[\"text\"][0][\"dialogue\"])\n",
        "print(\"Summary:\")\n",
        "print(pipe_out[0][\"summary_text\"].replace(\"  .<n>\", \".\\n\"))"
      ],
      "metadata": {
        "id": "CkzryGWi00hZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see that the model mostly tries to summarize by extracting the key sentences\n",
        "from the dialogue. This probably worked relatively well on the CNN/DailyMail dataset,\n",
        "but the summaries in SAMSum are more abstract.\n",
        "\n",
        "Let’s confirm this by running\n",
        "the full ROUGE evaluation on the test set:"
      ],
      "metadata": {
        "id": "oAGg60001TO2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "score = evaluate_summaries_pegasus(dataset_samsum[\"test\"], \n",
        "                                   rouge_metric, \n",
        "                                   model, \n",
        "                                   tokenizer, \n",
        "                                   column_text=\"dialogue\", \n",
        "                                   column_summary=\"summary\", \n",
        "                                   batch_size=8)\n",
        "rouge_dict = dict((rn, score[rn].mid.fmeasure) for rn in rouge_names)\n",
        "\n",
        "pd.DataFrame.from_dict(rouge_dict, index=[\"pegasus\"])"
      ],
      "metadata": {
        "id": "YDygpPy81WlB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Well, the results aren’t great, but this is not unexpected since we’ve moved quite a bit\n",
        "away from the CNN/DailyMail data distribution.\n",
        "\n",
        "Nevertheless, setting up the evaluation\n",
        "pipeline before training has two advantages: we can directly measure the success\n",
        "of training with the metric and we have a good baseline.\n",
        "\n",
        "Fine-tuning the model on\n",
        "our dataset should result in an immediate improvement in the ROUGE metric, and if\n",
        "that is not the case we’ll know something is wrong with our training loop."
      ],
      "metadata": {
        "id": "cNvKyncL15j2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Fine-Tuning PEGASUS"
      ],
      "metadata": {
        "id": "HcGFI8052E0_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Before we process the data for training, let’s have a quick look at the length distribution\n",
        "of the input and outputs:"
      ],
      "metadata": {
        "id": "U7Br_bdz2FlM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "qXW5sPLnH650"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}