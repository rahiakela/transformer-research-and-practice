{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "summarization.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMFbPvncNtBLfZhS61vTaL2",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/transformers-research-and-practice/blob/main/natural-language-processing-with-transformers/06-summarization/summarization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Summarization"
      ],
      "metadata": {
        "id": "yec-35M4BWvO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Text summarization is a\n",
        "difficult task for neural language models, including transformers. Despite these challenges,\n",
        "text summarization offers the prospect for domain experts to significantly\n",
        "speed up their workflows and is used by enterprises to condense internal knowledge,\n",
        "summarize contracts, automatically generate content for social media releases,\n",
        "and more.\n",
        "\n",
        "Summarization is a classic\n",
        "sequence-to-sequence (seq2seq) task with an input text and a target text."
      ],
      "metadata": {
        "id": "dfFj2oRmBXpd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Setup"
      ],
      "metadata": {
        "id": "0jROG17wBazd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install transformers[sentencepiece]\n",
        "!pip -q install datasets\n",
        "!pip -q install sacrebleu\n",
        "!pip -q install rouge_score"
      ],
      "metadata": {
        "id": "ojHJ4FhvBb7V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install rouge_score"
      ],
      "metadata": {
        "id": "bPvww4MxFlW-"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline, set_seed\n",
        "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
        "from transformers import DataCollatorForSeq2Seq\n",
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "from datasets import load_dataset, load_metric\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "\n",
        "import nltk\n",
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "dIrfRuBsBibh"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download(\"punkt\")"
      ],
      "metadata": {
        "id": "s7nIfW88cegm",
        "outputId": "e5c1cc16-9e7c-4e59-fd87-7754acf57dad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##CNN/DailyMail Dataset"
      ],
      "metadata": {
        "id": "qBE7AF9bD1Wx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The CNN/DailyMail dataset consists of around 300,000 pairs of news articles and\n",
        "their corresponding summaries, composed from the bullet points that CNN and the\n",
        "DailyMail attach to their articles.\n",
        "\n",
        "An important aspect of the dataset is that the summaries are abstractive and not extractive, which means that they consist of new\n",
        "sentences instead of simple excerpts.\n",
        "\n",
        "We’ll use version 3.0.0, which is a nonanonymized version set up for summarization."
      ],
      "metadata": {
        "id": "5IQkUfASD2Kw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = load_dataset(\"cnn_dailymail\", version=\"3.0.0\")"
      ],
      "metadata": {
        "id": "le4s8kDKEMwp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Features: {dataset['train'].column_names}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hlgyxXqHE5BQ",
        "outputId": "6929c885-7e97-416b-d66c-10c0553205f8"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Features: ['article', 'highlights', 'id']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s look at an excerpt from an article:"
      ],
      "metadata": {
        "id": "liZjNQ2KFA9w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample = dataset[\"train\"][1]\n",
        "\n",
        "print(f\"\"\"Article (excerpt of 500 characters, total length: {len(sample['article'])})\"\"\")\n",
        "print(sample[\"article\"])\n",
        "\n",
        "print(f\"\\nSummary (length: {len(sample['highlights'])})\")\n",
        "print(sample[\"highlights\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nKLCJt-wFC49",
        "outputId": "28976da6-e670-42cc-ac14-4396cca5a43b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Article (excerpt of 500 characters, total length: 3192)\n",
            "(CNN) -- Usain Bolt rounded off the world championships Sunday by claiming his third gold in Moscow as he anchored Jamaica to victory in the men's 4x100m relay. The fastest man in the world charged clear of United States rival Justin Gatlin as the Jamaican quartet of Nesta Carter, Kemar Bailey-Cole, Nickel Ashmeade and Bolt won in 37.36 seconds. The U.S finished second in 37.56 seconds with Canada taking the bronze after Britain were disqualified for a faulty handover. The 26-year-old Bolt has now collected eight gold medals at world championships, equaling the record held by American trio Carl Lewis, Michael Johnson and Allyson Felix, not to mention the small matter of six Olympic titles. The relay triumph followed individual successes in the 100 and 200 meters in the Russian capital. \"I'm proud of myself and I'll continue to work to dominate for as long as possible,\" Bolt said, having previously expressed his intention to carry on until the 2016 Rio Olympics. Victory was never seriously in doubt once he got the baton safely in hand from Ashmeade, while Gatlin and the United States third leg runner Rakieem Salaam had problems. Gatlin strayed out of his lane as he struggled to get full control of their baton and was never able to get on terms with Bolt. Earlier, Jamaica's women underlined their dominance in the sprint events by winning the 4x100m relay gold, anchored by Shelly-Ann Fraser-Pryce, who like Bolt was completing a triple. Their quartet recorded a championship record of 41.29 seconds, well clear of France, who crossed the line in second place in 42.73 seconds. Defending champions, the United States, were initially back in the bronze medal position after losing time on the second handover between Alexandria Anderson and English Gardner, but promoted to silver when France were subsequently disqualified for an illegal handover. The British quartet, who were initially fourth, were promoted to the bronze which eluded their men's team. Fraser-Pryce, like Bolt aged 26, became the first woman to achieve three golds in the 100-200 and the relay. In other final action on the last day of the championships, France's Teddy Tamgho became the third man to leap over 18m in the triple jump, exceeding the mark by four centimeters to take gold. Germany's Christina Obergfoll finally took gold at global level in the women's javelin after five previous silvers, while Kenya's Asbel Kiprop easily won a tactical men's 1500m final. Kiprop's compatriot Eunice Jepkoech Sum was a surprise winner of the women's 800m. Bolt's final dash for golden glory brought the eight-day championship to a rousing finale, but while the hosts topped the medal table from the United States there was criticism of the poor attendances in the Luzhniki Stadium. There was further concern when their pole vault gold medalist Yelena Isinbayeva made controversial remarks in support of Russia's new laws, which make \"the propagandizing of non-traditional sexual relations among minors\" a criminal offense. She later attempted to clarify her comments, but there were renewed calls by gay rights groups for a boycott of the 2014 Winter Games in Sochi, the next major sports event in Russia.\n",
            "\n",
            "Summary (length: 180)\n",
            "Usain Bolt wins third gold of world championship .\n",
            "Anchors Jamaica to 4x100m relay victory .\n",
            "Eighth gold at the championships for Bolt .\n",
            "Jamaica double up in women's 4x100m relay .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see that the articles can be very long compared to the target summary; in this particular\n",
        "case the difference is 17-fold.\n",
        "\n",
        "Long articles pose a challenge to most transformer\n",
        "models since the context size is usually limited to 1,000 tokens or so, which is\n",
        "equivalent to a few paragraphs of text. The standard, yet crude way to deal with this\n",
        "for summarization is to simply truncate the texts beyond the model’s context size."
      ],
      "metadata": {
        "id": "I3uztDnPIwQN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Text Summarization Pipelines"
      ],
      "metadata": {
        "id": "PXn-s8xdI3n-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s see how a few of the most popular transformer models for summarization perform\n",
        "by first looking qualitatively at the outputs for the preceding example."
      ],
      "metadata": {
        "id": "AIIQn9SpI4V1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample_text = dataset[\"train\"][1][\"article\"][:2000]  # restrict the input text to 2,000 characters\n",
        "\n",
        "# We'll collect the generated summaries of each model in a dictionary\n",
        "summaries = {}"
      ],
      "metadata": {
        "id": "KQoxjDP1buCn"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's differentiate the end of a sentence\n",
        "from punctuation that occurs in abbreviations"
      ],
      "metadata": {
        "id": "MUPpd8ctcWbt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "string = \"The U.S. are a country. The U.N. is an organization.\"\n",
        "sent_tokenize(string)"
      ],
      "metadata": {
        "id": "rCISIlGjcXxg",
        "outputId": "08278a7f-6afe-4899-81bd-355a51c53ab8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['The U.S. are a country.', 'The U.N. is an organization.']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Summarization Baseline"
      ],
      "metadata": {
        "id": "F2uP4JYIcr19"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A common baseline for summarizing news articles is to simply take the first three\n",
        "sentences of the article."
      ],
      "metadata": {
        "id": "M8FG9t65ctFT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def three_sentence_summary(text):\n",
        "  return \"\\n\".join(sent_tokenize(text)[:3])"
      ],
      "metadata": {
        "id": "o1JLfDwzc08a"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summaries[\"baseline\"] = three_sentence_summary(sample_text)"
      ],
      "metadata": {
        "id": "Db3V7AmodGMQ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###GPT-2"
      ],
      "metadata": {
        "id": "zq4j04_NdRsB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "One of GPT-2’s surprising features is that we can also use it to generate summaries\n",
        "by simply appending `TL;DR` at the end of the input text. \n",
        "\n",
        "The expression `TL;DR` (too long; didn’t read) is often used on platforms like Reddit to indicate a short version\n",
        "of a long post."
      ],
      "metadata": {
        "id": "1XT8F5eadSc1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed(42)\n",
        "\n",
        "pipe = pipeline(\"text-generation\", model=\"gpt2\")\n",
        "\n",
        "gpt2_query = sample_text + \"\\nTL;DR:\\n\"\n",
        "pipe_out = pipe(gpt2_query, max_length=512, clean_up_tokenization_spaces=True)\n",
        "summaries[\"gpt2\"] = \"\\n\".join(sent_tokenize(pipe_out[0][\"generated_text\"][len(gpt2_query):]))"
      ],
      "metadata": {
        "id": "1003nJfrfCew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###T5"
      ],
      "metadata": {
        "id": "ENKDRNdKgCkv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next let’s try the T5 transformer.\n",
        "\n",
        "The T5 checkpoints are trained on a mixture of unsupervised data (to\n",
        "reconstruct masked words) and supervised data for several tasks, including summarization.\n",
        "These checkpoints can thus be directly used to perform summarization\n",
        "without fine-tuning by using the same prompts used during pretraining.\n",
        "\n",
        "In this\n",
        "framework, the input format for the model to summarize a document is \"summarize:`<ARTICLE>`\", and for translation it looks like \"translate English to German:`<TEXT>`\"."
      ],
      "metadata": {
        "id": "2IQUpmWSgD2W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipeline(\"summarization\", model=\"t5-large\")\n",
        "\n",
        "pipe_out = pipe(sample_text)\n",
        "summaries[\"t5\"] = \"\\n\".join(sent_tokenize(pipe_out[0][\"summary_text\"]))"
      ],
      "metadata": {
        "id": "jRG5kmMRgj6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###BART"
      ],
      "metadata": {
        "id": "0mCTi_o0g502"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "BART also uses an encoder-decoder architecture and is trained to reconstruct corrupted inputs. It combines the pretraining schemes of BERT and GPT-2."
      ],
      "metadata": {
        "id": "DMA8SiSEg6qi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")\n",
        "\n",
        "pipe_out = pipe(sample_text)\n",
        "summaries[\"bart\"] = \"\\n\".join(sent_tokenize(pipe_out[0][\"summary_text\"]))"
      ],
      "metadata": {
        "id": "qJbRf5vthAtQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###PEGASUS"
      ],
      "metadata": {
        "id": "8bqGB7PuhOac"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Like BART, PEGASUS is an encoder-decoder transformer.its pretraining objective is to predict masked sentences in multisentence texts.\n",
        "\n",
        "The\n",
        "authors argue that the closer the pretraining objective is to the downstream task, the\n",
        "more effective it is. \n",
        "\n",
        "With the aim of finding a pretraining objective that is closer to\n",
        "summarization than general language modeling, they automatically identified, in a\n",
        "very large corpus, sentences containing most of the content of their surrounding\n",
        "paragraphs (using summarization evaluation metrics as a heuristic for content\n",
        "overlap) and pretrained the PEGASUS model to reconstruct these sentences, thereby\n",
        "obtaining a state-of-the-art model for text summarization.\n",
        "\n"
      ],
      "metadata": {
        "id": "32jotqkYhPMk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipeline(\"summarization\", model=\"google/pegasus-cnn_dailymail\")\n",
        "\n",
        "pipe_out = pipe(sample_text)\n",
        "summaries[\"pegasus\"] = pipe_out[0][\"summary_text\"].replace(\" .<n>\", \".\\n\")"
      ],
      "metadata": {
        "id": "imIO1Rdfiqe8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Comparing Different Summaries"
      ],
      "metadata": {
        "id": "r_VaWZ1bjFEc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have generated summaries with four different models, let’s compare the results.\n",
        "\n",
        "Keep in mind that one model has not been trained on the dataset at all\n",
        "(GPT-2), one model has been fine-tuned on this task among others (T5), and two\n",
        "models have exclusively been fine-tuned on this task (BART and PEGASUS).\n",
        "\n",
        "Let’s\n",
        "have a look at the summaries these models have generated:"
      ],
      "metadata": {
        "id": "6UBEAHomjH_e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"GROUND TRUTH\")\n",
        "print(dataset[\"train\"][1][\"highlights\"])\n",
        "print(\"\")\n",
        "\n",
        "for model_name in summaries:\n",
        "  print(model_name.upper())\n",
        "  print(\"-----------------------------------\")\n",
        "  print(summaries[model_name])\n",
        "  print(\"\")"
      ],
      "metadata": {
        "id": "fBv8k5aLmIcf",
        "outputId": "3df325dc-4c14-4d52-db34-f60acdd3c27a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GROUND TRUTH\n",
            "Usain Bolt wins third gold of world championship .\n",
            "Anchors Jamaica to 4x100m relay victory .\n",
            "Eighth gold at the championships for Bolt .\n",
            "Jamaica double up in women's 4x100m relay .\n",
            "\n",
            "BASELINE\n",
            "-----------------------------------\n",
            "(CNN) -- Usain Bolt rounded off the world championships Sunday by claiming his third gold in Moscow as he anchored Jamaica to victory in the men's 4x100m relay.\n",
            "The fastest man in the world charged clear of United States rival Justin Gatlin as the Jamaican quartet of Nesta Carter, Kemar Bailey-Cole, Nickel Ashmeade and Bolt won in 37.36 seconds.\n",
            "The U.S finished second in 37.56 seconds with Canada taking the bronze after Britain were disqualified for a faulty handover.\n",
            "\n",
            "GPT2\n",
            "-----------------------------------\n",
            "Usain Bolt triumphed after a difficult final, but then he got into trouble when Canada made him try to block.\n",
            "It's the last match he's held all of last year with the men, who were later picked in the third and fourth rounds of the men's 100m and 200m and at Rio-Gold.\n",
            "UPDATE - November 8 - Team USA won in 36.36,\n",
            "\n",
            "T5\n",
            "-----------------------------------\n",
            "usain bolt wins his third gold medal of the world championships in the men's 4x100m relay .\n",
            "the 26-year-old anchored Jamaica to victory in the event in the Russian capital .\n",
            "he has now collected eight gold medals at the championships, equaling the record .\n",
            "\n",
            "BART\n",
            "-----------------------------------\n",
            "Usain Bolt wins his third gold of the world championships in Moscow.\n",
            "Bolt anchors Jamaica to victory in the men's 4x100m relay.\n",
            "The 26-year-old has now won eight gold medals at world championships.\n",
            "Jamaica's women also win gold in the relay, beating France in the process.\n",
            "\n",
            "PEGASUS\n",
            "-----------------------------------\n",
            "Usain Bolt wins third gold of world championships.\n",
            "Anchors Jamaica to victory in men's 4x100m relay.\n",
            "Eighth gold at the championships for Bolt.\n",
            "Jamaica also win women's 4x100m relay .\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The first thing we notice by looking at the model outputs is that the summary generated\n",
        "by GPT-2 is quite different from the others. Instead of giving a summary of the\n",
        "text, it summarizes the characters.\n",
        "\n",
        "Comparing the other three model summaries against the ground truth, we see that\n",
        "there is remarkable overlap, with PEGASUS’s output bearing the most striking\n",
        "resemblance.\n",
        "\n",
        "Now that we have inspected a few models, let’s try to decide which one we would use\n",
        "in a production setting.\n",
        "\n",
        "However, this\n",
        "is not a systematic way of determining the best model! Ideally, we would define a metric, measure it for all models on some benchmark dataset, and choose the one\n",
        "with the best performance.\n",
        "\n",
        "But how do you define a metric for text generation?\n",
        "\n",
        "The\n",
        "standard metrics that we’ve seen, like accuracy, recall, and precision, are not easy to\n",
        "apply to this task."
      ],
      "metadata": {
        "id": "ZTNXqw4am90z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Measuring the Quality of Generated Text"
      ],
      "metadata": {
        "id": "MT1h8LjunfYM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Good evaluation metrics are important, since we use them to measure the performance\n",
        "of models not only when we train them but also later, in production.\n",
        "\n",
        "Measuring performance on a text generation task is not as easy as with standard classification\n",
        "tasks such as sentiment analysis or named entity recognition.\n",
        "\n",
        "Two of the most common metrics used to evaluate generated text are **BLEU** and **ROUGE**."
      ],
      "metadata": {
        "id": "FMU9qi7wnfrS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###BLEU"
      ],
      "metadata": {
        "id": "uoeKCUCgzuH2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The idea of BLEU is simple: instead of looking at how many of the tokens in the generated texts are perfectly aligned with the reference text tokens, we look at words or n-grams. \n",
        "\n",
        "BLEU is a precision-based metric, which means that when we compare the\n",
        "two texts we count the number of words in the generation that occur in the reference and divide it by the length of the reference.\n",
        "\n",
        "The weakness of the BLEU metric is that it expects the text to already\n",
        "be tokenized. This can lead to varying results if the exact same method for text tokenization\n",
        "is not used. \n",
        "\n",
        "The SacreBLEU metric addresses this issue by internalizing the\n",
        "tokenization step; for this reason, it is the preferred metric for benchmarking."
      ],
      "metadata": {
        "id": "cD5vGy6BzvFS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bleu_metric = load_metric(\"sacrebleu\")"
      ],
      "metadata": {
        "id": "nqA3xhmv2_Wc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `bleu_metric` object is an instance of the Metric class, and works like an aggregator: you can add single instances with `add()` or whole batches via `add_batch()`."
      ],
      "metadata": {
        "id": "fcqa8LIW6pgc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bleu_metric.add(prediction=\"the the the the the the\", reference=[\"the cat is on the mat\"])\n",
        "\n",
        "results = bleu_metric.compute(smooth_method=\"floor\", smooth_value=0)\n",
        "results[\"precisions\"] = [np.round(p, 2) for p in results[\"precisions\"]]\n",
        "\n",
        "pd.DataFrame.from_dict(results, orient=\"index\", columns=[\"Value\"])"
      ],
      "metadata": {
        "id": "c0kTEETC6hrq",
        "outputId": "d7443466-66c0-442c-d3c0-4b1bc2b61db3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                             Value\n",
              "score                          0.0\n",
              "counts                [2, 0, 0, 0]\n",
              "totals                [6, 5, 4, 3]\n",
              "precisions  [33.33, 0.0, 0.0, 0.0]\n",
              "bp                             1.0\n",
              "sys_len                          6\n",
              "ref_len                          6"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-dc80efbb-cbb8-4718-98a5-5c4c0eb09e21\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>score</th>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>counts</th>\n",
              "      <td>[2, 0, 0, 0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>totals</th>\n",
              "      <td>[6, 5, 4, 3]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>precisions</th>\n",
              "      <td>[33.33, 0.0, 0.0, 0.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bp</th>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sys_len</th>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ref_len</th>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-dc80efbb-cbb8-4718-98a5-5c4c0eb09e21')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-dc80efbb-cbb8-4718-98a5-5c4c0eb09e21 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-dc80efbb-cbb8-4718-98a5-5c4c0eb09e21');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can see the precision of the 1-gram is indeed 2/6, whereas the precisions for the 2/3/4-grams are all 0.\n",
        "\n",
        "This means the geometric mean is zero, and\n",
        "thus also the BLEU score. \n",
        "\n",
        "Let’s look at another example where the prediction is\n",
        "almost correct:"
      ],
      "metadata": {
        "id": "BmIb2a_C71h0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bleu_metric.add(prediction=\"the cat is on mat\", reference=[\"the cat is on the mat\"])\n",
        "\n",
        "results = bleu_metric.compute(smooth_method=\"floor\", smooth_value=0)\n",
        "results[\"precisions\"] = [np.round(p, 2) for p in results[\"precisions\"]]\n",
        "\n",
        "pd.DataFrame.from_dict(results, orient=\"index\", columns=[\"Value\"])"
      ],
      "metadata": {
        "id": "OklcxZWU76p6",
        "outputId": "ae551d5d-9a56-49ca-9c64-adb7327d10b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                 Value\n",
              "score                        57.893007\n",
              "counts                    [5, 3, 2, 1]\n",
              "totals                    [5, 4, 3, 2]\n",
              "precisions  [100.0, 75.0, 66.67, 50.0]\n",
              "bp                            0.818731\n",
              "sys_len                              5\n",
              "ref_len                              6"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ab05dd59-1ab9-4fe4-b989-6e02732f1876\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Value</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>score</th>\n",
              "      <td>57.893007</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>counts</th>\n",
              "      <td>[5, 3, 2, 1]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>totals</th>\n",
              "      <td>[5, 4, 3, 2]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>precisions</th>\n",
              "      <td>[100.0, 75.0, 66.67, 50.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bp</th>\n",
              "      <td>0.818731</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sys_len</th>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ref_len</th>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ab05dd59-1ab9-4fe4-b989-6e02732f1876')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ab05dd59-1ab9-4fe4-b989-6e02732f1876 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ab05dd59-1ab9-4fe4-b989-6e02732f1876');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We observe that the precision scores are much better. The 1-grams in the prediction\n",
        "all match, and only in the precision scores do we see that something is off.\n",
        "\n",
        "The BLEU score is widely used for evaluating text, especially in machine translation,\n",
        "since precise translations are usually favored over translations that include all possible\n",
        "and appropriate words.\n",
        "\n",
        "There are other applications, such as summarization, where the situation is different.\n",
        "There, we want all the important information in the generated text, so we favor high\n",
        "recall. \n",
        "\n",
        "This is where the ROUGE score is usually used."
      ],
      "metadata": {
        "id": "BgrOdLRu8OlZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###ROUGE"
      ],
      "metadata": {
        "id": "RdfWOsI48dwY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The ROUGE score was specifically developed for applications like summarization\n",
        "where high recall is more important than just precision.\n",
        "\n",
        "The approach is very similar\n",
        "to the BLEU score in that we look at different n-grams and compare their occurrences\n",
        "in the generated text and the reference texts. \n",
        "\n",
        "The difference is that with ROUGE we\n",
        "check how many n-grams in the reference text also occur in the generated text.\n",
        "\n",
        "In the Datasets implementation, two variations of ROUGE are calculated: \n",
        "\n",
        "* one calculates the score per sentence and averages it for the summaries (ROUGE-L)\n",
        "\n",
        "* the other calculates it directly over the whole summary (ROUGE-Lsum)."
      ],
      "metadata": {
        "id": "FfCQcp2j8fna"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rouge_metric = load_metric(\"rouge\")"
      ],
      "metadata": {
        "id": "cp5Qmm9nFR9s"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s apply the ROUGE score to all the summaries generated by the models:"
      ],
      "metadata": {
        "id": "z2E0oTAQFd4G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reference = dataset[\"train\"][1][\"highlights\"]\n",
        "records = []\n",
        "rouge_names = [\"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"]\n",
        "\n",
        "for model_name in summaries:\n",
        "  rouge_metric.add(prediction=summaries[model_name], reference=reference)\n",
        "  score = rouge_metric.compute()\n",
        "  rouge_dict = dict((rn, score[rn].mid.fmeasure) for rn in rouge_names)\n",
        "  records.append(rouge_dict)\n",
        "\n",
        "pd.DataFrame.from_records(records, index=summaries.keys())"
      ],
      "metadata": {
        "id": "efVZNWdyH0OO",
        "outputId": "d063c45d-f7c8-46f5-ec07-a53b4fb82d9f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "            rouge1    rouge2    rougeL  rougeLsum\n",
              "baseline  0.303571  0.090909  0.214286   0.232143\n",
              "gpt2      0.212766  0.021739  0.127660   0.148936\n",
              "t5        0.486486  0.222222  0.378378   0.486486\n",
              "bart      0.582278  0.207792  0.455696   0.506329\n",
              "pegasus   0.866667  0.655172  0.800000   0.833333"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3ed6e226-c898-4d8d-abd5-82008ff86cfe\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>rouge1</th>\n",
              "      <th>rouge2</th>\n",
              "      <th>rougeL</th>\n",
              "      <th>rougeLsum</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>baseline</th>\n",
              "      <td>0.303571</td>\n",
              "      <td>0.090909</td>\n",
              "      <td>0.214286</td>\n",
              "      <td>0.232143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>gpt2</th>\n",
              "      <td>0.212766</td>\n",
              "      <td>0.021739</td>\n",
              "      <td>0.127660</td>\n",
              "      <td>0.148936</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>t5</th>\n",
              "      <td>0.486486</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>0.378378</td>\n",
              "      <td>0.486486</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>bart</th>\n",
              "      <td>0.582278</td>\n",
              "      <td>0.207792</td>\n",
              "      <td>0.455696</td>\n",
              "      <td>0.506329</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pegasus</th>\n",
              "      <td>0.866667</td>\n",
              "      <td>0.655172</td>\n",
              "      <td>0.800000</td>\n",
              "      <td>0.833333</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3ed6e226-c898-4d8d-abd5-82008ff86cfe')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3ed6e226-c898-4d8d-abd5-82008ff86cfe button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3ed6e226-c898-4d8d-abd5-82008ff86cfe');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "These results are obviously not very reliable as we only looked at a single sample, but\n",
        "we can compare the quality of the summary for that one example.\n",
        "\n"
      ],
      "metadata": {
        "id": "HEbtaet9Jr-Q"
      }
    }
  ]
}