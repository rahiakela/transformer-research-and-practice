{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "case-study--intent-detection.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyOWzQlEkX1Vc2puBGzrkf2r",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/transformers-research-and-practice/blob/main/natural-language-processing-with-transformers/05-making-transformers-efficient-in-production/case_study_intent_detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Intent Detection: Case Study"
      ],
      "metadata": {
        "id": "W519IdztjisY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s suppose that we’re trying to build a text-based assistant for our company’s call center so\n",
        "that customers can request the balance of their account or make bookings without needing to\n",
        "speak with a human agent. In order to understand the goals of a customer, our assistant will\n",
        "need to be able to classify a wide variety of natural language text into a set of predefined\n",
        "actions or intents.\n",
        "\n",
        "For example, a customer may send a message about an upcoming trip:\n",
        "\n",
        "```txt\n",
        "Hey, I’d like to rent a vehicle from Nov 1st to Nov 15th in Paris and I need a 15 passenger van\n",
        "```\n",
        "\n",
        "and our intent classifier could automatically categorize this as a Car Rental intent, which then triggers an action and response.\n",
        "\n",
        "To be robust in a production environment, our classifier will\n",
        "also need to be able to handle out-of-scope queries.\n",
        "\n",
        "<img src='images/1.png?raw=1' width='600'/>\n",
        "\n",
        "In the third case, the text-assistant\n",
        "has been trained to detect out-of-scope queries (usually labelled as a separate class) and informs the customer about which topics they can respond to.\n",
        "\n",
        "As a baseline we’ve fine-tuned a BERT-base model that achieves around `94%` accuracy on the\n",
        "`CLINC150` dataset. This dataset includes `22,500` in-scope queries across `150` intents and `10`\n",
        "domains like banking and travel, and also includes `1,200` out-of-scope queries that belong to an\n",
        "oos intent class. In practice we would also gather our own in-house dataset, but using public\n",
        "data is a great way to iterate quickly and generate preliminary results.\n",
        "\n"
      ],
      "metadata": {
        "id": "XOmQOa_QjwHw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Setup"
      ],
      "metadata": {
        "id": "UP1EHAnilUGK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install transformers[sentencepiece]\n",
        "!pip -q install datasets"
      ],
      "metadata": {
        "id": "PJs0JgLwlVIt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import (AutoTokenizer, AutoModelForSequenceClassification, TextClassificationPipeline)"
      ],
      "metadata": {
        "id": "A15YGFMiloPN"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let’s download our fine-tuned model from the Hugging Face Hub and wrap it in a pipeline for text classification:"
      ],
      "metadata": {
        "id": "OIOFJ-dkm0E_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# molde path has changed: https://huggingface.co/transformersbook/bert-base-uncased-finetuned-clinc\n",
        "bert_ckpt = \"transformersbook/bert-base-uncased-finetuned-clinc\"\n",
        "\n",
        "bert_tokenizer = AutoTokenizer.from_pretrained(bert_ckpt)\n",
        "bert_model = (AutoModelForSequenceClassification.from_pretrained(bert_ckpt).to(\"cpu\"))\n",
        "\n",
        "bert_pipeline = TextClassificationPipeline(model=bert_model, tokenizer=bert_tokenizer)"
      ],
      "metadata": {
        "id": "l3NVuFLdm2qj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we’ve set the model’s device to cpu since our text-assistant will need to operate in an\n",
        "environment where queries are processed and responded to in real-time.\n",
        "\n",
        "Now that we have a pipeline, we can pass a query to get the predicted intent and confidence\n",
        "score from the model:"
      ],
      "metadata": {
        "id": "lQ6kcqUNrsUP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"\"\"Hey, I'd like to rent a vehicle from Nov 1st to Nov 15th in Paris and I need a 15 passenger van\"\"\"\n",
        "\n",
        "bert_pipeline(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fygRC29urv7Z",
        "outputId": "94d9b863-c864-44f8-ce03-637abdbdcc38"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'car_rental', 'score': 0.5490034818649292}]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Great, the `car_rental` intent makes sense so let’s now look at creating a benchmark that we\n",
        "can use to evaluate the performance of our baseline model."
      ],
      "metadata": {
        "id": "ckP-6KbIsBne"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Performance Benchmark"
      ],
      "metadata": {
        "id": "3auvFWv7sENZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "L-Wj4qUwsG5m"
      }
    }
  ]
}