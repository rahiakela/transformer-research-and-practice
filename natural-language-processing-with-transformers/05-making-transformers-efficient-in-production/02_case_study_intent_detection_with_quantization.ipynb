{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02-case-study-intent-detection-with-quantization.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPAenubYxZGGCRLgX3+/+Bm",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "dfa6f22a73e644a19d788956106efddf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ca5f6c401b5b4c46a008aec2d65169b1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a992b29ee2a94f40b91c02057138b367",
              "IPY_MODEL_cdea506700fa43f8a96ec777c24368ef",
              "IPY_MODEL_68b42cd3cbb34e0ea142799cbca5288b"
            ]
          }
        },
        "ca5f6c401b5b4c46a008aec2d65169b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a992b29ee2a94f40b91c02057138b367": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6311014059414e478101c22e2bcac5bb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: ",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_19037b0b8fe24109a4a79d9ea7b99dec"
          }
        },
        "cdea506700fa43f8a96ec777c24368ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a35f5e7b6b77420ea338f68b83eff121",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1420,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1420,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a85664ff3cca486e95cd807264423960"
          }
        },
        "68b42cd3cbb34e0ea142799cbca5288b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_22df2ece2d8d4cc5a89b32e0f917dcc4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 3.20k/? [00:00&lt;00:00, 79.4kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_55f42453402e41568eb6722aee615931"
          }
        },
        "6311014059414e478101c22e2bcac5bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "19037b0b8fe24109a4a79d9ea7b99dec": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a35f5e7b6b77420ea338f68b83eff121": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a85664ff3cca486e95cd807264423960": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "22df2ece2d8d4cc5a89b32e0f917dcc4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "55f42453402e41568eb6722aee615931": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/transformers-research-and-practice/blob/main/natural-language-processing-with-transformers/05-making-transformers-efficient-in-production/02_case_study_intent_detection_with_quantization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Case Study: Intent Detection with Quantization"
      ],
      "metadata": {
        "id": "W519IdztjisY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s suppose that we’re trying to build a text-based assistant for our company’s call center so\n",
        "that customers can request the balance of their account or make bookings without needing to\n",
        "speak with a human agent. In order to understand the goals of a customer, our assistant will\n",
        "need to be able to classify a wide variety of natural language text into a set of predefined\n",
        "actions or intents.\n",
        "\n",
        "For example, a customer may send a message about an upcoming trip:\n",
        "\n",
        "```txt\n",
        "Hey, I’d like to rent a vehicle from Nov 1st to Nov 15th in Paris and I need a 15 passenger van\n",
        "```\n",
        "\n",
        "and our intent classifier could automatically categorize this as a Car Rental intent, which then triggers an action and response.\n",
        "\n",
        "To be robust in a production environment, our classifier will\n",
        "also need to be able to handle out-of-scope queries.\n",
        "\n",
        "<img src='https://github.com/rahiakela/transformers-research-and-practice/blob/main/natural-language-processing-with-transformers/05-making-transformers-efficient-in-production/images/1.png?raw=1' width='600'/>\n",
        "\n",
        "In the third case, the text-assistant\n",
        "has been trained to detect out-of-scope queries (usually labelled as a separate class) and informs the customer about which topics they can respond to.\n",
        "\n",
        "As a baseline we’ve fine-tuned a BERT-base model that achieves around `94%` accuracy on the\n",
        "`CLINC150` dataset. This dataset includes `22,500` in-scope queries across `150` intents and `10`\n",
        "domains like banking and travel, and also includes `1,200` out-of-scope queries that belong to an\n",
        "oos intent class. In practice we would also gather our own in-house dataset, but using public\n",
        "data is a great way to iterate quickly and generate preliminary results.\n",
        "\n"
      ],
      "metadata": {
        "id": "XOmQOa_QjwHw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Setup"
      ],
      "metadata": {
        "id": "UP1EHAnilUGK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install transformers[sentencepiece]\n",
        "!pip -q install datasets\n",
        "!pip -q install optuna"
      ],
      "metadata": {
        "id": "PJs0JgLwlVIt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import (AutoTokenizer, AutoModelForSequenceClassification, TextClassificationPipeline)\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from transformers import AutoConfig\n",
        "from datasets import load_dataset, load_metric\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.quantized import QFunctional\n",
        "from torch import quantize_per_tensor\n",
        "\n",
        "\n",
        "import optuna\n",
        "\n",
        "from mpl_toolkits.axes_grid1.inset_locator import zoomed_inset_axes,mark_inset\n",
        "\n",
        "from pathlib import Path\n",
        "from time import perf_counter\n",
        "\n",
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "A15YGFMiloPN"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_metrics(perf_metrics, current_optim_type):\n",
        "  df = pd.DataFrame.from_dict(perf_metrics, orient=\"index\")\n",
        "  for idx in df.index:\n",
        "    df_opt = df.loc[idx]\n",
        "    if idx == current_optim_type:\n",
        "      plt.scatter(df_opt[\"time_avg_ms\"], df_opt[\"accuracy\"] * 100, alpha=0.5, s=df_opt[\"size_mb\"], label=idx, marker=\"$\\u25CC$\")\n",
        "    else:\n",
        "      plt.scatter(df_opt[\"time_avg_ms\"], df_opt[\"accuracy\"] * 100, s=df_opt[\"size_mb\"], label=idx, alpha=0.5)\n",
        "  legend = plt.legend(bbox_to_anchor=(1, 1))\n",
        "  for handle in legend.legendHandles:\n",
        "    handle.set_sizes([20])\n",
        "  plt.ylim(80,90)\n",
        "  plt.xlim(5, 53)\n",
        "  plt.ylabel(\"Accuracy (%)\")\n",
        "  plt.xlabel(\"Average latency (ms)\")\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "7xUwJN7YK_8e"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let’s download our fine-tuned model from the Hugging Face Hub and wrap it in a pipeline for text classification:"
      ],
      "metadata": {
        "id": "OIOFJ-dkm0E_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# molde path has changed: https://huggingface.co/transformersbook/bert-base-uncased-finetuned-clinc\n",
        "bert_ckpt = \"transformersbook/bert-base-uncased-finetuned-clinc\"\n",
        "\n",
        "bert_tokenizer = AutoTokenizer.from_pretrained(bert_ckpt)\n",
        "bert_model = (AutoModelForSequenceClassification.from_pretrained(bert_ckpt).to(\"cpu\"))\n",
        "\n",
        "bert_pipeline = TextClassificationPipeline(model=bert_model, tokenizer=bert_tokenizer)"
      ],
      "metadata": {
        "id": "l3NVuFLdm2qj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we’ve set the model’s device to cpu since our text-assistant will need to operate in an\n",
        "environment where queries are processed and responded to in real-time.\n",
        "\n",
        "Now that we have a pipeline, we can pass a query to get the predicted intent and confidence\n",
        "score from the model:"
      ],
      "metadata": {
        "id": "lQ6kcqUNrsUP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"\"\"Hey, I'd like to rent a vehicle from Nov 1st to Nov 15th in Paris and I need a 15 passenger van\"\"\"\n",
        "\n",
        "bert_pipeline(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fygRC29urv7Z",
        "outputId": "3a435bab-6213-4225-99f6-62c5e8357268"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'car_rental', 'score': 0.5490034818649292}]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Great, the `car_rental` intent makes sense so let’s now look at creating a benchmark that we\n",
        "can use to evaluate the performance of our baseline model."
      ],
      "metadata": {
        "id": "ckP-6KbIsBne"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Performance Benchmark"
      ],
      "metadata": {
        "id": "3auvFWv7sENZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Like any other machine learning model, deploying Transformers in production environments involves a trade-off among several constraints, the most common being:\n",
        "\n",
        "- **Model performance**\n",
        "  - How well does our model perform on a well-crafted test set that reflects production data?\n",
        "- **Latency**\n",
        "  - How fast can our model deliver predictions?\n",
        "- **Memory**\n",
        "  - How can we deploy billion-parameter models like GPT-2 or T5 that require gigabytes of disk storage and RAM?\n",
        "\n",
        "Failing to address these constraints can have a negative impact on the user experience of your\n",
        "application, or more commonly, lead to ballooning costs from running expensive cloud servers\n",
        "that may only need to handle a few requests.\n",
        "\n",
        "To explore how each of the these constraints can\n",
        "be optimized with various compression techniques, let’s begin by creating a simple benchmark\n",
        "that measures each quantity for a given pipeline and test set."
      ],
      "metadata": {
        "id": "L-Wj4qUwsG5m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PerformanceBenchmark:\n",
        "  def __init__(self, pipeline, dataset, optim_type=\"BERT baseline\") -> None:\n",
        "    self.pipeline = pipeline\n",
        "    self.dataset = dataset\n",
        "    self.optim_type = optim_type\n",
        "\n",
        "  def compute_accuracy(self):\n",
        "    preds, labels = [], []\n",
        "    for example in self.dataset:\n",
        "      pred = self.pipeline(example[\"text\"])[0][\"label\"]\n",
        "      label = example[\"intent\"]\n",
        "      preds.append(intents.str2int(pred))\n",
        "      labels.append(label)\n",
        "    accuracy = accuracy_score.compute(predictions=preds, references=labels)\n",
        "    print(f\"Accuracy on test set - {accuracy['accuracy']:.3f}\")\n",
        "    return accuracy\n",
        "\n",
        "  def compute_size(self):\n",
        "    state_dict = self.pipeline.model.state_dict()\n",
        "    tmp_path = Path(\"model.pt\")\n",
        "    torch.save(state_dict, tmp_path)\n",
        "    # Calculate size in megabytes\n",
        "    size_mb = Path(tmp_path).stat().st_size / (1024 * 1024)\n",
        "    # Delete temporary file\n",
        "    tmp_path.unlink()\n",
        "    print(f\"Model size (MB) - {size_mb:.2f}\")\n",
        "    return {\"size_mb\": size_mb}\n",
        "\n",
        "  def time_pipeline(self, query=\"What is the pin number for my account?\"):\n",
        "    latencies = []\n",
        "    # Warmup\n",
        "    for _ in range(10):\n",
        "      _ = self.pipeline(query)\n",
        "    # Timed run\n",
        "    for _ in range(100):\n",
        "      start_time = perf_counter()\n",
        "      _ = bert_pipeline(query)\n",
        "      latency = perf_counter() - start_time\n",
        "      latencies.append(latency)\n",
        "    # Compute run statistics\n",
        "    time_avg_ms = 1000 * np.mean(latencies)\n",
        "    time_std_ms = 1000 * np.std(latencies)\n",
        "    print(f\"Average latency (ms) - {time_avg_ms:.2f} +\\- {time_std_ms:.2f}\")\n",
        "    return {\"time_avg_ms\": time_avg_ms, \"time_std_ms\": time_std_ms}\n",
        "\n",
        "  # We’ll use the run_benchmark function to collect all the metrics in a dictionary, with keys given by optim_type.\n",
        "  def run_benchmark(self):\n",
        "    metrics = {}\n",
        "    metrics[self.optim_type] = self.compute_size()\n",
        "    metrics[self.optim_type].update(self.time_pipeline())\n",
        "    metrics[self.optim_type].update(self.compute_accuracy())\n",
        "    return metrics"
      ],
      "metadata": {
        "id": "mw8ChQz0zP0d"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "First we need some data to test on, so let’s download the CLINC150 dataset that was used to finetune our baseline model. \n",
        "\n",
        "We can get the dataset from the Hub with the Datasets library as follows:"
      ],
      "metadata": {
        "id": "RymNuU1w0rB3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clinc = load_dataset(\"clinc_oos\", \"plus\")"
      ],
      "metadata": {
        "id": "fWSUNfxG0vHo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clinc"
      ],
      "metadata": {
        "id": "bn0AF4divpQR",
        "outputId": "98ac47af-4011-4337-d5da-61a76b3146a1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text', 'intent'],\n",
              "        num_rows: 15250\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['text', 'intent'],\n",
              "        num_rows: 3100\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['text', 'intent'],\n",
              "        num_rows: 5500\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each example in the CLINC150 dataset consists of a query in the text column and its corresponding intent. \n",
        "\n",
        "We’ll use the test set to benchmark our models, so let’s take a look at one\n",
        "of the dataset’s examples:"
      ],
      "metadata": {
        "id": "q9J8hxCM1RuH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clinc[\"test\"][42]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7lx13kR1UGm",
        "outputId": "c4593501-3b38-4397-d9aa-c9571e2c053d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'intent': 133, 'text': 'transfer $100 from my checking to saving account'}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The intents are provided as IDs, but we can easily get the mapping to strings (and vice versa)\n",
        "by accessing the `Dataset.features` attribute:"
      ],
      "metadata": {
        "id": "_M_kfBpA1gNg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "intents = clinc[\"test\"].features[\"intent\"]\n",
        "intents.int2str(clinc[\"test\"][42][\"intent\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "VhTLlAHg1iVg",
        "outputId": "bf1eb3dc-9603-427c-8bb2-cb9f067f6776"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'transfer'"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Exploring Class distribution"
      ],
      "metadata": {
        "id": "9d7m9nc-D5Wk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have a basic understanding of the contents in the CLINC150 dataset, let’s check it class distribution."
      ],
      "metadata": {
        "id": "Ii9JuBXW3csg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clinc.set_format(type=\"pandas\")\n",
        "\n",
        "df = clinc[\"train\"][:]\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "kvjEe7k63yj_",
        "outputId": "1095971b-e584-47fa-e002-b28133867c2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-6bfd3008-895c-4b98-8a5f-c01e7770ffca\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>intent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>what expression would i use to say i love you ...</td>\n",
              "      <td>61</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>can you tell me how to say 'i do not speak muc...</td>\n",
              "      <td>61</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>what is the equivalent of, 'life is good' in f...</td>\n",
              "      <td>61</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>tell me how to say, 'it is a beautiful morning...</td>\n",
              "      <td>61</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>if i were mongolian, how would i say that i am...</td>\n",
              "      <td>61</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6bfd3008-895c-4b98-8a5f-c01e7770ffca')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6bfd3008-895c-4b98-8a5f-c01e7770ffca button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6bfd3008-895c-4b98-8a5f-c01e7770ffca');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                text  intent\n",
              "0  what expression would i use to say i love you ...      61\n",
              "1  can you tell me how to say 'i do not speak muc...      61\n",
              "2  what is the equivalent of, 'life is good' in f...      61\n",
              "3  tell me how to say, 'it is a beautiful morning...      61\n",
              "4  if i were mongolian, how would i say that i am...      61"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def label_int2str(row, split):\n",
        "  return clinc[split].features[\"intent\"].int2str(row)"
      ],
      "metadata": {
        "id": "S4qNxogY4G5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"label_name\"] = df[\"intent\"].apply(label_int2str, split=\"train\")\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "7BBQ5y8C4HUd",
        "outputId": "dc13c3d1-c0a4-41ca-b294-824d91d815ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-d47c1d80-b287-4058-8961-0a808633465c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>intent</th>\n",
              "      <th>label_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>what expression would i use to say i love you ...</td>\n",
              "      <td>61</td>\n",
              "      <td>translate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>can you tell me how to say 'i do not speak muc...</td>\n",
              "      <td>61</td>\n",
              "      <td>translate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>what is the equivalent of, 'life is good' in f...</td>\n",
              "      <td>61</td>\n",
              "      <td>translate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>tell me how to say, 'it is a beautiful morning...</td>\n",
              "      <td>61</td>\n",
              "      <td>translate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>if i were mongolian, how would i say that i am...</td>\n",
              "      <td>61</td>\n",
              "      <td>translate</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d47c1d80-b287-4058-8961-0a808633465c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d47c1d80-b287-4058-8961-0a808633465c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d47c1d80-b287-4058-8961-0a808633465c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                text  intent label_name\n",
              "0  what expression would i use to say i love you ...      61  translate\n",
              "1  can you tell me how to say 'i do not speak muc...      61  translate\n",
              "2  what is the equivalent of, 'life is good' in f...      61  translate\n",
              "3  tell me how to say, 'it is a beautiful morning...      61  translate\n",
              "4  if i were mongolian, how would i say that i am...      61  translate"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"label_name\"].value_counts(ascending=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ig5e0lu4-S5",
        "outputId": "db5de7a6-d3bf-4ec3-e175-a03d933596eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "todo_list                100\n",
              "credit_score             100\n",
              "book_hotel               100\n",
              "freeze_account           100\n",
              "reminder_update          100\n",
              "                        ... \n",
              "expiration_date          100\n",
              "what_are_your_hobbies    100\n",
              "pay_bill                 100\n",
              "transactions             100\n",
              "oos                      250\n",
              "Name: label_name, Length: 151, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"label_name\"].value_counts(ascending=True).plot.barh()\n",
        "plt.title(\"Intent Counts\");"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "2BXcUSw13gJK",
        "outputId": "7dbebc72-fbaf-494e-f51c-647c4e6ddf67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reset back to original format\n",
        "clinc.reset_format()"
      ],
      "metadata": {
        "id": "nogbgDni5pew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Benchmark statistics"
      ],
      "metadata": {
        "id": "5lrgcTOpDmNN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since the dataset is balanced across the intent\n",
        "classes, we’ll use accuracy as our metric which we can load from Datasets.\n",
        "\n",
        "let’s implement the compute_accuracy function:"
      ],
      "metadata": {
        "id": "MpBAkN4mDyoR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score = load_metric(\"accuracy\")\n",
        "accuracy_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358,
          "referenced_widgets": [
            "dfa6f22a73e644a19d788956106efddf",
            "ca5f6c401b5b4c46a008aec2d65169b1",
            "a992b29ee2a94f40b91c02057138b367",
            "cdea506700fa43f8a96ec777c24368ef",
            "68b42cd3cbb34e0ea142799cbca5288b",
            "6311014059414e478101c22e2bcac5bb",
            "19037b0b8fe24109a4a79d9ea7b99dec",
            "a35f5e7b6b77420ea338f68b83eff121",
            "a85664ff3cca486e95cd807264423960",
            "22df2ece2d8d4cc5a89b32e0f917dcc4",
            "55f42453402e41568eb6722aee615931"
          ]
        },
        "id": "3cNor6J857nf",
        "outputId": "fa78cab9-29bb-4158-9e42-d07b064fa627"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dfa6f22a73e644a19d788956106efddf",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.42k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Metric(name: \"accuracy\", features: {'predictions': Value(dtype='int32', id=None), 'references': Value(dtype='int32', id=None)}, usage: \"\"\"\n",
              "Args:\n",
              "    predictions: Predicted labels, as returned by a model.\n",
              "    references: Ground truth labels.\n",
              "    normalize: If False, return the number of correctly classified samples.\n",
              "        Otherwise, return the fraction of correctly classified samples.\n",
              "    sample_weight: Sample weights.\n",
              "Returns:\n",
              "    accuracy: Accuracy score.\n",
              "Examples:\n",
              "\n",
              "    >>> accuracy_metric = datasets.load_metric(\"accuracy\")\n",
              "    >>> results = accuracy_metric.compute(references=[0, 1], predictions=[0, 1])\n",
              "    >>> print(results)\n",
              "    {'accuracy': 1.0}\n",
              "\"\"\", stored examples: 0)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The metric’s description tells us that we need to provide the predictions and references (i.e. the ground truth labels) as integers, so we can use the pipeline to extract the predictions from the\n",
        "text field and then use the `ClassLabel.str2int` function to map the prediction to its corresponding ID.\n",
        "\n",
        "So we need to collect all the predictions and labels in lists before\n",
        "returning the accuracy on the dataset. "
      ],
      "metadata": {
        "id": "0ifeF1Ip6iyX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, let’s compute the size of our model by using the `torch.save` function from PyTorch to serialize the model to disk.In PyTorch,\n",
        "the recommended way to save a model is by using its `state_dict`, which is a Python dictionary that maps each layer in a model to its learnable parameters (i.e. weights and biases).\n",
        "\n",
        "Let’s see what is stored in the `state_dict` of our baseline model:"
      ],
      "metadata": {
        "id": "omnODJah9Zfb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "list(bert_pipeline.model.state_dict().items())[42]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6tJJOTl9quL",
        "outputId": "56de43d4-ff10-4a17-ea65-65010ba43fed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('bert.encoder.layer.2.attention.self.value.weight',\n",
              " tensor([[-1.0526e-02, -3.2215e-02,  2.2097e-02,  ..., -6.0953e-03,\n",
              "           4.6521e-03,  2.9844e-02],\n",
              "         [-1.4964e-02, -1.0915e-02,  5.2396e-04,  ...,  3.2047e-05,\n",
              "          -2.6890e-02, -2.1943e-02],\n",
              "         [-2.9640e-02, -3.7842e-03, -1.2582e-02,  ..., -1.0917e-02,\n",
              "           3.1152e-02, -9.7786e-03],\n",
              "         ...,\n",
              "         [-1.5116e-02, -3.3226e-02,  4.2063e-02,  ..., -5.2652e-03,\n",
              "           1.1093e-02,  2.9703e-03],\n",
              "         [-3.6809e-02,  5.6848e-02, -2.6544e-02,  ..., -4.0114e-02,\n",
              "           6.7487e-03,  1.0511e-03],\n",
              "         [-2.4961e-02,  1.4747e-03, -5.4271e-02,  ...,  2.0004e-02,\n",
              "           2.3981e-02, -4.2880e-02]]))"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can clearly see that each key-value pair corresponds to a specific layer and tensor in BERT.\n",
        "\n",
        "We can then use the Path.stat function from Python’s `pathlib` module to get information about the underlying files. In particular `Path(PATH).stat().st_size` will give us the model size in bytes."
      ],
      "metadata": {
        "id": "sRzVsR2k-BxR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally let’s implement the `time_pipeline` function so that we can time the median latency\n",
        "per query. For this application, latency refers to the time it takes to feed a text query to the\n",
        "pipeline and return the predicted intent from the model.\n",
        "\n",
        "Under the hood, the pipeline also\n",
        "tokenizes the text but this is around 1,000 times faster than generating the predictions and thus\n",
        "adds a negligible contribution to the overall latency.\n",
        "\n",
        "A simple way to measure the time of a\n",
        "code snippet is to use the `perf_counter` function from Python’s `time` module. This function has a better time resolution than the `time.time` function and so is well suited for getting precise results.\n",
        "\n",
        "We can use `perf_counter` to time our `pipeline` by passing our test query and calculating the\n",
        "time difference in milliseconds between the start and end:"
      ],
      "metadata": {
        "id": "wZF_qb7NAEXS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for _ in range(3):\n",
        "  start_time = perf_counter()\n",
        "  _ = bert_pipeline(query)\n",
        "  latency = perf_counter() - start_time\n",
        "  print(f\"Latency (ms) - {1000 * latency:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3kj_JIxAYDs",
        "outputId": "8f4bd8d6-8e54-4044-fb72-a86e0ee81486"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Latency (ms) - 156.390\n",
            "Latency (ms) - 149.952\n",
            "Latency (ms) - 138.118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So instead,\n",
        "we’ll collect the latencies over many runs and then use the resulting distribution to calculate the\n",
        "mean and standard deviation, which will give us an idea about the spread in values. "
      ],
      "metadata": {
        "id": "ZXrtyG41CIcI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Benchmarking Our Baseline Model"
      ],
      "metadata": {
        "id": "YmmzDTmVDada"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that our `PerformanceBenchmark` is complete, let’s give it a spin! For the baseline\n",
        "model we just need to pass the pipeline and dataset we wish to perform the benchmark on, and\n",
        "we’ll collect the results in the `perf_metrics` dictionary to keep track of each model’s\n",
        "performance:"
      ],
      "metadata": {
        "id": "83rwOZcdDbMO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pb = PerformanceBenchmark(bert_pipeline, clinc[\"test\"])\n",
        "perf_metrics = pb.run_benchmark()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMRdYK5sEehl",
        "outputId": "7431dc82-dd54-4583-d43f-c224eb789e6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model size (MB) - 418.16\n",
            "Average latency (ms) - 121.31 +\\- 56.99\n",
            "Accuracy on test set - 0.867\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once we have determined the best performing model we can then explore different backends to reduce the absolute latency if needed.\n",
        "\n",
        "Now that we have a reference point, let’s look at our first compression technique: **knowledge distillation**."
      ],
      "metadata": {
        "id": "UGxlw8_fE8Ou"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Knowledge Distillation for Smaller Models "
      ],
      "metadata": {
        "id": "eft__0YfFDQu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Knowledge distillation is a general-purpose method for training a smaller student model to mimic the behavior of a slower, larger, but better performing teacher."
      ],
      "metadata": {
        "id": "nAA500rZ_mXn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Knowledge Distillation for Pretraining"
      ],
      "metadata": {
        "id": "yZiJmuOy_Vas"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Knowledge distillation can also be used during pretraining to create a general-purpose student\n",
        "that can be subsequently fine-tuned on downstream tasks. In this case, the teacher is a\n",
        "pretrained language model like BERT which transfers its knowledge about masked-languagemodeling\n",
        "to the student. \n",
        "\n",
        "For example, in the DistilBERT paper, the masked-languagemodeling\n",
        "loss $L_{mlm}$ is augmented with a term from knowledge distillation and a cosine\n",
        "embedding loss $L_{cos} = 1− cos (h_s, h_t)$ to align the directions of the hidden state vectors between the teacher and student:\n",
        "\n",
        "$$L_{DistilBERT} = \\alpha L_{mlm} + \\beta L_{KD} + \\gamma L_{cos}$$\n",
        "\n",
        "Since we already have a fine-tuned BERT-base model, let’s see how we can use knowledge distillation to fine-tune a smaller and faster model. To do that we’ll need a way to augment the cross-entropy loss with a $L_{KD}$ term; fortunately we can do this by creating our own trainer!"
      ],
      "metadata": {
        "id": "u_NZvi7g_1Qi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Knowledge Distillation Trainer"
      ],
      "metadata": {
        "id": "Fp6K2B7nCh2N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To implement knowledge distillation we need to add a few things to the `Trainer` base class:\n",
        "\n",
        "- The new hyperparameters $\\alpha$ and $T$ which control the relative weight of the distillation loss and how much the probability distribution of the labels should be smoothed.\n",
        "- The fine-tuned teacher model, which in our case is `BERT-base`\n",
        "- A new loss function that includes the cross-entropy loss with the knowledge\n",
        "distillation loss.\n",
        "\n",
        "Adding the new hyperparameters is quite simple since we just need to subclass\n",
        "`TrainingArguments` and include them as new attributes:"
      ],
      "metadata": {
        "id": "npBIwXwuCjF-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DistillationTrainingArguments(TrainingArguments):\n",
        "  def __init__(self, *args, alpha=0.5, temperature=2.0, **kwargs):\n",
        "    super().__init__(*args, **kwargs)\n",
        "    self.alpha = alpha\n",
        "    self.temperature = temperature"
      ],
      "metadata": {
        "id": "1kTBUu3UDGMa"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the trainer itself, we want a new loss function so the way to implement this is by subclassing `Trainer` and overriding the `compute_loss` function to include the knowledge distillation loss term $L_{KD}$:"
      ],
      "metadata": {
        "id": "60pJYgs6D3g0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DistillationTrainer(Trainer):\n",
        "  def __init__(self, *args, teacher_model=None, **kwargs):\n",
        "    super().__init__(*args, **kwargs)\n",
        "    self.teacher_model = teacher_model\n",
        "\n",
        "  #reference: https://discuss.huggingface.co/t/custom-loss-compute-loss-got-an-unexpected-keyword-argument-return-outputs/4148\n",
        "  def compute_loss(self, model, inputs, return_outputs=False):\n",
        "    outputs_student = model(**inputs)\n",
        "    # Extract cross-entropy loss and logits from student\n",
        "    loss_ce = outputs_student.loss\n",
        "    logits_student = outputs_student.logits\n",
        "    # Extract logits from teacher\n",
        "    with torch.no_grad():\n",
        "      outputs_teacher = self.teacher_model(**inputs)\n",
        "      logits_teacher = outputs_teacher.logits\n",
        "    # Soften probabilities and compute distillation loss\n",
        "    loss_kld = nn.KLDivLoss(reduction=\"batchmean\")\n",
        "    loss_kd = self.args.temperature ** 2 * loss_kld(\n",
        "        F.log_softmax(logits_student / self.args.temperature, dim=-1),\n",
        "        F.softmax(logits_teacher / self.args.temperature, dim=-1)\n",
        "    )\n",
        "    # Return weighted student loss\n",
        "    return (loss_ce, outputs_student) if return_outputs else  self.args.alpha * loss_ce + (1. - self.args.alpha) * loss_kd"
      ],
      "metadata": {
        "id": "Wqs3s63AD_Z7"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "help(Trainer.compute_loss)"
      ],
      "metadata": {
        "id": "O57Zu5kdYKbU",
        "outputId": "e9f7d6ec-edac-45c6-9d0d-d38c7ce5752d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on function compute_loss in module transformers.trainer:\n",
            "\n",
            "compute_loss(self, model, inputs, return_outputs=False)\n",
            "    How the loss is computed by Trainer. By default, all models return the loss in the first element.\n",
            "    \n",
            "    Subclass and override for custom behavior.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "When we instantiate `DistillationTrainer`, we pass a `teacher_model` argument with a teacher that has already been fine-tuned on our task. \n",
        "\n",
        "Next, in the `compute_loss` function we extract the logits from the student and teacher, scale them\n",
        "by the temperature and then normalize them with a softmax before passing them to PyTorch’s `nn.KLDivLoss` function for computing the KL divergence. \n",
        "Since `nn.KLDivLoss` expects the inputs in the form of `log-probabilities`, we’ve used the `F.log_softmax` function to\n",
        "normalize the student’s logits, while the teacher’s logits are converted to probabilities with a standard softmax. The `reduction=batchmean` argument in `nn.KLDivLoss` specifies that we average the losses over the batch dimension."
      ],
      "metadata": {
        "id": "BPtnIJhBIv-J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Student Initialization"
      ],
      "metadata": {
        "id": "6knZ667PJX4e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We should pick smaller model for the student to reduce the latency and memory footprint, and a good rule of thumb from the literature is that knowledge distillation works best when the teacher and student are of the same model type.\n",
        "\n",
        "One possible reason for this is that different model types, say BERT and\n",
        "RoBERTa, can have different output embedding spaces which hinders the ability of the student to mimic the teacher.\n",
        "\n",
        "In our case study, the teacher is BERT-base so DistilBERT is natural\n",
        "candidate to intitialize the student since it has 40% less parameters and has been shown to achieve strong results on downstream tasks.\n",
        "\n",
        "First we’ll need to tokenize and encode our queries, so let’s instantiate the tokenizer from DistilBERT and create a simple function to take care of the preprocessing:"
      ],
      "metadata": {
        "id": "PH0nMZIJJYyr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "student_ckpt = \"distilbert-base-uncased\"\n",
        "student_tokenizer = AutoTokenizer.from_pretrained(student_ckpt)"
      ],
      "metadata": {
        "id": "ax_JZOv2K0vc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_text(batch, tokenizer):\n",
        "  return tokenizer(batch[\"text\"], truncation=True)"
      ],
      "metadata": {
        "id": "gCFG9TGyLIEs"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# removed the text column since we no longer need it\n",
        "clinc_enc = clinc.map(tokenize_text, batched=True, remove_columns=[\"text\"], fn_kwargs={\"tokenizer\": student_tokenizer})\n",
        "# renamed the intent column to labels so it can be automatically detected by the trainer\n",
        "clinc_enc.rename_column_(\"intent\", \"labels\")"
      ],
      "metadata": {
        "id": "0lqqjIXwLVm-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clinc_enc[\"train\"][0]"
      ],
      "metadata": {
        "id": "4N1gOFu3MMCO",
        "outputId": "8ae49d3d-ce01-4f50-fcb9-f726af5a5dd7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              " 'input_ids': [101,\n",
              "  2054,\n",
              "  3670,\n",
              "  2052,\n",
              "  1045,\n",
              "  2224,\n",
              "  2000,\n",
              "  2360,\n",
              "  1045,\n",
              "  2293,\n",
              "  2017,\n",
              "  2065,\n",
              "  1045,\n",
              "  2020,\n",
              "  2019,\n",
              "  3059,\n",
              "  102],\n",
              " 'labels': 61}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that our texts are processed, the next thing to do is instantiate\n",
        "DistilBERT for fine-tuning. Since we will be doing multiple runs with the trainer, we’ll use a function to initialize the model with each new run:"
      ],
      "metadata": {
        "id": "gEyc7WqqMdO_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_labels = intents.num_classes\n",
        "id2label = bert_model.config.id2label\n",
        "label2id = bert_model.config.label2id\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "rAihzuJYMes1"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "student_config = (AutoConfig.from_pretrained(student_ckpt, num_labels=num_labels, id2label=id2label, label2id=label2id))"
      ],
      "metadata": {
        "id": "wZDE5_CXNEki"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def student_init():\n",
        "  return (AutoModelForSequenceClassification.from_pretrained(student_ckpt, config=student_config).to(device))"
      ],
      "metadata": {
        "id": "CWMVApsPNci3"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we need to define the metrics to track during training. As we did in the\n",
        "performance benchmark, we’ll use accuracy as the main metric so we can reuse our\n",
        "`accuracy_score` function in the `compute_metrics` function that we’ll include in the trainer:"
      ],
      "metadata": {
        "id": "sDfs6hUbN55r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(pred):\n",
        "  predictions, labels = pred\n",
        "  # find the most confident class prediction\n",
        "  predictions = np.argmax(predictions, axis=1)\n",
        "  # and compare that against the ground truth labels\n",
        "  return accuracy_score.compute(predictions=predictions, references=labels)"
      ],
      "metadata": {
        "id": "BJkOaxRFN99g"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we just need to define the training arguments. To warm-up, we’ll set $\\alpha = 1$ to see how well DistilBERT performs without any signal from the teacher:"
      ],
      "metadata": {
        "id": "7HuGGqt_P_MI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 48\n",
        "\n",
        "student_training_args = DistillationTrainingArguments(\n",
        "    output_dir=\"checkpoints\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    num_train_epochs=5,\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    alpha=1,\n",
        "    weight_decay=0.01\n",
        ")"
      ],
      "metadata": {
        "id": "2cuML55IQHLn"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we load the teacher model, instantiate the trainer and start fine-tuning:"
      ],
      "metadata": {
        "id": "1Dz0_3o9Qqjc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "teacher_checkpoint = \"transformersbook/bert-base-uncased-finetuned-clinc\"\n",
        "teacher_model = (AutoModelForSequenceClassification.from_pretrained(teacher_checkpoint, num_labels=num_labels).to(device))"
      ],
      "metadata": {
        "id": "naP58JFbQrDO"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "distil_trainer = DistillationTrainer(model_init=student_init, \n",
        "                                     teacher_model=teacher_model,\n",
        "                                     args=student_training_args,\n",
        "                                     train_dataset=clinc_enc[\"train\"],\n",
        "                                     eval_dataset=clinc_enc[\"validation\"],\n",
        "                                     compute_metrics=compute_metrics,\n",
        "                                     tokenizer=student_tokenizer)"
      ],
      "metadata": {
        "id": "2VYL8HDKvYMr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Searching Hyperparameters with Optuna"
      ],
      "metadata": {
        "id": "djZ0VsfUitow"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To use Optuna in Transformers, we use logic by first defining the hyperparameter space that we wish to optimize over. \n",
        "\n",
        "In addition to $\\alpha$ and $T$, we’ll include the number of training epochs as follows:"
      ],
      "metadata": {
        "id": "pWJ8U18tt29M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def hp_space(trial):\n",
        "  return {\n",
        "      \"num_train_epochs\": trial.suggest_int(\"num_train_epochs\", 5, 10),\n",
        "      \"alpha\": trial.suggest_float(\"alpha\", 0, 1),\n",
        "      \"temperature\": trial.suggest_int(\"temperature\", 2, 20)\n",
        "  }"
      ],
      "metadata": {
        "id": "DfSs7BlcuJ9P"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Running the hyperparameter search with the `Trainer` is then quite simple; we just need to specify the number of trials to run and a direction to optimize for. \n",
        "\n",
        "Since we want the best possible accuracy, we pick `direction=\"maximize\"` in the\n",
        "`Trainer.hyperparameter_search` function and pass the hyperparameter search space as follows:"
      ],
      "metadata": {
        "id": "X2RnRgEQu0Ig"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#best_run = distil_trainer.hyperparameter_search(n_trials=9, direction=\"maximize\", hp_space=hp_space)"
      ],
      "metadata": {
        "id": "TaW2XKIEvAF6",
        "outputId": "35dc3c0a-df01-4f38-8b43-da11223ca3d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-01-04 05:44:21,314]\u001b[0m A new study created in memory with name: no-name-d2a99066-d76f-422a-a941-2172904d82d7\u001b[0m\n",
            "Trial:\n",
            "loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_transform.bias']\n",
            "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.weight', 'classifier.bias', 'pre_classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "***** Running training *****\n",
            "  Num examples = 15250\n",
            "  Num Epochs = 6\n",
            "  Instantaneous batch size per device = 48\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 48\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 1908\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1908' max='1908' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1908/1908 15:37, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>3.355246</td>\n",
              "      <td>0.591290</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.329500</td>\n",
              "      <td>2.493410</td>\n",
              "      <td>0.823548</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.329500</td>\n",
              "      <td>2.087803</td>\n",
              "      <td>0.883871</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.121200</td>\n",
              "      <td>1.869722</td>\n",
              "      <td>0.898387</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.081900</td>\n",
              "      <td>1.758626</td>\n",
              "      <td>0.906129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.081900</td>\n",
              "      <td>1.721609</td>\n",
              "      <td>0.909677</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "Saving model checkpoint to checkpoints/run-0/checkpoint-500\n",
            "Configuration saved in checkpoints/run-0/checkpoint-500/config.json\n",
            "Model weights saved in checkpoints/run-0/checkpoint-500/pytorch_model.bin\n",
            "tokenizer config file saved in checkpoints/run-0/checkpoint-500/tokenizer_config.json\n",
            "Special tokens file saved in checkpoints/run-0/checkpoint-500/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "Saving model checkpoint to checkpoints/run-0/checkpoint-1000\n",
            "Configuration saved in checkpoints/run-0/checkpoint-1000/config.json\n",
            "Model weights saved in checkpoints/run-0/checkpoint-1000/pytorch_model.bin\n",
            "tokenizer config file saved in checkpoints/run-0/checkpoint-1000/tokenizer_config.json\n",
            "Special tokens file saved in checkpoints/run-0/checkpoint-1000/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "Saving model checkpoint to checkpoints/run-0/checkpoint-1500\n",
            "Configuration saved in checkpoints/run-0/checkpoint-1500/config.json\n",
            "Model weights saved in checkpoints/run-0/checkpoint-1500/pytorch_model.bin\n",
            "tokenizer config file saved in checkpoints/run-0/checkpoint-1500/tokenizer_config.json\n",
            "Special tokens file saved in checkpoints/run-0/checkpoint-1500/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "\u001b[32m[I 2022-01-04 06:00:00,850]\u001b[0m Trial 0 finished with value: 0.9096774193548387 and parameters: {'num_train_epochs': 6, 'alpha': 0.2854327469522183, 'temperature': 10}. Best is trial 0 with value: 0.9096774193548387.\u001b[0m\n",
            "Trial:\n",
            "loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_transform.bias']\n",
            "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.weight', 'classifier.bias', 'pre_classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "***** Running training *****\n",
            "  Num examples = 15250\n",
            "  Num Epochs = 6\n",
            "  Instantaneous batch size per device = 48\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 48\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 1908\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1908' max='1908' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1908/1908 15:39, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>3.408157</td>\n",
              "      <td>0.578710</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.313600</td>\n",
              "      <td>2.579459</td>\n",
              "      <td>0.820645</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.313600</td>\n",
              "      <td>2.187435</td>\n",
              "      <td>0.881613</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.116500</td>\n",
              "      <td>1.973373</td>\n",
              "      <td>0.894194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.079700</td>\n",
              "      <td>1.863230</td>\n",
              "      <td>0.903548</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.079700</td>\n",
              "      <td>1.826285</td>\n",
              "      <td>0.907419</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "Saving model checkpoint to checkpoints/run-1/checkpoint-500\n",
            "Configuration saved in checkpoints/run-1/checkpoint-500/config.json\n",
            "Model weights saved in checkpoints/run-1/checkpoint-500/pytorch_model.bin\n",
            "tokenizer config file saved in checkpoints/run-1/checkpoint-500/tokenizer_config.json\n",
            "Special tokens file saved in checkpoints/run-1/checkpoint-500/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "Saving model checkpoint to checkpoints/run-1/checkpoint-1000\n",
            "Configuration saved in checkpoints/run-1/checkpoint-1000/config.json\n",
            "Model weights saved in checkpoints/run-1/checkpoint-1000/pytorch_model.bin\n",
            "tokenizer config file saved in checkpoints/run-1/checkpoint-1000/tokenizer_config.json\n",
            "Special tokens file saved in checkpoints/run-1/checkpoint-1000/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "Saving model checkpoint to checkpoints/run-1/checkpoint-1500\n",
            "Configuration saved in checkpoints/run-1/checkpoint-1500/config.json\n",
            "Model weights saved in checkpoints/run-1/checkpoint-1500/pytorch_model.bin\n",
            "tokenizer config file saved in checkpoints/run-1/checkpoint-1500/tokenizer_config.json\n",
            "Special tokens file saved in checkpoints/run-1/checkpoint-1500/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "\u001b[32m[I 2022-01-04 06:15:42,140]\u001b[0m Trial 1 finished with value: 0.9074193548387097 and parameters: {'num_train_epochs': 6, 'alpha': 0.1385401001076597, 'temperature': 18}. Best is trial 0 with value: 0.9096774193548387.\u001b[0m\n",
            "Trial:\n",
            "loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_transform.bias']\n",
            "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.weight', 'classifier.bias', 'pre_classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "***** Running training *****\n",
            "  Num examples = 15250\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 48\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 48\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 3180\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3180' max='3180' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3180/3180 26:04, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>3.253449</td>\n",
              "      <td>0.619355</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.342000</td>\n",
              "      <td>2.303326</td>\n",
              "      <td>0.840000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.342000</td>\n",
              "      <td>1.838901</td>\n",
              "      <td>0.899677</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.115700</td>\n",
              "      <td>1.581436</td>\n",
              "      <td>0.912258</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.071000</td>\n",
              "      <td>1.421929</td>\n",
              "      <td>0.917097</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.071000</td>\n",
              "      <td>1.321549</td>\n",
              "      <td>0.921290</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.054900</td>\n",
              "      <td>1.264956</td>\n",
              "      <td>0.922581</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.047300</td>\n",
              "      <td>1.224378</td>\n",
              "      <td>0.926129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.047300</td>\n",
              "      <td>1.202448</td>\n",
              "      <td>0.928710</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.043800</td>\n",
              "      <td>1.194174</td>\n",
              "      <td>0.928710</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "Saving model checkpoint to checkpoints/run-2/checkpoint-500\n",
            "Configuration saved in checkpoints/run-2/checkpoint-500/config.json\n",
            "Model weights saved in checkpoints/run-2/checkpoint-500/pytorch_model.bin\n",
            "tokenizer config file saved in checkpoints/run-2/checkpoint-500/tokenizer_config.json\n",
            "Special tokens file saved in checkpoints/run-2/checkpoint-500/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "Saving model checkpoint to checkpoints/run-2/checkpoint-1000\n",
            "Configuration saved in checkpoints/run-2/checkpoint-1000/config.json\n",
            "Model weights saved in checkpoints/run-2/checkpoint-1000/pytorch_model.bin\n",
            "tokenizer config file saved in checkpoints/run-2/checkpoint-1000/tokenizer_config.json\n",
            "Special tokens file saved in checkpoints/run-2/checkpoint-1000/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "Saving model checkpoint to checkpoints/run-2/checkpoint-1500\n",
            "Configuration saved in checkpoints/run-2/checkpoint-1500/config.json\n",
            "Model weights saved in checkpoints/run-2/checkpoint-1500/pytorch_model.bin\n",
            "tokenizer config file saved in checkpoints/run-2/checkpoint-1500/tokenizer_config.json\n",
            "Special tokens file saved in checkpoints/run-2/checkpoint-1500/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "Saving model checkpoint to checkpoints/run-2/checkpoint-2000\n",
            "Configuration saved in checkpoints/run-2/checkpoint-2000/config.json\n",
            "Model weights saved in checkpoints/run-2/checkpoint-2000/pytorch_model.bin\n",
            "tokenizer config file saved in checkpoints/run-2/checkpoint-2000/tokenizer_config.json\n",
            "Special tokens file saved in checkpoints/run-2/checkpoint-2000/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "Saving model checkpoint to checkpoints/run-2/checkpoint-2500\n",
            "Configuration saved in checkpoints/run-2/checkpoint-2500/config.json\n",
            "Model weights saved in checkpoints/run-2/checkpoint-2500/pytorch_model.bin\n",
            "tokenizer config file saved in checkpoints/run-2/checkpoint-2500/tokenizer_config.json\n",
            "Special tokens file saved in checkpoints/run-2/checkpoint-2500/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "Saving model checkpoint to checkpoints/run-2/checkpoint-3000\n",
            "Configuration saved in checkpoints/run-2/checkpoint-3000/config.json\n",
            "Model weights saved in checkpoints/run-2/checkpoint-3000/pytorch_model.bin\n",
            "tokenizer config file saved in checkpoints/run-2/checkpoint-3000/tokenizer_config.json\n",
            "Special tokens file saved in checkpoints/run-2/checkpoint-3000/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "\u001b[32m[I 2022-01-04 06:41:47,784]\u001b[0m Trial 2 finished with value: 0.9287096774193548 and parameters: {'num_train_epochs': 10, 'alpha': 0.945917733737466, 'temperature': 7}. Best is trial 2 with value: 0.9287096774193548.\u001b[0m\n",
            "Trial:\n",
            "loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_transform.bias']\n",
            "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.weight', 'classifier.bias', 'pre_classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "***** Running training *****\n",
            "  Num examples = 15250\n",
            "  Num Epochs = 9\n",
            "  Instantaneous batch size per device = 48\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 48\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 2862\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2862' max='2862' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2862/2862 23:25, Epoch 9/9]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>3.315619</td>\n",
              "      <td>0.606774</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.325300</td>\n",
              "      <td>2.409095</td>\n",
              "      <td>0.835161</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.325300</td>\n",
              "      <td>1.963006</td>\n",
              "      <td>0.894839</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.113100</td>\n",
              "      <td>1.708686</td>\n",
              "      <td>0.908387</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.071400</td>\n",
              "      <td>1.549338</td>\n",
              "      <td>0.914194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.071400</td>\n",
              "      <td>1.450197</td>\n",
              "      <td>0.919355</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.056200</td>\n",
              "      <td>1.393095</td>\n",
              "      <td>0.920323</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.049300</td>\n",
              "      <td>1.357662</td>\n",
              "      <td>0.922258</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.049300</td>\n",
              "      <td>1.346244</td>\n",
              "      <td>0.924194</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "Saving model checkpoint to checkpoints/run-3/checkpoint-500\n",
            "Configuration saved in checkpoints/run-3/checkpoint-500/config.json\n",
            "Model weights saved in checkpoints/run-3/checkpoint-500/pytorch_model.bin\n",
            "tokenizer config file saved in checkpoints/run-3/checkpoint-500/tokenizer_config.json\n",
            "Special tokens file saved in checkpoints/run-3/checkpoint-500/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "Saving model checkpoint to checkpoints/run-3/checkpoint-1000\n",
            "Configuration saved in checkpoints/run-3/checkpoint-1000/config.json\n",
            "Model weights saved in checkpoints/run-3/checkpoint-1000/pytorch_model.bin\n",
            "tokenizer config file saved in checkpoints/run-3/checkpoint-1000/tokenizer_config.json\n",
            "Special tokens file saved in checkpoints/run-3/checkpoint-1000/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "Saving model checkpoint to checkpoints/run-3/checkpoint-1500\n",
            "Configuration saved in checkpoints/run-3/checkpoint-1500/config.json\n",
            "Model weights saved in checkpoints/run-3/checkpoint-1500/pytorch_model.bin\n",
            "tokenizer config file saved in checkpoints/run-3/checkpoint-1500/tokenizer_config.json\n",
            "Special tokens file saved in checkpoints/run-3/checkpoint-1500/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "Saving model checkpoint to checkpoints/run-3/checkpoint-2000\n",
            "Configuration saved in checkpoints/run-3/checkpoint-2000/config.json\n",
            "Model weights saved in checkpoints/run-3/checkpoint-2000/pytorch_model.bin\n",
            "tokenizer config file saved in checkpoints/run-3/checkpoint-2000/tokenizer_config.json\n",
            "Special tokens file saved in checkpoints/run-3/checkpoint-2000/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "Saving model checkpoint to checkpoints/run-3/checkpoint-2500\n",
            "Configuration saved in checkpoints/run-3/checkpoint-2500/config.json\n",
            "Model weights saved in checkpoints/run-3/checkpoint-2500/pytorch_model.bin\n",
            "tokenizer config file saved in checkpoints/run-3/checkpoint-2500/tokenizer_config.json\n",
            "Special tokens file saved in checkpoints/run-3/checkpoint-2500/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "\u001b[32m[I 2022-01-04 07:05:15,327]\u001b[0m Trial 3 finished with value: 0.9241935483870968 and parameters: {'num_train_epochs': 9, 'alpha': 0.10172331227255782, 'temperature': 10}. Best is trial 2 with value: 0.9287096774193548.\u001b[0m\n",
            "Trial:\n",
            "loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_transform.bias']\n",
            "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.weight', 'classifier.bias', 'pre_classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "***** Running training *****\n",
            "  Num examples = 15250\n",
            "  Num Epochs = 7\n",
            "  Instantaneous batch size per device = 48\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 48\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 2226\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2226' max='2226' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2226/2226 18:14, Epoch 7/7]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.852755</td>\n",
              "      <td>0.660000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.644500</td>\n",
              "      <td>1.698372</td>\n",
              "      <td>0.833226</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.644500</td>\n",
              "      <td>1.247921</td>\n",
              "      <td>0.895806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.174700</td>\n",
              "      <td>1.074788</td>\n",
              "      <td>0.908387</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.090300</td>\n",
              "      <td>1.000575</td>\n",
              "      <td>0.916774</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.090300</td>\n",
              "      <td>0.966434</td>\n",
              "      <td>0.920000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.070800</td>\n",
              "      <td>0.957134</td>\n",
              "      <td>0.920645</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "Saving model checkpoint to checkpoints/run-4/checkpoint-500\n",
            "Configuration saved in checkpoints/run-4/checkpoint-500/config.json\n",
            "Model weights saved in checkpoints/run-4/checkpoint-500/pytorch_model.bin\n",
            "tokenizer config file saved in checkpoints/run-4/checkpoint-500/tokenizer_config.json\n",
            "Special tokens file saved in checkpoints/run-4/checkpoint-500/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "Saving model checkpoint to checkpoints/run-4/checkpoint-1000\n",
            "Configuration saved in checkpoints/run-4/checkpoint-1000/config.json\n",
            "Model weights saved in checkpoints/run-4/checkpoint-1000/pytorch_model.bin\n",
            "tokenizer config file saved in checkpoints/run-4/checkpoint-1000/tokenizer_config.json\n",
            "Special tokens file saved in checkpoints/run-4/checkpoint-1000/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "Saving model checkpoint to checkpoints/run-4/checkpoint-1500\n",
            "Configuration saved in checkpoints/run-4/checkpoint-1500/config.json\n",
            "Model weights saved in checkpoints/run-4/checkpoint-1500/pytorch_model.bin\n",
            "tokenizer config file saved in checkpoints/run-4/checkpoint-1500/tokenizer_config.json\n",
            "Special tokens file saved in checkpoints/run-4/checkpoint-1500/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "Saving model checkpoint to checkpoints/run-4/checkpoint-2000\n",
            "Configuration saved in checkpoints/run-4/checkpoint-2000/config.json\n",
            "Model weights saved in checkpoints/run-4/checkpoint-2000/pytorch_model.bin\n",
            "tokenizer config file saved in checkpoints/run-4/checkpoint-2000/tokenizer_config.json\n",
            "Special tokens file saved in checkpoints/run-4/checkpoint-2000/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "\u001b[32m[I 2022-01-04 07:23:31,116]\u001b[0m Trial 4 finished with value: 0.9206451612903226 and parameters: {'num_train_epochs': 7, 'alpha': 0.7201430024774579, 'temperature': 2}. Best is trial 2 with value: 0.9287096774193548.\u001b[0m\n",
            "Trial:\n",
            "loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_transform.bias']\n",
            "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.weight', 'classifier.bias', 'pre_classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "***** Running training *****\n",
            "  Num examples = 15250\n",
            "  Num Epochs = 6\n",
            "  Instantaneous batch size per device = 48\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 48\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 1908\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='637' max='1908' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 637/1908 04:55 < 09:50, 2.15 it/s, Epoch 2/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>3.271601</td>\n",
              "      <td>0.613871</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.358200</td>\n",
              "      <td>2.357357</td>\n",
              "      <td>0.826129</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "Saving model checkpoint to checkpoints/run-5/checkpoint-500\n",
            "Configuration saved in checkpoints/run-5/checkpoint-500/config.json\n",
            "Model weights saved in checkpoints/run-5/checkpoint-500/pytorch_model.bin\n",
            "tokenizer config file saved in checkpoints/run-5/checkpoint-500/tokenizer_config.json\n",
            "Special tokens file saved in checkpoints/run-5/checkpoint-500/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "\u001b[32m[I 2022-01-04 07:28:43,761]\u001b[0m Trial 5 pruned. \u001b[0m\n",
            "Trial:\n",
            "loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_transform.bias']\n",
            "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.weight', 'classifier.bias', 'pre_classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "***** Running training *****\n",
            "  Num examples = 15250\n",
            "  Num Epochs = 9\n",
            "  Instantaneous batch size per device = 48\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 48\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 2862\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='319' max='2862' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 319/2862 02:19 < 18:35, 2.28 it/s, Epoch 1/9]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>3.346272</td>\n",
              "      <td>0.597097</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "\u001b[32m[I 2022-01-04 07:31:20,543]\u001b[0m Trial 6 pruned. \u001b[0m\n",
            "Trial:\n",
            "loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_transform.bias']\n",
            "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.weight', 'classifier.bias', 'pre_classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "***** Running training *****\n",
            "  Num examples = 15250\n",
            "  Num Epochs = 9\n",
            "  Instantaneous batch size per device = 48\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 48\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 2862\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='319' max='2862' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 319/2862 02:19 < 18:41, 2.27 it/s, Epoch 1/9]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>3.346272</td>\n",
              "      <td>0.597097</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "\u001b[32m[I 2022-01-04 07:33:57,893]\u001b[0m Trial 7 pruned. \u001b[0m\n",
            "Trial:\n",
            "loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_transform.bias']\n",
            "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.weight', 'classifier.bias', 'pre_classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "***** Running training *****\n",
            "  Num examples = 15250\n",
            "  Num Epochs = 9\n",
            "  Instantaneous batch size per device = 48\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 48\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 2862\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='319' max='2862' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 319/2862 02:19 < 18:37, 2.28 it/s, Epoch 1/9]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>3.358032</td>\n",
              "      <td>0.594516</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "\u001b[32m[I 2022-01-04 07:36:34,750]\u001b[0m Trial 8 pruned. \u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `hyperparameter_search` method returns a `BestRun` object which contains the\n",
        "value of the objective that was maximized (by default the sum of all metrics) and the hyperparameters it used for that run:"
      ],
      "metadata": {
        "id": "wKADpZj9v7UC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#best_run"
      ],
      "metadata": {
        "id": "sE7kqdOSwA1G",
        "outputId": "854a40a7-0c2a-4d9d-b9f0-66d7cc8b2688",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BestRun(run_id='2', objective=0.9287096774193548, hyperparameters={'num_train_epochs': 10, 'alpha': 0.945917733737466, 'temperature': 7})"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This value of $\\alpha$ tells us that most of the training signal is coming from the knowledge distillation term. \n",
        "\n",
        "Let’s update our trainer with these values and run the final training run:"
      ],
      "metadata": {
        "id": "UXcJARmBwV3N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# just hard-coding hyper-parametrs due to Colab disk constraint\n",
        "hyperparameters={\"num_train_epochs\": 8, \"alpha\": 0.31235083318309453, \"temperature\": 16}\n",
        "\n",
        "#for k, v in best_run.hyperparameters.items():\n",
        "for k, v in hyperparameters.items():\n",
        "  setattr(distil_trainer.args, k, v)\n",
        "\n",
        "# now finally, train the model\n",
        "distil_trainer.train();"
      ],
      "metadata": {
        "id": "P73yTfPowcdN",
        "outputId": "0406b0f1-8204-4730-9d04-5c9b170420ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_projector.bias']\n",
            "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'pre_classifier.bias', 'pre_classifier.weight', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "***** Running training *****\n",
            "  Num examples = 15250\n",
            "  Num Epochs = 8\n",
            "  Instantaneous batch size per device = 48\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 48\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 2544\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2544' max='2544' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2544/2544 16:43, Epoch 8/8]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.931132</td>\n",
              "      <td>0.760000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.380700</td>\n",
              "      <td>1.535642</td>\n",
              "      <td>0.875161</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.380700</td>\n",
              "      <td>0.860632</td>\n",
              "      <td>0.920645</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.554300</td>\n",
              "      <td>0.583403</td>\n",
              "      <td>0.932903</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.271200</td>\n",
              "      <td>0.465287</td>\n",
              "      <td>0.940645</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.271200</td>\n",
              "      <td>0.416455</td>\n",
              "      <td>0.941290</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.191100</td>\n",
              "      <td>0.392423</td>\n",
              "      <td>0.941613</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.163800</td>\n",
              "      <td>0.386338</td>\n",
              "      <td>0.942903</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='319' max='2544' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 319/2544 01:51 < 13:00, 2.85 it/s, Epoch 1/8]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "    <div>\n",
              "      \n",
              "      <progress value='130' max='65' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [65/65 03:06]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to checkpoints/checkpoint-500\n",
            "Configuration saved in checkpoints/checkpoint-500/config.json\n",
            "Model weights saved in checkpoints/checkpoint-500/pytorch_model.bin\n",
            "tokenizer config file saved in checkpoints/checkpoint-500/tokenizer_config.json\n",
            "Special tokens file saved in checkpoints/checkpoint-500/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "Saving model checkpoint to checkpoints/checkpoint-1000\n",
            "Configuration saved in checkpoints/checkpoint-1000/config.json\n",
            "Model weights saved in checkpoints/checkpoint-1000/pytorch_model.bin\n",
            "tokenizer config file saved in checkpoints/checkpoint-1000/tokenizer_config.json\n",
            "Special tokens file saved in checkpoints/checkpoint-1000/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "Saving model checkpoint to checkpoints/checkpoint-1500\n",
            "Configuration saved in checkpoints/checkpoint-1500/config.json\n",
            "Model weights saved in checkpoints/checkpoint-1500/pytorch_model.bin\n",
            "tokenizer config file saved in checkpoints/checkpoint-1500/tokenizer_config.json\n",
            "Special tokens file saved in checkpoints/checkpoint-1500/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "Saving model checkpoint to checkpoints/checkpoint-2000\n",
            "Configuration saved in checkpoints/checkpoint-2000/config.json\n",
            "Model weights saved in checkpoints/checkpoint-2000/pytorch_model.bin\n",
            "tokenizer config file saved in checkpoints/checkpoint-2000/tokenizer_config.json\n",
            "Special tokens file saved in checkpoints/checkpoint-2000/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "Saving model checkpoint to checkpoints/checkpoint-2500\n",
            "Configuration saved in checkpoints/checkpoint-2500/config.json\n",
            "Model weights saved in checkpoints/checkpoint-2500/pytorch_model.bin\n",
            "tokenizer config file saved in checkpoints/checkpoint-2500/tokenizer_config.json\n",
            "Special tokens file saved in checkpoints/checkpoint-2500/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remarkably we’ve been able to train the student to match the accuracy of the teacher, despite having almost half the number of parameters! \n",
        "\n",
        "Let’s save the model for future use:"
      ],
      "metadata": {
        "id": "UAbMVYAtxBkL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "distil_trainer.save_model(\"models/distilbert-base-uncased-distilled-clinc\")"
      ],
      "metadata": {
        "id": "gBzSa92fxD0h",
        "outputId": "18c35ec5-c0e2-42d0-d3b8-4279001fece5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to models/distilbert-base-uncased-distilled-clinc\n",
            "Configuration saved in models/distilbert-base-uncased-distilled-clinc/config.json\n",
            "Model weights saved in models/distilbert-base-uncased-distilled-clinc/pytorch_model.bin\n",
            "tokenizer config file saved in models/distilbert-base-uncased-distilled-clinc/tokenizer_config.json\n",
            "Special tokens file saved in models/distilbert-base-uncased-distilled-clinc/special_tokens_map.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Benchmarking Our Distilled Model"
      ],
      "metadata": {
        "id": "AN8W3C1mxLrW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have an accurate student, let’s create a pipeline and redo our benchmark to see how we perform on the test set:"
      ],
      "metadata": {
        "id": "p7jjZW1PxQO2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_pipeline = TextClassificationPipeline(model=distil_trainer.model.to(\"cpu\"), tokenizer=distil_trainer.tokenizer)\n",
        "\n",
        "optim_type = \"Distillation\"\n",
        "pb = PerformanceBenchmark(final_pipeline, clinc[\"test\"], optim_type=optim_type)\n",
        "perf_metrics.update(pb.run_benchmark())"
      ],
      "metadata": {
        "id": "E2xvNsa-yfXp",
        "outputId": "6e863578-d75a-478c-833e-d363b705e9ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model size (MB) - 255.89\n",
            "Average latency (ms) - 81.47 +\\- 3.89\n",
            "Accuracy on test set - 0.888\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To put these results in context, let’s also visualise them with our `plot_metrics` function:"
      ],
      "metadata": {
        "id": "QFxefKjLzeKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_metrics(perf_metrics, optim_type)"
      ],
      "metadata": {
        "id": "DHYU9AN8zf3h",
        "outputId": "9f1d9ef2-d897-4c85-aeff-df15982d537d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As expected, the model size and latency remain essentially unchanged compared to the `DistilBERT` benchmark, but the accuracy has improved and even surpassed the performance of the teacher! \n",
        "\n",
        "We can actually compress our distilled model even further using a technique\n",
        "known as `quantization`."
      ],
      "metadata": {
        "id": "BKywL1zCzwXa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Quantization for Faster Models"
      ],
      "metadata": {
        "id": "ZgAMXKyfIGay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Quantization takes a different approach; instead of reducing the number of computations, it makes them much more efficient by representing the weights and activations with lowprecision data types like `8-bit` integer (`INT8`) instead of the usual `32-bit` floating-point (`FP32`).\n",
        "\n",
        "By reducing the number of bits, the resulting model requires less memory storage, and operations like matrix multiplication can be performed much faster with integer arithmetic.\n",
        "\n",
        "Remarkably, these performance gains can be realized with little to no loss in accuracy!\n",
        "\n",
        "The basic idea is that we can “discretize” the floating-point values $f$ in each tensor by mapping their range $[f_{max}, f_{min}]$ into a smaller one $[q_{max}, q_{min}]$ of fixed-point numbers $q$, and linearly distributing all\n",
        "values in between. \n",
        "\n",
        "Mathematically, this mapping is described by the following equation:\n",
        "\n",
        "$$\n",
        "f=\\begin {pmatrix} \\frac{f_{max} - f_{min}}{q_{max}-q_{min}} \\end {pmatrix}\n",
        "(q - Z) = S(q-Z)\n",
        "$$\n",
        "\n",
        "where the scale factor $S$ is a positive floating-point number and the constant $Z$ has the same type as $q$ and is called the zero-point because it corresponds to the quantized value of the floating-point value $f = 0$. \n",
        "\n",
        "Note that the map needs to be affine so that we get back floatingpoint\n",
        "numbers when we dequantize the fixed-point ones.\n",
        "\n",
        "<img src='https://github.com/rahiakela/transformers-research-and-practice/blob/main/natural-language-processing-with-transformers/05-making-transformers-efficient-in-production/images/5.png?raw=1' width='600'/>\n",
        "\n",
        "Now, one of the main reasons why Transformers (and deep neural networks more generally) are prime candidates for quantization is that the weights and activations tend to take values in relatively small ranges. \n",
        "\n",
        "This means we don’t have to squeeze the whole range of possible `FP32`\n",
        "numbers into, say, the `28 = 256` numbers represented by `INT8`.\n",
        "\n",
        "To see this, let’s pick out one of the attention weight matrices from our `BERT-base` model and plot the frequency distribution of the values:"
      ],
      "metadata": {
        "id": "pf7W1K3EIOc_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "state_dict = bert_model.state_dict()\n",
        "weights = state_dict[\"bert.encoder.layer.0.attention.output.dense.weight\"]\n",
        "\n",
        "plt.hist(weights.flatten().numpy(), bins=250, range=(-0.3, 0.3))"
      ],
      "metadata": {
        "id": "ar2B37HuRD0D",
        "outputId": "8ed9db56-ff0c-419d-deae-57d30d550872",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([2.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "        0.0000e+00, 0.0000e+00, 2.0000e+00, 1.0000e+00, 1.0000e+00,\n",
              "        1.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
              "        0.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
              "        2.0000e+00, 0.0000e+00, 0.0000e+00, 5.0000e+00, 0.0000e+00,\n",
              "        0.0000e+00, 2.0000e+00, 3.0000e+00, 1.0000e+00, 0.0000e+00,\n",
              "        0.0000e+00, 3.0000e+00, 2.0000e+00, 0.0000e+00, 1.0000e+00,\n",
              "        2.0000e+00, 0.0000e+00, 2.0000e+00, 2.0000e+00, 3.0000e+00,\n",
              "        1.0000e+00, 2.0000e+00, 5.0000e+00, 4.0000e+00, 1.0000e+00,\n",
              "        2.0000e+00, 4.0000e+00, 1.0000e+00, 2.0000e+00, 8.0000e+00,\n",
              "        6.0000e+00, 6.0000e+00, 5.0000e+00, 6.0000e+00, 4.0000e+00,\n",
              "        1.2000e+01, 8.0000e+00, 6.0000e+00, 1.3000e+01, 1.0000e+01,\n",
              "        9.0000e+00, 1.3000e+01, 1.9000e+01, 1.6000e+01, 1.5000e+01,\n",
              "        1.6000e+01, 2.5000e+01, 2.7000e+01, 1.7000e+01, 2.7000e+01,\n",
              "        2.8000e+01, 4.3000e+01, 3.8000e+01, 3.0000e+01, 3.6000e+01,\n",
              "        4.8000e+01, 5.2000e+01, 6.1000e+01, 7.1000e+01, 7.2000e+01,\n",
              "        7.8000e+01, 9.3000e+01, 1.0000e+02, 1.0700e+02, 1.4300e+02,\n",
              "        1.4800e+02, 1.8000e+02, 2.0600e+02, 2.7200e+02, 2.7000e+02,\n",
              "        3.3500e+02, 4.0400e+02, 4.7900e+02, 5.5700e+02, 6.7600e+02,\n",
              "        8.3200e+02, 9.8600e+02, 1.1770e+03, 1.3980e+03, 1.6560e+03,\n",
              "        2.0540e+03, 2.2850e+03, 2.7860e+03, 3.2000e+03, 3.6690e+03,\n",
              "        4.2650e+03, 5.0430e+03, 5.8480e+03, 6.5450e+03, 7.6060e+03,\n",
              "        8.6560e+03, 9.6540e+03, 1.0789e+04, 1.1823e+04, 1.3107e+04,\n",
              "        1.4331e+04, 1.5519e+04, 1.6615e+04, 1.7709e+04, 1.8765e+04,\n",
              "        1.9671e+04, 2.0493e+04, 2.1072e+04, 2.1483e+04, 2.1338e+04,\n",
              "        2.1551e+04, 2.1354e+04, 2.0945e+04, 2.0037e+04, 1.9719e+04,\n",
              "        1.8558e+04, 1.7780e+04, 1.6657e+04, 1.5495e+04, 1.4120e+04,\n",
              "        1.3152e+04, 1.1995e+04, 1.1003e+04, 9.5300e+03, 8.6180e+03,\n",
              "        7.6270e+03, 6.5350e+03, 5.7900e+03, 5.0750e+03, 4.3660e+03,\n",
              "        3.7760e+03, 3.1830e+03, 2.6170e+03, 2.2970e+03, 1.9800e+03,\n",
              "        1.5950e+03, 1.3230e+03, 1.1760e+03, 9.9300e+02, 8.2900e+02,\n",
              "        6.7800e+02, 5.9900e+02, 4.8100e+02, 3.9600e+02, 3.6300e+02,\n",
              "        2.7800e+02, 2.3100e+02, 2.3900e+02, 1.6100e+02, 1.7500e+02,\n",
              "        1.5200e+02, 1.1100e+02, 1.0200e+02, 8.7000e+01, 8.7000e+01,\n",
              "        6.9000e+01, 4.8000e+01, 5.8000e+01, 3.6000e+01, 4.9000e+01,\n",
              "        3.6000e+01, 3.3000e+01, 3.5000e+01, 2.8000e+01, 3.0000e+01,\n",
              "        3.4000e+01, 3.2000e+01, 1.5000e+01, 2.2000e+01, 2.4000e+01,\n",
              "        1.2000e+01, 2.3000e+01, 9.0000e+00, 1.7000e+01, 8.0000e+00,\n",
              "        8.0000e+00, 1.2000e+01, 1.0000e+01, 4.0000e+00, 7.0000e+00,\n",
              "        4.0000e+00, 8.0000e+00, 1.3000e+01, 6.0000e+00, 0.0000e+00,\n",
              "        6.0000e+00, 5.0000e+00, 5.0000e+00, 3.0000e+00, 3.0000e+00,\n",
              "        3.0000e+00, 1.0000e+00, 3.0000e+00, 4.0000e+00, 3.0000e+00,\n",
              "        2.0000e+00, 2.0000e+00, 3.0000e+00, 2.0000e+00, 1.0000e+00,\n",
              "        2.0000e+00, 2.0000e+00, 1.0000e+00, 2.0000e+00, 2.0000e+00,\n",
              "        3.0000e+00, 1.0000e+00, 0.0000e+00, 1.0000e+00, 4.0000e+00,\n",
              "        1.0000e+00, 0.0000e+00, 1.0000e+00, 1.0000e+00, 0.0000e+00,\n",
              "        0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00,\n",
              "        0.0000e+00, 1.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00,\n",
              "        1.0000e+00, 1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
              "        0.0000e+00, 0.0000e+00, 0.0000e+00, 1.0000e+00, 0.0000e+00]),\n",
              " array([-0.3   , -0.2976, -0.2952, -0.2928, -0.2904, -0.288 , -0.2856,\n",
              "        -0.2832, -0.2808, -0.2784, -0.276 , -0.2736, -0.2712, -0.2688,\n",
              "        -0.2664, -0.264 , -0.2616, -0.2592, -0.2568, -0.2544, -0.252 ,\n",
              "        -0.2496, -0.2472, -0.2448, -0.2424, -0.24  , -0.2376, -0.2352,\n",
              "        -0.2328, -0.2304, -0.228 , -0.2256, -0.2232, -0.2208, -0.2184,\n",
              "        -0.216 , -0.2136, -0.2112, -0.2088, -0.2064, -0.204 , -0.2016,\n",
              "        -0.1992, -0.1968, -0.1944, -0.192 , -0.1896, -0.1872, -0.1848,\n",
              "        -0.1824, -0.18  , -0.1776, -0.1752, -0.1728, -0.1704, -0.168 ,\n",
              "        -0.1656, -0.1632, -0.1608, -0.1584, -0.156 , -0.1536, -0.1512,\n",
              "        -0.1488, -0.1464, -0.144 , -0.1416, -0.1392, -0.1368, -0.1344,\n",
              "        -0.132 , -0.1296, -0.1272, -0.1248, -0.1224, -0.12  , -0.1176,\n",
              "        -0.1152, -0.1128, -0.1104, -0.108 , -0.1056, -0.1032, -0.1008,\n",
              "        -0.0984, -0.096 , -0.0936, -0.0912, -0.0888, -0.0864, -0.084 ,\n",
              "        -0.0816, -0.0792, -0.0768, -0.0744, -0.072 , -0.0696, -0.0672,\n",
              "        -0.0648, -0.0624, -0.06  , -0.0576, -0.0552, -0.0528, -0.0504,\n",
              "        -0.048 , -0.0456, -0.0432, -0.0408, -0.0384, -0.036 , -0.0336,\n",
              "        -0.0312, -0.0288, -0.0264, -0.024 , -0.0216, -0.0192, -0.0168,\n",
              "        -0.0144, -0.012 , -0.0096, -0.0072, -0.0048, -0.0024,  0.    ,\n",
              "         0.0024,  0.0048,  0.0072,  0.0096,  0.012 ,  0.0144,  0.0168,\n",
              "         0.0192,  0.0216,  0.024 ,  0.0264,  0.0288,  0.0312,  0.0336,\n",
              "         0.036 ,  0.0384,  0.0408,  0.0432,  0.0456,  0.048 ,  0.0504,\n",
              "         0.0528,  0.0552,  0.0576,  0.06  ,  0.0624,  0.0648,  0.0672,\n",
              "         0.0696,  0.072 ,  0.0744,  0.0768,  0.0792,  0.0816,  0.084 ,\n",
              "         0.0864,  0.0888,  0.0912,  0.0936,  0.096 ,  0.0984,  0.1008,\n",
              "         0.1032,  0.1056,  0.108 ,  0.1104,  0.1128,  0.1152,  0.1176,\n",
              "         0.12  ,  0.1224,  0.1248,  0.1272,  0.1296,  0.132 ,  0.1344,\n",
              "         0.1368,  0.1392,  0.1416,  0.144 ,  0.1464,  0.1488,  0.1512,\n",
              "         0.1536,  0.156 ,  0.1584,  0.1608,  0.1632,  0.1656,  0.168 ,\n",
              "         0.1704,  0.1728,  0.1752,  0.1776,  0.18  ,  0.1824,  0.1848,\n",
              "         0.1872,  0.1896,  0.192 ,  0.1944,  0.1968,  0.1992,  0.2016,\n",
              "         0.204 ,  0.2064,  0.2088,  0.2112,  0.2136,  0.216 ,  0.2184,\n",
              "         0.2208,  0.2232,  0.2256,  0.228 ,  0.2304,  0.2328,  0.2352,\n",
              "         0.2376,  0.24  ,  0.2424,  0.2448,  0.2472,  0.2496,  0.252 ,\n",
              "         0.2544,  0.2568,  0.2592,  0.2616,  0.264 ,  0.2664,  0.2688,\n",
              "         0.2712,  0.2736,  0.276 ,  0.2784,  0.2808,  0.2832,  0.2856,\n",
              "         0.288 ,  0.2904,  0.2928,  0.2952,  0.2976,  0.3   ],\n",
              "       dtype=float32),\n",
              " <a list of 250 Patch objects>)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As we can see, the values of the weights are uniformly distributed in the small range $[−0. 1, 0. 1]$ around zero.\n",
        "\n",
        "Now, suppose we want to quantize this tensor as a signed `8-bit` integer.\n",
        "In that case, the range of possible values for our integers is $[q_{max}, q_{min}] = [−128, 127]$ so the zero-point coincides with the zero of `FP32` and the scale factor is calculated according to the previous equation:"
      ],
      "metadata": {
        "id": "av_8uZGFSEuA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "zero_point = 0\n",
        "scale = (weights.max() - weights.min()) / (127 - (-128))"
      ],
      "metadata": {
        "id": "CwcU222qSZ9Q"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To obtain the quantized tensor, we just need to invert the mapping $q = f/S + Z$, clamp the values, round them to the nearest integer, and represent the result in the `torch.int8` data type using the `Tensor.char` function:"
      ],
      "metadata": {
        "id": "dj9x8ZAwSweG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(weights / scale + zero_point).clamp(-128, 127).round().char()"
      ],
      "metadata": {
        "id": "MyaXuK3ES4Wv",
        "outputId": "07881d22-84fb-43fe-db05-2b6320b4ebc3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  2,  -1,   1,  ...,  -2,  -6,   9],\n",
              "        [  7,   2,  -4,  ...,  -3,   5,  -3],\n",
              "        [-15,  -8,   5,  ...,   3,   0,  -2],\n",
              "        ...,\n",
              "        [ 11,  -1,  12,  ...,  -2,   0,  -3],\n",
              "        [ -2,  -6, -13,  ...,  11,  -3, -10],\n",
              "        [-12,   5,  -3,  ...,   7,  -3,  -1]], dtype=torch.int8)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Great, we’ve just quantized our first tensor! \n",
        "\n",
        "In PyTorch we can simplify the conversion by using the `quantize_per_tensor` function together with a quantized data type\n",
        "`torch.qint` that is optimized for integer arithmetic operations:"
      ],
      "metadata": {
        "id": "VmzNu8q3Tf9b"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dtype = torch.qint8\n",
        "quantized_weights = quantize_per_tensor(weights, scale, zero_point, dtype)\n",
        "quantized_weights.int_repr()"
      ],
      "metadata": {
        "id": "9yjG_YhjTlTy",
        "outputId": "ce98018b-2b97-4d00-ffbc-05f41fd12e84",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[  2,  -1,   1,  ...,  -2,  -6,   9],\n",
              "        [  7,   2,  -4,  ...,  -3,   5,  -3],\n",
              "        [-15,  -8,   5,  ...,   3,   0,  -2],\n",
              "        ...,\n",
              "        [ 11,  -1,  12,  ...,  -2,   0,  -3],\n",
              "        [ -2,  -6, -13,  ...,  11,  -3, -10],\n",
              "        [-12,   5,  -3,  ...,   7,  -3,  -1]], dtype=torch.int8)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If we dequantize this tensor, we can visualize the frequency distribution to see the effect that rounding has had on our original values:"
      ],
      "metadata": {
        "id": "JCLyVv6uUGb9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Create histogram\n",
        "fix, ax = plt.subplots()\n",
        "ax.hist(quantized_weights.dequantize().flatten().numpy(), bins=250, range=(-0.3, 0.3));\n",
        "\n",
        "# Create zoom inset\n",
        "axins = zoomed_inset_axes(ax, 5, loc=\"upper right\")\n",
        "axins.hist(quantized_weights.dequantize().flatten().numpy(), bins=250, range=(-0.3, 0.3));\n",
        "\n",
        "x1, x2, y1, y2 = 0.05, 0.1, 500, 2500\n",
        "axins.set_xlim(x1, x2)\n",
        "axins.set_ylim(y1, y2)\n",
        "axins.axes.xaxis.set_visible(False)\n",
        "axins.axes.yaxis.set_visible(False)\n",
        "mark_inset(ax, axins, loc1=2, loc2=4, fc=\"none\", ec=\"0.5\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wuBFiqxdUIyC",
        "outputId": "49d4f0e8-1033-4d59-d265-90e83cce412b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This shows very clearly the discretization that’s induced by only mapping some of the weight values precisely and rounding the rest. To round out our little analysis, let’s compare how long it takes to compute the multiplication of two weight tensors with `FP32` and `INT8` values. \n",
        "\n",
        "For the `FP32` tensors we can multiply them using PyTorch’s nifty `@` operator:"
      ],
      "metadata": {
        "id": "S23SFOAiWUxE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "weights @ weights"
      ],
      "metadata": {
        "id": "imGE6UakWfEW",
        "outputId": "a423d601-6656-41e0-9cd8-fc25b0fcbff6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "100 loops, best of 5: 12 ms per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the quantized tensors we need the `QFunctional` wrapper class so that we can perform operations with the special `torch.qint8` data type:"
      ],
      "metadata": {
        "id": "m-03JfjUWpK7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "q_fn = QFunctional()"
      ],
      "metadata": {
        "id": "-0oZHU_qWspy"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This class supports various elementary operations like addition and in our case we can time the\n",
        "multiplication of our quantized tensors as follows:"
      ],
      "metadata": {
        "id": "DjMTk10TW-8i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "q_fn.mul(quantized_weights, quantized_weights)"
      ],
      "metadata": {
        "id": "BPQY470gXAvW",
        "outputId": "9589907f-b37f-4755-cc18-81a84e87099c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The slowest run took 27.20 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
            "1000 loops, best of 5: 449 µs per loop\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compared to our FP32 computation, using the INT8 tensors is almost 100 times faster.\n",
        "\n",
        "Since `INT8` numbers have four times less bits than `FP32`, quantization also reduces the memory storage by up to a factor of four. \n",
        "\n",
        "In our simple example we can verify this by comparing the\n",
        "underlying storage size of our weight tensor and quantized cousin by using the\n",
        "`Tensor.storage` function and the `getsizeof` function from Python’s `sys` module:"
      ],
      "metadata": {
        "id": "wBHSj5RrXawG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sys.getsizeof(weights.storage()) / sys.getsizeof(quantized_weights.storage())"
      ],
      "metadata": {
        "id": "dDgCGdq1Xqa5",
        "outputId": "16e60912-cc3a-4758-b3b8-b2d4843ef7b8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.999633833760527"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "For a full-scale Transformer, the actual compression rate depends on which layers are quantized and as we’ll see in the next section it is only the linear layers that typically get quantized.\n",
        "\n",
        "Changing the precision for all computations in our\n",
        "model introduces small disturbances at each point in the model’s computational graph which\n",
        "can compound and affect the model’s performance. \n",
        "\n",
        "There are several ways to quantize a model\n",
        "which all have pros and cons."
      ],
      "metadata": {
        "id": "LcAgOgb-YBVp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Quantization Strategies"
      ],
      "metadata": {
        "id": "xKqZKp66YOLx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "YXaaCrYUYQrd"
      }
    }
  ]
}