{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "02-case-study-intent-detection-with-quantization.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyMbQmJ2o9RbD3infecUY/+9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "01d5d97305af40c686b1dffc8da0d4c8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_420ee7b3fd434c7baaec05af95f31dc4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_31205e1fec7e4ac28b25f03691449d07",
              "IPY_MODEL_9b2d09615bb741d99020147a5bed81bd",
              "IPY_MODEL_a541bb76e6f74da89ede1556109f45d1"
            ]
          }
        },
        "420ee7b3fd434c7baaec05af95f31dc4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "31205e1fec7e4ac28b25f03691449d07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_0a276c81a1974596a33dbb3bbfd3693c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ab4dca90b6a84968ae36ec40649f71e4"
          }
        },
        "9b2d09615bb741d99020147a5bed81bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_137a9476943f4f42a9b927d21600c1f8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 3,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 3,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_deca70a353a94962830a50cbadc9ee41"
          }
        },
        "a541bb76e6f74da89ede1556109f45d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e8defc6033f24f32a6aa82be2f46176a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 3/3 [00:00&lt;00:00, 49.62it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c19ad82986aa400f849ace813f65e357"
          }
        },
        "0a276c81a1974596a33dbb3bbfd3693c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ab4dca90b6a84968ae36ec40649f71e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "137a9476943f4f42a9b927d21600c1f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "deca70a353a94962830a50cbadc9ee41": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e8defc6033f24f32a6aa82be2f46176a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c19ad82986aa400f849ace813f65e357": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5754bcfbe30b451d9cdf6f372de8869d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_796b4d0b49e54e918f84676fcc20b269",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e6cb87a2c7f94b3b90af60782ffb2884",
              "IPY_MODEL_ecfdc154d0fa4dc78277333772ae3aaf",
              "IPY_MODEL_8202765e66804b718ba1fd0b3e2f2d5f"
            ]
          }
        },
        "796b4d0b49e54e918f84676fcc20b269": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e6cb87a2c7f94b3b90af60782ffb2884": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d61b93f44e6a4e64bd390af5db752166",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: ",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e84277503c4140c7a65f89060a5b0cad"
          }
        },
        "ecfdc154d0fa4dc78277333772ae3aaf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ba90ed8145284cbcb481b21e030e728e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1420,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1420,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6abdca4a9beb44a4886115829ab13e8d"
          }
        },
        "8202765e66804b718ba1fd0b3e2f2d5f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6fc50e8384d144b487aa0c5b2630aca4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 3.20k/? [00:00&lt;00:00, 67.7kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_adc2c777d2584a758db39a06533cdfdb"
          }
        },
        "d61b93f44e6a4e64bd390af5db752166": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e84277503c4140c7a65f89060a5b0cad": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ba90ed8145284cbcb481b21e030e728e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6abdca4a9beb44a4886115829ab13e8d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6fc50e8384d144b487aa0c5b2630aca4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "adc2c777d2584a758db39a06533cdfdb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/transformers-research-and-practice/blob/main/natural-language-processing-with-transformers/05-making-transformers-efficient-in-production/02_case_study_intent_detection_with_quantization.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Case Study: Intent Detection with Quantization"
      ],
      "metadata": {
        "id": "W519IdztjisY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s suppose that we’re trying to build a text-based assistant for our company’s call center so\n",
        "that customers can request the balance of their account or make bookings without needing to\n",
        "speak with a human agent. In order to understand the goals of a customer, our assistant will\n",
        "need to be able to classify a wide variety of natural language text into a set of predefined\n",
        "actions or intents.\n",
        "\n",
        "For example, a customer may send a message about an upcoming trip:\n",
        "\n",
        "```txt\n",
        "Hey, I’d like to rent a vehicle from Nov 1st to Nov 15th in Paris and I need a 15 passenger van\n",
        "```\n",
        "\n",
        "and our intent classifier could automatically categorize this as a Car Rental intent, which then triggers an action and response.\n",
        "\n",
        "To be robust in a production environment, our classifier will\n",
        "also need to be able to handle out-of-scope queries.\n",
        "\n",
        "<img src='https://github.com/rahiakela/transformers-research-and-practice/blob/main/natural-language-processing-with-transformers/05-making-transformers-efficient-in-production/images/1.png?raw=1' width='600'/>\n",
        "\n",
        "In the third case, the text-assistant\n",
        "has been trained to detect out-of-scope queries (usually labelled as a separate class) and informs the customer about which topics they can respond to.\n",
        "\n",
        "As a baseline we’ve fine-tuned a BERT-base model that achieves around `94%` accuracy on the\n",
        "`CLINC150` dataset. This dataset includes `22,500` in-scope queries across `150` intents and `10`\n",
        "domains like banking and travel, and also includes `1,200` out-of-scope queries that belong to an\n",
        "oos intent class. In practice we would also gather our own in-house dataset, but using public\n",
        "data is a great way to iterate quickly and generate preliminary results.\n",
        "\n"
      ],
      "metadata": {
        "id": "XOmQOa_QjwHw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Setup"
      ],
      "metadata": {
        "id": "UP1EHAnilUGK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install transformers[sentencepiece]\n",
        "!pip -q install datasets\n",
        "!pip -q install optuna"
      ],
      "metadata": {
        "id": "PJs0JgLwlVIt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import (AutoTokenizer, AutoModelForSequenceClassification, TextClassificationPipeline)\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from transformers import AutoConfig\n",
        "from datasets import load_dataset, load_metric\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import optuna\n",
        "\n",
        "from pathlib import Path\n",
        "from time import perf_counter\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "A15YGFMiloPN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_metrics(perf_metrics, current_optim_type):\n",
        "  df = pd.DataFrame.from_dict(perf_metrics, orient=\"index\")\n",
        "  for idx in df.index:\n",
        "    df_opt = df.loc[idx]\n",
        "    if idx == current_optim_type:\n",
        "      plt.scatter(df_opt[\"time_avg_ms\"], df_opt[\"accuracy\"] * 100, alpha=0.5, s=df_opt[\"size_mb\"], label=idx, marker=\"$\\u25CC$\")\n",
        "    else:\n",
        "      plt.scatter(df_opt[\"time_avg_ms\"], df_opt[\"accuracy\"] * 100, s=df_opt[\"size_mb\"], label=idx, alpha=0.5)\n",
        "  legend = plt.legend(bbox_to_anchor=(1, 1))\n",
        "  for handle in legend.legendHandles:\n",
        "    handle.set_sizes([20])\n",
        "  plt.ylim(80,90)\n",
        "  plt.xlim(5, 53)\n",
        "  plt.ylabel(\"Accuracy (%)\")\n",
        "  plt.xlabel(\"Average latency (ms)\")\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "7xUwJN7YK_8e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let’s download our fine-tuned model from the Hugging Face Hub and wrap it in a pipeline for text classification:"
      ],
      "metadata": {
        "id": "OIOFJ-dkm0E_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# molde path has changed: https://huggingface.co/transformersbook/bert-base-uncased-finetuned-clinc\n",
        "bert_ckpt = \"transformersbook/bert-base-uncased-finetuned-clinc\"\n",
        "\n",
        "bert_tokenizer = AutoTokenizer.from_pretrained(bert_ckpt)\n",
        "bert_model = (AutoModelForSequenceClassification.from_pretrained(bert_ckpt).to(\"cpu\"))\n",
        "\n",
        "bert_pipeline = TextClassificationPipeline(model=bert_model, tokenizer=bert_tokenizer)"
      ],
      "metadata": {
        "id": "l3NVuFLdm2qj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we’ve set the model’s device to cpu since our text-assistant will need to operate in an\n",
        "environment where queries are processed and responded to in real-time.\n",
        "\n",
        "Now that we have a pipeline, we can pass a query to get the predicted intent and confidence\n",
        "score from the model:"
      ],
      "metadata": {
        "id": "lQ6kcqUNrsUP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"\"\"Hey, I'd like to rent a vehicle from Nov 1st to Nov 15th in Paris and I need a 15 passenger van\"\"\"\n",
        "\n",
        "bert_pipeline(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fygRC29urv7Z",
        "outputId": "c949b329-1260-49f5-bc25-371eb82f5617"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'car_rental', 'score': 0.5490034818649292}]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Great, the `car_rental` intent makes sense so let’s now look at creating a benchmark that we\n",
        "can use to evaluate the performance of our baseline model."
      ],
      "metadata": {
        "id": "ckP-6KbIsBne"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Performance Benchmark"
      ],
      "metadata": {
        "id": "3auvFWv7sENZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Like any other machine learning model, deploying Transformers in production environments involves a trade-off among several constraints, the most common being:\n",
        "\n",
        "- **Model performance**\n",
        "  - How well does our model perform on a well-crafted test set that reflects production data?\n",
        "- **Latency**\n",
        "  - How fast can our model deliver predictions?\n",
        "- **Memory**\n",
        "  - How can we deploy billion-parameter models like GPT-2 or T5 that require gigabytes of disk storage and RAM?\n",
        "\n",
        "Failing to address these constraints can have a negative impact on the user experience of your\n",
        "application, or more commonly, lead to ballooning costs from running expensive cloud servers\n",
        "that may only need to handle a few requests.\n",
        "\n",
        "To explore how each of the these constraints can\n",
        "be optimized with various compression techniques, let’s begin by creating a simple benchmark\n",
        "that measures each quantity for a given pipeline and test set."
      ],
      "metadata": {
        "id": "L-Wj4qUwsG5m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PerformanceBenchmark:\n",
        "  def __init__(self, pipeline, dataset, optim_type=\"BERT baseline\") -> None:\n",
        "    self.pipeline = pipeline\n",
        "    self.dataset = dataset\n",
        "    self.optim_type = optim_type\n",
        "\n",
        "  def compute_accuracy(self):\n",
        "    pass\n",
        "\n",
        "  def compute_size(self):\n",
        "    pass\n",
        "\n",
        "  def time_pipeline(self):\n",
        "    pass\n",
        "\n",
        "  # We’ll use the run_benchmark function to collect all the metrics in a dictionary, with keys given by optim_type.\n",
        "  def run_benchmark(self):\n",
        "    metrics = {}\n",
        "    metrics[self.optim_type] = self.compute_size()\n",
        "    metrics[self.optim_type].update(self.time_pipeline())\n",
        "    metrics[self.optim_type].update(self.compute_accuracy())\n",
        "    return metrics"
      ],
      "metadata": {
        "id": "mw8ChQz0zP0d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "First we need some data to test on, so let’s download the CLINC150 dataset that was used to finetune our baseline model. \n",
        "\n",
        "We can get the dataset from the Hub with the Datasets library as follows:"
      ],
      "metadata": {
        "id": "RymNuU1w0rB3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clinc = load_dataset(\"clinc_oos\", \"plus\")\n",
        "clinc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 341,
          "referenced_widgets": [
            "01d5d97305af40c686b1dffc8da0d4c8",
            "420ee7b3fd434c7baaec05af95f31dc4",
            "31205e1fec7e4ac28b25f03691449d07",
            "9b2d09615bb741d99020147a5bed81bd",
            "a541bb76e6f74da89ede1556109f45d1",
            "0a276c81a1974596a33dbb3bbfd3693c",
            "ab4dca90b6a84968ae36ec40649f71e4",
            "137a9476943f4f42a9b927d21600c1f8",
            "deca70a353a94962830a50cbadc9ee41",
            "e8defc6033f24f32a6aa82be2f46176a",
            "c19ad82986aa400f849ace813f65e357"
          ]
        },
        "id": "fWSUNfxG0vHo",
        "outputId": "2b363d30-9c95-48c1-a517-b065bbd957e7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reusing dataset clinc_oos (/root/.cache/huggingface/datasets/clinc_oos/plus/1.0.0/abcc41d382f8137f039adc747af44714941e8196e845dfbdd8ae7a7e020e6ba1)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "01d5d97305af40c686b1dffc8da0d4c8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/3 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text', 'intent'],\n",
              "        num_rows: 15250\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['text', 'intent'],\n",
              "        num_rows: 3100\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['text', 'intent'],\n",
              "        num_rows: 5500\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each example in the CLINC150 dataset consists of a query in the text column and its corresponding intent. \n",
        "\n",
        "We’ll use the test set to benchmark our models, so let’s take a look at one\n",
        "of the dataset’s examples:"
      ],
      "metadata": {
        "id": "q9J8hxCM1RuH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clinc[\"test\"][42]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7lx13kR1UGm",
        "outputId": "1d67a802-eee0-4c1c-9260-e8ea42d40b63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'intent': 133, 'text': 'transfer $100 from my checking to saving account'}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The intents are provided as IDs, but we can easily get the mapping to strings (and vice versa)\n",
        "by accessing the `Dataset.features` attribute:"
      ],
      "metadata": {
        "id": "_M_kfBpA1gNg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "intents = clinc[\"test\"].features[\"intent\"]\n",
        "intents.int2str(clinc[\"test\"][42][\"intent\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "VhTLlAHg1iVg",
        "outputId": "16ad5efa-7757-4194-e5a3-9976e7a688a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'transfer'"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Exploring Class distribution"
      ],
      "metadata": {
        "id": "9d7m9nc-D5Wk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have a basic understanding of the contents in the CLINC150 dataset, let’s check it class distribution."
      ],
      "metadata": {
        "id": "Ii9JuBXW3csg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clinc.set_format(type=\"pandas\")\n",
        "\n",
        "df = clinc[\"train\"][:]\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "kvjEe7k63yj_",
        "outputId": "1095971b-e584-47fa-e002-b28133867c2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-6bfd3008-895c-4b98-8a5f-c01e7770ffca\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>intent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>what expression would i use to say i love you ...</td>\n",
              "      <td>61</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>can you tell me how to say 'i do not speak muc...</td>\n",
              "      <td>61</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>what is the equivalent of, 'life is good' in f...</td>\n",
              "      <td>61</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>tell me how to say, 'it is a beautiful morning...</td>\n",
              "      <td>61</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>if i were mongolian, how would i say that i am...</td>\n",
              "      <td>61</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6bfd3008-895c-4b98-8a5f-c01e7770ffca')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6bfd3008-895c-4b98-8a5f-c01e7770ffca button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6bfd3008-895c-4b98-8a5f-c01e7770ffca');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                text  intent\n",
              "0  what expression would i use to say i love you ...      61\n",
              "1  can you tell me how to say 'i do not speak muc...      61\n",
              "2  what is the equivalent of, 'life is good' in f...      61\n",
              "3  tell me how to say, 'it is a beautiful morning...      61\n",
              "4  if i were mongolian, how would i say that i am...      61"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def label_int2str(row, split):\n",
        "  return clinc[split].features[\"intent\"].int2str(row)"
      ],
      "metadata": {
        "id": "S4qNxogY4G5u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"label_name\"] = df[\"intent\"].apply(label_int2str, split=\"train\")\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "7BBQ5y8C4HUd",
        "outputId": "dc13c3d1-c0a4-41ca-b294-824d91d815ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-d47c1d80-b287-4058-8961-0a808633465c\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>intent</th>\n",
              "      <th>label_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>what expression would i use to say i love you ...</td>\n",
              "      <td>61</td>\n",
              "      <td>translate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>can you tell me how to say 'i do not speak muc...</td>\n",
              "      <td>61</td>\n",
              "      <td>translate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>what is the equivalent of, 'life is good' in f...</td>\n",
              "      <td>61</td>\n",
              "      <td>translate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>tell me how to say, 'it is a beautiful morning...</td>\n",
              "      <td>61</td>\n",
              "      <td>translate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>if i were mongolian, how would i say that i am...</td>\n",
              "      <td>61</td>\n",
              "      <td>translate</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d47c1d80-b287-4058-8961-0a808633465c')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d47c1d80-b287-4058-8961-0a808633465c button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d47c1d80-b287-4058-8961-0a808633465c');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                                                text  intent label_name\n",
              "0  what expression would i use to say i love you ...      61  translate\n",
              "1  can you tell me how to say 'i do not speak muc...      61  translate\n",
              "2  what is the equivalent of, 'life is good' in f...      61  translate\n",
              "3  tell me how to say, 'it is a beautiful morning...      61  translate\n",
              "4  if i were mongolian, how would i say that i am...      61  translate"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"label_name\"].value_counts(ascending=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ig5e0lu4-S5",
        "outputId": "db5de7a6-d3bf-4ec3-e175-a03d933596eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "todo_list                100\n",
              "credit_score             100\n",
              "book_hotel               100\n",
              "freeze_account           100\n",
              "reminder_update          100\n",
              "                        ... \n",
              "expiration_date          100\n",
              "what_are_your_hobbies    100\n",
              "pay_bill                 100\n",
              "transactions             100\n",
              "oos                      250\n",
              "Name: label_name, Length: 151, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"label_name\"].value_counts(ascending=True).plot.barh()\n",
        "plt.title(\"Intent Counts\");"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "2BXcUSw13gJK",
        "outputId": "7dbebc72-fbaf-494e-f51c-647c4e6ddf67"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAe0AAAEICAYAAAByPazKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOydd5SV5dXFf2eGoUkHqYqgoGBBlFERUYkFG3aNhdiNn8bejTGKBU3sJRU1auwtCrFhV6yIBRFBpSrSpcPQZs73xz6v9zLOoMYZpTx7Ldbcufctz33H5X72Ps3cnYSEhISEhIRVHwW/9AISEhISEhISfhgSaSckJCQkJKwmSKSdkJCQkJCwmiCRdkJCQkJCwmqCRNoJCQkJCQmrCRJpJyQkJCQkrCZIpJ2QkJCQkLCaIJF2QkJCtcDMJpjZbj/w2FfN7MQqvLebWYfvOaaVmd1pZlPMbL6ZjTazy81snapaRyX37Wdm91XnPRLWXCTSTkhIWOtgZk2At4E6wPbuXh/YHWgEbPRLri0hYWVIpJ2QkFDtMLNjzewNM7vezGab2Xgz2ys+6w/sCPzFzBaY2V/i/U5m9oKZzTKzz8zs13nXu9vM/mpmT4dKftfMNorPXo/Dhsf1DqtgSecA84HfuPsEAHf/yt3PdPeP4zo9zOw9M5sbP3vk3X8FFyFfPZtZu1D6x5jZl2Y208z+EJ/tCVwMHBZrG573fMbFdxlvZn2r4LEnrIFIpJ2QkPBzYTvgM6AZcC1wp5mZu/8BGAKc5u713P20sKhfAB4AmgOHA38zs03zrnc4cDnQGBgD9Adw953i8y3jeg9XsJbdgP+4e1lFCw0l/jRwK9AUuBF42sya/ojv2xPYBNgVuNTMOrv7c8DVwMOxti3ju94K7BWKvwfw0Y+4T8JahETaCQkJPxcmuvvt7l4K3AO0AlpUcmwfYIK73+Xuy939Q+Bx4NC8Y55w96Huvhy4H+j6I9bSFJiyks/3Ab5w93vj/g8Co4F9f8Q9Lnf3EncfDgwHtlzJsWXA5mZWx92nuPvIH3GfhLUIibQTEhJ+LkzNXrj7onhZr5JjNwC2M7M52T+gL9CyousBi1ZyrYrwDdo0VIbWwMRy700E2vyIe/yg9bn7QuAw4GRgSlj+nX7EfRLWIiTSTkhIWBVQftzgV8Br7t4o7189dz+liu73InCgmVX2/8DJaOOQj7bA1/F6IVA377OW/HB8Z7Siuw92993RRmI0cPuPuF7CWoRE2gkJCasCpgEb5v3+FLCxmR1lZkXxbxsz6/w/Xq88bgQaAPeY2QYAZtbGzG40sy7AM3H/I82sRiSzbRrrAsWcD491FQOH/OBvqrW1yzYMZtbCzPaP2PYSYAGyyxMSvoNE2gkJCasCbgEOiczyW919PtAbJZtNRlbzn4FaP/B6/RAhz8nPOs/g7rNQwtcy4F0zmw+8BMwFxrj7Nyiufi6y0i8A+rj7zLjEH1Fp2GyUDPfAj/iuj8bPb8zsA/T/4XPie84CdgaqylFIWMNg7t9xahISEhISEhJWQSSlnZCQkJCQsJogkXZCQkJCQsJqgkTaCQkJCQkJqwkSaVchzKyRmf3ul15HPqI9Yuu83+8o11UqISEhIWE1QUpEq0KYWTvgKXffvNz7NaJr0y+xpleB89x9WCWfnwMcH7/e4e43V/LeOsAjwHpAIXBlJe0hv0WzZs28Xbt2VfAtEhISEtYevP/++zPdfd2KPkukXYUws4eA/VF/5WXAYlQS0sndNzazJ4H1gdrALe4+IM5bgEpe+gAlwP7uPs3MDgUuA0qBue6+U2wM7gWy8YGnuftbcZ0Lgd+gGs9ngWHA3aghRAmwfbx/nrsPM7OLgUuBscBgYA/gaGAocAOwFypr2RdNPzoFNZEoBRa4+w4VPIOTgJMA2rZt223ixPJNpRISEhISVgYze9/diyv8LJF21SFfaZtZLzRwYHN3Hx+fN3H3WWZWB3gP2NndvzEzB/Zz9/+a2bXAPHe/ysxGAHu6+9dm1sjd55hZXaDM3RebWUfgQXcvjolJfwR2c/dFefd6lTylnf2OakJHAncCF6GJR4OBV4Cb89YzNj77NTAKDXHoD1wDnFWZggeo1aqjtzrm5ip5tgmrHyb8aZ9fegkJCaslVkbaNX7uxawMZrbA3X9w/+AgxqWZ0lwFMTQj7MAZZnZgvF4f6IgaNywl12npfTTXF+BN4CEz2xDoEu8VoRGGXZHi3Tje3w24Kwj7VUTMs/IXY2b94r4A2wBfoJ7IzVF+w3rxWSkrdn5q5e6fm9k4oDNwB3ILvoNySjv9jzshISGhCrG6J6L1Ql2NfhLMrLo2Lwvz7tELEev27r4l8CE54luG4sQgwqwB4O4nI5u6CHg/iHos0C2OGQvUNLNL0TCFfmY2IK7TJrotZffvCPxfufVNBw4A5iA1vSlwWqxls4hj7wY0jGS2d4C/Ax8ggm/4vz6YhISEhIQfj59VaZvZ+cASd7/VzG5C8253MbNdgBPimP58N7a7L3AJUBMp075AHTQVp9TMfgOc7u5DKrjnd86Na/ZD8doNgS/N7AzgH2goAMj6fbOC6xWgmHUPd58Rv3+O4sWNgA5mNg8YB8yMc+5G/YZnhxJeiIixq5ldich7ctjr2X2eAS5GSvcbNIN4IBop+Ii7/y5IuRBNCBqL/p714pi9kJIvQKp6fbRR2Bq4D2iPehzfHO83RSp/O6T8h6MNxFSkxncGjoj3SuOYysYqAvD1nBLaXfT0yg5JWIORXJaEhKrHz620hwA7xutioJ6ZFcV7r6PkqndCib4O/DaOfQPo7u5bAQ8BF7j7BESyN7l714oIu7Jz8z7bFMWAj0CJYDe5+zbAwcgC/g7cvQyRXt94azdguLvPAK5EBPglUqH5WeQfAjXMbBTqn/xOvL81GhKwiLypQe6+N0oSew7oBDyPiLME6GNmwxHxlsVxGwBbIQLfGJHvyYh8b0Y9lEchUv8D2lQAHJndMo47AViOCP3FOL4WGlU4H5H4OGS9f17B8xng7sXuXlxYNwnxhISEhKrEzx3Tfh/oZmYNEFF9gMh7R+AMKo/trgc8bGatkGLOjxN/H1Z27iB3L4nXuwGbmlljpGqLzOxOYAAak7ctUrVDgTOBv5nZQUAHoMzM/oHUdisUK+4OfGpmn8V5uwI9UdLXxsC6QNe43hPA9SgJbKa7/8rMJsSzqYeS1rZEiWLEmgaijcBXwMPxvAqBEXH9c4G3UPb5POATlBleK9ZWH5gB3AScGNe9KN6biFT6HojMF8b166JNQjaJ6DtIMe2EhISE6sPPStruvszMxgPHIkL5GPgVIr5RwDLPpbN/G9sFbgNudPdBERvu9yNuu7JzF+a9LgCOAa4CDoq1/g3YBBgU79cB7nP3F81sNiK/qchmfwZtCuqixK4X0ei/RsgaP9PdJ5rZiyi23AVtUr5G6taBX7v7KDNrgUj91bheA6AdUtMjUUx7ICLpr9DGpAMi5C0QqbYCnoz7N0NE/iYq38pgwNXATojsx8brQeTmA89HG6lNEPmXIau9EKnvSpHs8bUbacOWkFD1+CUS0YagzObX4/XJwId5ZF0RGpIbPn9M3vvzkWJcGSo7tzyeR4TeDXgvFPKuKOZ9BVL9xcC1cfzTiGgfdPdlwINIpV6BNhz/QKP+vkSbj55x3jWILD9Ez39phAMWA0fFMbci4v1vfL8CZNf3jeP2QS4FiECvR6GFdeL7rgtcB5yOXAIQiWfF+mPimu0QCb8bv++MSP6ouObraMPRAzgbkX+j+D5FyClYAckeT0hISKg+/BIlX0NQTPVtd19oZovjvZWhH/BoqNuXUSwXRGqPmdn+VJKItpJzy+MMRNw1kGJ+JbK3CWu9HiKq2kihv4nU5l1513gF2ej1gAuRij0Vzdo90sz2QKp8obt3MbNScjbzEmB3M7sK2CV+7wP8EynzYhRLro1I9jG0AWgK7I02EKNR3fXpiMyHI3dgSay1LVL3/cllfr8S690L+FN8VorckGbxnQ9C9jrxWRki+XyngnhWyR5PSEhIqCb87KTt7i8hIsh+3zjvdb28148hYsLdByI7uPy1PidXv1zZ/So7t1+532dGFvpAoJe7TzezJkjp3oYal7QH/ozKojogxbwkMsgPAwa4+4lm9iUi7GORuv0Lig8/iwitZVjgBUCLyC5vHP/2RGq2ADUy+QxZ5A4cF8s9BbkAyxDpX4mU/gJkg89GBD0HWeZXA4eg8rELgTbIFWiM8glqIiLeL+7r8d2KUGLgBDMriXV8jki+NUqeqxTJHl+7kTZsCQlVj1WquUp5mNlb7v6T67B/KNz9UzO7BHg+iHgZIvFl7v6AmRUCb5nZ7Sg2PAIRciegCSoduxoR9VNIzfZHjkA7lA3/FiK7kUi1tkDqdxiKkT+MMrMbAr2RHX418HtEpCALfhtEyE1R0tkiZFd3Qdb5IuRg7B+vr0aqvX7cr35cr2ncwxAZL0b/XTSMnzuY2bmIwMuQYi+M3z+r4BkOQIly1GrVMbXbS0hISKhCrDFtTM3sD8Ch5d5+1N37lzvuBw/vMLPjECl/gdRoe+Bf7n5qJLWd5+59or56DLKwWyDinYuUbAmwGYrdn+/uDc1sCzR8I7PqG6DSq7uASXFue6Rs5yBreltE5i2RTX4vKl/LktHaodh9M1SyVRttOrJr3BzPpy3aRPSN41qguHdWz/4Aip/3JrdJqA/ciBLmRsd6WwGbuPvYcs8s9R5PSEhI+AlYWRvTVbojWgzSwMx6mdlrZjbQzMaZ2Z/MrK+ZDTWzEWa2UZDzR6j+eTkiq+Fx/rFmNsjMXgZeMrMmZvakmX1sZu+YWRczKzCzCWbWKG8JF6NEtN1RGZQD25rZdwZlAOPd/SMU6x6DVHA9pMBfQeq4MOqrGyKVXhMR422IhBeiuHpNtFFYHN+jNcrszpLP2qG8gJpoU3A4SspbjIj6VaTiv0RWeU0Ul64R1+uN1PYi4HFU7laGSsLuQ3H3eXENUAz9oXjdPtazZuz2EhISElYjrNL2eDlsifpez0JK8w5339bMzkSJV2fFce2QKt0IeMXMOsT7WwNdYojGbShj/YDoxvZvd+8asehPzGwOIs+JiCwHoQSv9VHjlcHu3hmRY4YlZnY9ylCvg+qvHZFoU0TOs1Ds+0EUV84U/35xH0ODOV5D6rYWIs9LUDy6Uxy/EJF6M0Tk96PM8ZI4b6tYw3JExs+7+0FRbvdJfK9ecexMROyfx/e5CpH5AqSoQbZ6m/g+Y+N1DZQhn9XSfwcppr12I8W0ExKqHqsTab/n7lMAYvLU8/H+CFTrneGR6Fr2RQy4yIjuBXfPBmj0ROSLu79sZk3NbCdERqOAAxGx/RXFmXdD8eL2iMAbmFk9d88yv7sjm7kdUrcvIAKujRLWrkRNTO5D5W7DUDe2L5GSz7K1HfUD3xTFoociYr0H2eCZXV2A6rGnISt9HNpQ3Iss8n8jsl4Pxc7fjfNaoSYpbdBmYApS4MuRem6Dpn+1ImevZx3rZsd9N4vjC+L8FZAf0y4uLvZh6X/cCQkJCVWGVdoeL4clea/L8n4vY8XNh7EiMhv3O+VJ5dAdKdb2SKUWkMuOLkBEPjZaprbJI+zs3PpIkWYoQXHj+iieXYAUd0cUG34FqeOp8bMVIvPWKO58JOo5vjzOn44s7SVx3H+Q1b0rUruLUXnbXfFMuqLZ2vWAEyNDvSbagMxCxL5JrKsUWfozkLrPHIKlaGPRB7kXS8hZ8MuAbcxso/yHaGYnmdkwMxs2Y8aMlT/xhISEhIQfhZ+stCMJ6zkUS+6BWm7eBVyOOoP1RWrvNtSLuwjo5+4D49x7EWkBnObub0Vd9MNAHTP7hCBDW3F05y5mdhpwN7B3tBHdB9jZzF5DdnZ3pJafjvPvRmTaEhgWbUgvQNneB6M2oU8g+7o2qrGujbqdHQNsbGaXIwt7OUrsWoxiyo4mYL0D1Hb3i+KeM1DTkomoHKtbHLszMAElgZ2CFPcstLmojZQ36G/0l1hbJ6Tc58dzbISIdg6yrbPs79mAu/szZvZ7pMo3jOMmooS59ZDano9I3lHDlxbIQt8ebV72Q3Z9qzgmm0a2DM0Dn04lSPb42o1kjyckVD2qSml3IBdz7YRUYk9kBV+MkqZedvdtkZV9nWns43Rgd3ffGsV6b43rHYlIqgTFssf8gDWsh8h1MIrztkXW77nkOo2BMro3QzHcl+K87ZAiPhzFdXdFKnc/pELHIeKrgTKjX0MEfV7e4JKnUSLcqUATMxsVSWfZ+M1aiJSHxff6Eqn6/ohsl6IEsSFIQbdE5WGz47MNEaF63D/7P+JDyI7fCHjD3bsBb6N4/scovk18D4/n2RS1RJ2I1PNryNo/FVnkmyJyXoYs+iKUPFcLxcCLYo2Ny/8RUke0hISEhOpDVcW0x7v7CAAzGwm85O5uZiMQGawH7Gdm58XxtRGpTgb+YpoTXYqUKEit/wu10twCKfTngV6mkZ5liEh3QbXPWZeufRHZFqFY7zUo1lsLEfMMZIGfgeKxS5ELMBmp/brIdi5DNvtdca11UbLbHmi4xiVo89HCzK6LNZciBTsZkeOlse6+qBPb0rhuhhvRJiUj5SzJK7PxPZ5H41hLZ+QenBTXnhjP9n7kdDQCTjCzY+Ia77t7bzObHN//C0TAhyNCnkmuQcrWsf5a8W8KchKaoI1dUfzLNiHrxnmpI1pCQkLCz4iqIu3vizeXAge7+wrNOEwzrach9VeArF3c/fVIDNsH2d8DUUzVETHWQiTbAtnZRyLynYUyqltGNvgDwCnu/oaZtUUDSv4Vt+8AjHP3I+K4kfFZfeBmd29T/ksGAY5EiVl7AY8iwlyH3JzpD1Em+0GIJHdByn06ytj+Op7JJnHZZfHZukjhvo5IejlS228icp4O7IDItjFS6UVo05LF7f+LlHIjlPwGchQKgH3yOpudGOesg/5WpeSSy5ahUMH7cf3laGPRBDkC2VS0/IEuFSLZ42s30oYtIaHq8XNljw8GTjez00OBb+XuHyLLdZK7l4VCLAQwsw3i/dvNrBa5WPD0OOZtFPNtgezkMqQsHzOzw1CC1KHkxm3WRhuCrHc4aApXVq60G3oWnVGp0zpm1sXdPw4bv020TAWVQT2KiDubMz0Tke4McmVcvREptkb29VJgorsXm9l8RJbz4zuMRUlihWgDkinySUj1Fse1MtXtcUwpCkEQ7/chtwm4FVnj2SZnVDzLeWjGeGaBt4m1vxJ/j+7Iws8S1EYjVd00jpuASLw58LSZ7ZffYCV1REtISEioPvxcpH0l6sj1cbQHHY8I5m/A42Z2NFKsmd3aCzjfzLLe2kejOPQElMXdDNngDVCJVr7tXIqI/AREMt8AD7j7FZGItjiOWwRgZmchgnoaGBjEvwtwZ5AcyA7PSPsWlAE+D6lPAz5FbUUbkRvEYWhj8XCo/j8Dx5jZp4hEe6INxAco6QtEuAtjja3jPi/EZ0WILBvHd2oWa2iANgQFKPa/cdx7czP7KM4tRERfGtfpRa68rEXeel9ApD2F3PjNO5C78EK8n40fBbjiezqiJbWVkJCQUIX4yaQdiVib5/1+bCWf/V8F537BigM/Loz370G1yd/CzIYAx6PM7REo7v1CKPclMWAkwwJ3PyRs7w/dPYs73+zuH5nZ5sBsd9/czCagRKyP864xy923qWC97czsCTSm8j1kfy9y993N7CGULDYPEehgVKqVYWNk39dAyXEboWz7U2JNH6P4fS00WGQPZJUfizYmXwAHILJdjBLmWiLLOvs7ZomF84BWsVnohiz2r9Cs7PGI9Oug+PYAZLWPjb+FIxeiCCXwHRHrMUTwX+Z9p6nln1FCQkJCQvVhdWqu8r+M9NwPtQ4diwhuaqj3pcC/zewMcslYPc3sKCJLOuLXY4Hj3H1BkPvDyFa+FdnFy4CGkXCXkdlClNE9D5F4nVDXG5EbnzkdJc0tDcJuh+xmkILeB6n23ijG3hQR6vNoDOdf0QanISLTmXF8X3KNVAilXYQ2AgtQvL0mcggcOQQF6L+DkxEJL0NW+eVx7a0R0YM2ChvG8R7XWQHl7fEU0157kVyWhISqxxozMKQiZHXdMdxjILLYJyPleX4kqE0AimM0ZzOUPb5XbAwuBGqFtT4B+Ju7XxvXngQUuHtrM/sdquN+Flnyx5NTxA1Rtvec+DkfZbZ/A+zg7uuY2VOImLvHZ5+gWPQiRKSGyLY5UtZjUEx8KbLQS/Lu80dyw0N2QHXoQ1GJ1z7I9n6WXCJdI0TMM9DGpkE8q0EoMe+buFczRPyGNgEzgGPd/c1yzzwNDElISEj4CbCVDAxZnZT2T8VQd58E3yrQdighC3Jd1LojJf2mmYGI8u28azyc93o5IkVQpvVB7t7PzNYnF492YLq79zezAeQak7Qgxlya2bsoYWxx/KuPbPMxqE67OSpXq4Ni4Nms649RcxdDSWpzkBNRF9nqkxEJH4Jq5xvFtbOpYMtRqKEw7tsUqe6paKb3/uS6uE3Nu3fWCKchyjJfgbQTEhISEqoPaxNp55el1UUNXnojgj0vks+aAVMiFvwwIuVuZjY9PrvUzO5HSW4AV5nGbDYmR8hXotjxHUjZNg31eTyyzrMmJU3iZ9ZKtCYqb7sB2datUAx7IWo5+n/kCLsMZa9/hpLTeiJC/gaR6lJUB38DSjp7HCnobI1FqDnM2fF7AUq0exJlo3+F8gb6xOdnoxyDD9EGIrPHR6/sgaeSr7UbyR5PSKh6rLakHVnfA9x90fceXDFaoOz1HRHBbYus7YlmdgQa8FEEXISamjRESvb/kJLdAVnQpxLNX8ysSxxXigj0MeA44M8ouWsaUsx1kfLdBBHzxaj8rDvq0rYQZWq/i5LFihCxZk1fyuL67dBc7p7IVi8AlsSmYzzaFGSd5aaRU9tHIHW9CCnoYUiNn0mu3GujuMdM1KSmRqz9NhQKaAL8iYhfZ0gDQxISEhKqD6vMwBATfsx6ziJXevS/4Bt3fwd1VjsEJY49jzK8r0bEsw+yrpfEv66I5LMEuN8h+/z+WMumwLVIeR+NiK4Ikd/I+LwYqWjiXjei9qegv8cXaIRo53ivFGWVD43PDfVi74BU9bnkGqPUjfuBNhSHuHsdpKJrIwUOike/E+uCXAmbk+sgV4hIvk48o5oo9n0uch2WEj3d85EGhiQkJCRUH35RpR1Z04ORouwGPGJmfRBpPOHul0Vzk0dQK9RCZD+3QLb2K2Y2091/ZWZ/R7XSdYDH3P2ySEKbgBLN+phZMWqNeiywl5ndixTmhyi+ey+5mu/T4l47IIIcGZ/XQSVYdwOXIUU8Cane2u7+tpl9DfSK5LZzEKGehmrMd0X2ehlStaNRclohIkMDDjazl+P+eyO7fR6qU1+f3DARkHIuJTcKdLGZLUEE/JaZlZFLHBuIMurboFh1nTj3eaSo90Ix9CaxnswGbxnXz9R7S6C3u680ez/Z42s3kj2ekFD1WBWUdkdkU5+NyGRbpGi7RSvTPYHJ7r6lu28OPOfut6JEq1+5ezZL+w+RbdcFTfr6Ibb5puRixVuizOt90dStW5GiPgyR6SnkYsI7oPapy1DM+PC8z8qjDiK/S1BjljMQSQ9CJHsSalwyCyV8lcWa9kdq/7C4ToNYRynaIBQhop2L7PtMKT+HksMKUJ31dsga/xo924Zoo5Elq2Wd1TLUR+Q+L84bivqsl6HwwV9Q0tszZnZ1+S+bBoYkJCQkVB9WhZj2RHd/x8yuR3XJH8b79RChDwFuiI5iT61E3f06Er5qIPv5h2xIBrn7U6aZ0LcjwiojN4zjQkS2r0U99UykWNu5+31mthTZ4xPjPExp542BIWa2PN4/GhH2+rGu1oj410PK9Y1Y9yOof/jzyOr+PYqtZ3V5tZEVXhdlj3+IZmbvR24s5x4oQa0IWfVNyfVpX0IuQ/w1pPoNqfnhKMa9HJH+wbGmXyOb/EOU0PbHWHMB2jCsgNQRLSEhIaH6sCqQdta61IBr3P2f5Q8ws60RsVxlZi+5+xVIef4WuMbM7kTJVW1QDPp2oL6Z9UcE/pyZ7YNIrykq3SoF+prmcA9EIzKXo4YqZwEvuvtLZrYbuf7eDxB9yqMxS01EhDOAxe5+t5kdjNTpnkiZTkGk/g+kWHugHufNUFLXzqi061RURz4AlXsdgBRth7hHEYpNrxv/RiCSvgWRbzdkn6+H7O2l8XousuCXxLMpRLHptrGmU5EK3ynvPtkktazt6Xbx84p4DmVIiR+LkuwqRLLH126kDVtCQtVjVbDHMwwGjjezegBm1sbMmptZa9Qq9D7gOkQ4IDu5Z7zOZkYvJEeWtVCy1RAUi/0tUo9zUZb2P1EC2AXRbnUE8Iq7d0VtPSuzuzNchEi0Dyu2K+0JPOjupe6e2d1noban2yDVuynKvH4MEe9A4Hp3fxz1Im/v7vNQl7WaiDx3Q85DFlt/Ku43Kq43CSnsGnHOYqTQ66MSsolx7BK0SRiO/v6FKIu9lJwSXxLr/AaR89txXCm5aWoNgQbZ3ytDsscTEhISqg+rgtIGwN2fN7POwNvR2GQBsn47oJrqMhRDPiVOuS3efx2RyASkUOuhxLZeiNjmIGXdC9Ua10dEtAip+w/ieu8Bh5jZcFYcXlIZPkaW81so47vSrwbs4u6/NbPZqK76GUSsrWMN44B9zGx0fN+Z0QBmHaRwC1Hi2yxWrDevnfd6OrLGl6Os9pMQ6fZFm5pPUBlXDUT+9VAm/BxE4J1RfXaD+Gxh3LcE2fo1yYUelqCNVEXjS5M9npCQkFBN+EWVtrtPiOSy7Pdb3H2L+Le9u49198Hu3sXdu7r7Nu4+LDsWqejHEHFeiuzeeSg2vsSFISj562l3Pw+R0Cx3b4HitRnxzQJujIS3C929XtznVXfPmowAPOnud6NysHOAB5GyzzAEOMzMCs1sXWQ9T4ja7xYoaex8ZF93RwQ4Bih1906InM8Ixf9+3nXfQRuZzAovjtcgNd8cdUgrJZe8NgJtSu6Le92JiPga5DLMj+9fHGt7Jc4vQRuK99B/I5Pj9Wxy5H29mXUlISEhIeFnwyqjtP9HDEHx5tn5Uj8AACAASURBVOMRQd2I5mp7qPWKUB8oM7PbUX22m1mdeP/EGBM6Nq5ZBDzr7t3MbEtU4tU/6snHIXX6Bsoez/AEUrxzEUGOQQlmf0OEd1ac+3HcpwYq/cqSzSYQ5W/Ay4iADZFua7S5aITKxiajZLXaiFxvQGGB3WPti1HCWW+klrdAm4TjkCU+DynzdcgNDlkS15sR742O43ZFSXLLUX7BpbHO/fIfbhoYkpAhuSwJCVWPNYG0K5v8VaeSc25GpLIDajV6DIp174MIqwwR7mXufpaZ1TazBshKnozi3e1Rhvi7iFBvBQ7Mm1/dHlnTfVAce39E4HcBE9z9ejMbRW5IxzRivjdKohsYNv1bsZ5JiOSbI9JuF2sZjBLJytDkr4ao+cljaGNwJkqE2wPF9K9Ef/Pl8fOTuE5bFD7I2qWWIifAUR37J3HOQeQ2FzPRJmkFJHs8ISEhofqwWpO2u79ErgMY7r5x3uvCvNePISID1USPcfdNAaKM6yA0cnIUUuz1UTb1WYg4pyGV+XdEkp0RiZ2OiLAHIvHOKMHsLJT41QNNyro1jt8FaGZm2yJ1+3fU7GUxynzH3achVZ01n9kx1rMJsqcbEk1UUOnXULQBOQTVmhcgFT46ns3e8XspKvUahyZ+FcR3PBTZ58uQyp+JFH0dtJGYhhyBkng+pUjpz6z4r5KQkJCQUF1YrUl7ZSg3lvNuZPHWJFf+hJn9CTgRkVCJu29pZg8g0spwFCK4zZHqbIkIty9wFbA9IrXrETnORc/1OVQ6dSki10XkepYfgJT3MKR0HwLONbMSlAA2Ke5diEi6PkoW2xAliVl8dgKKNYOSzObGsZe5+5/MrDFS93Ni3XNQwtozqP58GrLzDcX550W2/kK0QWiDYt3vIgXfOtZWi1zGfqVIJV9rN5LLkpBQ9ViVSr6qEy1RWdWmyAqua2ZNUVvRIUhNTzCzHZEtvAmazvURUqtFiPA7IuKbg2LZf0ZlXy8hcr4OkSGow9tylIj2JSqb6omU7nC0iagf1+4LjIs+4Y+ghLiu7r5FrK8+qr2eEOsnfi5F9nsRUsZ/Rwr8fDMrQhuERrH2hagOvAZS6oWIwLO2rZhZw/h8lrtvRG6W91Bky2eldAvjGl3KP+hU8pWQkJBQfTB3//6jVkNE/+2JSFWvi5Twi8geb4jUZgekXBehrmV/ATZGcdv57t7OzBYgZT0dqeKmcb0xiLjWQyTWBJH/lchKX4hKqCzOLUHNVa4g121sY3KjNMtQnXXnWPNi4D53PydKxbL+4mWIxO9A5Vm7xHcoRM1fZqENwwSkkochFV4WP6fFeXVQjPze+A7roXr2rmhEZxdkoxeiTUZz1BAm60deAFzn7heUe+75Me1uEydO/J6/VEJCQkJCPszs/WjL/R2scfZ4ZH//EanLYUgJ/xER2WXIon4UZVBnjUQ2AR5y9w4xRKQjsLWZfUYuoW0gIttGqMHIAETAs4H/IJt9OKojXx6vT0KJZR0R0RrqOZ5lfA+Le9eP9VyCVHymit8zs9vITTN7EmWCj0Cd1NqTy/DuiP6eo1Ap1+Mo87xn/J59j+dQ7LsrarpShDYEtdx9KzMrRXH0KSjOTYz6nBXrfwFtdtYtT9jlkezxtRvJHk9IqHqsUfa4mW2GiO9uRDinIWKciEh2Kbl49UikJLsAFwAbRcZ2N0Skk5CtXoCUZQ9EpnNQVviFiNiy2di1EKF9igh5G9R1LZu+9SYi7IGxnqeRpb4gzn0AKf5vkHL+GhFx1lxlGiqvqo26wm1OTn1vEO8fhRR4MxSDbhDvZ7Y2cXz9eN2MnEtQy8xGog1HU9REpQgojBrzBbGObmhDVN/Mjiv/N0j2eEJCQkL1YU1T2rsgFb0QwN1nRYOTlqhLWANEUJCLVb+HiGwKKvs6GmWIL0BkvBjZ3fuT68c9CJF5w7jmoYjYb0KkuRgYFiNDXwE+i9Gg7ZGtXoZs8C1iLctizdvE77PiZ41YT2aJL0Wx9N7Ibp+LysbmoXj9YqTib0f9wr9E5J/Z56BscmK985FbcG3c6wty08Ay1d4Zxe4vBfqR2wiUkSv/+hap5CshISGh+rDakraZPYkahtQGbommHp1Rctl8YEk0TfltnFIW/0pjsMfZiPiyISFZkta5yFKvh8h0GepGdgiKUbcCznH3l83sbkT8s1FmeXOkaucDbcysW6xpoZkNRsp/OupGtjUi2SxmvjOqh3a0GfgAdSr7LxoX+hmytXeINZUiy3srROQvIPv+ZkT6DVApmyGyHxXnfxRrnRHH7E1Oze+MEt/moYS5LdDmpEVc5/O4//z4vdPK/kbJHl+7kTZsCQlVj9XZHj/e3bN2nmeYWQtE2CWoDOsWFPstRkR5A4rnNgsbuCMi+62Rhd4e2AsRaUfUbOQfiEBvQYldr8UxN5jZF2gT8Eqs53IU6z0SJXd9jfqjv4Ks9H8B98f6eiECnIlIsgjZ5UaunGsbRMzbIWs7G8u5DrkuaqWI5LdBA0WyQSGHodrwhshWN7QJAW0sWiALvBZS1ReSq7/eA22GdorjS+O6fVBXtFrkRph+WyOfIdnjCQkJCdWH1VZpI6I+MF6vjyzZl9Es6tcQ2byBErFqotGdLyMiux6VVp1gZvvF59kGZhmyuV9DVnoNdy81s3dR9vVN6Lm95O4nm9mxAO4+xMyGohrp18xsc5RN3gk1S1mAYtajEOltj4hvPEqGa0mOtBeSq+1uHGvrhLqiDUKWdh20IeiMeqjPQgTdDLVM7YSS4trHsxiC6rzfiuc1G3VW+xJNLJuNNgtTkAIviHX2RXXkvYBnUSy9EGWbb1D+j5Ls8YSEhITqw2pJ2tEwZTdge3dfZGavEravu9+Dpnllx74PHO7uX+S9ty/K7l4HkeT7qBa5MyLPMxB5laEErZdQtvUCNMxjoJm1i1akbwA9zOx5RHQLzWwbpKoLUTLaXu6+hZnVItdhbB2ktHdFJN0YqeaHkDW+P4pTz0cq+XNE1EfFmtdD1ngJIuit0fCSrZHir4U2KFOQut41vs8B8f5bcW5pfOfp5Jq5TEfKvgjF+UEbhGy9mcL+auV/qYSEhISEqsRqSdqIWGYHYWdKtjawk5m1d/fxZtbE3WehWO+pqLUo0SVsNrLNewDHIhWZjZksQGp4I5R4dTiyvPvHe3ea2aA4tiNwRIzdfAQR5mPZ+hAJnw0UmNnU+L0QNUYZF+cXovrvG1AWe5agVoJcg8EouW1DRNyDgIsRydcErnL3QWb2K+DDOPblWF+TuH4Z+ltn9eDT4zsXovj1kjh3M7QZqIHq2LdAKh5yxD8WWf+7kbPQK0SKaa/dSC5LQkLVY7VsrhKK9Ulk736GYrH9kBK9GhHvdHff3czqoWEa3ZCqvBwR9HaotCsrhZqB4s790fzt85DiPQolkO0Z9ytEm4RpwAvu3jHW9BzKXi9CsecvEfEuQYp5OSLn5rHe5YjEDdVZ74iI/vP4rGX8XIqIdDmytf+EhpzMi+/+rLtfZmYdUW12XXL29REoGa1HnDsXlay1jmf0KiLoX8V9743nOBHZ7U3Q5iBb79K4dq1Y9+3uflJlf6fi4mIfNmxYZR8nJCQkJFSANa65irsvQQlhFeHZcscuQCT3LczsdEReDVBf7W6IoC5HhGaoF/k2ZvYYSs76GJWH7YEIuy3QMuz3RchuHo1Isikiz/VQK1BQrLwpsrsboVKurZAD0I7oWubum8Qan0QjNrOys0IU/34xrjcRWexnRmz/NlROditqp7o++vt2j9eL4/vWRQRcGynn0rheaxTbNrR56Br3dLTxKEBkXRDn1EAkvwLKx7QTEhISEqoOqyVpVwFeRrZ1O0TobZBCvwglqW2JLO1uSKXehzKsRyHlCXANMCVmbW8XxzyNiHEa6jU+Ain2scg274uy0GsAd6LY+QHI0t4RNWDJUIx6gC+L2eCGrPMFyBX4nbu/YWYXIjK9C9VogzYgc9BG4CNE2CWIiFsja/xxpK57oLj3eFRedj7abLyDnIbjYr0FaMPxT1Qath1qBFMpkj2+diPZ4wkJVY+1krTdfaSZ/RUR7z+RomyDFGpGdgWISO9HGehvIgVaAxH89gAxmQtkHYOSxqajuu7DEVnOR5nYj6J4925IwfZFNvoncd12ZtbB3ccQ7UXNbAQi7PFx/e7x8+7oi14TzRNfbmZjkQPQKK65KSLpr1Cf8wUoHm1x/7rk6rTXQ7H7pcgRGIyIuSTWniWpXUTO1m9QwbMdgLrPUatVx9Uv9pKQkJCwCmO1jGlXBWJW9VPuvrmZ3QB87u7/LHfMWUATd780fr8RxaUHoC5nrSq45highbt/Y2ZnIvVbA5HffWiT8BzaGIxBynsbRN5NERF+Ha8Pcve3zcyBTdz9czO7BjgebS5K0YagLsrs3plcydZyZNuPQDH6vyJL/HOk7K9G5JvF1hejevTjkQNBfLYMbQxmkYu1ZwNDTnH3f5R7BmlgSEJCQsJPwBoX064GDAauNLP73X2BmbVBZPU6UrTXoGe1L/DPmDs93swOdfdHTf51F3cfHlnkt0SddtYa9CByrVFB5LfE3TtHTLwpGlhympn9C/Uv7xNrAJFk1tr0CxTL3gF1P3sMxdN3QSq8FJHvpfH+JqgXew20YeiNiL4/OefgXVQ2thNKVsu6tN2ACLgmUuCNUBz8NWTRn4Ma0FSIZI+v3Uj2eEJC1SORNuDuz5tZZ+DtiB8vAH7j7h+Y2cOopns6SkTL0Bf4u5ldguzlh+K4M5CqLYh/I919Rly3IlyMyqsONLOeyF4/ACW+VYR5qDb8SVSitStS10uRkm4D/AYR/oYo3t0P1VlPR6VmFp+vG+u9FanyZ5DtPxHFzy8gZ/tPj2tn5WRlyD1YAckeT0hISKg+rLX2+A9B9BZ/yt0fq8Z7LETW9jGIXA3Vey8C9nH3YTEbfCxS6F8hlQvqNf4SsrOzPuGT4risHepwlNSWxaoXAJu5+0wzW4bqvvdHxF+MVHcJIujpce3nUIZ9Y7SZqIO6oY1z967lvk+yxxMSEhJ+AlZmj6/OvcfXJLRFSWNboXj25Ug1b2lmTREBH4yyv0vzzvsceDCIM4tNH0WuQcoSlEy3CFnkU8kloRHH9EKlamPIDVdpi7q0bRe/j0FEXQtlppfG68VV8u0TEhISEn4QktLOg5kdjUq0HCnKUmRHF6MErAvc/bFo2DIQKc8i4JKstSmqE38DlVJ9Dezv7iVmdj1q0lIDZaI3jSS4hYj8aqAEshIUt+6MSqqOR33SCxExDyGntDsh9bwYkX4BItgGKKZ9IOpF/hRwcrwuQHb4bqgj26R4f2b8zJqnZPXYJSir/nyU8JaFVMpQc5WTK3uetVp19FbH3Px9jz1hDUWKaSck/G9YmdJOpB0ws82AJ4AeYR03AW5ECVmHIYIchMi7EVA3EtKaoZrmjsgyHgMUu/tHkZQ2yN3vC4v70Gg5+iegT5D2EpQJfhiKITdH87nPRTO57zazfyNbvDuwqbu3ioS1/VCZ1s2xvgVoY3A7ssXnItU8F20UlqOEuMNR9viGSH23Q8Q+C3VRq4EI+mzg9+7e0MyyWPiGqPRreKxlYbnnmOzxhISEhJ+AlD3+w7AL8Ki7zwRw91mRPPaku5cBn8b4TxB5XW1mOyHF2QaNuwQY7+4fxev3Ue31v1AGdn8z24iYjpU3j3td1Gd8OWrM0hFlch9sZscgxTsIZYVPiTauNVEW+N9Q+RhIIf8eqeNXgN8hmx2URf4y+pvfgsg863K2EGWS94z1lKINQAkw1cwaIvchmxjmKEbeHcXUExISEhJ+BiTSLgczOx+VY92K6qe7Afeb2S6IAJcA/0Gx4s+Q2n0XTda6Flg/poIdhwiuDiqNOhr1+O6DYsUN0QQtQwp7X0Sar6EM8kYo1twcWd/FSG2/jYg5Gyk6H5FoKYo3vx/XPhNtKECkXIYaqbyFyPsyZKvvH+/1iOsZyh5fN9bRDiW5rY8S0lqhsECbWGOlSCVfazeSPZ6QUPVIpJ3Dy8gePw34rZndh2K888ysCJF0KbLLpyDCXoSIbAOU+f04iiffj+LGbwC4+xwzK0NZ4cQxhahtaGtkVf8GEXMx2hz0Qyp/lpn9BynlvsiefgBZ3rNQm9K9UQnYH9DQk2uQkv4KqfdJaIrX4Yh0j0UqexCy5bOOcG+jJLZxqMf6Oyhmfjf6b2VHchsEQ/3fH89/iPklX8XFxT4s/Y87ISEhocqQsscD7j4SNRy5EanY2xA5fY6INCPtpai2ujXK5l4HKeKtUXIaaJBGz3K3mAncBFyBnvu0eH8gUsvXI7JuhpQywK/N7ANUi70eUtyTkIX9XBzzKLkSr7NQ5jkoYa0Gan/aHTkGBaidqaNY9o5I4S9DdeadkCJ/EhHvkPj96vjeI5Aazyz1q8o/RzM7ycyGmdmwGTNmlP84ISEhIeEnICntPLj7PcA9YW+/i2qjP0a2dgdEXlciUnsDEdmOyNI+EMWRF8a5NePcy81sP0TE28e1bkS2936o9ehUZEVbnLcMqeHWyE5/Gynqpsj2XkpO7WbIYs2zEYn/Pa6xSax53Tj+S5QJfh6wOdp01Izj68X3OAcp+qyxyuVxzNdoc7Igvk9b1Ia1QiR7fO1GsscTEqoeSWlXjCGI1F6P1ycjxXo4ssT3RvFu0DPcA8WFayPbvCUiubtQadUdyIIeitR8I6TkByEbvQwlopXFe/9GBLleHPcNquE+AHghfn8bkeZBsYZitGGoEWsuRqRfGxiG2o2WIWJ+Am1Cst/nkhtfWoDU+zQ0BvRrFP9+FyXHgZR+DbQBWAHuPsDdi929uLBuw/IfJyQkJCT8BKzSJV9mdiwqnzrtfzy/F3Ceu/f5nuMWuHu9vN93RfZzI3dfaGafo37gHwPnuHu9GB7SFJFmTVTq1Qmp2beQ8u2JSN5QfLkQJbJ1QnHveUh1P4Xix9uicZg1UZJafl30bJTNvQTFnHeM6w2L80oRmddAU7kMkSsoKe48NFr04PgubVFjlfcQ2U9EBJ+Vga0b18z6kg9BG5W2sYY5wPbuPqHcs0wlXwkJCQk/Aank60fC3V8iR3i4+8Z5E7/q5R06AtnL27r7ZjEqsy6yjmchJbsB6u+9I1Ley9Es7cOR+s0mjd0R12qJYuWFiCRfQHHuGfFZK+BId3/HzOYhZb8xItGsSco9yIrfNq7zV6Tws3nbheTi2mWI5DeNc5ejLPQXkKPQASXOdUPqvhWyxzM7v1Ike3ztRrLHExKqHr+IPW5m65jZ02Y23Mw+MbPDzGwbM3sr3htqZvXj8NZm9pyZfWFm1+Zdo7eZvW1mH5jZo9GlDDMrMbPRkcB1UN7x/czsvLzfPzGzdqHGC/LeP9/M3jOzj80sS+oCWeUHmFmdWNuBqFSrGGhlZveTG6BRF6lXkJo9AZH27SgTuyg+PxBoYmZPopKrDVAM+pU493JEjo5s6jnx/svRlKU+yuBegmqoi1CsfCdyrUhB5HxYfP4Z8Ee0QRiHnABHVngrRNoFqCObo1j6B4jos0zz+sgl6Eg5JHs8ISEhofrwSyntPYHJ7r4PQDTv+BA4zN3fM7OsnSdIdW6FiOkzM7stPrsE2C3s6wuBc4LUa6GM6DFojvT3oRciIsysNyKibZGKHGRmO7n76xVM/PoYJYl9hEiuEyLr5SgGfBUitvsQWRbG7w3QWM17yDU4+RTVQs9GKvZAZHXfixqnbIyyzJeiGPh4ZMEfi+LPj6GStdL4txHK/j4BKemWcZ8a8f0eIDfpqzTWvEl8Xic+K0AE/xhwIrLLX0Nk3x65CWPLP8xy9nhSWwkJCQlViF+KtEcAN5jZn1E8dw4wxd3fA3D3eQDRkewld58bv38KXITWvSkw3szqoHjxBNT0xBGZ9UEx2iyoujGwg5n1RYRYiBK9TgaKzOwjFPPdHm0gQCq3o5l9hqzsDdGG4QJgMirFao5I8WtUCnYdmltt8W8UUqatsvdiY3IjGu7RGan1D4GpMVN7MrnSr6y/+anxvR2R7W7x+kS0yRiHiHw3VKa2Xtw36x/+Tax/IZof/mukwN+IdWyA2pZmlneLuO+u8Wx7oBh9Gbl4+a5UQNwJCQkJCdWDX4S03f1zM9saxUyvIjejuSIsyXtdCoxE/bZfQMRUCynXi9H32Qt4x93/YGaPo5nTIFL7yN2vNbMTEblOQmT8e3fvamY3ANe4+z/zFxAK+zV3P9DMChGZNwa+ivMeBg4hFDtS3EsRURahGPFDSMUeEX28pyFizrA873UZUuXnIIW7OL7H0LjWAag2vH3c90yUKb59HNslXpfG/U9H7sCzaCPQI+6xbjy/0lj7CXnP+XQUAz8cNYEpRTHvmWgz1AFtWFZA+XnaKaa99iK5LAkJVY9fhLTNrDUwKwZpzEE9sluZ2TahQuuTs8fL4zNE1hugkqO3kQLcI65zCbKbQQq4brxeAJxtZkchBVpRC87BwJVmdr+7LzCzNkjV7oLakOLupcBcM2sMNDWz4XFuKSqlao5UdZblXROVVI2Odc6ItayLiHKF8ZZm9mqsrw5qupLNxS6JtcyL77QIeBDVjF+H+onXQaQ+B21GJqOGLqei+vDZsb7ZiMzrAk8jgt8AEf+iuNfFse7SeFZl5MaCZmNAv/MMkz2ekJCQUH34pezxLYDrorXnMuAURE63hd1dgmzeilCKLNlPUaLZesjqLUDx5sXA02a2CLUbbRvn7Y3U5oaIcBxZ6GcBhWY2Iu47GHg7FHULZHs3QsT2qpn1i2t2R0r5z+5+g5lNRXbxUvRcSxCh1kQtSU+NNTZFhHpErP2zWN8oROrbxHFLke09AdnYTyCX4RQUBqiLmqNshuLMy1Gi2wmI9LM53DPiOl+i8rC94vOaaDPQE20gQMScJZ9tj1R5zXhuWblaGSL8LO6dkJCQkPAz4ZeyxwcjciyP7uV+vzv+Zef1gW/rr49HDUFGoFrj993dzazU3TvFcYcgYgYR1X0otl0DWcv3orai7yICnotI/HpUpjUbkeUE4NEosSqKY4fHfa8KtyDL2n4QKdaZSK2+Tq5pSmY//x7NzJ4a62mGku2WIaV7BUo4OwhZ0cvivL5Isa+DEseKUP31FYhc/w/Z9n9Aarcm0Dqey5coAW0PRLhjgC3juCnxHTdB5J+NGN0w7tsLEfe68XmDeD8bSFIhUsnX2o3ksiQkVD1WV6U0BFnQb7v7NKSuh3zPOf0QER+NktgaRoLbIqSoN0YNTxwNz8jGU56FFG19RGItUceyz5ASLQD+gpLhHiSXpDUo7jsfxc6HIKU7HWjv7puhEqopyML+GsXmRyLLfw5wKSL42oiQHcWz90SEWYCGg4xEVvg/UWb5RETwrYBHzOygOP7P8X3PQ05GVt7VDW1uJqENTSPkhtRDWfKnoUz8eojQM9JeVP4hp5KvhISEhOrDKt0R7afAzNqhrmbvoMSr91Bzk/6IeCajeO5ZiHA3Qpb1fYhY26LNQCHKuJ6KyrpAZPfv+H0r4BOkylsg0u6I1HtWrvZEfFYPqd9sCtdg4FR37xXZ6weidqaFscZJ7r5B1KA/h5TwdKTqC5BFfiO5kqw9UZJeF+Qk1EYx8PeA3WOdLZEaX4Q2HY4y+PdGm42COGd5fD4677h1UOJa3fj9fHe/sdxzTx3REhISEn4C1uaOaB2AQ5GV/h6yp3dGFvFFKBa+GGVH74s6h00F3kTEdx+yqd9EavpPiNAGoIYj+c1XJqIGKkeguHNvZLd3RDOpT0WJctsDuPuJZpb/R3kz1tMWlZTdjJQ5qBlKCXCvu59jZt2BR1DS2baot/lFSIWDYs+/Rm7AC2hzUQM5CBPQpqF3fOds5vcYcpn2r6PYeiFyAvohld6YXLvUBkidr0Da+Uj2+NqNZI8nJFQ91nTSHu/uIwDMLLOQhyJirIMS2hoiMm+CLOTpiHhLEbldjVTlUUgtZ5OvjkTx9K4ooexdRLz3IlJbQG6YSN24TtZM5XdmdgEqwcLMFsb7NePn9bGWXmbWDFnZi4HXzKwzKpNbN9a1QXynMkSi9RGhDkKqOL/VaIs458/xmcf9dmfF+HRTcuVonVGuwRdIvdcgNxmsRfkHXr7kq/znCQkJCQn/O9Z00s6v8S4Dhrn7RWb2GFKoJYik90UqdnOAsKobIuJdAPwGkfjriOROQNnrA5AVfABS5QCPI6U9Dm0MQAT5G2RNPxDvf4Ayz4eZmaPs7o3ivAlIHS9DLU07xPoGmllmk3+G4s6/B95HSrsJcgoaAme6+wAzewOVwd2NyDzrOz47jhuBYt8tyXVIaxrf5xhytdgT4rwFaIOyC7mZ4N8ilXwlJCQkVB/WdNIGwMyORrOre5nZ/vH2OoiAWwNdY2hHDzR7ujFKxjrX3f9jZr9CFnQjRHqfIhLeDinZm+LnaDQ8ZImZzUax4v0R2XVFrUunI9s8X9kuRRuM95CC3R65ABuiCV27AB2ihnt7RPAjgQ7u/nhMQytDanwUUt8HmVkXpJIHIGu8IM59N9ZehGLuN6PY/lKUA7ATuZ7nWeb6znF+1szG4nWlSPb42o20YUtIqHqs8aRtZpshpTkYqeCXEYnVQBnjdwH/iGEiE1Ay2ALgBuDBIN8SYP14fzlS6Vl2eAFSzXsiApwc77dFZV+9EZHehpqgLEDk2A643MyaIPJcB8WUP0EKuC0i96fj/A3jGJDd3gkoMLPayHqfjuLXfRHZ9o5/hqz0rPa7Lmq0UieOW4TCAcvis10Q+c9HG5oM9eO7L43zjLxyvAzJHk9ISEioPqyxpB1znjc3s9OBR939D9lnMULzd+6+CDjMzObHaM0ipJp3Qsq1DCWxnYoIaypSl0+gOPN/4+fj7n6smd2FsrBB1nFP4BmUxT0FlW09iizpQ+LYrHtb63jvSdSWtAARayGyzBsg0l6ANgMfIIV8PnIADBF71tgFgY+3bQAAIABJREFURK410UaiDNnnS1Bzlr6oxGsR2ryAStYORA1Zsu5nNZGqzzLWs+Eni8n1aP8WyR5PSEhIqD6srnXaVYH8eHeWrNUXqdJu7t4VEe/nKHa8LM55GxFs+3gNssFBBPztHG6klPdGhN8MkeVYFPPO2pnuTI5kS1Cv75rIah8Xa2uI6rZLUHy7NlLH/RFBjo7r7hf3moCI+uNYU91YC2gEZ3ukmF+NRjTZeM4OKNadtU5div4b2QBtBmbF9bOe5pV1rUtISEhIqAassUo7Dy8DT5jZje7+TdjRlaEhMN3dl0UcewNEUl8honsMEeHxSLVmWdvbojjx9uQ2ABORxX0LIrmPUQnXMWgTMB1Z7q8ggu2ArOkCYLS7b2lmxwH/QqR8CFLeX6LNwwSUZX4BsuWnoQ5sILKvF2urgRLo9ovPJqH49qfAb8ysFlLwMxFJN0Ed1jZB5WoFSImXkGtfmrU7rah/+7dIMe21G8llSUioeqzxpO3uI82sPyqXKqUCSzcP9wP/jT7kwxBZghLEtkHkNwL1+J4S7UGXALdHH/WvyZWEfYJ6kXdFRLc+UuTZzOpn4rM9UT/w21EdeDPgkFjDM2jTUCfeX45U83ByhNkTWe/NUKezLOltDOqO1gbFsMcih6A7GuF5aKzr4LjOQ2ik6TxUUpaVg81FGe8HxO/j4js0R3H58s/725h2cXGxD0v/405ISEioMqyxHdF+CMzsSUSmtYFbokRqT5TYVQjMdPddzWwfFL/+FKnMZkjlTkGlUaNQwlgbYGuksO9Aqvpk1KBlIarnLkEquW3c9xPUJrU2IuOXEaHWRHHsWsgab0wuu7s7MNfdm5vZJajJy7JYc2ZrL49jn0M2fH+koktRffjMWJ8h275WrINY23yk1pfEeQ8i4s6GrSxFI1B/Ve6Zpo5oCQkJCT8Ba3NHNMzsLXfvUcnHx7v7LDM7HzjTzAYixbuTu4/Ps9J3Am5197Pimo2R+n0HJZedhpLVRqMY9XiUJHYgOZL8N1LydVDb0WMRoT+LkslejDg6MZjkSBRPX4Ds98WI2DdHBN3MzK5FXdYMkXwpik/XRrXbmyPL/MlY0wSUrLYVubKzAkTO8xBZTyHXsjRT2zehjUlvclO+asXaK0Wyx9duJHs8IaHqscYnoq2EsAHOiHnY/ZHiPgl43d3Hx7mz4rjdUIvT7JqzUZ3zq+5+R5DtmXHuDGRhN0YkmGVmH4nUbz2kzo9Gz7+i/7Nd7+4bo25qbeJaNVDc/APUee0pRPoTkXr/DJH353GNZYi4u8e5A1BSXC1gaAwsyUq3hpEbWZrVZTvKGp+CEu6aoo3BAaiRy5vkppZ9izQwJCEhIaH6sDYo7QXuXi/GefZDtvDmKLmsDlLA1yACPRQYYWa9keVcC8WCC+JaE9C0q92Bl1ADk/Goo1pzVCed4W5kLV8Uv7+IyDdDlmX+bYzdzF5G1ntzM/sGWd3ZuM5CpLjnxhr2Q2q4U6xvEyqYuoXU9XSUXHYY+pvPNrOL4nUZIuJsWAiI+Ncnt+FYTi6j/Pk4zlE2+QpIJV8JCQkJ1Yc1nrTLYSvUwGQyik9/4+43mNk5SEleiWztzRCJ7Qj8Fo2uvBe1+twhPtsX2dAlSBGPBw6NZLdSZJe/hQizPtooFCFiH46yvkHkuwsixW1RAtnnKHN9GsrgNmSD/wOp+BMR2ZagTcXGiEiHokEnhUhh10KJbjNQAtmnKCntUJR4liXY1SXXSKUWcgjGxe9FqFVqo7jn14jQDdWtV4pkj6/dSBu2hISqxxpvj5fDUHef5O5lwGtAPTMbhRTw+4jcBiCC7Yys52PQAJDayB7eDLiMUJPx+WhEtu+gxis1UAe2BXHtJYjki4Aid7+IXJ/vdVA5l8X97on3mrv7tihjvWacOyleZ4q3jNwIzqJY/5RY15eolnso8BHaCOyOVHNW5pVN9ZpMzhZ/N35uiHqSr4datmZNYzJyd3JW/LdI9nhCQkJC9WFtU9r5DVWWATe5+91he+/v7jPNrD4qtdowb4DIeSgW3Qk4zt2fjPdBMen/ICI/292fNrOlwFXufk0kldVGZA5qXpLhKaT+74zfi1Dmei1d3rLaaIAhKGP7TrTZ6ooyzwci1V4fkfkwRMa/j/c7oA3BtSgD/jqk4g+L97+J62e14lPjOb2AVHoBsuMnkmtjWi/ObVX+ASd7PCEhIaH6sLaRdmWYj0hvJlLL/yDiw2Z2Aqp/Bj2vjmb2MbKyQSVVZYjENjKzTxDRbhZx9LpIcWdtQVvGzwJkv2fZ2POR+j0V9SkvQ6p6GVLLHRDxZu7IVFZsoFKE6sKzcZwPoZnau6JEusOBTeN7LY9rFCFlf1b8XkpuqleXvHs1R7H2ZazYe3zkSp5pQkJCQkIVI5G2MAB4zswmu/uvYmrWM2Y2BhHWFFSnfAmKQQ9Cg0YMqdCGwNlIUZ+MFPQOQA9EcKXAucgy7xIZ6wUo5j0LWfW3IWK8FhF9GbLdOyFLegwrhjM2RIr4krjvxPj8OUTQc4C/I+L/f/bOOzzL+vzinzsJCWGELQKKoCAqIMpQcVD3FrfWva3WbbVqqy1W22r156h1lFr3qAquuivugYIDUFSciLJBZghk3L8/zv34vkTAlbRIvue6uPLmeZ8dL8/3nHs1R4uCKtRh7fS49y9QPP5VNBt7TVTWldWI18T9PYqUfR9yi48lca2lUHtgSIppN1wklyUhoe7RoJurrAhmdipwASKvhYikylA70sYoW/tjRGQtUZLXImQr74iS1+YjO/xLlKi2DSK919FioCuytKviZzaooxUi1ErUdWwsWhxcGPdg5Gz2abHPBKSOq+Nc82PfKrRwqEGZ541i+xIULx+D4vIt4v5bxDkeRguUwvi9Js7ZitxM7o+iNC3/vaXmKgkJCQk/AitqrtLQEtG+M9z9r6hM6gp3b+3uqyOyPRm1HZ2M3l9jd58FvAQc5+7Hufta7j7T3Rej7PGBiMi+RMTZDhH/b5DS/RiR4BOImN+Ifxnhzo3j30SlaosRaVcgFV6MrPUliGhfjeOqkAIvR4Rcgxq8VKEFwTiUnJYR8xRyMey9Yvt7SG0vRk1asjat01H2eUJCQkLCfwnJHl8xRgAPmdmV7j4dva/VkUI9HZHvpYjI/wP8wsyedfcqM2ud15wlw1rAW+7eN5Lf+sV5HkSkW4TKv6agePQWaODIAESyrRHhNopzZUNKJqFObuci0j8edXG7CpFsBYp1lyBVXRzP0BGp82loEbJO3OeGiKQLkYvwIWomszMaLXoAIvNbV/TyUslXw0ayxxMS6h6JtFcAdx8fvb2fMrMCRJx9kYq9H6ndV8xsW9RrfF1grJlVoiEij5ArkdoMEeH8+P1yFL/ObGsQCV6KSPIT4DlEtB7HliAlXI2Uc484vjnKFs/qwUcgdewovn0P6qzWjNwY0PfJDQ3piGLaE1GsfDKy7pugRcq8uP5qwGFxzKbxvE/VemdpYEhCQkJCPSHZ49+OR5Ct7Yg0P0Cx51OQPdwEkVwNytjOenofjAhwArA7ykBvBGBmTVGpWEVcY5S7d4nPn6NpX9PcvQnK/h6Fkti6xjFz416uj/tZC5V+zY97Ox7Z3qDRny3ju88R4Toi7HYoYa0q7vNXKNN9UxTHXwwMR73HS9AiZTpaNLRx97/VfllmdryZjTaz0TNmzPhubzghISEh4TshKe1vx87AZHffDcDMWiA1XIMs7a9QDPlBRHbVaLTlLDQIJENXtEg6F3Ve64+s66bAtWY2AhHvxYiIu4SFfgbqUFaK1HFpnHtOnH9xbF8Yxz+CJoVlCWUjUWnWMejvXRHXfQSp8v6ItIejTPRSlDT3dzSdbGvg/9CCoxg5BEOAm8ysPbCbu2fqfSkke7xhI9njCQl1j6S0vx3jgB3M7FIz28rdMyv7CdRidCiKKa+BEtQmoZan15Dr3Z2dZyGqwz4Vqd9pSAF3QklmE1Fr1Qq0MGiNCLMlIu8JqD57UVy7EJH+dKTmuwHHxECT/RDRbo/IvTUi8gxliMy/RCr6HJQJX4k6qF2D/vsoRUq7HNn2v4/tPwfa1ybs1BEtISEhof6QlPa3wN0nmFlf1MbzdjN7P75agkh2LCqDugolgT2BlPDzSJFmpPYVmgp2qJntC0xx9z7RgOVxpHh7Ab9DSWXdkF39IbLGr0SLgM8Q+TaNc1+LMtBBdd5fxufh5EZ/vhj33xJluZ8c97kDIukv0NCUc1Dc+gwUuy6P7e1QvfjjqNvaQhTnPqL2+0od0RISEhLqD4m0vwVm1hGY7e53mNmuKLM6w8Jau7dApDkAxaJXhM5m9jYizQI0bWw9oJOZtUMlVxWIuBuhErAXUMx6O6TwS9FAkyeRgs/uuRWKmXdAi4E9kZpfjLLKF6NFRhYXPxW4Di1EiuI6xPnfQW7AaShhbSGyydf4ludL9ngDR1qwJSTUPVb55ipm1hI42N2v+4HH34ySyioR2d2OBmhMRSVSryBy7IpU7CYoi3teHFOEFHElMM7ddzezD5CSrox/zVA3sj4oNl6OlPkHSOnehYhyDlLTWVz7EaSWO6P4dRFKMpuJss8/RaQ9CSWvrR77NorzVKFa9ItRjH4sUtKzYt+aeM7paLHyadznrHjmXdz9G13RMpR06O4djrjqO77phFUNibQTEn4YVtRcpSEo7ZZorOVSpG1mRe5etexDvt6nHyK9VuhdvYms5B4oUasMJaFNQ8Q3AJHmQUgl34FIrweqay6LUx+LWoN+hoh/LCLaG1C99y6xfxsU226EFgKV5BYLh6GBIF8hwt4HzeaeiEh2J3efl/cs7VAr1GtRbHwfZHufjMj5b2iRcC2qxT4FOQBZG9esDeoXKLt9KHCNmQ1095l510n2eEJCQkI9oSGQ9iVokEdmRVcgolsPWNfMHkTqsTFwtbsPNbMTEDF+iaZzHYDI+2FUp30MUsoVwCHIns6yyB9x93vMbG1gqrt3jxKvpsCaMVBkHCLi9ZAKz0i3OVLIpyJi741qrDdCyt2QBV+ISLY58DTK8M5KtNqhmusdgOFmtj9KHmsa9zsEkXcpUvj/QIuak5DCd2DL+LkorpVNKpsSz/+HeLcn5BN2QkJCQkL9oiHY410QkfaKpK9HgV7u/ml83xrZzNuhrOkaFPd9FRFja6SgRyNiK0UkOwJZ4qvFv9lIJT8KHIWIsxsagVmERmIWIwt9n7jONESgayIyXg0RZQkiyjJkl++D4s2vk7Pez0cjRIch0p6ErPlypIrboYXGWDTOcydEvL2Q5b5lvKLuiPAfjnN+ghR3D7TImeHua5hZFr//LLb3AbZ39xHLe/fJHm/YSC5LQsIPQ4Ozx83sFkTUw5bx9esZYQdORSp0JIrTznD3GWb2CVLPxyFC7YaINqutHoTe33RygzaI7/dGZP84KtnaFZF4KRossj6y7Tuh5K4qlOj1V9SHvAfKPh+ICLkG2d4bAreg9qblaCHRGynwgUgVFyJyLkQLj4L4LstuvxyRbic02OQltADZGjgyzlUTzzKNXEe38njGJcii77OMd5vs8YSEhIR6xCpJ2t+C1cKiBrUJ3QhYx92bmdlIRK6g7mZ9UPx3J5R89RlSsAtjv9lI7R6F3uVOaBznYNRXfO3YPhxZ11VI0bdEiV4FiPANkfmHsb0RUsIl5IaGtEMq+yTUtawJUtFbIdu7Ova9DU0TG0CuO9sDKC5fjOqrFyJrPFPJg+Ma2X8PXRCxtwfMzJqhRcg0ZOmv/d1edUJCQkJCXWKVIG0zOxy1CXVEZNXAIDM7EynFprFrb6Ri30HEeCAiSzOzjxFZVZvZU6gG+bdIbS+I/RejUqc1UKy8I1LcxXH+dYErEOH2QMp6LEqC+wWy0y9DM62XoPanYxFpPhTnX4LI1hAxlyPV/EzcwxYoi/vfiESHuvvlZvYKUuEDUYb4u4jEATq6+7Fm9ltyU7pAinkwGs85HpWGgVR5/7jWbHdfYGYgV+HLeO4yZMkvF6nkq2EjuSwJCXWPn3xHNDPriWKx27p7H2Qzg6zuLZE13TjU9dnAZ+6+EbAHIsV2iFy7kusQNgcp4veQJX06iiP3RgT+FOo41g+R8eS4ZmeUBd7I3StRC9S10KSuDZFSvgOR3XRULrYLUsNvkMvWbh7nm4/Iuwop6oGILHsjC3w8uWEjv0ax7+3QYqwAWfMAR5tZ1ud8QVwv66Xek9zksPNin/PQtLECpNCJY1qguPnlse0bMZfUES0hISGh/rAqKO1tgfuyLGZ3nx2q8EF3rwHGmxmRiHYGcJCZjUXP3gTNl/4NIt7BKCntDaS6DwXGuPtdZtYITfIivm+OFPYNSHk6qn1+FDjGzMYhYp2GbPQlwAbu3tLMno7jP0ZqtwOytBcjkja0kMgWVUVx7vI434sog/2FuBdQtnsvZGMbIv8L895TYRw/BcXUPe7htniOMSimDbn68knA2pF5X4Di4OVxn8Q7Wgoppp2QkJBQf1gVSHt5WJz32eJnGbKwO6OM6vUR+RWjOPOTSBn3QoQK0CqaoUxCMe1OqBzrGWSTF8a1urj7ZDPrj2Zmb21mDyBlfT6quZ4cQ0C+jH8/Q3HjKjT0oyUiQkcWfzaGcxNkqWdK/gA06nMoItVT3f1IMzsOkfsspIqLkUK+B4UCmsV1V0cK+hxgY5RstxVq4gIi8I0Qedeg/uUTkRqfgLqybRnXXy6SPd6wkRZsCQl1j5+8PY7Ic38zawNfl3AtD3NQjfQriPRASr0aKdtdULx4d0RwmUV8JHA4Ks2qinNsjtRzX7QoOMvM1kTKvX+o057x+7rkbOYCFO9ug+zp65DN3TLv/DXx3WKkxCtRJnoFUtAGPOnuf17GM5Yjkn4OOQkF8VzZPPC/I2I3lASX1VkviWesQclmRShjviDeVxNyteUD4/6ypL2vkezxhISEhPrDKlGnbWZHoHh1NeoKBnklX2a2ILLD26IErmZI2e6BSOgC1EFsjdj/DaQosylceyIya4ZI9UA0BeulOEez+NctbwpY/v09h5Tq5kidj0AW9zmICKchAr0ckeppKDa9G1LytyDy3hwlrp2BFg4gRd3M3duZ2UvIHn8GEfOBiMTLUSz7eRRnb4cIfFHeOSqRMq+O6+0c99UXxd+boIQ+J7fYu9PdD631rPn2eL+JEyfWfh0JCQkJCSvAKl+n7e63Areu4Ptm8XMmUolZ05X13f0zM5uHpmtlGI9aeW6LZmlvGMe8g8g3O+9vgN+Y2XbAScsi7Dxc4+5HhD1+pLvPNLMXgPsROT6JFhT/RAuQqrjWdHc/wcyGAE9FpvgvIpkOMzsU2dcZJrv7yfF8+6CmKW1QE5WrkQL/B0qyGwGcGZ9fQEq7BJF4J3LWf0H8LEWLmMy2P30Fz5vs8QaOZI8nJNQ9VgV7/IdiPrks7ReBA82sMHp07wj8CSnsK8xskZnNR7b2cNQxrIuZdYvjD0Mq9jsjpoe9BZyL1PevULnYF0jxLkRJbcvCNDNb38yORl3bBocdvxGwiZkVoPi3xXk2Qtb7RYiMi1CtdZZF3h4p+cYoG33fuM4cRNxtkIJ/A5XANUHEnln+XyPZ4wkJCQn1h1VCaf8QuPssM3s51PPjyHYeg0js1OgfbsgG3wH4HFnI89y9wsyOAu4zsyJgFHCDmfVGU8DysZicDZ2P3qhmuwbZz/u6+2gzOwUN8Zjn7mfn3e+QvGPPRSq5Bbk6blAC2uOo3WlrpLqPNbMewGsow3x1cuVee5LLVv8VuUVcVWzrGr8/iZLzWsQ2j3exN/CX/IdK2eMJCQkJ9YdVIqbd0BDW95OIiPshkh6AVPTN7n6mmQ0G/uXuTWL/NxAxb4+mkFWiNqcDkHJ+DS0kSlFy2mpoQVGJssUfRDXpjWLbPKCd1/oPKMW0ExISEn4cVvmY9k8JEZte4O6Xf9u+K8AglJFuiET3Q9O+3gFON7PLEKl+FU7Ce3nHPg3sBUxy923MLGt12pxcbfiTcc4SZNW3QK1aX47rdQAW1Sbs2kgx7YaN5LIkJNQ9ktKuQ0Rddtdam8919yfy9hnCdyRtM3sNEWc+ngeuBJ51965mdiUwzt1vimOqUC32EcBZ7r57bP8bMNrdbzGzL4D57r6+mb2HktQ+RWo8q+eehhR11nmtL8q4b4oIvtzdO63o/vv37++jR4/+tsdMSEhISMjDipR2Q05EqxOY2Zlm9k4o2ueRis16jjcC3jOz35rZhCjJ6pF37Dpm9oSZvWFmL5rZerH9FjO7IXZ7JjLFNyY3yxtgkZndjJLgLjSzLHkMpIxvBLYws6yWuiVwspmNQiVfWT37OeRapfZBneGyXu0LUHb7mvF52/hZALQxs62W8T6ON7PRZjZ6xowZ3+tdJiQkJCSsGMkeB8zsdDR4o/x7HtcP2cabIuJ7HWVer4ve7W9Q3LgItQ9tgjqJ9TWzE5GS3SO+Gw+MipKwbNznQcDjUV+exa5L0WSxtVEP9ONRrPm5yHwvRBnjryPV/LKZbYkWEwtQVzcHWpvZeJRFD4phN0HKfvO4TmHc36GoBO5etCBoEs+7Dsq8XyaSPd6wkezxhIS6x09OaZvZgu+wj0XZ03fFFYiIvi+2BB5w94XuvgANHClEQ0nWAZ5A9vKoGGbyfPx+G2qe0gOR4Usoq3sKubGa96FYc3fgOnfv6e5HITLfFRHvtWjs5tg49zNIMbdHWd2PInJ/CS0cWqPyrZnob18W26tQ57Zfofrre2Lb3Hiel1ENd1/UtCUr/crmbn+NVPKVkJCQUH9YZZT2MjKq7zWz3ZFyfMDdf29mTZFazHqGX0TMjAaeNbOZkZx1PSLOUmCYu/8+rvEZ0D8ao/RHpVl3R5x6HUTirYEFZjYGEWAZOTW7JM55IIo5gxqUbIQmcq2JYsulyFoHmOjuI+P6C1Bi2EOo8crgOFcxItZfEh3Q3P1tM7sDlastQuq7lbt3j3NdApwS9zsDEfU/49wtgK3RwqAKjSj9GSLxUjTdqxA1gbmt1t8hlXwlJCQk1BNWOtI2s7OBxe7+10iy6uPu25rZtkQ818z+iPqDLwL2dPdpiIjXRWQyPz5vggj5YTMbhGK5kxHZ3oW6oD2AyGkbYFZkXm+NyOoi4AQz29Ddx9a61Qvj3HuhTma7ImLcHZVHdUMZ3POBPWOYx45I0T+EYtTdEXk/j/qK7+Huz5jZIuDnKNO7sZl94u5rE21E3b2PmT2KGsBMQHXijYBD4meZmb0Z5y0CPkFJZPuZ2cWo+1kf1CTmKdQ29deoIUtnpPgL4timyH7/BBF2KaoHn08uLr5MJHu8YSMt2BIS6h4roz3+Ipo4BVJ0zUxjMbdCZNMUGBl28wtoQhXAEGCmu3dDmc97o45jb6L+4t1Rv+4dEFGNcPeeiKAy7INU718Rkd+Gapc3WMZ9PoSSu25ByrIlmsS1HYpVv4ayrFsi8rseNShx1NSkANnLg4A/EmNCzexTZKF3Qy1X26LFRKc41s2sGYo7FyKL/XAUS7+RXLOUKrRoKEILkn5x38fHve+ICPpEpNQHIsIvQfHtAhRbnxufu8TxxfF9JxTPXwrJHk9ISEioP6x0ShvFS/uZWRnqJvYmIu+tgFORxfxI3r47xOe+SEWD6pK3zPpz58PM+iJreZCZ/Q64CnU9A9nb/0Gx3QGIvDsiEgURYbbQGY9U5+0oq7oZSjq7F9ni6yOyfBGRYQFStiXAaHJTxoaj+POXKE78OjnSHIuI+SFE7sQ1snng44E/xHEnoYXKzLh+K1RrPTfuuzNyJrL2rePi/m5HLsXl8bzT4vhiFFf/VRw3Pp5pBlo4VaG/x1O13m+yxxMSEhLqCSud0nb3ShTXPRKNhHwRkUs3RMaVeU09qln2wuMpoCQUKWbWycxWi37f5Yj4L0dED1KwWR/yUmRzz0Vk3S/vvJ/l/b4v6td9KFLnr7v7kygZ7BngcncfhdqfFiBL+X2UrHYHUtALkUoeEc9SSK6pSTNEyIvRVK9bkILujRR6DaoJL4tzZENDmqD4dGcUZ69Gi4bCOO+SeAcbxLGlKGywNyL6dRE5rwOcF8d+GL83zTvmaUT2CQkJCQn/JayMShtE1GcBRyNFeAXwhru72oEvE28gGxyUXPYe8GrsvwCRazfU77sIKewDUBy4CmV6L0Fq/W1EVB0RAWe4EPinmV2EpmVNJTfpanrevQ8EjjCzY+NeyuMa3RDx59dJXw/cgOLSayCSfw1Z6XsjlT2Y3AIry+iuivu9II4rQIp4BiJ6R4uCccCzKHzgwM3xbuejPuVrIaIfjuLyoMXKaLRI6IdcgI3i+OlogbNvvL+l4O5DgaEAJR26e4ppN1wklyUhoe6xUnZEi1GXTwAt3X2hmU0AbnD3KyxmY8d++wG7u/uRZrYWIqS2iLiOcvfPl3P+rigRrRkixdNj3rYhq3oXRFAXu/s933KvTwAPuvsN8XtjRMTbIJV6KHIOPkUOwFqIFJsiFbw7ioHfhuLEfVBIYCQi6x5oAVKAYtQgtVsR56ntOsxGWeADUNx7KiL3bnFfuyKl3Aoll3WLfeaiRY8D/0Jk3QotOrKhJ83jXEXxb7i771/rfaTe4wkJCQk/Aj+5jmjuPsLdG7n7wvh9XXe/Ij43y9tvmLsfGZ8nuvu27r6hu2+3PMKOfT9194Hu3tvdz8+bt+3ufra794rvvo2wm6AEt7vzzl3h7ke5exd37+Tuz8ZXH6DFhCNX4M+IDHH3MShprhWKMb+M3IFF7j4BEeai2OeyON9RKP58E1K/f0DKegqKR7ePnydnZV6xrQbZ5AZ8HOesROp7Sez3s7i3n8f9/plIlItrFMX3v1/R+0lISEhIqFusrPb4So2oCX8BWdzlwHXRUvRClER2CIoZ93f3k1H8vB1qdFKCSP494ASkwAHOjPONQ/XTxSguPys+LwJ6Itu8GrUfBc3fboJs8g/iGvtqQ9DWAAAgAElEQVSRG9c5KGqyl6DuZlXkEuqqUDnXS2gut6GFxWux7xOx7bw43zpInbeK4/+JQgHLRCr5athI9nhCQt1jlSZtM/stajgyk5yNfJ+7//F7nGNZM7Idxbs3Rollo4CDUfb5YNS+9MFaxxTF9+sBD7t7t6g3nxS2/CKkkrdHtverKM58WVyvCbKw2yO12ybO6cjufgLZ/avF9jZx3V7I/u6G7PoKlD3fC1nzuyFiLkYLgNYoG744jp+OpnpNRol7xYjAF6M2q0u/mLyYdv/+/X10+h93QkJCQp1hpbTH6wpBzpXAdu6+Ufz7zoQd5xgXpWP9snOgBLFP47saRNwjIqt9HLma5gwLgF+6e427j0fEi7vf6u5N3L3U3VtH3fiuwEvuvkWEBI5DhD4NkbajmHYnVAN+BiLRfqhkqx2yrbM+6p2BS1A8vQrZ43sj0n023o/FuTqhbmjjEblXxHmyjPqsqUoFKjP7RkvZNDAkISEhof6wyijtsKyfQPHivohIX0CKOL9F6UFICRvwqLufs+wzft029O9I/Z4U1zgVKdo2Zlbo7tXIkr7MzE5DceI14xTbRbIcwOK8JDqLzm8H8M02q38GesfUsItQs5YmiJg7oRj0ZETgOyGi3hrFoYchYj4HEWsZUu2Zze2IlN+K6/Yi99/AwviuCtWQT47rrYWcisWxbwFS251QMt3M5b2/ZI83bCR7PCGh7rGqKe0eaLjG+ijTuhiRzzZB2B2BS5H9uxEwwMz2WsH5mgKvRfe1WajP9xbkBnYcYmYd4lznI/u7+3LOlY/C2G+TOLZftFndGWVoNwE+Qr3U28a1j0Oq+D/Ifs7qsu9APcBnx+/PI3W9WvzeOY77C8qUn49qvSE3qzsj9Jvi80wUV38VWf+vxTmmoOYvVUhlV9R+sNQRLSEhIaH+8D9T2mb2irtvXsenneTuL8fnO5AqzsdbwHPuPsPMXkGJVIP4Zvw5QzWKK4MUbz9EYu2Q2l4bjeWcCsxz9yVm9ggivBWhELURfSt+b4e6su2PYt5TEem+hizsHojAh6FGKiej2unWiGxPI9e+9AukwlvE71cjcq5AC4XmSHmDyPdIRNZt456M3DztrOnMorjnCWixMCmefThaqHyN1BEtISEhof7wPyPtuiJsMyty96rstLUvs6Lrm9kx33L6irC/QWR2q7ufZ2bPoUElo0Opv+Luw2K/2cDd7n5LzLEuiDryAlQbDiLoCe7+93iGrVHJ1Zlxz60QUS5BtdYdUBvXo5EK/xTZ/o2A09z9cDN7AbV7PRKp6RqkjtdFFndhfJ6LFP2nyGl5KO9dFcb9lyJHYk1kr6+FFglbIfeic7yPs1b08pI93rCRFmwJCXWP/5k9ns3FNrOtzew5MxtmZu+b2Z2RTY2Z7Rrb3jCzv4aKxcyGmNntZvYycLuZtUONQzqb2Xgz2wKRV5ZF/YqZ3YhIbHMzaxvXPwh43szONrNRZjbWzC6Ma3QBmpjZP8zsXVSzvL+ZHY3I8e7Y/jdgGzNrE4NN9o/jL0GZ5H8zs8vjc6OIcT8JHG252eBt4z67ob/JVygZzBBpFqDWpJNRSVYZsv8bAQebWTUqvRpPrg67ESLinZHNnWWJf4hK0IhzvxT7TUEWfGuk1lshJb4QuQu7IAVeg6xxRyVoSyHZ4wkJCQn1h5UlEW1jRACTUWORLcxsNEoCG+Tun5rZ3bWO2QANBVlkZnchq7sr6u+d9f/eBCWjdYvPndBUq2eRmnwDKdosvpw/xvPz+P1adz/OzO5Fncoyy70KjQr9F5qF/SowB7VAbYwGmfRGSnYnZLVXAbj7UzFqdJMYwwki2k/JZXLviOqjd0HK/ApyDVFmI4t8GCLnMfE+msS59kKNUP6EJohtFvdUgWqteyPSvRMNGnk47vHRuMe2sW/L+NkZEXlBPMecuNY3eo8nezwhISGh/rCyJKK97u5fRPnU26hkaj3gE3fPmo/UJu2H3T0jvO1RR7C1UKx1JlKIrRCRz0O2cCVwlrtnpLU9sqz3QfHliSjRLEsmmwYcG5+zUinifEe4+8js3qJr2yZoyMliRHbXIGJ7HdVETydX//yvOOeHqM/3SHINU+ahv83LKGa8JbLKGyECXRPF17Nks4q4Zvb3zMh707hGIxR/bowWasVoAdAXORQ7xDVnx/bmKM4+DS06SlGcHWShd0bJcFmWfEJCQkLCfwEri9JenPd5eZO7amNh3ucCRKjDs3GcYW/vhsiyM1KR5eRGYla4ez8zuxp1EOuGCP51pG5HIPL6zMzWR+r0Jnf/nZl9iWzn11FC2iXAsWZ2AiLCJUi5HxTn7u3uPc3sE2Rj34V6jWdW8ydIWRfHsbejBcWOiNC/QguORSg7fNN4hjGIiDdBg0juAM6N99EKJaH1BDZEC4C5yM4/FrkOJ6A6b0Md2kaiAShj4r5fQwuDsXEvFSirfW687xG1/yhpYEhChuSyJCTUPVYW0l4WPgDWNrMu7v4ZKrdaHp4CBrt7LwAz2whZuOWoU9lLiGw2zDum2MzGINLtiJT3f5DC3BjFrUuQ6t8OKebjzWwwysxeu/ZN5A0NaRb7PIcs73Vilw+BPmbWAiWXFUVC3MHAYchuB9VdXxXP3DeOX4CasvSJe8najn6ESPoKZIuXIqv7c7RAWBeR7urxrJD7u9+NiJ54N83RQqJ9vIMitHj4Mt5PcZxn/drPniHZ4wkJCQn1h5WWtCNW/UvgCTPLkqG+ATM7HBHZrmaWNU35ktzwi51QM5Ws9WY3M+sVv1eQS/xqGdtmIZXaI851YBw3CRjm7kPMbF/gT2b2dq17GYLI9U606KiK8041swFI8XdD5F0CLIxktOMRKQ6KeyhGavtttOBoi5R0NVLeTRF5ViFyXYiaq7RFFvc2ce/nxLvIEtyyLPsypNw7ovryqrjWq2gxYsCt6L+PRcixyJ51STzjG8v6eyQkJCQk1B/+lyVf2WSt55AizbafnLfbs+6+XmSTX4sIC3cfAmBmPRHpbO7uM82sNVKcbdEUrNGIZI5DVvVFqOPY1SgL+1pkcY8DFrt7bzPbEC0QtgcuRlnd16HY7nXZfQE7uvtEM/tGRzB3n2JmbyLLeSvgH3H8PxB5HoXi2yeimdbrAvcjlezAFRHfH2Nm85EFnmWFb4aIdUvg30gVL0BhgLsQmTdGMfoNEWG3RouI0njekriPkWhxMBQtLvaLfTZBi5SZ6L+Re2P/K9EwlAK0SNim9rPnI5V8NWwklyUhoe6xsiSiLQ/HhZp9F9nNf6/1/bZoAMhMAHfPuoLd5+7ZtKptEFluFcd3QM1FWqPs7EsQeWWYh5T1WsQErugXfj7wlJmNRTZ6h+9w/6+Sm9z1LqqfrkYx7IvQMJBS1BXt1jjmFuAGM3vbzEpRQ5MZaNHhiHDHoYlioGz2rIvaAUh1N0VqeipyE6bE+ytGmeJZydYWcQzx/U2x/f64x0Kkuu9Bi4YT0CKheWyfXPuBU8lXQkJCQv2h3pV2NCI5y91Hf99j3f1KpO6+L7IktWOBrdz9GwQbCra3u1eZWRkwOez4x4DP3b2XmR2Zdy/3IPKqjYnAnmbWH6ncajMbF999hezqGqTkL49rb4NKt3qhmdl7RYMV3H04uS5sAFub2WeIpA14y933NLObkEK/FRH3JGSlv4nKwZqhhLEzUNy6DDkaL6LktKZoYTIhztMGLWKqUIe4LdACYSTKgj8F2foboBK3D4DfooYv+e81xbQTEhIS6gnfi7TDprawblcGPAM8YGZXuPussMe/hrvPM7NPzWx/d78v7n9Ddx+Dsql/jgjtEESIGWlnmI9U5YpwDTE3O4tpu/uTZnYeIs91gBuBtmb2IiLyAXFsY/Ra3wUeAJpHBvo67n42+vJIpNZBhLpDuA+T4t4GIkXcATkPc2LfAqS+v0QW/Mao9KsFIvOy2G9nZI3fjMIIRSgp7u/Ivt8QOQ/FKDmvCM3urkSLhOUi2eMNG2nBlpBQ9/hWe9zMupjZB2Z2G/AOcMGyuofldTN7L7qbNVnGua43jW18Nzs2tg8ws1fMbIyZvW5mzc2s0Mwuy7vWL2Lfrc3seTN7CMV0JwBvm1k5Uq/NY792ZjYcKcobzexDZFFfFSp1tdieTbMqRgT7GDE6E8WuNwir+sA47zlmNi7u9ZLYb8O4/m+BiyIrvT8i5awdaTmqrV4DKe8TkXW9KPbdCy0cTgaONOFvKEu8BCWNgch6A0TQ2VQwULb4hyjxriNS0c+jRckmiMynIbJtj0i7GJF4IXAoSsKrju9/i3IDGqEww8PxHei/mzfR4JSlkOzxhISEhHqEu6/wHyp5qkEJUDuipCVD/+N+BGU8dyFipHHMTcgSB1my/eNz6/hZGNs3RMTxCTAgvitDau544PzYVoKSyrqicqg5SFmWICV5Yex3GnBVfL4LdUwDZW2/F5+HoAYoJeQmaDWKZ3jnW97FLnFsk1rP0yZvn4uBU+LzMBQjL4z7ngkcHt+dhMh8PCLuucBm8d1TqN76ORRXnxT7OLL+a8hlcX+FlPAHKLltchz7Nip3a4+IemocV40WOtOQch8T9+jxL6sHfy/es8fvU+PnPORAOPD+Mt7R8fG3Gt25c2dPSEhISPh+AEb7cnjou9rjE919ZPTQzp9O1Qx1D/ucZU/YurzWeQ6ImGcRIt0N4n/+U9x9FMjSBjCzHZGCzeZRt4hrLQFGufuU2O9jRHKgBK0so3l7pJKza5dF/TRojvZiNON6Ojll/W3YHrjZ3cvjXrPEt15mdjGymZuh3uIZ5rl7ddxHGbnObp8iMt8HkftMpMxB3dJORvXVb7r7mWY2HnUgewgljz2JytGuQdnoWV36HHe/xMzWQ+/59rhOW7TYmoYWSZ1RHNvR368JSoprG/fWlZyy/iOKjd9KrpZ8CWodu1wke7xhI9njCQl1j++aPZ4ldhnwZ3ffKP51c/fsf9wrnLBlZl3RVKjt3H1D1KGsMcuHIcWaXauru2fknN9BrSbv9xpycfoCpFyz4zu5+4JlHP+dOrCZ2VEo1ntB2OVvm9m18fUtwMmu9qgX5j1XJbmZ1Rmy91IWn3dHRL8lcLOZPYUUbR80hvMkM5uDmr6Uo85snyPHYyF6j0uQ3f8Y8L6Zbe7uR6LSsDJE1PfGdVcnR8ZL0ILlkfiZJdCdGPeQvZdfIkdkb6S4X0cZ6UfUfk+e7PGEhISEesP3zR5/EsVs73T3BWbWCRETaMLWQHd/lVwXsnyUIZKZa2btkdX8HLJ1O5jZAHcfZWbZ/OYngRPN7Bl3rzSzdZEV/l3xFMp4vgzUJc3d317B/itMOnP3m81sCvA7pLgXkUsQaw5MMU35OiTvPhcjEn0n9p9NLvmtXexzESL2N9Gi5pfkGsEUoLj1ZbH9OkSo1UjlvoeSx0BKvRLF5bdANv5eKDO8OK4LUtkDkc2dYSoatLJpXHt43NNxaEGyAWpveij6e20f+11U+z2l7PGEhISE+sP3qtMOpXsX8GqUNQ0jR3QfIFX4Huoodn2tY8cgW/39OMfLsX0JYfNGAtd/kFK9EcV73wzS+zvfb5FxKtA/ktjGoxrjFT3bLOBlM3vHzC5bzm7vI4t+MlK9D5jZKJRQ9kE800fAdvEseyIrv1dcfyKqwZ6PyLUSuQNV8WyvoU5j6yASzt7B/ijuvi9KNhuC7OzOqMkJiJwPQC1XL4jEuNZEhjo5tyRbCHSK71oh8u0T91CBEvaaIDt8IYqVH4ni5JvHvRSitq5Zi9aEhISEhHqGKeb9I0+i4RyPBDmtsojn/AQRVxnqIPYLYqQn8BekoHcGzkaOw50oHv8msL67z4hM9J3c/WgzGwm0dfducY2zEKHu6+6dzawN6tA2x937Rhb9WkjN7o1UeG9EsgNRglv3+DwYEe8naKF0GVpsgBYFHeL3cmTVr4bi2U1QCdiWKPO8SZzjBbTAmoWS43Zx97m13tHXSruwrF2/NU68+Qe964SfPpLLkpDww2Bmb7h7/2V9t9L2Hl+J8W1JeS+i5iN/RsR8nZmtiSzq/0RCWiGy05f3/ucCX5nZVqi5SROg3Mz2QbXpI+J616C4dRNkmQ9FKr2EHDlXxfe7IaIdhTLZj0dJbV8gxZ61LO1ArnXp06gtbN/Y1jjOtzrwjLvPNbMid896mi815at///4+Ov2POyEhIaHOUCdKe1WDmfVGWdf5WIxU5iOubmn/B0xw99qtVYkmL48ilTodZYFv5e5NolnKPoh0C5E93RPZ0oaSw5qiVqvbodhzCbl5123IEevriKRbI6JvhAj6NXcfGLXwZ5NLtitGinoxsup7xHVLUcy9GCW5dSaXRFeDLPWP4twL47h5qOTsCnf/v7xnz49p95s4ceK3v/CEhISEhK+RlPZyEATa35ceUoK7j0P9wGvv3yXv1ydRo5a93H2XvKS8IkSuB6HmJm8BOwCFZjYwju0L7O/ur0bTl0vc/bdm1hLZ6GWozOoalEB2LlLC4xBhr4di26ORDb4IqeAmKB49IMrbpiByvh7FwwehhjElcdzc+O484Pdxrb4otv4IinW/gBq5tEeEfQtqvFKCBrp8Tdi1kUq+GjaSPZ6QUPdY2QeGrLSIpLwRwBa1kvJ6IwX8GIpvXxyHTAIuBf6AlPRfzGwDpK7PMrNFiORLgMnuPhLZ7zugOPNCRNZPI+X8Kaqpfhsp7Jooyv8b+rvOiGuvjSzuQUhlr0eujeo8pNJnA79Git9j+x5xb9vGvmVowfCnuP8SVAe/VCJaKvlKSEhIqD+skkrbzJqimOwa5EqTPkEjOZsie3i72L2jmT2BbOYH3P3XcY4dUc11CWqPepS7f2ZmZ5nZ+yhm/BLwgrvvbuo7vrdrKMiTZvYBajgzOuLYFe4+yMzuQTHlFshunwvs5u4fxHW7AK+b2R/RMI73kZIehWzrNZH6XQ2R66+Q6p8eLVkLEPF+gEq1ahD5Tkck/3n8BLgKlYe1RAq6KaobXxMtQBajjmklKF7/ZZynO3C3u5++jHefSr4SEhIS6gmrJGmj7O3J7r4bgJm1QDb1gVELXoaIEGSDb4ySq94J0uyLSOsYZB1vA/yfaQjIMETiFvvNiWOOQhb4waibWQ0aEvIcQXpmNgItIu5DE762RSVd46LMbPfYN2vj1gKVYn0W+2YNVKagEqztUG33EqTgN0alZYbUfjv0N24bnx1Z7U8CVe5+Zdjoe8U5KhFxv4UWFiWoL/pr8f3U+L4dOQW+XCR7vGEjLdgSEuoeqyppj0MkeymKzc5h2a1SAUZEFnQrRKiPoCS0B1C51CSkqneO779w9z4Rf34XJZlNRwr3KpSRfTeysD9Ac7wdxaCzxIKeKPnrK1QSdihqnlJGjrCPic+LkMVdHL9XIQVeGNeehsj1MhTXzpT2sbFvYWyrQUln+yA7HTN7FrkJhag8LWvQciAi6RqUbJZ1VhuQd39dzGyQu7+Q/+Lzs8dLOnRPWY4JCQkJdYhVkrTdfYKZ9UVTqC5GZVLLQ35L00XIPm6OyPp8RHDbouEmuwJtTKMxQURaGvvMQlb1oajRyWQUX16Ekr6uQ7PBh6GM7jHITh9tZn9FpVebogYpV6OOZ78BBrn7+LDwd3D3vaOW+zx3X8PM3kC29b9RCOBSFJ8+BZHxJfFvGFqQzESE3tndZ5rZdoichyJiPgx1QssWO5+hhcgFaJExHcXFQTb5UqSd7PGEhISE+sMqSdpm1hGY7e53RN/uX7LsVqm1kfXkHoks4FZIaRaizOyp8f2+7v6xmd2NCP4MZHcPA/6BksXWQfXajtTp+eh974dixu8CO5rZ9bE9U8QL0EJg+7jWY2ZWjeLZBWZ2H1EbbhoN2hklkw2M+3fgHBSnron7AhFyCWrX2hi42Mz6Ixu9ABF147iXPyO7HUTMh8a5ro7r9Izf31/e3yAhISEhoe6xStZpm9lOyC5eC5HQVDQ5aztk8U4nN3byFXc/NjqT9UVKuwKRWztEdE3j988RkRchgmyDyHwRIsmXkB3eCNnL1yCbuzmynYtRvbMjNV6OsrpHxecFwA2I4Kvj2hXxM3MEhqAY+yYoQ3wjcvZ8KVogvIZi4Y3imEJko78c76RfnO88ROZDkFNQjMi4Uew3BWWpz0bqunk8F8h6n5Z1clsWSjp09w5HXLW8rxNWcSSXJSHhh2FFddqrJGlnMLPW7j7bzEoRMf4M2cOHuvudZvY7YDV3PzlIe113b21mg5AlfBxqgrINIroHEfE3Q0p6vLv3j0zzJ1GMeQJqL7o6ssArUaz7WKSKf4Os5/cRIS8EOiISfQyReOvYZydEmO3IxZIrEWF+iUi2aew/L445BGWkv45U8mvIcp+HSHiXuMf5qM67NVoAzEeE3TzOPwLF8RegxUoBWmgUxL04WjSskzc9LTVXSUhISPiRWBFpr+p12qfG4I6RyJLujojpnvj+DtRfG0Sg+wFEctV8ZHMDzI++6lVoAtbmyH7PXuqEOG9/pMLL49jWKJ6ehSFmI8UPUr6PI3LdDpWl9UIqtwIp7YdRbHw+ueEia6Ds9BeAzVAWeQVaSPRDqv9upOhBJV3HxLkmobruYpRRPiiehdh+B1L6xahc7CmU6b42WlgUxn2MB64F8sedJiQkJCTUM1bJmDaAmW2N4sID3b08Sq+yOdfvhLL+GdDCzLZH5VK3RX/vdxHhjkDk9k4c1xLNuD4UWC3mVr+Sd9lDUJnWi+6+m5l9hoiuPSI+Q73JT0Tkty+yrIcimz2bnlWMCLkULRRaIGJ+Ck0764OI8xmkhCci+3qtOMdhiLgnxXnOQYuAteN8xO+VQJfYVhHbs2Yp7ZHCXxz3NDf2aY0WQPvH+3lweX+DVPLVsJHs8YSEuscqS9qI6L4Kwl6IiAfkLnRHpPMxyrI+GCV3VSD7eh7KlL4d2cBDomHLQmCou18SGeS3Ad0QyWbXnAMUm9k2iERBcfRyVF51Msrmrkax9k3juhXIyu6NOo/diRYZGyK1XIKy15cg8m8b18tGe1aSa6rSEy0s3o3jFiHyNaTILd5HM5SkV41U98YoTg+y39vFPVTGz/I4T2Nko59DLdJOA0MSEhIS6g+rsj3+BFAU871LkEUOIp55SIlug3pxj4jvJqPWofsjcvwLal5SRGRvA/tH29JioKuZjUWW+UeIaDsgsj4cxa1/j0isCPXsfgH1+IZcG9GHEJH2Q6M1pyB1v1r8A3glrv8vRO7DERkfTS6+3QQp7kqkvksRkfdAA0zK45gKtLi4391/hRYo2UzvJYj4M3VfGc9RSk7Vz4h7Glr7pZvZ8WY22sxGz5gxo/bXCQkJCQk/Aqus0nb3xSjpCjNb4O5bR/ev/AYkV6OkMZDCzYh5MiL1XyNy+8jd3zOzxYjkfx37VSDL+U7gCESopyGy/xlwerQ+BTVXWR1Z12NRHPtZYHRMDRuO4sino/jxBoiou8W1sraie6Lks42QWr4+nmkJWpzMin3boMzw95HlnfVAfwnFxRfGu7kJ2f6O6rx7otj+jSibvlGcpzFamGyLCJy41nKR7PGGjWSPJyTUPVZlpb0sVCDi+5hoTRrbN4rtpyFiegAR2eTY70wzuwUlmk1x9xpEvoWIQF+J4+YjctwBLQayWucmaDTnmijZ62yUiNYGtT4tiXtYHcW5J8T5WyJyrXH3jVAG/OdI8f4C/f1eRA1Qpse1jkHW+eNxfzVxvnHIBv8IkfDzKC6+HlLqN6P4dhFaMLRGi4qPyCWrNUbW/h8RyV9e+wWngSEJCQkJ9YdVuuQrQyjtZmbWCCnIA5EC7YGyql9C3cweR2VWPVGZ1lFIfX6ESsVGo3ImR/b7SUiJ9kDlVvcDi939j2ZWgDLMW5rZ71EDlhJy4zunoyz201Hmdm9kX09DpLwBWgS0Qdb3Z8hC7xjXzAaBGCL2c1Fd+IR47Ifi/tvE/XeK61cjsp+PFirTEHEviOfyuMfV49lXR6VvN8XxHucoRjH57qnkKyEhIaHukOZp53AIkUTl7pWR3X1OWNh3okSvDZASfhmRXhWK+YLqlBcgIhsVC4EFqOXoEqR+H4t9OwNlZvYPZGnPiXMvQYq/Y2yfhxR1CWpF+jlSy0WIPEcjpVuMyPr+OO58NCYzy/z+ZVy3CsXvDyTXXKUjIvm58SwdEWkXo/h5p3iuNVBZ2jWoK9pXKEZ/RhzbLs6XJfVtu6KSr2SPN2wkezwhoe7R0OzxFsD0IOyvs7uj7Wm5u9+BOqmdiUjxIzRX+rQ4vgMquaoE7jSz2xGBtSA33GOwKYh9emwbgIhwPkogmxjHzAIOyrs3R+Q5FxFvI0T8m5FrhdoctREtQaQ6H1nw75OLS6+BMsfvQJnd5SieDlLIL6KFwRi0gNg+rrUmWiiMRclzIHK/BhF6pugXI6LPOrYthWSPJyQkJNQfGprSvhP4d2R/jybXO7s3cJmZ1SBCHho/pyIbfDIi21EoA3xz1N7zNBS7HolKptqh+PU4VOdMHHcWssBrkCo/Fal1kALP0AllnUNuMtfLcb3VUEb5LETGhyOi/hMi36wFaeN4zg/ifCBivx+R88zY1guR9xooxj0XLT76x/Nmk8WOIlf+9RGKe68R1zoh/n2NNDAkISEhof7QIEjb3ZvFz5lIqdbGZ6gNKQCRJX45It8piCj3Rt3T7onpWEUoAW0uIrZqNKlrbRRXboVU6bGoy1gjZDc/HucqA65ACrY9IsF3UELYfUgRN0Kkv258PxpZ/B3JKetKRMRroMSyDRCh/xzVnjdBWe2O/t7bEglwKKa+MbmM+uq4r5Z576Y4nqkAeA8tHhrF75ub2Tru/vHy3n1CQkJCQt2hQZD2D0A1qtV+DZHaFsgi3gVYw8waI2t4F9SlDESQT6Pxm92Rst0PlZVdiWzuJ1GC23yktF8DXkUk2wJla59Ars/4A0jNF8a2nyG7exek9N9z955m9m7sfwpKiBYvUIgAAB1bSURBVJsRn++O7Y1RnfY25JLJmqMkvJPi3EvQAmQeUugt434HI2U/GNgt3sNX6L+dvu6edVgDvjlPO8W0Gy6Sy5KQUPdoENnj3xeRXHYSmn61OlLibVF9ckn83g0p7+uROm2NMrHXQn25DSWDFSK7uRu5vuJ/RHOvJyD7vT+wPspCfz4+ZyrayWWLT4z7mRU/vyCXYNYP2ff94nogtd8UWfCL4pjF5NqlDkTK+49xnmpyo0jLEIE3RW7Damixkc3TrgQ2qK2yU/Z4QkJCwo9DQx4Y8oPh7rci2/sDYIS7twNuiX9ZUtZxwAVIydYgRToZxYDnoDrwAqSy10IkuwiRciVqnzoF2d4ggt41znUBuVj1I8B5MQZzS7RoyBLXhpEbQtIo7q0piqE/F+c6NZ7DkTV+L7n4999QotxjyJr/MI5fENd+AbVrnY4WJhVoseHk5osnJCQkJPwX8JOzx6NMq3/Ep3/MeQ5HCWKOMqbvRRnjxUBTM+u+jMMaoyYoc1C29b/d/SEzuwjZyQOQzb2lu+8V1zkMkVsNspsztb4YJbAtQrHoVnGNfyCiHwy8iez5Q9x9gZl1QjHtgYicy1E99gNIJR8Vx5SSI/+5KFltXJz3JZSdni3YBiFVvUucYxq5crCCuP7biNjXQAuOIkTeXckNU/kGUslXw0ayxxMS6h4/OdKuC5hZT0TQm0dSWWtE3pu5u5tZBYot/7vWoYOA+9z9t2Z2FHCXmb2DFHEpasxyEXBSNHLZEKnfMagl6L5IhfdEyWTXkWt6ktWCZ0lgmwNbIRKfEa1QifucTW44SDa5rAYtJiyu6YiAa+L+dkLqvhmyurO4yEHIdn8GKey90YLiM2Sn18R9d0Tx+xbI6m8N3G1me+Vb5LVj2sv+CyQkJCQk/BCs1DHtmKx1L1J4hYgQLwVuRfXTjYD93f39IN6bUKZzOXC8u481syGo93Y3FJf+CyK6TZBlPT++G4MIswOK2b6Ampy8Qo5Qu6EyMUdZ2V1RRnU7oJm7N4/7fg+1Mt2P3Ezts5Ct/AuUIHY7IuRuce5qpLh7IeIdi1R0P3ffPc67J8pG3zXub4s4pncc8zRKNnsVKeQapJYnxvdrk4tpl6L+539C7kExuQ5rp8d7LkZOwCmxXyu00CtAan1Pd8+ayWR/sxTTTkhISPgR+Cl3RNsZmOzuuwGYWQtEJjPdva+Z/RKR4bFo7OVb7r6XmW2L4rAbxXk2RHHlpijL+4bYvgkqkcomVw1193PNbCo5BdseeMHdfx6lYFe5+81mNgVlcBehBUV+Z7BqVM98HooFH0FuCldjpGYPQTHuk2O/5igpbT4i1yJEztPyzntn3GdBPNMUcoRdg9RwESoBa4IWLyXIym+OFPpYtMjogaabPY0UeCNy3dkuRZb4hnG+y+P4LMO8bTzzneRs/W8g2eMNG8keT0ioe6zsiWjjgB3M7FIz28rd58b2++PnG4gcQQlatwO4+zNAGzMri+8ecvdFEQd/FpHT1sCb7v4Jsnznow5kIHLPMINcQ5LxwIFm1hIR2AHuvgEak7ksrIYU7XFImfZGseAHUCLbWyhZrRwR9gCkzMe4ey93H5Cnso+M+zoHLQqmI6t9NCLth+PcIBt/NIpfVyKyrkYq25FDkKnqbcjZ6VXxL7PgZ6O4+20oY70Jin9bnG927QdOHdESEhIS6g8rtdJ29wlm1hcpzovNLJt7vTh+VvPdnqF2DOBz1ObzVDMbg8jzIeBwM3sDqdYM+XXIDwAHIDLswDI6gtXCJJSR/U+0MJiLiA+UHT4knmUusDvwG0TKK3qO4ei526B68JrY3o+YCIYs7d6IuD9GcezJSIkXILt+U6SYZ8W5ivL+EedqjCz4NZGT0AItYDrGOXatfYOpI1pCQkJC/WGlJu3oCT7b3e8wsznIBl8eXkSW80VmtjWy0OdFAteeZvZnpFS3RhOx5qLY7V7IHn8cOMbdh0eG+p6I7Oa4+8lm9iCqpy5GSWynIpJfCOwDLDSzQ2N7FXAi4DHx62XUK3wqSi7LBo/8Do3g7IJs7KPj2B3MbBFaXAxCav1ioMrdq82sENnV8+J+CuPZH0WkPBctKjZBpFyOFPI7iHi3iOsVIMdgUZyvLK4/Oa7djFw/8znxXUektAchBX7I8v4gyR5v2EgLtoSEusfKbo/3Bl43s7fREIuLV7DvEKCfmY1FM5+PyPtuLLLFRwIXuXvWfGQUqlN+D8WnH1jB+Y9G3cyGImI+A5HpvqhOeg5qprJFzL6uATqbWdY2tRNS6ItQLHsPNNhjC3K109WIgMegeul25GZWtwAamdkf0N+tAhGtIYJtjki2BiXeZbO026GEu5uQYu5AbgAJKGbeLD4/HNuLkKVfgeLmXyGHYC45W70GZa8vhWSPJyQkJNQfVurs8bpAZI8vcPfLa23fGjgrixl/x/PsHb92QQr9P0ixno1KqnqgWDOIRFugWHU/FA8/DGWknxzfP4riy5uj2dVT0VCOtRG5dkHx5k/i3AWoTOwI1Br1HZTEVoCIdD1kaz8b91eFFgnViIRfjH+dkPpug0IDixDRL4zrfoms80vQwqIJIv7D0CLnY5SwNtndt6n1nlL2eEJCQsKPQOqI9iMRBL89MNDd+yCi2xoR5RhkeT8F3OruG4XS3g6Y6u6Huvv67r6vu5e7+zXu3gMtADZFhHiWu/dCdeE7A39z996IwAuQlZ7Z2DvHMfuhxLXuSPG/HLfbHMXHHRH8mNh2Ocqab4HIfSaKp28U56lCQ0YypV+GSr1aojK1BaiPemtUTnZ1bcJOSEhISKhfrNQx7bqAuw9ZzvbnzGy3GLbxGFKP5e5+2zJ2bwF85e7lZrYeKh8bAvwqyBYz2wD4j5ntgQiwMdDFzB5w971rn9DdX4tJYQOQmgWRZXtglpltgUquFiNSzkrQisglhR2OLP7fA+8iNf0gqhFviuzsdrH/WWiRsB0aQtIWLQQ+Rl3O2iM13wip//moJr0U9WEvQ6r+rLjW5WZ2q7svXNb7hRTTbuhIMe2EhLrHKm+PrwhmNhdo7e7VK9gnq8N+ENnVHyD1OQR4JBv7GfseSM6urgROcveR8V3WtOTv7l4e285FNnYzZGG/Ra4daTZ5qxIp7qweezoi2jWRzV2DFPSvUPy5GJH06ihR7WmU5T099p0d56pChN8CEXKX2FYYzzAWxeqbI/JviRYQJdnjokXLFct7d/379/fRo0cv7+uEhISEhGXgp9xcZblYRu/wC1CyVVtUW32Uu39uZrcg8uqPiOzX7j7MzB5GZPlGZJavT8S+zew51FxkS9S9bA9EqFlTksMRsU0xs4vd/XwAd78HzajO7rGLmX2ARnD2Q+RYZma7I/JrjLLMR6JEtI0RaR6EYss9UaZ5M0SS88jVc7+OVPMSFCfvidTxKFR7XYks+8GoJek7qPf5nrGvobr07VH5VqW7l8SEs1NR8tlLiLT3QMT9TxR//7oT3TL+LkuVfCUkJCQk1B1+kqS9nN7ht6KY8q1mdjTwV6RiQQS4JYrlPgwMc/fBZrYg4s9Zolk+irOVTljeS9y9v5mdRrQXRar1YzO70t1n5d1fF0Su7yPS/RL4O2qkchqyl1ugRcBQRIJfRbw86/zWA43MzJLBLI7ZBxF+G5TNfjCysH+Gsr3bxvkHouY028S1z0LzsKeiRUJvRObnIdWOmR2ElHoFWnxciNT3b5ADsDNS/RsAr5rZwGURd4ZkjzdsJHs8IaHu8VNNRNsWDe6YCeDusxFJ3RXf345IOsOD7l7j7uNR7Pa74J5avz8cP8cB77r7FHdfjDK718x2ihrvVoh0b0eWch/UNKUAqeZ2SCE3Q4uLnYB1zez+vM5v5Uh1X4jqpEGuwgxyIzhPQr3LS2P/xkhFd0ELsnVRKdol5IaEtEdKvTkqN9sD1XI7al/6RVzvQqTcq1G/9qnxnNuiRVBjlOi2FFLJV0JCQkL94SeptH8AFud9tuXutTRqJ1hl56ipdb4alv0eJ6E2qx8hu/lUpHovdPcrYvjHvu5+NYCZnYOUbNb57QFEuK3RwqAX8A93/4WZfYGcgNXM7C1ExKsjVdwMkeoFKPt7WxSPHoqIuwiR/pQ4742oZK0pipFPBq5FLsFFyCIvi2tk9dmQWxQshdQRLSEhIaH+8FMl7WeAB8zsCnefFfb4K6hk6XbUpevF+r6JmELWG43oXIJIDlRH3R5Z5JmbUYRs7YvN7OeojWqpmV2GsrX7IoV+R3x+BdnhNUhJg6xvEEHPCRu+D+roNj+u1Si6pnVEZH0nUs7FKIFtClLMf0FZ5k1QPL8irrU6sH88SwuUC/BY3P9stJhpH7/fu6L3k+zxho20YEtIqHv8JO1xd38XxXufj97hVyBVeVR0RDsMxY7rGzsj1X1wlH49Edu/QiT5PCLag8n1Hr+M3IjQwbG9L1LB81BNdD9kp5cgVZwNMNndzJ5FijcbMmKom9vxRMJaDDTZCyn97nGNYkTOWyFr/GxkjV+CbPisJ/rTqFXpDcgCvxElxlWh5LbmiNxrUKx+KSR7PCEhIaH+0KBLvn4szGxdlKF9Dyr/ejFi2geixLhPUY/uJ1DHsQcRAU5Gsejfo57kBtzs7ueY2XCUbHYKGk6yMSL6C1HseRaypZcg0uyCyHQBIuamKON9N+B6FC/vFbdchWLU01BXtkfjfIuQmm9CLtFsBiLvGpSp3hcluDWK6xcDT7r7zrXeSeqIlpCQkPAjkDqi1RPcfQIis3HI9v5dfLUEEeQFwCh33xclet3m7j3yOokNQ8R6vbvnT/eaiUq0HNnRmyFSnoJIGGSJb4tIeE7suzj+rYnIe2dE6jXABETQlUiRPxL3/R4i51IU487qwWeQG9PZA5E0KAN+Slz3xh/y3hISEhISfhh+qjHtlQLZFDI0IewPqMFJKWpK0hnZ0hm+MYUMOBPVPa+WN4VsM3KJbpsgsnZklU+L7Y7scRAhtyGXPb4Qqfg5aO54Z1THTZy/LPZdjNT/kYiU28fxs8gl1xUiNb8VUuAbxrFZo5VvwN2HoqQ3Sjp09xTTbrhIMe2EhLpHIu0fh97Iuq5BZHcAUs9bRP14vr0xBLgpYu7lKFltn/gum0LWFinYNVFCXTUi/s1QotmJsX9G1K3IdV+rQSVb1Sg+vl9csxIp51KkkCcjRd2S3Hzt7JwHAPfFeTdGC4ZOKJN8ISL91vGzEC04huW/kJQ9npCQkFB/SKT9I+DuT6IuYwCY2ZmI6J4zsxtRDLuDmd2Gkst2RY1SjkA1zpPi0LEoZn0tIskOyGJ3RLKzUYb5eKRwC4EX0DzrAmRjt0ANVBYhVb4YEbHFebrGfo3i/IZU97/iHI5K0uYhxZ0l04HmmN+NWqFeH9uWoAz3hISEhIT/En7ypG1mpwNDs37e/8N7GIV6hm+KCPE1lD3eHTjC3UeaWT9UlrYRevdvItULspRPQMr4RaSWn0c2+r4omewrpHT/gzLPv4jrbIbquvsg0u2OCDkb2emopOsqROz7AsMR+U9CJN8O9VV/AmWuv0du3OfB8XszFBt/BGjr7kup7NpIJV8NG8llSUioe6x02eMxWMPcveZbd+brDmT9s+5oP/LaRe5e9R33HQxs4O6XxD0MBRq7++/i+4tQMtcZ7t41tr0OTHT3/eP3K5CSviH2/QCp266IcLsiZbs+6nR2Jeo33iVuoyuqqT4xtn2FRnTeieLZC+K+9kEkvR85xV2ElPgbSEGXoqzwIrRg+DSusRZaSHyOYuCOysImufsvVvSO0sCQhISEhO+PlT57PBusETbyO8AFZjbKzMaa2YWxT1Mze9TMxpjZO2Z2oJmdiuKyz0b9MmZ2vZn9f3vnHiNlecXh5yzLJbooohEJ0pYqRsELiFLwVjFB8dIS1BJptag11Rasmnot1tJqa41Vq63VYkS8oMZYTYkiakm91GqQIggoxlVBRRQiiIACAqd//M6w0+0OVrsze5nzJJOdnW++mffs921+7znvec+ZbWYLC+fG64vNbJd4fpCZPWVmNWY20czuNrPngLtjLM+a2Zx4HBLnHBnnPGhmi9C2rmuKxjAeNRJpzDoz6xCNS/YFhpvZBXHsO6jwSQ3RScvd+6H16nrkiR+J1p8nIG+4EBKvQSJ+MvKyR6C16JNRyBvkKQ+L8Y1Fa9HrkACDRH1WfN/XUbb7JBr2Y3dEon4c8rQ3oonBcOC06IDW+Fr+MP7+s1esWNHEnyNJkiT5srSm8HhfJCw7IOEZjERnmpkdgQTrPXc/HtRUw91XxzrysCJPe4K7rzSzDsBMM9vf3V+OY71DnOtR/e2fox7UOwE3uPsEU7/sXVH29UA0ITgeCWQ/1CVrOgoTP+juJ5nZb4DngRFm9hZqZjIKFXn5BapE1hWJcG/gPjM7HInpGORJLwN6RYexGiTmq1BIeuf4uQ4VX3kWedx7hC2XoQzwS+L7lqIJgsfnXoCS0vZHHvWa+Hs8G+efge6Fi5CHXRuPOhTuH45C8RtRBvtnaO29GwrfN0mGx6ubDI8nSfPTKjztYEn0nj46Hi8hkdsbCfp85KVeU9RUoylGm9mcOL8/Etpi+qIM6XokPLeh6mQHxOSgY7xnIPB6/P5dVOxkPnBWhO7fRkJcoBa4AoWeJ6M9zIPRevEgJJSDkQA/gwqbrEQJXpPRvuuuqGzoEBTeXhOPJWhb2SEo4eybSIynx2dsQevUN8bnd0Ih7+2AE4CZSHxXxVh7IUEHhdJfi+drUTGYWWjytF28rw558nVoctAzXi9kv28lK6IlSZKUj9bkaRcadBhwtbv/ufEbzOxAFKq9ysxmuvuvGh3vgxKtDnb3VRGS7hKHN6FJyhIk2N3R5KAL2ib1KRLr/ZBHWUND9vVewB+Qt98hqpYNiu88ND5/JkowW4VCzW+h0PScOPYxEsvOaAngKyhcfQ7ythchL3YxShC7C/WsrjOz1TQ0EHk7xjMBTQJOijF+hgT6CjTZOIgGwb0cOB+te7+BJgJr3f0EM/sEVTrbgLz7OrR1rNDlazBKeuuJJgLd0H1jSMgnNboGueUrSZKkTLQm0S7wOCpAMtXd15pZLyRItcBKd7/HzD5C25BAwtIVhWl3QOK/2sx6AMcCT8X7FqOQ8TokdKASoj2RgP0OwMxuR8K7AQnSTfGeH6Hw86B4viMNtbk/Q5OJe9z9TDNbi/ZvPwFMQW09e6BM709RVbNaJMC/Rxnl+yBB7Iz2Po9GE4RXw65p8f0L0GSiG3Bm2O1xfBSaDMxGofnhSNxPQgllHyJRvwbY0cxeoKF86fNoUjAauB1NKN5Dk481SPDXoYjDmait55NNXsEgw+PVTU7YkqT5aXWi7e5PmNk+wPNKJGct2tu8J3CtmW1BIlkoNDIJmGFm77n7sGhVuQhtZXqu6KN/ieqB90TbmlYi8ZkJUDQ5KHQJq0Ge9xYkghvjc+qAP9KQSb0Gee5HAYeZ2YVIBL+GmnacGI8RyIPeHon3YLS+fQPyWmchT3xXJOKr0KTgHVR05XgUuu4Qj+vj+wuVy85B4fvd4vxT4/zt0YQAFDa/Nr6jY3yuI8+9L0qG8/j7DY3xbEFNRQbF325qXJMm753GFdGaek+SJEny5Wh1W77KSbSyfCQ6cmFm59HgsRcmB5vRPuQ6FGL+GzDP3cfG+fVx7BS01Wx8hOEPR952LRLPXZFnOwkl2G1Ee7n3RRXRHgEOQ2LZGYnut1CIvR4lup2NJhB3oDXsOWidfnck1LXIwz46wugz0Hr3unj8A61lXwRchcR5OYo6HOzuncxsc9hcWKffI855DE0+uqC95HuiEH/XsGU9Wt/fVkW0bBiSJEnyBWn1W74qhbsvLgh2/H6ju+8Xj6Hu/kbj96CqZvML56Me0ue6+5QQ7AHufjrq9HUu8rivBnq7ZkRzUZh5HMrS/hR5w6cj8d8Yj7+ikPNZaAIxJr7/DhS27obC3XuhkPZ6Gjz9pZF13i3euwhNDI5CAj8aefXTUTh/I1pCKPTrfgUJ+ZvontgRCfmK+J4ChazzTjT0+E6SJEkqRKsLj7cBfgLcHDXEa1Em+DnAlWh9+jokfONj+9c+SCQnIsHujTzwK9H2rPVIAAsThe+hkP1EtEd6IJoo9Efr2V2QN3woEvQxaA91TXzG62gd+hvIM+4Qn/8O2vM9NM7rHs8/is9ejUL0heS1zsjz3hRjuQsVZlmMxL0/Ctn/h6ddHB43szVm9hrVyy5sY0tcFZD2V6/91Ww7/P/2f7XUgaoKj1cCM+uPMr2HuvuHZtYdrT8/gtbGZ6BtWRvQ2vZpSKh/jMT4JZTVfiES9vXIszUk2gtRUZbT0V7zg4B/uvvFZvYQcC+aHFyCir3MQxOJY9Aa9dTYj34EsdUtxjIKhdYvQqH4nkjIH0ftR/dG+793QJODW1HiXclSpmY2u1SIpxpI+9P+arW/mm2H8tpfVeHxSuDuC4FfA0+b2Twk2IVji919b5SEtgCtE88Gerr7QCSgneK13XSKb4cS6Ja5+wGo8tpqJOh7AZPd/eJGwzgVJY5NQyHxWWg72a3AKDObC4xw9yHI265B3vEAFAUYgtbfT0Ve/0coo/xdJNpPAY9+Xu3xJEmSpHnJ8HgZcPc7kdCWOv4WyibfipntjDx00HrykcDmeP1RYPeo8tYBJZkdEo+zzexOlPg2DHnaZ6BEthPdvT4S5Z529xtRJnjxWOZGMZoL3X121FEHFZRZ6e7rC1vs3P0IM5sPfDtsSJIkSSpIinYrwd0/RJ7uVszsXtTp6zHUvnMeWnO+2N3fN7OHUbLZIsIzR1u6Lkfr6A+Z9s29iLzsL8J+/A9b7D7nMyZ9zvH2Ttpf3VSz/dVsO5TR/lzTbsOY2RnAeY1efs7dx7XEeJIkSZLykqKdJEmSJG2EDI9XERFO79Po5Uvc/fGWGE+SJEnyxcjs8SrC3Ue5+4BGj7IItpmNiB7p9WZ2aTm+ozUR/drnm9lcM5sdr3U3syfN7PX4uVNLj7O5MLPJZrbczBYUvdakvSZuinvh5Wj806YpYf9EM1sa98BcMzuu6NhlYf9rZnZMy4y6+TCz3mb2dzN7xcwWRnXJqrgHtmF7Ra5/inbS7ESW+82oYUs/YIyZNW6R2h4ZFhOhwv7MS4GZ7t4XbZ1rT5OXKTTaAUFpe49F5Xr7ohK3t1RojOVkCv9tP8ANRRPi6QBx75+CChKNAP4U/yNtmU3AT929H9oiOi7srIZ7oJTtUIHrn6KdlIPBQL27v+nuG4H7gZEtPKaWYCQNW//uRA1k2gXu/gxqulNMKXtHAne5eAHoZmY9KzPS8lDC/lKMBO539w2xVbIe/Y+0Wdx9mbvPiedrUFXGXlTBPbAN20vRrNc/RTspB71Q2dQC77Ltm7o94MATZvavaJoC0MPdl8Xz91F71vZMKXur6X4YH+HfyUXLIe3aflMjpYGowmNV3QONbIcKXP8U7SRpHg5z9wNRGHBclIndSjSPqZqtGtVmb3ALKkU8AJUCvq5lh1N+zKwO+Atwvrt/XHysvd8DTdhekeufop2Ug6WoMUqB3eO1dou7L42fy1Flu8HAB4UQYPxc3nIjrAil7K2K+8HdP3D3ze6+BbiNhhBou7TfzDoi0Zrq7g/Fy1VxDzRle6Wuf4p2Ug5eBPqaWR8z64SSMKa18JjKhpltb2ZdC89Rw5cFyOax8baxqP1qe6aUvdOA70cG8RBgdVEItd3QaI12FLoHQPafYmadzawPSsaaVenxNSdRafF24FV3v77oULu/B0rZXqnrn/u0k2bH3TeZ2XjUIawDamqysIWHVU56AA/rf5la4F53n2FmLwIPmNkPgCWor3m7wMzuQ/XxdzGzd1Gb2d/StL3TgeNQAs4nqDZ+m6aE/Uea2QAUEl4MnA1qImRmD6C+9ZuAce6+uSXG3YwcijoUzjc1IAL4GdVxD5SyfUwlrn9WREuSJEmSNkKGx5MkSZKkjZCinSRJkiRthBTtJEmSJGkjpGgnSZIkSRshRTtJkiRJ2ggp2kmSJEnSRkjRTpIkSZI2wr8BCkI7UpoTvy4AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reset back to original format\n",
        "clinc.reset_format()"
      ],
      "metadata": {
        "id": "nogbgDni5pew"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Updating Benchmark statistics"
      ],
      "metadata": {
        "id": "5lrgcTOpDmNN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since the dataset is balanced across the intent\n",
        "classes, we’ll use accuracy as our metric which we can load from Datasets.\n",
        "\n",
        "let’s implement the compute_accuracy function:"
      ],
      "metadata": {
        "id": "MpBAkN4mDyoR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score = load_metric(\"accuracy\")\n",
        "accuracy_score"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 358,
          "referenced_widgets": [
            "5754bcfbe30b451d9cdf6f372de8869d",
            "796b4d0b49e54e918f84676fcc20b269",
            "e6cb87a2c7f94b3b90af60782ffb2884",
            "ecfdc154d0fa4dc78277333772ae3aaf",
            "8202765e66804b718ba1fd0b3e2f2d5f",
            "d61b93f44e6a4e64bd390af5db752166",
            "e84277503c4140c7a65f89060a5b0cad",
            "ba90ed8145284cbcb481b21e030e728e",
            "6abdca4a9beb44a4886115829ab13e8d",
            "6fc50e8384d144b487aa0c5b2630aca4",
            "adc2c777d2584a758db39a06533cdfdb"
          ]
        },
        "id": "3cNor6J857nf",
        "outputId": "6095bb3d-f6a3-4454-aa9b-c5cca0332495"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5754bcfbe30b451d9cdf6f372de8869d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/1.42k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Metric(name: \"accuracy\", features: {'predictions': Value(dtype='int32', id=None), 'references': Value(dtype='int32', id=None)}, usage: \"\"\"\n",
              "Args:\n",
              "    predictions: Predicted labels, as returned by a model.\n",
              "    references: Ground truth labels.\n",
              "    normalize: If False, return the number of correctly classified samples.\n",
              "        Otherwise, return the fraction of correctly classified samples.\n",
              "    sample_weight: Sample weights.\n",
              "Returns:\n",
              "    accuracy: Accuracy score.\n",
              "Examples:\n",
              "\n",
              "    >>> accuracy_metric = datasets.load_metric(\"accuracy\")\n",
              "    >>> results = accuracy_metric.compute(references=[0, 1], predictions=[0, 1])\n",
              "    >>> print(results)\n",
              "    {'accuracy': 1.0}\n",
              "\"\"\", stored examples: 0)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The metric’s description tells us that we need to provide the predictions and references (i.e. the ground truth labels) as integers, so we can use the pipeline to extract the predictions from the\n",
        "text field and then use the `ClassLabel.str2int` function to map the prediction to its corresponding ID.\n",
        "\n",
        "So we need to collect all the predictions and labels in lists before\n",
        "returning the accuracy on the dataset. \n",
        "\n",
        "Let’s also add it to our PerformanceBenchmark class:"
      ],
      "metadata": {
        "id": "0ifeF1Ip6iyX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_accuracy(self):\n",
        "  preds, labels = [], []\n",
        "  for example in self.dataset:\n",
        "    pred = self.pipeline(example[\"text\"])[0][\"label\"]\n",
        "    label = example[\"intent\"]\n",
        "    preds.append(intents.str2int(pred))\n",
        "    labels.append(label)\n",
        "  accuracy = accuracy_score.compute(predictions=preds, references=labels)\n",
        "  print(f\"Accuracy on test set - {accuracy['accuracy']:.3f}\")\n",
        "  return accuracy\n",
        "\n",
        "# now update compute_accuracy method of PerformanceBenchmark class\n",
        "PerformanceBenchmark.compute_accuracy = compute_accuracy"
      ],
      "metadata": {
        "id": "orlz3RxM6vNL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, let’s compute the size of our model by using the `torch.save` function from PyTorch to serialize the model to disk.In PyTorch,\n",
        "the recommended way to save a model is by using its `state_dict`, which is a Python dictionary that maps each layer in a model to its learnable parameters (i.e. weights and biases).\n",
        "\n",
        "Let’s see what is stored in the `state_dict` of our baseline model:"
      ],
      "metadata": {
        "id": "omnODJah9Zfb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "list(bert_pipeline.model.state_dict().items())[42]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6tJJOTl9quL",
        "outputId": "56de43d4-ff10-4a17-ea65-65010ba43fed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('bert.encoder.layer.2.attention.self.value.weight',\n",
              " tensor([[-1.0526e-02, -3.2215e-02,  2.2097e-02,  ..., -6.0953e-03,\n",
              "           4.6521e-03,  2.9844e-02],\n",
              "         [-1.4964e-02, -1.0915e-02,  5.2396e-04,  ...,  3.2047e-05,\n",
              "          -2.6890e-02, -2.1943e-02],\n",
              "         [-2.9640e-02, -3.7842e-03, -1.2582e-02,  ..., -1.0917e-02,\n",
              "           3.1152e-02, -9.7786e-03],\n",
              "         ...,\n",
              "         [-1.5116e-02, -3.3226e-02,  4.2063e-02,  ..., -5.2652e-03,\n",
              "           1.1093e-02,  2.9703e-03],\n",
              "         [-3.6809e-02,  5.6848e-02, -2.6544e-02,  ..., -4.0114e-02,\n",
              "           6.7487e-03,  1.0511e-03],\n",
              "         [-2.4961e-02,  1.4747e-03, -5.4271e-02,  ...,  2.0004e-02,\n",
              "           2.3981e-02, -4.2880e-02]]))"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can clearly see that each key-value pair corresponds to a specific layer and tensor in BERT.\n",
        "\n",
        "We can then use the Path.stat function from Python’s `pathlib` module to get information about the underlying files. In particular `Path(PATH).stat().st_size` will give us the model size in bytes, so let’s put this all together in the `compute_size` function and add it to PerformanceBenchmark:"
      ],
      "metadata": {
        "id": "sRzVsR2k-BxR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_size(self):\n",
        "  state_dict = self.pipeline.model.state_dict()\n",
        "  tmp_path = Path(\"model.pt\")\n",
        "  torch.save(state_dict, tmp_path)\n",
        "  # Calculate size in megabytes\n",
        "  size_mb = Path(tmp_path).stat().st_size / (1024 * 1024)\n",
        "  # Delete temporary file\n",
        "  tmp_path.unlink()\n",
        "  print(f\"Model size (MB) - {size_mb:.2f}\")\n",
        "  return {\"size_mb\": size_mb}\n",
        "\n",
        "# now update compute_size method of PerformanceBenchmark class\n",
        "PerformanceBenchmark.compute_size = compute_size"
      ],
      "metadata": {
        "id": "Shhg-0oO-Qh1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally let’s implement the `time_pipeline` function so that we can time the median latency\n",
        "per query. For this application, latency refers to the time it takes to feed a text query to the\n",
        "pipeline and return the predicted intent from the model.\n",
        "\n",
        "Under the hood, the pipeline also\n",
        "tokenizes the text but this is around 1,000 times faster than generating the predictions and thus\n",
        "adds a negligible contribution to the overall latency.\n",
        "\n",
        "A simple way to measure the time of a\n",
        "code snippet is to use the `perf_counter` function from Python’s `time` module. This function has a better time resolution than the `time.time` function and so is well suited for getting precise results.\n",
        "\n",
        "We can use `perf_counter` to time our `pipeline` by passing our test query and calculating the\n",
        "time difference in milliseconds between the start and end:"
      ],
      "metadata": {
        "id": "wZF_qb7NAEXS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for _ in range(3):\n",
        "  start_time = perf_counter()\n",
        "  _ = bert_pipeline(query)\n",
        "  latency = perf_counter() - start_time\n",
        "  print(f\"Latency (ms) - {1000 * latency:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3kj_JIxAYDs",
        "outputId": "8f4bd8d6-8e54-4044-fb72-a86e0ee81486"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Latency (ms) - 156.390\n",
            "Latency (ms) - 149.952\n",
            "Latency (ms) - 138.118\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So instead,\n",
        "we’ll collect the latencies over many runs and then use the resulting distribution to calculate the\n",
        "mean and standard deviation, which will give us an idea about the spread in values. \n",
        "\n",
        "The following code does what we need and includes a phase to warm-up the CPU before performing the actual timed run:"
      ],
      "metadata": {
        "id": "ZXrtyG41CIcI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def time_pipeline(self, query=\"What is the pin number for my account?\"):\n",
        "  latencies = []\n",
        "  # Warmup\n",
        "  for _ in range(10):\n",
        "    _ = self.pipeline(query)\n",
        "  # Timed run\n",
        "  for _ in range(100):\n",
        "    start_time = perf_counter()\n",
        "    _ = bert_pipeline(query)\n",
        "    latency = perf_counter() - start_time\n",
        "    latencies.append(latency)\n",
        "  # Compute run statistics\n",
        "  time_avg_ms = 1000 * np.mean(latencies)\n",
        "  time_std_ms = 1000 * np.std(latencies)\n",
        "  print(f\"Average latency (ms) - {time_avg_ms:.2f} +\\- {time_std_ms:.2f}\")\n",
        "  return {\"time_avg_ms\": time_avg_ms, \"time_std_ms\": time_std_ms}\n",
        "\n",
        "# now update time_pipeline method of PerformanceBenchmark class\n",
        "PerformanceBenchmark.time_pipeline = time_pipeline"
      ],
      "metadata": {
        "id": "knmN6SIHCL2Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Benchmarking Our Baseline Model"
      ],
      "metadata": {
        "id": "YmmzDTmVDada"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that our `PerformanceBenchmark` is complete, let’s give it a spin! For the baseline\n",
        "model we just need to pass the pipeline and dataset we wish to perform the benchmark on, and\n",
        "we’ll collect the results in the `perf_metrics` dictionary to keep track of each model’s\n",
        "performance:"
      ],
      "metadata": {
        "id": "83rwOZcdDbMO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pb = PerformanceBenchmark(bert_pipeline, clinc[\"test\"])\n",
        "perf_metrics = pb.run_benchmark()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMRdYK5sEehl",
        "outputId": "7431dc82-dd54-4583-d43f-c224eb789e6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model size (MB) - 418.16\n",
            "Average latency (ms) - 121.31 +\\- 56.99\n",
            "Accuracy on test set - 0.867\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once we have determined the best performing model we can then explore different backends to reduce the absolute latency if needed.\n",
        "\n",
        "Now that we have a reference point, let’s look at our first compression technique: **knowledge distillation**."
      ],
      "metadata": {
        "id": "UGxlw8_fE8Ou"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Knowledge Distillation for Smaller Models "
      ],
      "metadata": {
        "id": "eft__0YfFDQu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Knowledge distillation is a general-purpose method for training a smaller student model to mimic the behavior of a slower, larger, but better performing teacher."
      ],
      "metadata": {
        "id": "nAA500rZ_mXn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Knowledge Distillation for Fine-tuning"
      ],
      "metadata": {
        "id": "gNZunsXj_mvu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For supervised tasks like fine-tuning, the main idea is to augment the ground truth labels with a distribution of `soft probabilities` from the teacher which provide complementary information for the student to learn from. \n",
        "\n",
        "For example, if our BERT-base classifier assigns high\n",
        "probabilities to multiple intents, then this could be a sign that these intents lie close to each\n",
        "other in the feature space. By training the student to mimic these probabilities, the goal is to\n",
        "distill some of this `dark knowledge` that the teacher has learnt; knowledge which is not available from the labels alone.\n",
        "\n",
        "Mathematically, the way this works is as follows. Suppose we feed an input sequence x to the teacher to generate a vector of logits $z(x) = [z_1 (x), ..., z_N (x)]$. We can convert these logits into probabilities by applying a softmax function:\n",
        "\n",
        "$$\n",
        "\\frac{exp(z_i(x))}{\\sum_j{exp(z_i(x))}}\n",
        "$$\n",
        "\n",
        "but this isn’t quite what we want because in many cases the teacher will assign a high\n",
        "probability to one class, with all other class probabilities close to zero.\n",
        "\n",
        "When that happens, the\n",
        "teacher doesn’t provide much additional information beyond the ground truth labels, so instead\n",
        "we `soften` the probabilities by scaling the logits with a positive temperature hyperparameter\n",
        "$T$ before applying the softmax:\n",
        "\n",
        "$$\n",
        "p_i(x) = \\frac{exp(z_i(x)/T)}{\\sum_j{exp(z_i(x)/T)}}\n",
        "$$\n",
        "\n",
        "As shown, higher values of $T$ produce a softer probability distribution over the classes and reveal much more information about the decision boundary that the teacher has learned for each training example. When $T = 1$ we recover the original softmax distribution.\n",
        "\n",
        "<img src='https://github.com/rahiakela/transformers-research-and-practice/blob/main/natural-language-processing-with-transformers/05-making-transformers-efficient-in-production/images/2.png?raw=1' width='600'/>\n",
        "\n",
        "Since the student also produces softened probabilities $q_i(x)$ of its own we can use the Kullback-Leibler (KL) divergence:\n",
        "\n",
        "$$\n",
        "D_{KL}(p, q) = \\sum_i p_i(x)log\\frac{p_i(x)}{q_i(x)}\n",
        "$$\n",
        "\n",
        "to measure the difference between the two probability distributions and thereby define a knowledge distillation loss:\n",
        "\n",
        "$$\n",
        "L_{KD} = T^2 D_{KL} = T^2 \\sum_i p_i(x)log\\frac{p_i(x)}{q_i(x)}\n",
        "$$\n",
        "\n",
        "where $T^2$ is a normalization factor to account for the fact that the magnitude of the gradients produced by soft labels scales as $1/T^2$. \n",
        "\n",
        "For classification tasks, the student loss is then a weighted average of the distillation loss with the usual cross-entropy  $loss_{CE}$ of the ground truth labels:\n",
        "\n",
        "$$\n",
        "L_{student} = \\alpha L_{CE} + (1 - \\alpha) L_{KD}\n",
        "$$\n",
        "\n",
        "where $\\alpha$ is a hyperparameter that controls the relative strength of each loss.\n",
        "\n",
        "A diagram of the whole process is shown below and the temperature is set to 1 at inference time to recover the standard softmax probabilities.\n",
        "\n",
        "\n",
        "<img src='https://github.com/rahiakela/transformers-research-and-practice/blob/main/natural-language-processing-with-transformers/05-making-transformers-efficient-in-production/images/3.png?raw=1' width='600'/>\n"
      ],
      "metadata": {
        "id": "3B9QAGIDFIHU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Knowledge Distillation for Pretraining"
      ],
      "metadata": {
        "id": "yZiJmuOy_Vas"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Knowledge distillation can also be used during pretraining to create a general-purpose student\n",
        "that can be subsequently fine-tuned on downstream tasks. In this case, the teacher is a\n",
        "pretrained language model like BERT which transfers its knowledge about masked-languagemodeling\n",
        "to the student. \n",
        "\n",
        "For example, in the DistilBERT paper, the masked-languagemodeling\n",
        "loss $L_{mlm}$ is augmented with a term from knowledge distillation and a cosine\n",
        "embedding loss $L_{cos} = 1− cos (h_s, h_t)$ to align the directions of the hidden state vectors between the teacher and student:\n",
        "\n",
        "$$L_{DistilBERT} = \\alpha L_{mlm} + \\beta L_{KD} + \\gamma L_{cos}$$\n",
        "\n",
        "Since we already have a fine-tuned BERT-base model, let’s see how we can use knowledge distillation to fine-tune a smaller and faster model. To do that we’ll need a way to augment the cross-entropy loss with a $L_{KD}$ term; fortunately we can do this by creating our own trainer!"
      ],
      "metadata": {
        "id": "u_NZvi7g_1Qi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Knowledge Distillation Trainer"
      ],
      "metadata": {
        "id": "Fp6K2B7nCh2N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To implement knowledge distillation we need to add a few things to the `Trainer` base class:\n",
        "\n",
        "- The new hyperparameters $\\alpha$ and $T$ which control the relative weight of the distillation loss and how much the probability distribution of the labels should be smoothed.\n",
        "- The fine-tuned teacher model, which in our case is `BERT-base`\n",
        "- A new loss function that includes the cross-entropy loss with the knowledge\n",
        "distillation loss.\n",
        "\n",
        "Adding the new hyperparameters is quite simple since we just need to subclass\n",
        "`TrainingArguments` and include them as new attributes:"
      ],
      "metadata": {
        "id": "npBIwXwuCjF-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DistillationTrainingArguments(TrainingArguments):\n",
        "  def __init__(self, *args, alpha=0.5, temperature=2.0, **kwargs):\n",
        "    super().__init__(*args, **kwargs)\n",
        "    self.alpha = alpha\n",
        "    self.temperature = temperature"
      ],
      "metadata": {
        "id": "1kTBUu3UDGMa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the trainer itself, we want a new loss function so the way to implement this is by subclassing `Trainer` and overriding the `compute_loss` function to include the knowledge distillation loss term $L_{KD}$:"
      ],
      "metadata": {
        "id": "60pJYgs6D3g0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DistillationTrainer(Trainer):\n",
        "  def __init__(self, *args, teacher_model=None, **kwargs):\n",
        "    super().__init__(*args, **kwargs)\n",
        "    self.teacher_model = teacher_model\n",
        "\n",
        "  #reference: https://discuss.huggingface.co/t/custom-loss-compute-loss-got-an-unexpected-keyword-argument-return-outputs/4148\n",
        "  def compute_loss(self, model, inputs, return_outputs=False):\n",
        "    outputs_student = model(**inputs)\n",
        "    # Extract cross-entropy loss and logits from student\n",
        "    loss_ce = outputs_student.loss\n",
        "    logits_student = outputs_student.logits\n",
        "    # Extract logits from teacher\n",
        "    with torch.no_grad():\n",
        "      outputs_teacher = self.teacher_model(**inputs)\n",
        "      logits_teacher = outputs_teacher.logits\n",
        "    # Soften probabilities and compute distillation loss\n",
        "    loss_kld = nn.KLDivLoss(reduction=\"batchmean\")\n",
        "    loss_kd = self.args.temperature ** 2 * loss_kld(\n",
        "        F.log_softmax(logits_student / self.args.temperature, dim=-1),\n",
        "        F.softmax(logits_teacher / self.args.temperature, dim=-1)\n",
        "    )\n",
        "    # Return weighted student loss\n",
        "    return (loss_ce, outputs_student) if return_outputs else  self.args.alpha * loss_ce + (1. - self.args.alpha) * loss_kd"
      ],
      "metadata": {
        "id": "Wqs3s63AD_Z7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "help(Trainer.compute_loss)"
      ],
      "metadata": {
        "id": "O57Zu5kdYKbU",
        "outputId": "e9f7d6ec-edac-45c6-9d0d-d38c7ce5752d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on function compute_loss in module transformers.trainer:\n",
            "\n",
            "compute_loss(self, model, inputs, return_outputs=False)\n",
            "    How the loss is computed by Trainer. By default, all models return the loss in the first element.\n",
            "    \n",
            "    Subclass and override for custom behavior.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "When we instantiate `DistillationTrainer`, we pass a `teacher_model` argument with a teacher that has already been fine-tuned on our task. \n",
        "\n",
        "Next, in the `compute_loss` function we extract the logits from the student and teacher, scale them\n",
        "by the temperature and then normalize them with a softmax before passing them to PyTorch’s `nn.KLDivLoss` function for computing the KL divergence. \n",
        "Since `nn.KLDivLoss` expects the inputs in the form of `log-probabilities`, we’ve used the `F.log_softmax` function to\n",
        "normalize the student’s logits, while the teacher’s logits are converted to probabilities with a standard softmax. The `reduction=batchmean` argument in `nn.KLDivLoss` specifies that we average the losses over the batch dimension."
      ],
      "metadata": {
        "id": "BPtnIJhBIv-J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Student Initialization"
      ],
      "metadata": {
        "id": "6knZ667PJX4e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We should pick smaller model for the student to reduce the latency and memory footprint, and a good rule of thumb from the literature is that knowledge distillation works best when the teacher and student are of the same model type.\n",
        "\n",
        "One possible reason for this is that different model types, say BERT and\n",
        "RoBERTa, can have different output embedding spaces which hinders the ability of the student to mimic the teacher.\n",
        "\n",
        "In our case study, the teacher is BERT-base so DistilBERT is natural\n",
        "candidate to intitialize the student since it has 40% less parameters and has been shown to achieve strong results on downstream tasks.\n",
        "\n",
        "First we’ll need to tokenize and encode our queries, so let’s instantiate the tokenizer from DistilBERT and create a simple function to take care of the preprocessing:"
      ],
      "metadata": {
        "id": "PH0nMZIJJYyr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "student_ckpt = \"distilbert-base-uncased\"\n",
        "student_tokenizer = AutoTokenizer.from_pretrained(student_ckpt)"
      ],
      "metadata": {
        "id": "ax_JZOv2K0vc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_text(batch, tokenizer):\n",
        "  return tokenizer(batch[\"text\"], truncation=True)"
      ],
      "metadata": {
        "id": "gCFG9TGyLIEs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# removed the text column since we no longer need it\n",
        "clinc_enc = clinc.map(tokenize_text, batched=True, remove_columns=[\"text\"], fn_kwargs={\"tokenizer\": student_tokenizer})\n",
        "# renamed the intent column to labels so it can be automatically detected by the trainer\n",
        "clinc_enc.rename_column_(\"intent\", \"labels\")"
      ],
      "metadata": {
        "id": "0lqqjIXwLVm-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clinc_enc[\"train\"][0]"
      ],
      "metadata": {
        "id": "4N1gOFu3MMCO",
        "outputId": "3bad13c4-480c-49da-8beb-0c99193f4120",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              " 'input_ids': [101,\n",
              "  2054,\n",
              "  3670,\n",
              "  2052,\n",
              "  1045,\n",
              "  2224,\n",
              "  2000,\n",
              "  2360,\n",
              "  1045,\n",
              "  2293,\n",
              "  2017,\n",
              "  2065,\n",
              "  1045,\n",
              "  2020,\n",
              "  2019,\n",
              "  3059,\n",
              "  102],\n",
              " 'labels': 61}"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that our texts are processed, the next thing to do is instantiate\n",
        "DistilBERT for fine-tuning. Since we will be doing multiple runs with the trainer, we’ll use a function to initialize the model with each new run:"
      ],
      "metadata": {
        "id": "gEyc7WqqMdO_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_labels = intents.num_classes\n",
        "id2label = bert_model.config.id2label\n",
        "label2id = bert_model.config.label2id\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "rAihzuJYMes1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "student_config = (AutoConfig.from_pretrained(student_ckpt, num_labels=num_labels, id2label=id2label, label2id=label2id))"
      ],
      "metadata": {
        "id": "wZDE5_CXNEki"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def student_init():\n",
        "  return (AutoModelForSequenceClassification.from_pretrained(student_ckpt, config=student_config).to(device))"
      ],
      "metadata": {
        "id": "CWMVApsPNci3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we need to define the metrics to track during training. As we did in the\n",
        "performance benchmark, we’ll use accuracy as the main metric so we can reuse our\n",
        "`accuracy_score` function in the `compute_metrics` function that we’ll include in the trainer:"
      ],
      "metadata": {
        "id": "sDfs6hUbN55r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(pred):\n",
        "  predictions, labels = pred\n",
        "  # find the most confident class prediction\n",
        "  predictions = np.argmax(predictions, axis=1)\n",
        "  # and compare that against the ground truth labels\n",
        "  return accuracy_score.compute(predictions=predictions, references=labels)"
      ],
      "metadata": {
        "id": "BJkOaxRFN99g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we just need to define the training arguments. To warm-up, we’ll set $\\alpha = 1$ to see how well DistilBERT performs without any signal from the teacher:"
      ],
      "metadata": {
        "id": "7HuGGqt_P_MI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 48\n",
        "\n",
        "student_training_args = DistillationTrainingArguments(\n",
        "    output_dir=\"checkpoints\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    num_train_epochs=5,\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    alpha=1,\n",
        "    weight_decay=0.01\n",
        ")"
      ],
      "metadata": {
        "id": "2cuML55IQHLn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we load the teacher model, instantiate the trainer and start fine-tuning:"
      ],
      "metadata": {
        "id": "1Dz0_3o9Qqjc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "teacher_checkpoint = \"transformersbook/bert-base-uncased-finetuned-clinc\"\n",
        "teacher_model = (AutoModelForSequenceClassification.from_pretrained(teacher_checkpoint, num_labels=num_labels).to(device))"
      ],
      "metadata": {
        "id": "naP58JFbQrDO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "distil_trainer = DistillationTrainer(model_init=student_init, \n",
        "                                     teacher_model=teacher_model,\n",
        "                                     args=student_training_args,\n",
        "                                     train_dataset=clinc_enc[\"train\"],\n",
        "                                     eval_dataset=clinc_enc[\"validation\"],\n",
        "                                     compute_metrics=compute_metrics,\n",
        "                                     tokenizer=student_tokenizer)"
      ],
      "metadata": {
        "id": "2VYL8HDKvYMr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# start fine-tuning\n",
        "distil_trainer.train();"
      ],
      "metadata": {
        "id": "n0piU3z7RPW-",
        "outputId": "b79940b6-56a5-4c9b-cebd-eecb5e6be1bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight']\n",
            "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.weight', 'classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight']\n",
            "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.bias', 'classifier.weight', 'classifier.bias', 'pre_classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "***** Running training *****\n",
            "  Num examples = 15250\n",
            "  Num Epochs = 5\n",
            "  Instantaneous batch size per device = 48\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 48\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 1590\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1590' max='1590' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1590/1590 13:20, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>3.307489</td>\n",
              "      <td>0.741613</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>3.806900</td>\n",
              "      <td>1.879182</td>\n",
              "      <td>0.838387</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>3.806900</td>\n",
              "      <td>1.151380</td>\n",
              "      <td>0.893871</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.684800</td>\n",
              "      <td>0.856650</td>\n",
              "      <td>0.907742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.890200</td>\n",
              "      <td>0.773014</td>\n",
              "      <td>0.911613</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "Saving model checkpoint to checkpoints/checkpoint-500\n",
            "Configuration saved in checkpoints/checkpoint-500/config.json\n",
            "Model weights saved in checkpoints/checkpoint-500/pytorch_model.bin\n",
            "tokenizer config file saved in checkpoints/checkpoint-500/tokenizer_config.json\n",
            "Special tokens file saved in checkpoints/checkpoint-500/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "Saving model checkpoint to checkpoints/checkpoint-1000\n",
            "Configuration saved in checkpoints/checkpoint-1000/config.json\n",
            "Model weights saved in checkpoints/checkpoint-1000/pytorch_model.bin\n",
            "tokenizer config file saved in checkpoints/checkpoint-1000/tokenizer_config.json\n",
            "Special tokens file saved in checkpoints/checkpoint-1000/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "Saving model checkpoint to checkpoints/checkpoint-1500\n",
            "Configuration saved in checkpoints/checkpoint-1500/config.json\n",
            "Model weights saved in checkpoints/checkpoint-1500/pytorch_model.bin\n",
            "tokenizer config file saved in checkpoints/checkpoint-1500/tokenizer_config.json\n",
            "Special tokens file saved in checkpoints/checkpoint-1500/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The accuracy on the validation set looks quite good compared to the 94% that BERT-base teacher achieves.\n",
        "\n",
        "Now that we’ve fine-tuned `DistilBERT`, we can wrap it in a\n",
        "`TextClassificationPipeline` and run it through our performance benchmark:"
      ],
      "metadata": {
        "id": "4HosG-frbp81"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "distil_bert_pipeline = TextClassificationPipeline(model=distil_trainer.model.to(\"cpu\"), tokenizer=distil_trainer.tokenizer)\n",
        "\n",
        "optim_type = \"DistilBERT\"\n",
        "pb = PerformanceBenchmark(distil_bert_pipeline, clinc[\"test\"], optim_type=optim_type)\n",
        "perf_metrics.update(pb.run_benchmark())"
      ],
      "metadata": {
        "id": "cGli0gNkb60u",
        "outputId": "3d82991e-17da-41b0-8d5f-d7fb795fba44",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model size (MB) - 255.89\n",
            "Average latency (ms) - 79.01 +\\- 3.96\n",
            "Accuracy on test set - 0.860\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To compare these results against our baseline, let’s create a scatter plot of the accuracy against the latency, with the radius of each point corresponding to the size of the model."
      ],
      "metadata": {
        "id": "KwViR6mmc3Aa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "perf_metrics"
      ],
      "metadata": {
        "id": "EbF0XPQSfqIo",
        "outputId": "d1d2b9bb-27b0-48ae-e6c7-68e3bae3b3fe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'BERT baseline': {'accuracy': 0.8672727272727273,\n",
              "  'size_mb': 418.162091255188,\n",
              "  'time_avg_ms': 81.88562939999741,\n",
              "  'time_std_ms': 4.060993653998385},\n",
              " 'DistilBERT': {'accuracy': 0.8598181818181818,\n",
              "  'size_mb': 255.8870096206665,\n",
              "  'time_avg_ms': 79.01073841999278,\n",
              "  'time_std_ms': 3.9551259328212667}}"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.DataFrame.from_dict(perf_metrics, orient=\"index\")\n",
        "print(df.index)"
      ],
      "metadata": {
        "id": "FNEEbYLch3h6",
        "outputId": "7427c761-b7f6-467c-ad95-f736b09c7670",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index(['BERT baseline', 'DistilBERT'], dtype='object')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for idx in df.index:\n",
        "  print(idx)"
      ],
      "metadata": {
        "id": "QqY7yINKh7gd",
        "outputId": "b3e70810-6ecd-4b92-c909-425c06e16170",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERT baseline\n",
            "DistilBERT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plot_metrics(perf_metrics, optim_type)"
      ],
      "metadata": {
        "id": "G6s9nLXrc-Ti",
        "outputId": "180b3c02-9c0a-403d-8070-34464aaedc73",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "From the plot we can see that by using a smaller model we’ve managed to decrease the average latency by almost a factor of two. And all this at the price of just over a 1% reduction in accuracy! \n",
        "\n",
        "Let’s see if we can close that last gap by including the distillation loss the teacher and finding good values for $\\alpha$ and $T$."
      ],
      "metadata": {
        "id": "C9rJ5le4ijzV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Searching Hyperparameters with Optuna"
      ],
      "metadata": {
        "id": "djZ0VsfUitow"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "So what values of $\\alpha$ and $T$ should we pick?\n",
        "\n",
        "We could do a grid search over the 2D parameter space but a much better alternative is to use Optuna, which is an optimization framework\n",
        "designed for just this type of task. Optuna formulates the search problem in terms of an objective function that is optimized through multiple trials.\n",
        "\n",
        "For example, suppose we wished to minimize Rosenbrock’s `banana function`.\n",
        "\n",
        "$$f(x, y)=(1-x)^2 + 100(y-x^2)^2$$\n",
        "\n",
        "which is a famous test case for optimization frameworks.\n",
        "\n",
        "As shown, the function gets its name from the curved contours and has a global minimum at $(x, y) = (1, 1)$. Finding the valley is an easy optimization problem, but converging to the global minimum is not.\n",
        "\n",
        "<img src='https://github.com/rahiakela/transformers-research-and-practice/blob/main/natural-language-processing-with-transformers/05-making-transformers-efficient-in-production/images/4.png?raw=1' width='600'/>\n",
        "\n",
        "In Optuna, we can find the minimum of $f(x, y)$ by defining an `objective` function that returns the value of $f(x, y)$:"
      ],
      "metadata": {
        "id": "K4aVw0lti5GQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def objective(trial):\n",
        "  x = trial.suggest_float(\"x\", -2, 2)\n",
        "  y = trial.suggest_float(\"y\", -2, 2)\n",
        "  return (1 - x) ** 2 + 100 * (y - x ** 2) ** 2"
      ],
      "metadata": {
        "id": "3wjDLnC9qKDH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `trial.suggest_float` object specifies the parameter ranges to sample uniformly from and Optuna also provides `suggest_int` and `suggest_categorical` for integer and categorical parameters respectively. \n",
        "\n",
        "Optuna collects multiple trials as a study so to create one we just pass the `objective` function to `study.optimize` as follows:"
      ],
      "metadata": {
        "id": "5fP9OpDprNu8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "study = optuna.create_study()\n",
        "study.optimize(objective, n_trials=1000)"
      ],
      "metadata": {
        "id": "bv1MOfWtrgTK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once the study is completed, we can then find the best parameters as follows:"
      ],
      "metadata": {
        "id": "x6nCa3hMtiyp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "study.best_params"
      ],
      "metadata": {
        "id": "vnUdqnOitql8",
        "outputId": "89fc031f-7aa1-42c0-ffd6-d971873dce46",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'x': 0.9512870706810229, 'y': 0.9052202864189003}"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see that with 1,000 trials, Optuna has managed to find values for x and y that are reasonably close to the global minimum.\n",
        "\n",
        "To use Optuna in Transformers, we use a similar logic by first defining the hyperparameter space that we wish to optimize over. \n",
        "\n",
        "In addition to $\\alpha$ and $T$, we’ll include the number of training epochs as follows:"
      ],
      "metadata": {
        "id": "pWJ8U18tt29M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def hp_space(trial):\n",
        "  return {\n",
        "      \"num_train_epochs\": trial.suggest_int(\"num_train_epochs\", 5, 10),\n",
        "      \"alpha\": trial.suggest_float(\"alpha\", 0, 1),\n",
        "      \"temperature\": trial.suggest_int(\"temperature\", 2, 20)\n",
        "  }"
      ],
      "metadata": {
        "id": "DfSs7BlcuJ9P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Running the hyperparameter search with the `Trainer` is then quite simple; we just need to specify the number of trials to run and a direction to optimize for. \n",
        "\n",
        "Since we want the best possible accuracy, we pick `direction=\"maximize\"` in the\n",
        "`Trainer.hyperparameter_search` function and pass the hyperparameter search space as follows:"
      ],
      "metadata": {
        "id": "X2RnRgEQu0Ig"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_run = distil_trainer.hyperparameter_search(n_trials=9, direction=\"maximize\", hp_space=hp_space)"
      ],
      "metadata": {
        "id": "TaW2XKIEvAF6",
        "outputId": "35dc3c0a-df01-4f38-8b43-da11223ca3d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[32m[I 2022-01-04 05:44:21,314]\u001b[0m A new study created in memory with name: no-name-d2a99066-d76f-422a-a941-2172904d82d7\u001b[0m\n",
            "Trial:\n",
            "loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_transform.bias']\n",
            "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.weight', 'classifier.bias', 'pre_classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "***** Running training *****\n",
            "  Num examples = 15250\n",
            "  Num Epochs = 6\n",
            "  Instantaneous batch size per device = 48\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 48\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 1908\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1908' max='1908' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1908/1908 15:37, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>3.355246</td>\n",
              "      <td>0.591290</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.329500</td>\n",
              "      <td>2.493410</td>\n",
              "      <td>0.823548</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.329500</td>\n",
              "      <td>2.087803</td>\n",
              "      <td>0.883871</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.121200</td>\n",
              "      <td>1.869722</td>\n",
              "      <td>0.898387</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.081900</td>\n",
              "      <td>1.758626</td>\n",
              "      <td>0.906129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.081900</td>\n",
              "      <td>1.721609</td>\n",
              "      <td>0.909677</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "Saving model checkpoint to checkpoints/run-0/checkpoint-500\n",
            "Configuration saved in checkpoints/run-0/checkpoint-500/config.json\n",
            "Model weights saved in checkpoints/run-0/checkpoint-500/pytorch_model.bin\n",
            "tokenizer config file saved in checkpoints/run-0/checkpoint-500/tokenizer_config.json\n",
            "Special tokens file saved in checkpoints/run-0/checkpoint-500/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "Saving model checkpoint to checkpoints/run-0/checkpoint-1000\n",
            "Configuration saved in checkpoints/run-0/checkpoint-1000/config.json\n",
            "Model weights saved in checkpoints/run-0/checkpoint-1000/pytorch_model.bin\n",
            "tokenizer config file saved in checkpoints/run-0/checkpoint-1000/tokenizer_config.json\n",
            "Special tokens file saved in checkpoints/run-0/checkpoint-1000/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "Saving model checkpoint to checkpoints/run-0/checkpoint-1500\n",
            "Configuration saved in checkpoints/run-0/checkpoint-1500/config.json\n",
            "Model weights saved in checkpoints/run-0/checkpoint-1500/pytorch_model.bin\n",
            "tokenizer config file saved in checkpoints/run-0/checkpoint-1500/tokenizer_config.json\n",
            "Special tokens file saved in checkpoints/run-0/checkpoint-1500/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "\u001b[32m[I 2022-01-04 06:00:00,850]\u001b[0m Trial 0 finished with value: 0.9096774193548387 and parameters: {'num_train_epochs': 6, 'alpha': 0.2854327469522183, 'temperature': 10}. Best is trial 0 with value: 0.9096774193548387.\u001b[0m\n",
            "Trial:\n",
            "loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_transform.bias']\n",
            "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.weight', 'classifier.bias', 'pre_classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "***** Running training *****\n",
            "  Num examples = 15250\n",
            "  Num Epochs = 6\n",
            "  Instantaneous batch size per device = 48\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 48\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 1908\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1908' max='1908' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1908/1908 15:39, Epoch 6/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>3.408157</td>\n",
              "      <td>0.578710</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.313600</td>\n",
              "      <td>2.579459</td>\n",
              "      <td>0.820645</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.313600</td>\n",
              "      <td>2.187435</td>\n",
              "      <td>0.881613</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.116500</td>\n",
              "      <td>1.973373</td>\n",
              "      <td>0.894194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.079700</td>\n",
              "      <td>1.863230</td>\n",
              "      <td>0.903548</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.079700</td>\n",
              "      <td>1.826285</td>\n",
              "      <td>0.907419</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "Saving model checkpoint to checkpoints/run-1/checkpoint-500\n",
            "Configuration saved in checkpoints/run-1/checkpoint-500/config.json\n",
            "Model weights saved in checkpoints/run-1/checkpoint-500/pytorch_model.bin\n",
            "tokenizer config file saved in checkpoints/run-1/checkpoint-500/tokenizer_config.json\n",
            "Special tokens file saved in checkpoints/run-1/checkpoint-500/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "Saving model checkpoint to checkpoints/run-1/checkpoint-1000\n",
            "Configuration saved in checkpoints/run-1/checkpoint-1000/config.json\n",
            "Model weights saved in checkpoints/run-1/checkpoint-1000/pytorch_model.bin\n",
            "tokenizer config file saved in checkpoints/run-1/checkpoint-1000/tokenizer_config.json\n",
            "Special tokens file saved in checkpoints/run-1/checkpoint-1000/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "Saving model checkpoint to checkpoints/run-1/checkpoint-1500\n",
            "Configuration saved in checkpoints/run-1/checkpoint-1500/config.json\n",
            "Model weights saved in checkpoints/run-1/checkpoint-1500/pytorch_model.bin\n",
            "tokenizer config file saved in checkpoints/run-1/checkpoint-1500/tokenizer_config.json\n",
            "Special tokens file saved in checkpoints/run-1/checkpoint-1500/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "\u001b[32m[I 2022-01-04 06:15:42,140]\u001b[0m Trial 1 finished with value: 0.9074193548387097 and parameters: {'num_train_epochs': 6, 'alpha': 0.1385401001076597, 'temperature': 18}. Best is trial 0 with value: 0.9096774193548387.\u001b[0m\n",
            "Trial:\n",
            "loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_transform.bias']\n",
            "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.weight', 'classifier.bias', 'pre_classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "***** Running training *****\n",
            "  Num examples = 15250\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 48\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 48\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 3180\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3180' max='3180' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3180/3180 26:04, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>3.253449</td>\n",
              "      <td>0.619355</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.342000</td>\n",
              "      <td>2.303326</td>\n",
              "      <td>0.840000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.342000</td>\n",
              "      <td>1.838901</td>\n",
              "      <td>0.899677</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.115700</td>\n",
              "      <td>1.581436</td>\n",
              "      <td>0.912258</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.071000</td>\n",
              "      <td>1.421929</td>\n",
              "      <td>0.917097</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.071000</td>\n",
              "      <td>1.321549</td>\n",
              "      <td>0.921290</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.054900</td>\n",
              "      <td>1.264956</td>\n",
              "      <td>0.922581</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.047300</td>\n",
              "      <td>1.224378</td>\n",
              "      <td>0.926129</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.047300</td>\n",
              "      <td>1.202448</td>\n",
              "      <td>0.928710</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.043800</td>\n",
              "      <td>1.194174</td>\n",
              "      <td>0.928710</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "Saving model checkpoint to checkpoints/run-2/checkpoint-500\n",
            "Configuration saved in checkpoints/run-2/checkpoint-500/config.json\n",
            "Model weights saved in checkpoints/run-2/checkpoint-500/pytorch_model.bin\n",
            "tokenizer config file saved in checkpoints/run-2/checkpoint-500/tokenizer_config.json\n",
            "Special tokens file saved in checkpoints/run-2/checkpoint-500/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "Saving model checkpoint to checkpoints/run-2/checkpoint-1000\n",
            "Configuration saved in checkpoints/run-2/checkpoint-1000/config.json\n",
            "Model weights saved in checkpoints/run-2/checkpoint-1000/pytorch_model.bin\n",
            "tokenizer config file saved in checkpoints/run-2/checkpoint-1000/tokenizer_config.json\n",
            "Special tokens file saved in checkpoints/run-2/checkpoint-1000/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "Saving model checkpoint to checkpoints/run-2/checkpoint-1500\n",
            "Configuration saved in checkpoints/run-2/checkpoint-1500/config.json\n",
            "Model weights saved in checkpoints/run-2/checkpoint-1500/pytorch_model.bin\n",
            "tokenizer config file saved in checkpoints/run-2/checkpoint-1500/tokenizer_config.json\n",
            "Special tokens file saved in checkpoints/run-2/checkpoint-1500/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "Saving model checkpoint to checkpoints/run-2/checkpoint-2000\n",
            "Configuration saved in checkpoints/run-2/checkpoint-2000/config.json\n",
            "Model weights saved in checkpoints/run-2/checkpoint-2000/pytorch_model.bin\n",
            "tokenizer config file saved in checkpoints/run-2/checkpoint-2000/tokenizer_config.json\n",
            "Special tokens file saved in checkpoints/run-2/checkpoint-2000/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "Saving model checkpoint to checkpoints/run-2/checkpoint-2500\n",
            "Configuration saved in checkpoints/run-2/checkpoint-2500/config.json\n",
            "Model weights saved in checkpoints/run-2/checkpoint-2500/pytorch_model.bin\n",
            "tokenizer config file saved in checkpoints/run-2/checkpoint-2500/tokenizer_config.json\n",
            "Special tokens file saved in checkpoints/run-2/checkpoint-2500/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "Saving model checkpoint to checkpoints/run-2/checkpoint-3000\n",
            "Configuration saved in checkpoints/run-2/checkpoint-3000/config.json\n",
            "Model weights saved in checkpoints/run-2/checkpoint-3000/pytorch_model.bin\n",
            "tokenizer config file saved in checkpoints/run-2/checkpoint-3000/tokenizer_config.json\n",
            "Special tokens file saved in checkpoints/run-2/checkpoint-3000/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "\u001b[32m[I 2022-01-04 06:41:47,784]\u001b[0m Trial 2 finished with value: 0.9287096774193548 and parameters: {'num_train_epochs': 10, 'alpha': 0.945917733737466, 'temperature': 7}. Best is trial 2 with value: 0.9287096774193548.\u001b[0m\n",
            "Trial:\n",
            "loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_transform.bias']\n",
            "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.weight', 'classifier.bias', 'pre_classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "***** Running training *****\n",
            "  Num examples = 15250\n",
            "  Num Epochs = 9\n",
            "  Instantaneous batch size per device = 48\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 48\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 2862\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2862' max='2862' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2862/2862 23:25, Epoch 9/9]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>3.315619</td>\n",
              "      <td>0.606774</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.325300</td>\n",
              "      <td>2.409095</td>\n",
              "      <td>0.835161</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.325300</td>\n",
              "      <td>1.963006</td>\n",
              "      <td>0.894839</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.113100</td>\n",
              "      <td>1.708686</td>\n",
              "      <td>0.908387</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.071400</td>\n",
              "      <td>1.549338</td>\n",
              "      <td>0.914194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.071400</td>\n",
              "      <td>1.450197</td>\n",
              "      <td>0.919355</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.056200</td>\n",
              "      <td>1.393095</td>\n",
              "      <td>0.920323</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.049300</td>\n",
              "      <td>1.357662</td>\n",
              "      <td>0.922258</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.049300</td>\n",
              "      <td>1.346244</td>\n",
              "      <td>0.924194</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "Saving model checkpoint to checkpoints/run-3/checkpoint-500\n",
            "Configuration saved in checkpoints/run-3/checkpoint-500/config.json\n",
            "Model weights saved in checkpoints/run-3/checkpoint-500/pytorch_model.bin\n",
            "tokenizer config file saved in checkpoints/run-3/checkpoint-500/tokenizer_config.json\n",
            "Special tokens file saved in checkpoints/run-3/checkpoint-500/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "Saving model checkpoint to checkpoints/run-3/checkpoint-1000\n",
            "Configuration saved in checkpoints/run-3/checkpoint-1000/config.json\n",
            "Model weights saved in checkpoints/run-3/checkpoint-1000/pytorch_model.bin\n",
            "tokenizer config file saved in checkpoints/run-3/checkpoint-1000/tokenizer_config.json\n",
            "Special tokens file saved in checkpoints/run-3/checkpoint-1000/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "Saving model checkpoint to checkpoints/run-3/checkpoint-1500\n",
            "Configuration saved in checkpoints/run-3/checkpoint-1500/config.json\n",
            "Model weights saved in checkpoints/run-3/checkpoint-1500/pytorch_model.bin\n",
            "tokenizer config file saved in checkpoints/run-3/checkpoint-1500/tokenizer_config.json\n",
            "Special tokens file saved in checkpoints/run-3/checkpoint-1500/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "Saving model checkpoint to checkpoints/run-3/checkpoint-2000\n",
            "Configuration saved in checkpoints/run-3/checkpoint-2000/config.json\n",
            "Model weights saved in checkpoints/run-3/checkpoint-2000/pytorch_model.bin\n",
            "tokenizer config file saved in checkpoints/run-3/checkpoint-2000/tokenizer_config.json\n",
            "Special tokens file saved in checkpoints/run-3/checkpoint-2000/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "Saving model checkpoint to checkpoints/run-3/checkpoint-2500\n",
            "Configuration saved in checkpoints/run-3/checkpoint-2500/config.json\n",
            "Model weights saved in checkpoints/run-3/checkpoint-2500/pytorch_model.bin\n",
            "tokenizer config file saved in checkpoints/run-3/checkpoint-2500/tokenizer_config.json\n",
            "Special tokens file saved in checkpoints/run-3/checkpoint-2500/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "\u001b[32m[I 2022-01-04 07:05:15,327]\u001b[0m Trial 3 finished with value: 0.9241935483870968 and parameters: {'num_train_epochs': 9, 'alpha': 0.10172331227255782, 'temperature': 10}. Best is trial 2 with value: 0.9287096774193548.\u001b[0m\n",
            "Trial:\n",
            "loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_transform.bias']\n",
            "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.weight', 'classifier.bias', 'pre_classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "***** Running training *****\n",
            "  Num examples = 15250\n",
            "  Num Epochs = 7\n",
            "  Instantaneous batch size per device = 48\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 48\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 2226\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='2226' max='2226' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2226/2226 18:14, Epoch 7/7]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.852755</td>\n",
              "      <td>0.660000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.644500</td>\n",
              "      <td>1.698372</td>\n",
              "      <td>0.833226</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.644500</td>\n",
              "      <td>1.247921</td>\n",
              "      <td>0.895806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.174700</td>\n",
              "      <td>1.074788</td>\n",
              "      <td>0.908387</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.090300</td>\n",
              "      <td>1.000575</td>\n",
              "      <td>0.916774</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.090300</td>\n",
              "      <td>0.966434</td>\n",
              "      <td>0.920000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.070800</td>\n",
              "      <td>0.957134</td>\n",
              "      <td>0.920645</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "Saving model checkpoint to checkpoints/run-4/checkpoint-500\n",
            "Configuration saved in checkpoints/run-4/checkpoint-500/config.json\n",
            "Model weights saved in checkpoints/run-4/checkpoint-500/pytorch_model.bin\n",
            "tokenizer config file saved in checkpoints/run-4/checkpoint-500/tokenizer_config.json\n",
            "Special tokens file saved in checkpoints/run-4/checkpoint-500/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "Saving model checkpoint to checkpoints/run-4/checkpoint-1000\n",
            "Configuration saved in checkpoints/run-4/checkpoint-1000/config.json\n",
            "Model weights saved in checkpoints/run-4/checkpoint-1000/pytorch_model.bin\n",
            "tokenizer config file saved in checkpoints/run-4/checkpoint-1000/tokenizer_config.json\n",
            "Special tokens file saved in checkpoints/run-4/checkpoint-1000/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "Saving model checkpoint to checkpoints/run-4/checkpoint-1500\n",
            "Configuration saved in checkpoints/run-4/checkpoint-1500/config.json\n",
            "Model weights saved in checkpoints/run-4/checkpoint-1500/pytorch_model.bin\n",
            "tokenizer config file saved in checkpoints/run-4/checkpoint-1500/tokenizer_config.json\n",
            "Special tokens file saved in checkpoints/run-4/checkpoint-1500/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "Saving model checkpoint to checkpoints/run-4/checkpoint-2000\n",
            "Configuration saved in checkpoints/run-4/checkpoint-2000/config.json\n",
            "Model weights saved in checkpoints/run-4/checkpoint-2000/pytorch_model.bin\n",
            "tokenizer config file saved in checkpoints/run-4/checkpoint-2000/tokenizer_config.json\n",
            "Special tokens file saved in checkpoints/run-4/checkpoint-2000/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "\u001b[32m[I 2022-01-04 07:23:31,116]\u001b[0m Trial 4 finished with value: 0.9206451612903226 and parameters: {'num_train_epochs': 7, 'alpha': 0.7201430024774579, 'temperature': 2}. Best is trial 2 with value: 0.9287096774193548.\u001b[0m\n",
            "Trial:\n",
            "loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_transform.bias']\n",
            "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.weight', 'classifier.bias', 'pre_classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "***** Running training *****\n",
            "  Num examples = 15250\n",
            "  Num Epochs = 6\n",
            "  Instantaneous batch size per device = 48\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 48\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 1908\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='637' max='1908' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 637/1908 04:55 < 09:50, 2.15 it/s, Epoch 2/6]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>3.271601</td>\n",
              "      <td>0.613871</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.358200</td>\n",
              "      <td>2.357357</td>\n",
              "      <td>0.826129</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "Saving model checkpoint to checkpoints/run-5/checkpoint-500\n",
            "Configuration saved in checkpoints/run-5/checkpoint-500/config.json\n",
            "Model weights saved in checkpoints/run-5/checkpoint-500/pytorch_model.bin\n",
            "tokenizer config file saved in checkpoints/run-5/checkpoint-500/tokenizer_config.json\n",
            "Special tokens file saved in checkpoints/run-5/checkpoint-500/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "\u001b[32m[I 2022-01-04 07:28:43,761]\u001b[0m Trial 5 pruned. \u001b[0m\n",
            "Trial:\n",
            "loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_transform.bias']\n",
            "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.weight', 'classifier.bias', 'pre_classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "***** Running training *****\n",
            "  Num examples = 15250\n",
            "  Num Epochs = 9\n",
            "  Instantaneous batch size per device = 48\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 48\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 2862\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='319' max='2862' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 319/2862 02:19 < 18:35, 2.28 it/s, Epoch 1/9]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>3.346272</td>\n",
              "      <td>0.597097</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "\u001b[32m[I 2022-01-04 07:31:20,543]\u001b[0m Trial 6 pruned. \u001b[0m\n",
            "Trial:\n",
            "loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_transform.bias']\n",
            "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.weight', 'classifier.bias', 'pre_classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "***** Running training *****\n",
            "  Num examples = 15250\n",
            "  Num Epochs = 9\n",
            "  Instantaneous batch size per device = 48\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 48\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 2862\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='319' max='2862' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 319/2862 02:19 < 18:41, 2.27 it/s, Epoch 1/9]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>3.346272</td>\n",
              "      <td>0.597097</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "\u001b[32m[I 2022-01-04 07:33:57,893]\u001b[0m Trial 7 pruned. \u001b[0m\n",
            "Trial:\n",
            "loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_transform.bias']\n",
            "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.weight', 'classifier.bias', 'pre_classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "***** Running training *****\n",
            "  Num examples = 15250\n",
            "  Num Epochs = 9\n",
            "  Instantaneous batch size per device = 48\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 48\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 2862\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='319' max='2862' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [ 319/2862 02:19 < 18:37, 2.28 it/s, Epoch 1/9]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>3.358032</td>\n",
              "      <td>0.594516</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "\u001b[32m[I 2022-01-04 07:36:34,750]\u001b[0m Trial 8 pruned. \u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `hyperparameter_search` method returns a `BestRun` object which contains the\n",
        "value of the objective that was maximized (by default the sum of all metrics) and the hyperparameters it used for that run:"
      ],
      "metadata": {
        "id": "wKADpZj9v7UC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_run"
      ],
      "metadata": {
        "id": "sE7kqdOSwA1G",
        "outputId": "854a40a7-0c2a-4d9d-b9f0-66d7cc8b2688",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BestRun(run_id='2', objective=0.9287096774193548, hyperparameters={'num_train_epochs': 10, 'alpha': 0.945917733737466, 'temperature': 7})"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This value of $\\alpha$ tells us that most of the training signal is coming from the knowledge distillation term. \n",
        "\n",
        "Let’s update our trainer with these values and run the final training run:"
      ],
      "metadata": {
        "id": "UXcJARmBwV3N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for k, v in best_run.hyperparameters.items():\n",
        "  setattr(distil_trainer.args, k, v)\n",
        "\n",
        "# now finally, train the model\n",
        "distil_trainer.train();"
      ],
      "metadata": {
        "id": "P73yTfPowcdN",
        "outputId": "346ca196-48fc-47fa-cec4-6471430dd33f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_projector.weight', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_transform.weight', 'vocab_projector.bias', 'vocab_transform.bias']\n",
            "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'classifier.weight', 'classifier.bias', 'pre_classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "***** Running training *****\n",
            "  Num examples = 15250\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 48\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 48\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 3180\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='3180' max='3180' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [3180/3180 26:05, Epoch 10/10]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>3.172010</td>\n",
              "      <td>0.759355</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>3.530100</td>\n",
              "      <td>1.563872</td>\n",
              "      <td>0.857742</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>3.530100</td>\n",
              "      <td>0.764525</td>\n",
              "      <td>0.915806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.276800</td>\n",
              "      <td>0.462028</td>\n",
              "      <td>0.932258</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.430500</td>\n",
              "      <td>0.336366</td>\n",
              "      <td>0.938710</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.430500</td>\n",
              "      <td>0.288748</td>\n",
              "      <td>0.942258</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.203600</td>\n",
              "      <td>0.265336</td>\n",
              "      <td>0.943871</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.125700</td>\n",
              "      <td>0.252804</td>\n",
              "      <td>0.945484</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.125700</td>\n",
              "      <td>0.251038</td>\n",
              "      <td>0.945806</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.099000</td>\n",
              "      <td>0.249616</td>\n",
              "      <td>0.946129</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "Saving model checkpoint to checkpoints/checkpoint-500\n",
            "Configuration saved in checkpoints/checkpoint-500/config.json\n",
            "Model weights saved in checkpoints/checkpoint-500/pytorch_model.bin\n",
            "tokenizer config file saved in checkpoints/checkpoint-500/tokenizer_config.json\n",
            "Special tokens file saved in checkpoints/checkpoint-500/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "Saving model checkpoint to checkpoints/checkpoint-1000\n",
            "Configuration saved in checkpoints/checkpoint-1000/config.json\n",
            "Model weights saved in checkpoints/checkpoint-1000/pytorch_model.bin\n",
            "tokenizer config file saved in checkpoints/checkpoint-1000/tokenizer_config.json\n",
            "Special tokens file saved in checkpoints/checkpoint-1000/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "Saving model checkpoint to checkpoints/checkpoint-1500\n",
            "Configuration saved in checkpoints/checkpoint-1500/config.json\n",
            "Model weights saved in checkpoints/checkpoint-1500/pytorch_model.bin\n",
            "tokenizer config file saved in checkpoints/checkpoint-1500/tokenizer_config.json\n",
            "Special tokens file saved in checkpoints/checkpoint-1500/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "Saving model checkpoint to checkpoints/checkpoint-2000\n",
            "Configuration saved in checkpoints/checkpoint-2000/config.json\n",
            "Model weights saved in checkpoints/checkpoint-2000/pytorch_model.bin\n",
            "tokenizer config file saved in checkpoints/checkpoint-2000/tokenizer_config.json\n",
            "Special tokens file saved in checkpoints/checkpoint-2000/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "Saving model checkpoint to checkpoints/checkpoint-2500\n",
            "Configuration saved in checkpoints/checkpoint-2500/config.json\n",
            "Model weights saved in checkpoints/checkpoint-2500/pytorch_model.bin\n",
            "tokenizer config file saved in checkpoints/checkpoint-2500/tokenizer_config.json\n",
            "Special tokens file saved in checkpoints/checkpoint-2500/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "Saving model checkpoint to checkpoints/checkpoint-3000\n",
            "Configuration saved in checkpoints/checkpoint-3000/config.json\n",
            "Model weights saved in checkpoints/checkpoint-3000/pytorch_model.bin\n",
            "tokenizer config file saved in checkpoints/checkpoint-3000/tokenizer_config.json\n",
            "Special tokens file saved in checkpoints/checkpoint-3000/special_tokens_map.json\n",
            "***** Running Evaluation *****\n",
            "  Num examples = 3100\n",
            "  Batch size = 48\n",
            "\n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remarkably we’ve been able to train the student to match the accuracy of the teacher, despite having almost half the number of parameters! \n",
        "\n",
        "Let’s save the model for future use:"
      ],
      "metadata": {
        "id": "UAbMVYAtxBkL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "distil_trainer.save_model(\"models/distilbert-base-uncased-distilled-clinc\")"
      ],
      "metadata": {
        "id": "gBzSa92fxD0h",
        "outputId": "18c35ec5-c0e2-42d0-d3b8-4279001fece5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Saving model checkpoint to models/distilbert-base-uncased-distilled-clinc\n",
            "Configuration saved in models/distilbert-base-uncased-distilled-clinc/config.json\n",
            "Model weights saved in models/distilbert-base-uncased-distilled-clinc/pytorch_model.bin\n",
            "tokenizer config file saved in models/distilbert-base-uncased-distilled-clinc/tokenizer_config.json\n",
            "Special tokens file saved in models/distilbert-base-uncased-distilled-clinc/special_tokens_map.json\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Benchmarking Our Distilled Model"
      ],
      "metadata": {
        "id": "AN8W3C1mxLrW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have an accurate student, let’s create a pipeline and redo our benchmark to see how we perform on the test set:"
      ],
      "metadata": {
        "id": "p7jjZW1PxQO2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_pipeline = TextClassificationPipeline(model=distil_trainer.model.to(\"cpu\"), tokenizer=distil_trainer.tokenizer)\n",
        "\n",
        "optim_type = \"Distillation\"\n",
        "pb = PerformanceBenchmark(final_pipeline, clinc[\"test\"], optim_type=optim_type)\n",
        "perf_metrics.update(pb.run_benchmark())"
      ],
      "metadata": {
        "id": "E2xvNsa-yfXp",
        "outputId": "6e863578-d75a-478c-833e-d363b705e9ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model size (MB) - 255.89\n",
            "Average latency (ms) - 81.47 +\\- 3.89\n",
            "Accuracy on test set - 0.888\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "To put these results in context, let’s also visualise them with our `plot_metrics` function:"
      ],
      "metadata": {
        "id": "QFxefKjLzeKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_metrics(perf_metrics, optim_type)"
      ],
      "metadata": {
        "id": "DHYU9AN8zf3h",
        "outputId": "9f1d9ef2-d897-4c85-aeff-df15982d537d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "As expected, the model size and latency remain essentially unchanged compared to the `DistilBERT` benchmark, but the accuracy has improved and even surpassed the performance of the teacher! \n",
        "\n",
        "We can actually compress our distilled model even further using a technique\n",
        "known as `quantization`."
      ],
      "metadata": {
        "id": "BKywL1zCzwXa"
      }
    }
  ]
}