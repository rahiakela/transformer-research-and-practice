{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "04-case-study-intent-detection-with-weight-pruning.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPJBdFGDDwFgicvqM1eneF9",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/transformers-research-and-practice/blob/main/natural-language-processing-with-transformers/08-making-transformers-efficient-in-production/04_case_study_intent_detection_with_weight_pruning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Case Study: Intent Detection with weight-pruning"
      ],
      "metadata": {
        "id": "W519IdztjisY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s suppose that we’re trying to build a text-based assistant for our company’s call center so\n",
        "that customers can request the balance of their account or make bookings without needing to\n",
        "speak with a human agent. In order to understand the goals of a customer, our assistant will\n",
        "need to be able to classify a wide variety of natural language text into a set of predefined\n",
        "actions or intents.\n",
        "\n",
        "For example, a customer may send a message about an upcoming trip:\n",
        "\n",
        "```txt\n",
        "Hey, I’d like to rent a vehicle from Nov 1st to Nov 15th in Paris and I need a 15 passenger van\n",
        "```\n",
        "\n",
        "and our intent classifier could automatically categorize this as a Car Rental intent, which then triggers an action and response.\n",
        "\n",
        "To be robust in a production environment, our classifier will\n",
        "also need to be able to handle out-of-scope queries.\n",
        "\n",
        "<img src='https://github.com/rahiakela/transformers-research-and-practice/blob/main/natural-language-processing-with-transformers/05-making-transformers-efficient-in-production/images/1.png?raw=1' width='600'/>\n",
        "\n",
        "In the third case, the text-assistant\n",
        "has been trained to detect out-of-scope queries (usually labelled as a separate class) and informs the customer about which topics they can respond to.\n",
        "\n",
        "As a baseline we’ve fine-tuned a BERT-base model that achieves around `94%` accuracy on the\n",
        "`CLINC150` dataset. This dataset includes `22,500` in-scope queries across `150` intents and `10`\n",
        "domains like banking and travel, and also includes `1,200` out-of-scope queries that belong to an\n",
        "oos intent class. In practice we would also gather our own in-house dataset, but using public\n",
        "data is a great way to iterate quickly and generate preliminary results.\n",
        "\n"
      ],
      "metadata": {
        "id": "XOmQOa_QjwHw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Setup"
      ],
      "metadata": {
        "id": "UP1EHAnilUGK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install transformers[sentencepiece]\n",
        "!pip -q install transformers[onnx]\n",
        "!pip -q install datasets\n",
        "!pip -q install optuna"
      ],
      "metadata": {
        "id": "PJs0JgLwlVIt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import (AutoTokenizer, AutoModelForSequenceClassification, TextClassificationPipeline)\n",
        "from transformers import TrainingArguments, Trainer\n",
        "from transformers import AutoConfig\n",
        "from datasets import load_dataset, load_metric\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.nn.quantized import QFunctional\n",
        "from torch import quantize_per_tensor\n",
        "from torch.quantization import quantize_dynamic\n",
        "\n",
        "\n",
        "import optuna\n",
        "\n",
        "from mpl_toolkits.axes_grid1.inset_locator import zoomed_inset_axes,mark_inset\n",
        "\n",
        "# ONNX imports\n",
        "from psutil import cpu_count\n",
        "from transformers.convert_graph_to_onnx import convert\n",
        "from onnxruntime import (GraphOptimizationLevel, InferenceSession, SessionOptions)\n",
        "from onnxruntime_tools.transformers.onnx_model_bert import (BertOptimizationOptions)\n",
        "from onnxruntime_tools import optimizer\n",
        "from onnxruntime.quantization import quantize_dynamic, QuantType\n",
        "from scipy.special import softmax\n",
        "\n",
        "from pathlib import Path\n",
        "from time import perf_counter\n",
        "\n",
        "import sys\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "A15YGFMiloPN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_metrics(perf_metrics, current_optim_type):\n",
        "  df = pd.DataFrame.from_dict(perf_metrics, orient='index')\n",
        "\n",
        "  for idx in df.index:\n",
        "    df_opt = df.loc[idx]\n",
        "    # Add a dashed circle around the current optimization type\n",
        "    if idx == current_optim_type:\n",
        "      plt.scatter(df_opt[\"time_avg_ms\"], df_opt[\"accuracy\"] * 100, alpha=0.5, s=df_opt[\"size_mb\"], label=idx, marker='$\\u25CC$')\n",
        "    else:\n",
        "      plt.scatter(df_opt[\"time_avg_ms\"], df_opt[\"accuracy\"] * 100, s=df_opt[\"size_mb\"], label=idx, alpha=0.5)\n",
        "          \n",
        "  legend = plt.legend(bbox_to_anchor=(1,1))\n",
        "  for handle in legend.legendHandles:\n",
        "    handle.set_sizes([20])\n",
        "\n",
        "  plt.ylim(80,90)\n",
        "  # Use the slowest model to define the x-axis range\n",
        "  xlim = int(perf_metrics[\"BERT baseline\"][\"time_avg_ms\"] + 3)\n",
        "  plt.xlim(1, xlim)\n",
        "  plt.ylabel(\"Accuracy (%)\")\n",
        "  plt.xlabel(\"Average latency (ms)\")\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "7xUwJN7YK_8e"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let’s download our fine-tuned model from the Hugging Face Hub and wrap it in a pipeline for text classification:"
      ],
      "metadata": {
        "id": "OIOFJ-dkm0E_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# molde path has changed: https://huggingface.co/transformersbook/bert-base-uncased-finetuned-clinc\n",
        "bert_ckpt = \"transformersbook/bert-base-uncased-finetuned-clinc\"\n",
        "\n",
        "bert_tokenizer = AutoTokenizer.from_pretrained(bert_ckpt)\n",
        "bert_model = (AutoModelForSequenceClassification.from_pretrained(bert_ckpt).to(\"cpu\"))\n",
        "\n",
        "bert_pipeline = TextClassificationPipeline(model=bert_model, tokenizer=bert_tokenizer)"
      ],
      "metadata": {
        "id": "l3NVuFLdm2qj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we’ve set the model’s device to cpu since our text-assistant will need to operate in an\n",
        "environment where queries are processed and responded to in real-time.\n",
        "\n",
        "Now that we have a pipeline, we can pass a query to get the predicted intent and confidence\n",
        "score from the model:"
      ],
      "metadata": {
        "id": "lQ6kcqUNrsUP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = \"\"\"Hey, I'd like to rent a vehicle from Nov 1st to Nov 15th in Paris and I need a 15 passenger van\"\"\"\n",
        "\n",
        "bert_pipeline(query)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fygRC29urv7Z",
        "outputId": "4cd077ce-c1a7-48a9-d563-824ae90958d9"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'car_rental', 'score': 0.5490034818649292}]"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Great, the `car_rental` intent makes sense so let’s now look at creating a benchmark that we\n",
        "can use to evaluate the performance of our baseline model."
      ],
      "metadata": {
        "id": "ckP-6KbIsBne"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Performance Benchmark"
      ],
      "metadata": {
        "id": "3auvFWv7sENZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Like any other machine learning model, deploying Transformers in production environments involves a trade-off among several constraints, the most common being:\n",
        "\n",
        "- **Model performance**\n",
        "  - How well does our model perform on a well-crafted test set that reflects production data?\n",
        "- **Latency**\n",
        "  - How fast can our model deliver predictions?\n",
        "- **Memory**\n",
        "  - How can we deploy billion-parameter models like GPT-2 or T5 that require gigabytes of disk storage and RAM?\n",
        "\n",
        "Failing to address these constraints can have a negative impact on the user experience of your\n",
        "application, or more commonly, lead to ballooning costs from running expensive cloud servers\n",
        "that may only need to handle a few requests.\n",
        "\n",
        "To explore how each of the these constraints can\n",
        "be optimized with various compression techniques, let’s begin by creating a simple benchmark\n",
        "that measures each quantity for a given pipeline and test set."
      ],
      "metadata": {
        "id": "L-Wj4qUwsG5m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PerformanceBenchmark:\n",
        "  def __init__(self, pipeline, dataset, optim_type=\"BERT baseline\") -> None:\n",
        "    self.pipeline = pipeline\n",
        "    self.dataset = dataset\n",
        "    self.optim_type = optim_type\n",
        "\n",
        "  def compute_accuracy(self):\n",
        "    preds, labels = [], []\n",
        "    for example in self.dataset:\n",
        "      pred = self.pipeline(example[\"text\"])[0][\"label\"]\n",
        "      label = example[\"intent\"]\n",
        "      preds.append(intents.str2int(pred))\n",
        "      labels.append(label)\n",
        "    accuracy = accuracy_score.compute(predictions=preds, references=labels)\n",
        "    print(f\"Accuracy on test set - {accuracy['accuracy']:.3f}\")\n",
        "    return accuracy\n",
        "\n",
        "  def compute_size(self):\n",
        "    state_dict = self.pipeline.model.state_dict()\n",
        "    tmp_path = Path(\"model.pt\")\n",
        "    torch.save(state_dict, tmp_path)\n",
        "    # Calculate size in megabytes\n",
        "    size_mb = Path(tmp_path).stat().st_size / (1024 * 1024)\n",
        "    # Delete temporary file\n",
        "    tmp_path.unlink()\n",
        "    print(f\"Model size (MB) - {size_mb:.2f}\")\n",
        "    return {\"size_mb\": size_mb}\n",
        "\n",
        "  def time_pipeline(self, query=\"What is the pin number for my account?\"):\n",
        "    latencies = []\n",
        "    # Warmup\n",
        "    for _ in range(10):\n",
        "      _ = self.pipeline(query)\n",
        "    # Timed run\n",
        "    for _ in range(100):\n",
        "      start_time = perf_counter()\n",
        "      _ = bert_pipeline(query)\n",
        "      latency = perf_counter() - start_time\n",
        "      latencies.append(latency)\n",
        "    # Compute run statistics\n",
        "    time_avg_ms = 1000 * np.mean(latencies)\n",
        "    time_std_ms = 1000 * np.std(latencies)\n",
        "    print(f\"Average latency (ms) - {time_avg_ms:.2f} +\\- {time_std_ms:.2f}\")\n",
        "    return {\"time_avg_ms\": time_avg_ms, \"time_std_ms\": time_std_ms}\n",
        "\n",
        "  # We’ll use the run_benchmark function to collect all the metrics in a dictionary, with keys given by optim_type.\n",
        "  def run_benchmark(self):\n",
        "    metrics = {}\n",
        "    metrics[self.optim_type] = self.compute_size()\n",
        "    metrics[self.optim_type].update(self.time_pipeline())\n",
        "    metrics[self.optim_type].update(self.compute_accuracy())\n",
        "    return metrics"
      ],
      "metadata": {
        "id": "mw8ChQz0zP0d"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "First we need some data to test on, so let’s download the CLINC150 dataset that was used to finetune our baseline model. \n",
        "\n",
        "We can get the dataset from the Hub with the Datasets library as follows:"
      ],
      "metadata": {
        "id": "RymNuU1w0rB3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clinc = load_dataset(\"clinc_oos\", \"plus\")"
      ],
      "metadata": {
        "id": "fWSUNfxG0vHo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clinc"
      ],
      "metadata": {
        "id": "bn0AF4divpQR",
        "outputId": "4d94cb12-6b51-4735-be44-a12bf1047a78",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['text', 'intent'],\n",
              "        num_rows: 15250\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['text', 'intent'],\n",
              "        num_rows: 3100\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['text', 'intent'],\n",
              "        num_rows: 5500\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each example in the CLINC150 dataset consists of a query in the text column and its corresponding intent. \n",
        "\n",
        "We’ll use the test set to benchmark our models, so let’s take a look at one\n",
        "of the dataset’s examples:"
      ],
      "metadata": {
        "id": "q9J8hxCM1RuH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clinc[\"test\"][42]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H7lx13kR1UGm",
        "outputId": "c1d731a8-660a-4794-bc07-c81ffb9d61de"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'intent': 133, 'text': 'transfer $100 from my checking to saving account'}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The intents are provided as IDs, but we can easily get the mapping to strings (and vice versa)\n",
        "by accessing the `Dataset.features` attribute:"
      ],
      "metadata": {
        "id": "_M_kfBpA1gNg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "intents = clinc[\"test\"].features[\"intent\"]\n",
        "intents.int2str(clinc[\"test\"][42][\"intent\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "VhTLlAHg1iVg",
        "outputId": "8e488d4e-3105-4a11-aa09-7c000dc7909a"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'transfer'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Exploring Class distribution"
      ],
      "metadata": {
        "id": "9d7m9nc-D5Wk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have a basic understanding of the contents in the CLINC150 dataset, let’s check it class distribution."
      ],
      "metadata": {
        "id": "Ii9JuBXW3csg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clinc.set_format(type=\"pandas\")\n",
        "\n",
        "df = clinc[\"train\"][:]\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "kvjEe7k63yj_",
        "outputId": "32b4b335-8e2a-4db7-bfa6-bfa387f6e04d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  intent\n",
              "0  what expression would i use to say i love you ...      61\n",
              "1  can you tell me how to say 'i do not speak muc...      61\n",
              "2  what is the equivalent of, 'life is good' in f...      61\n",
              "3  tell me how to say, 'it is a beautiful morning...      61\n",
              "4  if i were mongolian, how would i say that i am...      61"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-ae728ccb-285c-43b5-8b6e-4116463d25cc\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>intent</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>what expression would i use to say i love you ...</td>\n",
              "      <td>61</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>can you tell me how to say 'i do not speak muc...</td>\n",
              "      <td>61</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>what is the equivalent of, 'life is good' in f...</td>\n",
              "      <td>61</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>tell me how to say, 'it is a beautiful morning...</td>\n",
              "      <td>61</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>if i were mongolian, how would i say that i am...</td>\n",
              "      <td>61</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-ae728ccb-285c-43b5-8b6e-4116463d25cc')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-ae728ccb-285c-43b5-8b6e-4116463d25cc button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-ae728ccb-285c-43b5-8b6e-4116463d25cc');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def label_int2str(row, split):\n",
        "  return clinc[split].features[\"intent\"].int2str(row)"
      ],
      "metadata": {
        "id": "S4qNxogY4G5u"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"label_name\"] = df[\"intent\"].apply(label_int2str, split=\"train\")\n",
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "7BBQ5y8C4HUd",
        "outputId": "3d81af31-64be-474b-a3ed-f22082693178"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                text  intent label_name\n",
              "0  what expression would i use to say i love you ...      61  translate\n",
              "1  can you tell me how to say 'i do not speak muc...      61  translate\n",
              "2  what is the equivalent of, 'life is good' in f...      61  translate\n",
              "3  tell me how to say, 'it is a beautiful morning...      61  translate\n",
              "4  if i were mongolian, how would i say that i am...      61  translate"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-87752fc7-1b5b-47d5-870d-5252aea12396\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>intent</th>\n",
              "      <th>label_name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>what expression would i use to say i love you ...</td>\n",
              "      <td>61</td>\n",
              "      <td>translate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>can you tell me how to say 'i do not speak muc...</td>\n",
              "      <td>61</td>\n",
              "      <td>translate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>what is the equivalent of, 'life is good' in f...</td>\n",
              "      <td>61</td>\n",
              "      <td>translate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>tell me how to say, 'it is a beautiful morning...</td>\n",
              "      <td>61</td>\n",
              "      <td>translate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>if i were mongolian, how would i say that i am...</td>\n",
              "      <td>61</td>\n",
              "      <td>translate</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-87752fc7-1b5b-47d5-870d-5252aea12396')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-87752fc7-1b5b-47d5-870d-5252aea12396 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-87752fc7-1b5b-47d5-870d-5252aea12396');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"label_name\"].value_counts(ascending=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4ig5e0lu4-S5",
        "outputId": "45f0a0a9-2f06-4895-d818-ac1506597def"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "translate             100\n",
              "goodbye               100\n",
              "account_blocked       100\n",
              "what_song             100\n",
              "international_fees    100\n",
              "                     ... \n",
              "change_speed          100\n",
              "tire_pressure         100\n",
              "no                    100\n",
              "nutrition_info        100\n",
              "oos                   250\n",
              "Name: label_name, Length: 151, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df[\"label_name\"].value_counts(ascending=True).plot.barh()\n",
        "plt.title(\"Intent Counts\");"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "2BXcUSw13gJK",
        "outputId": "2a103d8c-5db1-4da3-b9c5-8e5cd9c90c9c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# reset back to original format\n",
        "clinc.reset_format()"
      ],
      "metadata": {
        "id": "nogbgDni5pew"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Benchmark statistics"
      ],
      "metadata": {
        "id": "5lrgcTOpDmNN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since the dataset is balanced across the intent\n",
        "classes, we’ll use accuracy as our metric which we can load from Datasets.\n",
        "\n",
        "let’s implement the compute_accuracy function:"
      ],
      "metadata": {
        "id": "MpBAkN4mDyoR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_score = load_metric(\"accuracy\")\n",
        "accuracy_score"
      ],
      "metadata": {
        "id": "3cNor6J857nf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s see what is stored in the `state_dict` of our baseline model:"
      ],
      "metadata": {
        "id": "omnODJah9Zfb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "list(bert_pipeline.model.state_dict().items())[42]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6tJJOTl9quL",
        "outputId": "40e2514b-5d6a-4a7e-8b03-7b1f5bf9a038"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('bert.encoder.layer.2.attention.self.value.weight',\n",
              " tensor([[-1.0526e-02, -3.2215e-02,  2.2097e-02,  ..., -6.0953e-03,\n",
              "           4.6521e-03,  2.9844e-02],\n",
              "         [-1.4964e-02, -1.0915e-02,  5.2396e-04,  ...,  3.2047e-05,\n",
              "          -2.6890e-02, -2.1943e-02],\n",
              "         [-2.9640e-02, -3.7842e-03, -1.2582e-02,  ..., -1.0917e-02,\n",
              "           3.1152e-02, -9.7786e-03],\n",
              "         ...,\n",
              "         [-1.5116e-02, -3.3226e-02,  4.2063e-02,  ..., -5.2652e-03,\n",
              "           1.1093e-02,  2.9703e-03],\n",
              "         [-3.6809e-02,  5.6848e-02, -2.6544e-02,  ..., -4.0114e-02,\n",
              "           6.7487e-03,  1.0511e-03],\n",
              "         [-2.4961e-02,  1.4747e-03, -5.4271e-02,  ...,  2.0004e-02,\n",
              "           2.3981e-02, -4.2880e-02]]))"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can use `perf_counter` to time our `pipeline` by passing our test query and calculating the\n",
        "time difference in milliseconds between the start and end:"
      ],
      "metadata": {
        "id": "wZF_qb7NAEXS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for _ in range(3):\n",
        "  start_time = perf_counter()\n",
        "  _ = bert_pipeline(query)\n",
        "  latency = perf_counter() - start_time\n",
        "  print(f\"Latency (ms) - {1000 * latency:.3f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j3kj_JIxAYDs",
        "outputId": "9223af7f-b520-4e60-e0b3-dc8df82526df"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Latency (ms) - 120.991\n",
            "Latency (ms) - 111.850\n",
            "Latency (ms) - 108.616\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Benchmarking Our Baseline Model"
      ],
      "metadata": {
        "id": "YmmzDTmVDada"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that our `PerformanceBenchmark` is complete, let’s give it a spin! For the baseline\n",
        "model we just need to pass the pipeline and dataset we wish to perform the benchmark on, and\n",
        "we’ll collect the results in the `perf_metrics` dictionary to keep track of each model’s\n",
        "performance:"
      ],
      "metadata": {
        "id": "83rwOZcdDbMO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pb = PerformanceBenchmark(bert_pipeline, clinc[\"test\"])\n",
        "perf_metrics = pb.run_benchmark()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMRdYK5sEehl",
        "outputId": "3498698a-8de1-48ed-c25a-071f66274956"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model size (MB) - 418.16\n",
            "Average latency (ms) - 68.95 +\\- 2.40\n",
            "Accuracy on test set - 0.867\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once we have determined the best performing model we can then explore different backends to reduce the absolute latency if needed.\n",
        "\n",
        "Now that we have a reference point, let’s look at our first compression technique: **knowledge distillation**."
      ],
      "metadata": {
        "id": "UGxlw8_fE8Ou"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Knowledge Distillation for Smaller Models "
      ],
      "metadata": {
        "id": "eft__0YfFDQu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Knowledge distillation is a general-purpose method for training a smaller student model to mimic the behavior of a slower, larger, but better performing teacher."
      ],
      "metadata": {
        "id": "nAA500rZ_mXn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Knowledge Distillation Trainer"
      ],
      "metadata": {
        "id": "Fp6K2B7nCh2N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To implement knowledge distillation we need to add a few things to the `Trainer` base class:\n",
        "\n",
        "- The new hyperparameters $\\alpha$ and $T$ which control the relative weight of the distillation loss and how much the probability distribution of the labels should be smoothed.\n",
        "- The fine-tuned teacher model, which in our case is `BERT-base`\n",
        "- A new loss function that includes the cross-entropy loss with the knowledge\n",
        "distillation loss.\n",
        "\n",
        "Adding the new hyperparameters is quite simple since we just need to subclass\n",
        "`TrainingArguments` and include them as new attributes:"
      ],
      "metadata": {
        "id": "npBIwXwuCjF-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DistillationTrainingArguments(TrainingArguments):\n",
        "  def __init__(self, *args, alpha=0.5, temperature=2.0, **kwargs):\n",
        "    super().__init__(*args, **kwargs)\n",
        "    self.alpha = alpha\n",
        "    self.temperature = temperature"
      ],
      "metadata": {
        "id": "1kTBUu3UDGMa"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "For the trainer itself, we want a new loss function so the way to implement this is by subclassing `Trainer` and overriding the `compute_loss` function to include the knowledge distillation loss term $L_{KD}$:"
      ],
      "metadata": {
        "id": "60pJYgs6D3g0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DistillationTrainer(Trainer):\n",
        "  def __init__(self, *args, teacher_model=None, **kwargs):\n",
        "    super().__init__(*args, **kwargs)\n",
        "    self.teacher_model = teacher_model\n",
        "\n",
        "  #reference: https://discuss.huggingface.co/t/custom-loss-compute-loss-got-an-unexpected-keyword-argument-return-outputs/4148\n",
        "  def compute_loss(self, model, inputs, return_outputs=False):\n",
        "    outputs_student = model(**inputs)\n",
        "    # Extract cross-entropy loss and logits from student\n",
        "    loss_ce = outputs_student.loss\n",
        "    logits_student = outputs_student.logits\n",
        "    # Extract logits from teacher\n",
        "    with torch.no_grad():\n",
        "      outputs_teacher = self.teacher_model(**inputs)\n",
        "      logits_teacher = outputs_teacher.logits\n",
        "    # Soften probabilities and compute distillation loss\n",
        "    loss_kld = nn.KLDivLoss(reduction=\"batchmean\")\n",
        "    loss_kd = self.args.temperature ** 2 * loss_kld(\n",
        "        F.log_softmax(logits_student / self.args.temperature, dim=-1),\n",
        "        F.softmax(logits_teacher / self.args.temperature, dim=-1)\n",
        "    )\n",
        "    # Return weighted student loss\n",
        "    return (loss_ce, outputs_student) if return_outputs else  self.args.alpha * loss_ce + (1. - self.args.alpha) * loss_kd"
      ],
      "metadata": {
        "id": "Wqs3s63AD_Z7"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "help(Trainer.compute_loss)"
      ],
      "metadata": {
        "id": "O57Zu5kdYKbU",
        "outputId": "94738c86-b11e-45b0-e0c8-dbcb31db1949",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Help on function compute_loss in module transformers.trainer:\n",
            "\n",
            "compute_loss(self, model, inputs, return_outputs=False)\n",
            "    How the loss is computed by Trainer. By default, all models return the loss in the first element.\n",
            "    \n",
            "    Subclass and override for custom behavior.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Student Initialization"
      ],
      "metadata": {
        "id": "6knZ667PJX4e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "First we’ll need to tokenize and encode our queries, so let’s instantiate the tokenizer from DistilBERT and create a simple function to take care of the preprocessing:"
      ],
      "metadata": {
        "id": "PH0nMZIJJYyr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "student_ckpt = \"distilbert-base-uncased\"\n",
        "student_tokenizer = AutoTokenizer.from_pretrained(student_ckpt)"
      ],
      "metadata": {
        "id": "ax_JZOv2K0vc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_text(batch, tokenizer):\n",
        "  return tokenizer(batch[\"text\"], truncation=True)"
      ],
      "metadata": {
        "id": "gCFG9TGyLIEs"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# removed the text column since we no longer need it\n",
        "clinc_enc = clinc.map(tokenize_text, batched=True, remove_columns=[\"text\"], fn_kwargs={\"tokenizer\": student_tokenizer})"
      ],
      "metadata": {
        "id": "0lqqjIXwLVm-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# renamed the intent column to labels so it can be automatically detected by the trainer\n",
        "clinc_enc.rename_column(\"intent\", \"labels\")"
      ],
      "metadata": {
        "id": "vqXyBrFc_eCn",
        "outputId": "3ef96431-de85-4489-c542-fb0ed598734e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['labels', 'input_ids', 'attention_mask'],\n",
              "        num_rows: 15250\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['labels', 'input_ids', 'attention_mask'],\n",
              "        num_rows: 3100\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['labels', 'input_ids', 'attention_mask'],\n",
              "        num_rows: 5500\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "clinc_enc[\"train\"][0]"
      ],
      "metadata": {
        "id": "4N1gOFu3MMCO",
        "outputId": "caa58363-92da-4cad-d809-a2637bc515f3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n",
              " 'input_ids': [101,\n",
              "  2054,\n",
              "  3670,\n",
              "  2052,\n",
              "  1045,\n",
              "  2224,\n",
              "  2000,\n",
              "  2360,\n",
              "  1045,\n",
              "  2293,\n",
              "  2017,\n",
              "  2065,\n",
              "  1045,\n",
              "  2020,\n",
              "  2019,\n",
              "  3059,\n",
              "  102],\n",
              " 'intent': 61}"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that our texts are processed, the next thing to do is instantiate\n",
        "DistilBERT for fine-tuning. Since we will be doing multiple runs with the trainer, we’ll use a function to initialize the model with each new run:"
      ],
      "metadata": {
        "id": "gEyc7WqqMdO_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_labels = intents.num_classes\n",
        "id2label = bert_model.config.id2label\n",
        "label2id = bert_model.config.label2id\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "metadata": {
        "id": "rAihzuJYMes1"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "student_config = (AutoConfig.from_pretrained(student_ckpt, num_labels=num_labels, id2label=id2label, label2id=label2id))"
      ],
      "metadata": {
        "id": "wZDE5_CXNEki"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def student_init():\n",
        "  return (AutoModelForSequenceClassification.from_pretrained(student_ckpt, config=student_config).to(device))"
      ],
      "metadata": {
        "id": "CWMVApsPNci3"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we need to define the metrics to track during training. As we did in the\n",
        "performance benchmark, we’ll use accuracy as the main metric so we can reuse our\n",
        "`accuracy_score` function in the `compute_metrics` function that we’ll include in the trainer:"
      ],
      "metadata": {
        "id": "sDfs6hUbN55r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(pred):\n",
        "  predictions, labels = pred\n",
        "  # find the most confident class prediction\n",
        "  predictions = np.argmax(predictions, axis=1)\n",
        "  # and compare that against the ground truth labels\n",
        "  return accuracy_score.compute(predictions=predictions, references=labels)"
      ],
      "metadata": {
        "id": "BJkOaxRFN99g"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Finally, we just need to define the training arguments. To warm-up, we’ll set $\\alpha = 1$ to see how well DistilBERT performs without any signal from the teacher:"
      ],
      "metadata": {
        "id": "7HuGGqt_P_MI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 48\n",
        "\n",
        "student_training_args = DistillationTrainingArguments(\n",
        "    output_dir=\"checkpoints\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    num_train_epochs=5,\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=batch_size,\n",
        "    per_device_eval_batch_size=batch_size,\n",
        "    alpha=1,\n",
        "    weight_decay=0.01\n",
        ")"
      ],
      "metadata": {
        "id": "2cuML55IQHLn"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next we load the teacher model, instantiate the trainer and start fine-tuning:"
      ],
      "metadata": {
        "id": "1Dz0_3o9Qqjc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "teacher_checkpoint = \"transformersbook/bert-base-uncased-finetuned-clinc\"\n",
        "teacher_model = (AutoModelForSequenceClassification.from_pretrained(teacher_checkpoint, num_labels=num_labels).to(device))"
      ],
      "metadata": {
        "id": "naP58JFbQrDO"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "distil_trainer = DistillationTrainer(model_init=student_init, \n",
        "                                     teacher_model=teacher_model,\n",
        "                                     args=student_training_args,\n",
        "                                     train_dataset=clinc_enc[\"train\"],\n",
        "                                     eval_dataset=clinc_enc[\"validation\"],\n",
        "                                     compute_metrics=compute_metrics,\n",
        "                                     tokenizer=student_tokenizer)"
      ],
      "metadata": {
        "id": "2VYL8HDKvYMr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Searching Hyperparameters with Optuna"
      ],
      "metadata": {
        "id": "djZ0VsfUitow"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To use Optuna in Transformers, we use logic by first defining the hyperparameter space that we wish to optimize over. \n",
        "\n",
        "In addition to $\\alpha$ and $T$, we’ll include the number of training epochs as follows:"
      ],
      "metadata": {
        "id": "pWJ8U18tt29M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def hp_space(trial):\n",
        "  return {\n",
        "      \"num_train_epochs\": trial.suggest_int(\"num_train_epochs\", 5, 10),\n",
        "      \"alpha\": trial.suggest_float(\"alpha\", 0, 1),\n",
        "      \"temperature\": trial.suggest_int(\"temperature\", 2, 20)\n",
        "  }"
      ],
      "metadata": {
        "id": "DfSs7BlcuJ9P"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Running the hyperparameter search with the `Trainer` is then quite simple; we just need to specify the number of trials to run and a direction to optimize for. \n",
        "\n",
        "Since we want the best possible accuracy, we pick `direction=\"maximize\"` in the\n",
        "`Trainer.hyperparameter_search` function and pass the hyperparameter search space as follows:"
      ],
      "metadata": {
        "id": "X2RnRgEQu0Ig"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#best_run = distil_trainer.hyperparameter_search(n_trials=9, direction=\"maximize\", hp_space=hp_space)"
      ],
      "metadata": {
        "id": "TaW2XKIEvAF6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `hyperparameter_search` method returns a `BestRun` object which contains the\n",
        "value of the objective that was maximized (by default the sum of all metrics) and the hyperparameters it used for that run:"
      ],
      "metadata": {
        "id": "wKADpZj9v7UC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#best_run"
      ],
      "metadata": {
        "id": "sE7kqdOSwA1G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This value of $\\alpha$ tells us that most of the training signal is coming from the knowledge distillation term. \n",
        "\n",
        "Let’s update our trainer with these values and run the final training run:"
      ],
      "metadata": {
        "id": "UXcJARmBwV3N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# just hard-coding hyper-parametrs due to Colab disk constraint\n",
        "hyperparameters={\"num_train_epochs\": 10, \"alpha\": 0.12468168730193585, \"temperature\": 7}\n",
        "\n",
        "#for k, v in best_run.hyperparameters.items():\n",
        "for k, v in hyperparameters.items():\n",
        "  setattr(distil_trainer.args, k, v)\n",
        "\n",
        "# now finally, train the model\n",
        "distil_trainer.train();"
      ],
      "metadata": {
        "id": "P73yTfPowcdN",
        "outputId": "2dbb1995-1d8b-4b82-dee0-bb5d5a1bad09",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 626
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "loading weights file https://huggingface.co/distilbert-base-uncased/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/9c169103d7e5a73936dd2b627e42851bec0831212b677c637033ee4bce9ab5ee.126183e36667471617ae2f0835fab707baa54b731f991507ebbb55ea85adb12a\n",
            "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_projector.bias', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_layer_norm.bias']\n",
            "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight', 'pre_classifier.weight', 'pre_classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "The following columns in the training set don't have a corresponding argument in `DistilBertForSequenceClassification.forward` and have been ignored: intent. If intent are not expected by `DistilBertForSequenceClassification.forward`,  you can safely ignore this message.\n",
            "/usr/local/lib/python3.7/dist-packages/transformers/optimization.py:309: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  FutureWarning,\n",
            "***** Running training *****\n",
            "  Num examples = 15250\n",
            "  Num Epochs = 10\n",
            "  Instantaneous batch size per device = 48\n",
            "  Total train batch size (w. parallel, distributed & accumulation) = 48\n",
            "  Gradient Accumulation steps = 1\n",
            "  Total optimization steps = 3180\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-42-e9992cb0e1c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# now finally, train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mdistil_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m             \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m             \u001b[0mtrial\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1321\u001b[0;31m             \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1322\u001b[0m         )\n\u001b[1;32m   1323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1552\u001b[0m                         \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1553\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1554\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1555\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1556\u001b[0m                 if (\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2181\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2182\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocast_smart_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2183\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2185\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_gpu\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-22-06b0ea950622>\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m     21\u001b[0m     )\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# Return weighted student loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mloss_ce\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs_student\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mreturn_outputs\u001b[0m \u001b[0;32melse\u001b[0m  \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mloss_ce\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mloss_kd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for *: 'float' and 'NoneType'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remarkably we’ve been able to train the student to match the accuracy of the teacher, despite having almost half the number of parameters! \n",
        "\n",
        "Let’s save the model for future use:"
      ],
      "metadata": {
        "id": "UAbMVYAtxBkL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "distil_trainer.save_model(\"models/distilbert-base-uncased-distilled-clinc\")"
      ],
      "metadata": {
        "id": "gBzSa92fxD0h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Benchmarking Our Distilled Model"
      ],
      "metadata": {
        "id": "AN8W3C1mxLrW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have an accurate student, let’s create a pipeline and redo our benchmark to see how we perform on the test set:"
      ],
      "metadata": {
        "id": "p7jjZW1PxQO2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "final_pipeline = TextClassificationPipeline(model=distil_trainer.model.to(\"cpu\"), tokenizer=distil_trainer.tokenizer)\n",
        "\n",
        "optim_type = \"Distillation\"\n",
        "pb = PerformanceBenchmark(final_pipeline, clinc[\"test\"], optim_type=optim_type)\n",
        "perf_metrics.update(pb.run_benchmark())"
      ],
      "metadata": {
        "id": "E2xvNsa-yfXp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To put these results in context, let’s also visualise them with our `plot_metrics` function:"
      ],
      "metadata": {
        "id": "QFxefKjLzeKd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_metrics(perf_metrics, optim_type)"
      ],
      "metadata": {
        "id": "DHYU9AN8zf3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As expected, the model size and latency remain essentially unchanged compared to the `DistilBERT` benchmark, but the accuracy has improved and even surpassed the performance of the teacher! \n",
        "\n",
        "We can actually compress our distilled model even further using a technique\n",
        "known as `quantization`."
      ],
      "metadata": {
        "id": "BKywL1zCzwXa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Quantization for Faster Models"
      ],
      "metadata": {
        "id": "ZgAMXKyfIGay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Quantizing Transformers in PyTorch"
      ],
      "metadata": {
        "id": "CiX6dfnwNp1E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The main bottleneck for running inference with Transformers is the compute and memory\n",
        "bandwidth associated with the enormous number of weights in these models. \n",
        "\n",
        "For this reason,\n",
        "dynamic quantization is currently the best approach for Transformer-based models in NLP. \n",
        "\n",
        "In smaller computer vision models the limiting factor is the memory bandwidth of the activations\n",
        "which is why static quantization is generally used and quantization aware training in cases\n",
        "where the performance drops are too significant.\n",
        "\n",
        "Implementing dynamic quantization in PyTorch is quite simple and can be done with a single line of code:"
      ],
      "metadata": {
        "id": "MentPLUoNqwI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_ckpt = \"models/distilbert-base-uncased-distilled-clinc\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)\n",
        "model = (AutoModelForSequenceClassification.from_pretrained(model_ckpt).to(\"cpu\"))\n",
        "\n",
        "# model_quantized = quantize_dynamic(model, {nn.Linear}, dtype=torch.qint8)"
      ],
      "metadata": {
        "id": "TU4Fymq7N5dK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Benchmarking Quantized Model"
      ],
      "metadata": {
        "id": "awvWOw7TOriq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Our model now quantized, let’s pass it through the benchmark and visualise the results:"
      ],
      "metadata": {
        "id": "2m8VezBTPDIn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "quantized_pipeline = TextClassificationPipeline(model=model_quantized, tokenizer=tokenizer)\n",
        "\n",
        "optim_type = \"Distillation + quantization\"\n",
        "pb = PerformanceBenchmark(quantized_pipeline, clinc[\"test\"], optim_type=optim_type)\n",
        "perf_metrics.update(pb.run_benchmark())"
      ],
      "metadata": {
        "id": "UqVhhe0zPJkj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_metrics(perf_metrics, optim_type)"
      ],
      "metadata": {
        "id": "3MVsiGVZPibn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wow, the quantized model is almost half the size of our distilled one and twice as fast! \n",
        "\n",
        "Let’s see if we can push our optimization to the limit with a powerful framework called `ONNX` in the next notebook."
      ],
      "metadata": {
        "id": "E2imB6ofPnwF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Optimizing Inference with ONNX"
      ],
      "metadata": {
        "id": "KFugIhWS0s1j"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ONNX is an open standard that defines a common set of operators and a common file format to represent deep learning models in a wide variety of frameworks, including PyTorch and TensorFlow. \n",
        "\n",
        "When a model is exported to the ONNX format, these operators are used to\n",
        "construct a computational graph (often called an intermediate representation) which represents the flow of data through the neural network.\n",
        "\n",
        "<img src='https://github.com/rahiakela/transformers-research-and-practice/blob/main/natural-language-processing-with-transformers/05-making-transformers-efficient-in-production/images/6.png?raw=1' width='600'/>\n",
        "\n",
        "By exposing a graph with standardized operators and data types, ONNX makes it easy to switch between frameworks. For example, a model trained in PyTorch can be exported to ONNX format and then imported in TensorFlow (and vice versa).\n",
        "\n",
        "Where ONNX really shines is when it is coupled with a dedicated accelerator like the ONNX\n",
        "Runtime, or ORT for short. ORT provides tools to optimize the ONNX graph through\n",
        "techniques like operator fusion and constant folding, and defines an interface to Execution Providers that allow you to run the model on different types of hardware.\n",
        "\n",
        "<img src='https://github.com/rahiakela/transformers-research-and-practice/blob/main/natural-language-processing-with-transformers/05-making-transformers-efficient-in-production/images/7.png?raw=1' width='600'/>\n",
        "\n",
        "To see ORT in action, the first thing we need to do is convert our distilled model into the ONNX format. \n",
        "\n",
        "Transformers has an in-built function called `convert_graph_to_onnx.convert` that simplifies the process by doing the following steps:\n",
        "\n",
        "- Initializes the model as a Pipeline\n",
        "- Runs dummy inputs through the pipeline so that ONNX can record the computational graph\n",
        "- Defines dynamic axes to handle dynamic sequence lengths\n",
        "- Saves the graph with network parameters\n",
        "\n",
        "To use this function, we first need to set some OpenMP environment variables for ONNX:"
      ],
      "metadata": {
        "id": "QZLqOunB0tqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%env OMP_NUM_THREADS={cpu_count()}   # sets the number of threads to use for parallel computations\n",
        "%env OMP_WAIT_POLICY=ACTIVE          # specifies that waiting threads should be active"
      ],
      "metadata": {
        "id": "5sRF6L4Z10Kb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, let’s convert our distilled model to the ONNX format. Here we need to specify the argument `pipeline_name=\"sentiment-analysis\"` since convert wraps the model in a Transformers `pipeline` during the conversion. We use the `sentiment-analysis` argument since this is the name of the text classification pipeline in Transformers. \n",
        "\n",
        "In addition to the `model_ckpt` we also pass the tokenizer to initialize the pipeline:"
      ],
      "metadata": {
        "id": "MNgZv5lS2xp8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "onnx_model_path = Path(\"onnx/model.onnx\")\n",
        "convert(framework=\"pt\", model=model_ckpt, tokenizer=tokenizer, output=onnx_model_path, opset=12, pipeline_name=\"sentiment-analysis\")"
      ],
      "metadata": {
        "id": "WLAVXzrc297B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we have our model saved, we need to create and inference session to feed inputs to the model:"
      ],
      "metadata": {
        "id": "7bTi3jPq3fko"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model_for_provider(model_path, provider=\"CPUExecutionProvider\"):\n",
        "  options = SessionOptions()\n",
        "  options.intra_op_num_threads = 1\n",
        "  options.graph_optimization_level = GraphOptimizationLevel.ORT_ENABLE_ALL\n",
        "\n",
        "  session = InferenceSession(str(model_path), options, providers=[provider])\n",
        "  session.disable_fallback()\n",
        "  return session"
      ],
      "metadata": {
        "id": "DskAvkAh3iB6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "onnx_model = create_model_for_provider(onnx_model_path)"
      ],
      "metadata": {
        "id": "Jy5UfkgKtYVG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s test this out with an example from the test set. \n",
        "\n",
        "Since the output from the `convert` function tells us that ONNX expects just the `input_ids` and `attention_mask` as inputs, we need to drop the `label` column from our sample:"
      ],
      "metadata": {
        "id": "d-A5QoShthEt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = clinc_enc[\"test\"][:1]\n",
        "del inputs[\"labels\"]\n",
        "\n",
        "logits_onnx = onnx_model.run(None, inputs)[0]\n",
        "logits_onnx.shape"
      ],
      "metadata": {
        "id": "NH7IyyMQtrrA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As expected, by specifying the `sentiment-analysis` pipeline name we get the class logits as the output so we can easily get the predicted label by taking the argmax:"
      ],
      "metadata": {
        "id": "OaFVEc9KuC0u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.argmax(logits_onnx)"
      ],
      "metadata": {
        "id": "UL_7sPdTuGFW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "which indeed agrees with the ground truth label:"
      ],
      "metadata": {
        "id": "YEgXlromuMaz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clinc_enc[\"test\"][0][\"labels\"]"
      ],
      "metadata": {
        "id": "rwtsQYgYuM4W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since we cannot use the `TextClassificationPipeline` class to wrap our ONNX\n",
        "model, we’ll create our own class that mimics the core behaviour."
      ],
      "metadata": {
        "id": "qd1y-rJuuT9q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class OnnxPipeline:\n",
        "  def __init__(self, model, tokenizer):\n",
        "    self.model = model\n",
        "    self.tokenizer = tokenizer\n",
        "\n",
        "  def __call__(self, query):\n",
        "    model_inputs = self.tokenizer(query, return_tensors=\"pt\")\n",
        "    inputs_onnx = {k: v.cpu().detach().numpy() for k, v in model_inputs.items()}\n",
        "    logits = self.model.run(None, inputs_onnx)[0][0, :]\n",
        "    probs = softmax(logits)\n",
        "    pred_idx = np.argmax(probs).item()\n",
        "    return [{\"label\": intents.int2str(pred_idx), \"score\": probs[pred_idx]}]"
      ],
      "metadata": {
        "id": "UlnDdMA8vdKK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can then test this on our simple query to see if we recover the `car_rental` intent:"
      ],
      "metadata": {
        "id": "Kus2jyJ7w3O-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "onnx_pipeline = OnnxPipeline(onnx_model, tokenizer)\n",
        "onnx_pipeline(query)"
      ],
      "metadata": {
        "id": "ZwiPIdoQw5H2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Great, our pipeline works well so the next step is to create a performance benchmark for ONNX models.\n",
        "\n",
        "Here we can build on the work we did with the `PerformanceBenchmark`\n",
        "class by simply overriding the `compute_size` function and leaving the\n",
        "`compute_accuracy` and `time_pipeline` functions intact. \n",
        "\n",
        "The reason we need to\n",
        "override the `compute_size` function is that we cannot rely on the `state_dict` and `torch.save` to measure a model’s size since `onnx_model` is technically an ONNX InferenceSession object which doesn’t have access to the attributes of PyTorch’s `nn.Module`."
      ],
      "metadata": {
        "id": "Xcs2Ego1xZQN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class OnnxPerformanceBenchmark(PerformanceBenchmark):\n",
        "  def __init__(self, *args, model_path, **kwargs):\n",
        "    super().__init__(*args, **kwargs)\n",
        "    self.model_path = model_path\n",
        "\n",
        "  def compute_size(self):\n",
        "    size_mb = Path(self.model_path).stat().st_size / (1024 * 1024)\n",
        "    print(f\"Model size (MB) - {size_mb: .2f}\")\n",
        "    return {\"size_mb\": size_mb}"
      ],
      "metadata": {
        "id": "s_8CETXkxxi2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "With our new benchmark, let’s see how our distilled model performs when converted to ONNX format:"
      ],
      "metadata": {
        "id": "2D0mj6why6ce"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "optim_type = \"Distillation + ORT\"\n",
        "pb = OnnxPerformanceBenchmark(onnx_pipeline, clinc[\"test\"], optim_type=optim_type, model_path=\"onnx/model.onnx\")\n",
        "perf_metrics.update(pb.run_benchmark())"
      ],
      "metadata": {
        "id": "vv2Kk9OYy7l_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_metrics(perf_metrics, optim_type)"
      ],
      "metadata": {
        "id": "OkdfITxGzSLM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remarkably, converting to the ONNX format and using the ONNX runtime has more than halved the average latency of our distilled model (and is almost five times faster than our baseline)! \n",
        "\n",
        "Let’s see if we can squeeze a bit more performance by applying some Transformerspecific optimizations."
      ],
      "metadata": {
        "id": "PL_BODDo8S41"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Optimizing for Transformer Architectures"
      ],
      "metadata": {
        "id": "6MDXsyOp8XZM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ONNX Runtime library also offers an `optimizer` module that\n",
        "contains some Transformer-specific optimizations that we can try to see if the model is fully optimized or not. To use the `optimizer` module we first need to define some optimization options that are specific to our model.\n",
        "\n",
        "In our case, `DistilBERT` belongs to the bert model type\n",
        "so we need to use the `BertOptimizationOptions` class from `onnxruntime_tools`:\n",
        "\n"
      ],
      "metadata": {
        "id": "kGBz0xN28Z8F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_type = \"bert\"\n",
        "opt_options = BertOptimizationOptions(model_type)\n",
        "opt_options.enable_embed_layer_norm = False"
      ],
      "metadata": {
        "id": "3vPjIPWmBOXy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here we’ve disabled the norm optimization on the embedding layer to get better model size compression. Now that we’ve specified the model options, we can then run `optimizer.optimize_model` to optimize the ONNX model specifically for BERT-like architectures:"
      ],
      "metadata": {
        "id": "hjczWGZEBnBg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "opt_model = optimizer.optimize_model(\"onnx/model.onnx\", \n",
        "                                     model_type, num_heads=12, hidden_size=768,\n",
        "                                     optimization_options=opt_options)\n",
        "opt_model.save_model_to_file(\"onnx/model.opt.onnx\")"
      ],
      "metadata": {
        "id": "fd6Wnz03BvNg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The last thing to do is create an inference session for our optimized model, wrap it in a pipeline and run it through our benchmark:"
      ],
      "metadata": {
        "id": "DaJok8s9CSkq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "onnx_model_opt = create_model_for_provider(\"onnx/model.opt.onnx\")\n",
        "onnx_pipeline = OnnxPipeline(onnx_model_opt, tokenizer)\n",
        "\n",
        "optim_type = \"Distillation + ORT (optimized)\"\n",
        "pb = OnnxPerformanceBenchmark(onnx_pipeline, clinc[\"test\"], optim_type, model_path=\"onnx/model.opt.onnx\")\n",
        "perf_metrics.update(pb.run_benchmark())"
      ],
      "metadata": {
        "id": "6502f4pdCU1J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_metrics(perf_metrics, optim_type)"
      ],
      "metadata": {
        "id": "3yEQGTwnDBBp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Okay, it seems that our original ORT optimization was already close to the optimal one for this architecture.\n",
        "\n",
        "Let’s now see what happens if we add quantization to the mix. Similar to PyTorch, ORT offers three ways to quantize a model: dynamic, static, and quantization aware training.\n",
        "\n",
        "In ORT, the\n",
        "quantization is applied through the quantize_dynamic function which requires a path to\n",
        "the ONNX model to quantize, a target path to save the quantized model to, and the data type to\n",
        "reduce the weights to:"
      ],
      "metadata": {
        "id": "WAIwPmE6DfnY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_input = \"onnx/model.onnx\"\n",
        "model_output = \"onnx/model.quant.onnx\"\n",
        "quantize_dynamic(model_input, model_output, weight_type=QuantType.QInt8)"
      ],
      "metadata": {
        "id": "VfnHDl8SDrHf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that the model is quantized, let’s run it through our benchmark:"
      ],
      "metadata": {
        "id": "qT1nzg7FEJc8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "onnx_quantized_model = create_model_for_provider(model_output)\n",
        "onnx_quantized_pipeline = OnnxPipeline(onnx_quantized_model, tokenizer)\n",
        "\n",
        "optim_type = \"Distillation + ORT (optimized)\"\n",
        "pb = OnnxPerformanceBenchmark(onnx_quantized_pipeline, clinc[\"test\"], optim_type, model_path=model_output)\n",
        "perf_metrics.update(pb.run_benchmark())"
      ],
      "metadata": {
        "id": "h6FCUA76EKE9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_metrics(perf_metrics, optim_type)"
      ],
      "metadata": {
        "id": "YMV6dkdCEuUu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Wow, ORT quantization has reduced the model size and latency by around a factor of two\n",
        "compared to the model obtained from PyTorch quantization (the Distillation + quantization\n",
        "blob). \n",
        "\n",
        "One reason for this is that PyTorch only optimizes the nn.Linear modules, while\n",
        "ONNX quantizes the embedding layer as well.\n",
        "\n",
        "We have seen that methods such as quantization reduce the model size by reducing the precision of the representation. Another strategy to reduce the size is to remove some weights altogether - this technique is called **weight pruning**."
      ],
      "metadata": {
        "id": "jOQfn5QLE34T"
      }
    }
  ]
}