{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "tour-of-transformer-applications.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN5L0HLK2TxOPWtKuE6PQOc",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/transformers-research-and-practice/blob/main/natural-language-processing-with-transformers/01-hello-transformers/tour_of_transformer_applications.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OtKVmqdL3i55"
      },
      "source": [
        "##Tour of Transformer Applications"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lS2IyueG3jyx"
      },
      "source": [
        "Text is everywhere around us and being able to understand and act on information we can find\n",
        "in text is a crucial aspect in every company. Every NLP task starts with a piece of text, like the\n",
        "following made-up customer feedback about a certain online order:\n",
        "\n",
        "```python\n",
        "text = \"\"\"Dear Amazon, last week I ordered an Optimus Prime action figure \\\n",
        "from your online store in Germany. Unfortunately, when I opened the package, \\\n",
        "I discovered to my horror that I had been sent an action figure of Megatron \\\n",
        "instead! As a lifelong enemy of the Decepticons, I hope you can understand my \\\n",
        "dilemma. To resolve the issue, I demand an exchange of Megatron for the \\\n",
        "Optimus Prime figure I ordered. Enclosed are copies of my records concerning \\\n",
        "this purchase. I expect to hear from you soon. Sincerely, Bumblebee.\"\"\"\n",
        "```\n",
        "\n",
        "Depending on your application, this text could be a legal contract, a product description or\n",
        "something else entirely.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y56gWasI3399"
      },
      "source": [
        "##Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYC6jxyO-FtT"
      },
      "source": [
        "!pip -q install transformers[sentencepiece]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eB4MarKn35T6"
      },
      "source": [
        "from transformers import pipeline\n",
        "from transformers import set_seed\n",
        "\n",
        "import pandas as pd"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nn1KM8CF4t6o"
      },
      "source": [
        "text = \"\"\"Dear Amazon, last week I ordered an Optimus Prime action figure \\\n",
        "from your online store in Germany. Unfortunately, when I opened the package, \\\n",
        "I discovered to my horror that I had been sent an action figure of Megatron \\\n",
        "instead! As a lifelong enemy of the Decepticons, I hope you can understand my \\\n",
        "dilemma. To resolve the issue, I demand an exchange of Megatron for the \\\n",
        "Optimus Prime figure I ordered. Enclosed are copies of my records concerning \\\n",
        "this purchase. I expect to hear from you soon. Sincerely, Bumblebee.\"\"\""
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzVDkwTu35dR"
      },
      "source": [
        "##Text Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9_PtWVS236NB"
      },
      "source": [
        "Transformers has a layered API which allows you to interact with\n",
        "the library at various levels of abstraction. \n",
        "\n",
        "We’ll start with the most high level\n",
        "API pipelines, which abstract away all the steps needed to convert raw text into a set of predictions from a fine-tuned model.\n",
        "\n",
        "In Transformers, we instantiate a pipeline by providing the name of the task we are\n",
        "interested in:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D6JbSg2K4UrV"
      },
      "source": [
        "classifier = pipeline(\"sentiment-analysis\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jz6fCDVe4g65"
      },
      "source": [
        "Now that we have our pipeline, let’s generate some predictions! Each pipeline takes a string of\n",
        "text (or a list of strings) as input and returns a list of predictions. Each prediction is a Python\n",
        "dictionary, so we can use Pandas to display them nicely as a DataFrame:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "rHutZc_q4buV",
        "outputId": "beb979ad-7d08-448f-bfb1-4df1bba113e8"
      },
      "source": [
        "outputs = classifier(text)\n",
        "pd.DataFrame.from_records(outputs)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>NEGATIVE</td>\n",
              "      <td>0.901546</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      label     score\n",
              "0  NEGATIVE  0.901546"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M8ycCGvt42vp"
      },
      "source": [
        "In this case the model is very confident that the text has a negative sentiment, which makes\n",
        "sense given that we’re dealing with complaint from an irate Autobot!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eniSSAxU43VY"
      },
      "source": [
        "##Named Entity Recognition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9WnAZe5g45at"
      },
      "source": [
        "Predicting the sentiment of customer feedback is a good first step, but you often want to know\n",
        "if the feedback was about a particular product or service. Names of products, places or people\n",
        "are called named entities and detecting and extracting them from text is called named entity\n",
        "recognition (NER). \n",
        "\n",
        "We can apply NER by spinning up the corresponding pipeline and feeding\n",
        "our piece of text to it:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YTh5T32-5OXN"
      },
      "source": [
        "ner_tagger = pipeline(\"ner\", aggregation_strategy=\"simple\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "aVEQ8zBH5YLB",
        "outputId": "bcaca2eb-9493-4f70-feaa-1366caf16688"
      },
      "source": [
        "outputs = ner_tagger(text)\n",
        "pd.DataFrame.from_records(outputs)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>entity_group</th>\n",
              "      <th>score</th>\n",
              "      <th>word</th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>ORG</td>\n",
              "      <td>0.879010</td>\n",
              "      <td>Amazon</td>\n",
              "      <td>5</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>MISC</td>\n",
              "      <td>0.990859</td>\n",
              "      <td>Optimus Prime</td>\n",
              "      <td>36</td>\n",
              "      <td>49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>LOC</td>\n",
              "      <td>0.999755</td>\n",
              "      <td>Germany</td>\n",
              "      <td>90</td>\n",
              "      <td>97</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>MISC</td>\n",
              "      <td>0.556570</td>\n",
              "      <td>Mega</td>\n",
              "      <td>208</td>\n",
              "      <td>212</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>PER</td>\n",
              "      <td>0.590256</td>\n",
              "      <td>##tron</td>\n",
              "      <td>212</td>\n",
              "      <td>216</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>ORG</td>\n",
              "      <td>0.669692</td>\n",
              "      <td>Decept</td>\n",
              "      <td>253</td>\n",
              "      <td>259</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>MISC</td>\n",
              "      <td>0.498349</td>\n",
              "      <td>##icons</td>\n",
              "      <td>259</td>\n",
              "      <td>264</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>MISC</td>\n",
              "      <td>0.775362</td>\n",
              "      <td>Megatron</td>\n",
              "      <td>350</td>\n",
              "      <td>358</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>MISC</td>\n",
              "      <td>0.987854</td>\n",
              "      <td>Optimus Prime</td>\n",
              "      <td>367</td>\n",
              "      <td>380</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>PER</td>\n",
              "      <td>0.812096</td>\n",
              "      <td>Bumblebee</td>\n",
              "      <td>502</td>\n",
              "      <td>511</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  entity_group     score           word  start  end\n",
              "0          ORG  0.879010         Amazon      5   11\n",
              "1         MISC  0.990859  Optimus Prime     36   49\n",
              "2          LOC  0.999755        Germany     90   97\n",
              "3         MISC  0.556570           Mega    208  212\n",
              "4          PER  0.590256         ##tron    212  216\n",
              "5          ORG  0.669692         Decept    253  259\n",
              "6         MISC  0.498349        ##icons    259  264\n",
              "7         MISC  0.775362       Megatron    350  358\n",
              "8         MISC  0.987854  Optimus Prime    367  380\n",
              "9          PER  0.812096      Bumblebee    502  511"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2l2qlAQ5864"
      },
      "source": [
        "You can see that the pipeline detected all the entities and also assigned a category such as ORG\n",
        "(organization), LOC (location) or PER (person) to them.\n",
        "\n",
        "Here we used the\n",
        "aggregation_strategy argument to group the words according to the model’s\n",
        "predictions; for example “Optimus Prime” has two words but is assigned a single MISC\n",
        "(miscellaneous) category. The scores tell us how confident the model was about the entity and\n",
        "we can see that it was least confident about “Decepticons” and the first occurrence of\n",
        "“Megatron”, both of which it failed to group as a single entity.\n",
        "\n",
        "Extracting all the named entities is nice but sometimes we would like to ask more targeted\n",
        "questions. This is where we can use question answering."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhni5UD-6JHq"
      },
      "source": [
        "##Question Answering"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmvmAmue6O7E"
      },
      "source": [
        "In question answering we provide the model with a passage of text called the context, along\n",
        "with a question whose answer we’d like to extract. The model then returns the span of text\n",
        "corresponding to the answer. \n",
        "\n",
        "So let’s see what we get when we ask a specific question about the\n",
        "text:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6a8fDpPw6XXz"
      },
      "source": [
        "reader = pipeline(\"question-answering\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "ALXVrauv6jKI",
        "outputId": "088c9e5d-45ec-4351-fece-40b08ab2bd97"
      },
      "source": [
        "question = \"What does the customer want?\"\n",
        "outputs = reader(question=question, context=text)\n",
        "pd.DataFrame.from_records([outputs])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>score</th>\n",
              "      <th>start</th>\n",
              "      <th>end</th>\n",
              "      <th>answer</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.631292</td>\n",
              "      <td>335</td>\n",
              "      <td>358</td>\n",
              "      <td>an exchange of Megatron</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      score  start  end                   answer\n",
              "0  0.631292    335  358  an exchange of Megatron"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oRFgJlh27D4Q"
      },
      "source": [
        "There are several flavors of question answering, but this particular kind\n",
        "is called extractive question answering because the answer is extracted directly from the text.\n",
        "\n",
        "With this approach you can read and extract relevant information quickly from a customer’s feedback.\n",
        "\n",
        "But what if you get a mountain of long-winded complaints and you don’t have the\n",
        "time to read them all? Let’s see if a summarization model can help!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-T51iQd8ikX"
      },
      "source": [
        "##Summarization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zCFz8IBe8kRZ"
      },
      "source": [
        "The goal of text summarization is to take a long text as input and generate a short version with\n",
        "all relevant facts. This is a much more complicated task than the previous ones since it requires the model to produce coherent text as output. \n",
        "\n",
        "In what should be a familiar pattern by now, we\n",
        "can instantiate a summarization pipeline as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GTNUbzj28xj8"
      },
      "source": [
        "summarizer = pipeline(\"summarization\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjia86gH83KB",
        "outputId": "02470fa0-f288-4944-8f60-61b862d1c90c"
      },
      "source": [
        "outputs = summarizer(text, max_length=45, clean_up_tokenization_spaces=True)\n",
        "print(outputs[0][\"summary_text\"])"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Bumblebee ordered an Optimus Prime action figure from your online store in Germany. Unfortunately, when I opened the package, I discovered to my horror that I had been sent an action figure of Megatron instead.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-iuJirr59X4g"
      },
      "source": [
        "This isn’t too bad! Although parts of the original text have been copy-pasted, the model was\n",
        "able to correctly identify that “Bumblebee” (which appeared at the end) was the author of the\n",
        "complaint, and has captured the essence of the problem.\n",
        "\n",
        "But what happens when you get a feedback that is in a language you don’t\n",
        "understand? You could use Google Translate or you can use your very own transformer to\n",
        "translate it for you!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4UUABUOa9dUX"
      },
      "source": [
        "##Translation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zwMbp9wf9fSI"
      },
      "source": [
        "Like summarization, translation is a task where the output consists of generated text. \n",
        "\n",
        "Let’s use\n",
        "the translation pipeline to translate the English text to German:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LwYZwjct9jQM"
      },
      "source": [
        "translator = pipeline(\"translation_en_to_de\", model=\"Helsinki-NLP/opus-mt-en-de\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tBL9QORK9ugI",
        "outputId": "ab492add-b0cf-4d09-965b-3fb3ccd5212e"
      },
      "source": [
        "outputs = translator(text, clean_up_tokenization_spaces=True, min_length=100)\n",
        "print(outputs[0][\"translation_text\"])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sehr geehrter Amazon, letzte Woche habe ich eine Optimus Prime Action Figur aus Ihrem Online-Shop in Deutschland bestellt. Leider, als ich das Paket öffnete, entdeckte ich zu meinem Entsetzen, dass ich stattdessen eine Action Figur von Megatron geschickt worden war! Als lebenslanger Feind der Decepticons, Ich hoffe, Sie können mein Dilemma verstehen. Um das Problem zu lösen, Ich fordere einen Austausch von Megatron für die Optimus Prime Figur habe ich bestellt. Anbei sind Kopien meiner Aufzeichnungen über diesen Kauf. Ich erwarte, bald von Ihnen zu hören. Aufrichtig, Bumblebee.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0Daa4dl-1DI"
      },
      "source": [
        "Again, the model has produced a very good translation that correctly uses the formal pronouns\n",
        "like “Ihrem” and “Sie” in German! \n",
        "\n",
        "Here we’ve also shown how you can override the default\n",
        "model in the pipeline to pick the best one for your application, and you can find models for\n",
        "thousands of language pairs on the Hub."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V7h0yAzU-2-D"
      },
      "source": [
        "##Text Generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ndDApx_x-5dF"
      },
      "source": [
        "Let’s say you would like to write faster answers to customer feedback by having access to an\n",
        "autocomplete function.\n",
        "\n",
        "With a text generation model you can continue an input text as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBh2pA-k_GHK"
      },
      "source": [
        "set_seed(42)\n",
        "\n",
        "generator = pipeline(\"text-generation\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dVlELWuj_Sq-",
        "outputId": "14ba5d9c-2d4f-49e7-d289-c9d7e64652c1"
      },
      "source": [
        "response = \"Dear Bumblebee, I am sorry to hear that your order was mixed up.\"\n",
        "\n",
        "prompt = text + \"\\n\\nCustomer service response:\\n\" + response\n",
        "outputs = generator(prompt, max_length=200)\n",
        "print(outputs[0][\"generated_text\"])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dear Amazon, last week I ordered an Optimus Prime action figure from your online store in Germany. Unfortunately, when I opened the package, I discovered to my horror that I had been sent an action figure of Megatron instead! As a lifelong enemy of the Decepticons, I hope you can understand my dilemma. To resolve the issue, I demand an exchange of Megatron for the Optimus Prime figure I ordered. Enclosed are copies of my records concerning this purchase. I expect to hear from you soon. Sincerely, Bumblebee.\n",
            "\n",
            "Customer service response:\n",
            "Dear Bumblebee, I am sorry to hear that your order was mixed up. I have received your order. I would apologize in advance. I feel bad for you, but if my previous order wasn't received late, I apologize as well. I regret not sending you a package in advance. Thank you for your patience. We appreciate you coming to our store in Germany.\n",
            "\n",
            "Packing for the Optimus Prime\n"
          ]
        }
      ]
    }
  ]
}