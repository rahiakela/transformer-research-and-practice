{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "question-answering.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPtsAmZbtLFNx7bQTSBHjQ7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/transformers-research-and-practice/blob/main/natural-language-processing-with-transformers/07-question-answering/question_answering.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Question Answering"
      ],
      "metadata": {
        "id": "GMN-3GGZJ4tD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Setup"
      ],
      "metadata": {
        "id": "FxxA5iitLJi8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install transformers[sentencepiece]\n",
        "!pip -q install datasets\n",
        "!pip install farm-haystack"
      ],
      "metadata": {
        "id": "EVi7I2MwMFYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "\n",
        "from transformers import pipeline\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import AutoModelForQuestionAnswering\n",
        "from datasets import get_dataset_config_names\n",
        "from datasets import load_dataset\n",
        "\n",
        "from haystack.document_store.elasticsearch import ElasticsearchDocumentStore\n",
        "from haystack.retriever.sparse import ElasticsearchRetriever\n",
        "from haystack.reader.farm import FARMReader\n",
        "from haystack.pipeline import ExtractiveQAPipeline"
      ],
      "metadata": {
        "id": "jwK0oo9kLLJ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import logging\n",
        "from subprocess import Popen, PIPE, STDOUT\n",
        "\n",
        "for module in [\"farm.utils\", \"farm.infer\", \"haystack.reader.farm.FARMReader\",\n",
        "              \"farm.modeling.prediction_head\", \"elasticsearch\", \"haystack.eval\",\n",
        "               \"haystack.document_store.base\", \"haystack.retriever.base\", \n",
        "              \"farm.data_handler.dataset\"]:\n",
        "    module_logger = logging.getLogger(module)\n",
        "    module_logger.setLevel(logging.ERROR)"
      ],
      "metadata": {
        "id": "wmRKWTWfLOxN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##The Dataset"
      ],
      "metadata": {
        "id": "yRKPr4gwMwWu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# use the get_dataset_config_names() function to find out which subsets are available\n",
        "domains = get_dataset_config_names(\"subjqa\")\n",
        "domains"
      ],
      "metadata": {
        "id": "BJJKVJnUMxDK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's download the electronics subset\n",
        "subjqa = load_dataset(\"subjqa\", \"electronics\")"
      ],
      "metadata": {
        "id": "giwXzvO9NTIb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(subjqa[\"train\"][\"answers\"][1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AOW2OEp0N_dl",
        "outputId": "eb65dee1-a03a-4ba8-9037-563264729609"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'text': ['Bass is weak as expected', 'Bass is weak as expected, even with EQ adjusted up'], 'answer_start': [1302, 1302], 'answer_subj_level': [1, 1], 'ans_subj_score': [0.5083333253860474, 0.5083333253860474], 'is_ans_subjective': [True, True]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert each split to a Pandas DataFrame\n",
        "dfs = {split: dset.to_pandas() for split, dset in subjqa.flatten().items()}\n",
        "for split, df in dfs.items():\n",
        "  print(f\"Number of questions in {split}: {df['id'].nunique()}\")"
      ],
      "metadata": {
        "id": "0OQ9uGugPoJQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Let’s focus on these columns and take a look at a few of the training examples\n",
        "qa_cols = [\"title\", \"question\", \"answers.text\", \"answers.answer_start\", \"context\"]\n",
        "\n",
        "sample_df = dfs[\"train\"][qa_cols].sample(2, random_state=7)\n",
        "sample_df"
      ],
      "metadata": {
        "id": "gabfRFLsR9oS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# use the start index and length of the answer span to slice out the span of text in the review that corresponds to the answer\n",
        "start_idx = sample_df[\"answers.answer_start\"].iloc[0][0]\n",
        "end_idx = start_idx + len(sample_df[\"answers.text\"].iloc[0][0])\n",
        "sample_df[\"context\"].iloc[0][start_idx: end_idx]"
      ],
      "metadata": {
        "id": "KiupvrSKSm8d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let’s get a feel for what types of questions are in the training set by counting the questions that begin with a few common starting words\n",
        "counts = {}\n",
        "question_types = [\"What\", \"How\", \"Is\", \"Does\", \"Do\", \"Was\", \"Where\", \"Why\"]\n",
        "\n",
        "for q in question_types:\n",
        "  counts[q] = dfs[\"train\"][\"question\"].str.startswith(q).value_counts()[True]\n",
        "\n",
        "pd.Series(counts).sort_values().plot.barh()\n",
        "plt.title(\"Frequency of Question Types\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dtS9N4tVTQ9o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let’s have a look at some examples\n",
        "for question_type in [\"How\", \"What\", \"Is\"]:\n",
        "  for question in (dfs[\"train\"][dfs[\"train\"].question.str.startswith(question_type)].sample(n=3, random_state=42)[\"question\"]):\n",
        "    print(question)"
      ],
      "metadata": {
        "id": "IEqIv4hrUXkU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Extracting Answers from Text"
      ],
      "metadata": {
        "id": "0_V8aOc3VE3m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# let's load the MiniLM model checkpoint\n",
        "model_ckpt = \"deepset/minilm-uncased-squad2\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_ckpt)"
      ],
      "metadata": {
        "id": "7QM1ttrkU7Rr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To see the model in action, let’s first try to extract an answer from a short passage of text. \n",
        "\n",
        "In extractive QA tasks, the inputs are provided as (question, context) pairs."
      ],
      "metadata": {
        "id": "hyHLYGJvZNtV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "question = \"How much music can this hold?\"\n",
        "context = \"\"\" An MP3 is about 1 MB/minute, so about 6000 hours depending on file size.\"\"\"\n",
        "inputs = tokenizer(question, context, return_tensors=\"pt\")"
      ],
      "metadata": {
        "id": "UEXQWYQcZCXm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_df = pd.DataFrame.from_dict(tokenizer(question, context), orient=\"index\")\n",
        "input_df"
      ],
      "metadata": {
        "id": "H26CWa-AZws-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let’s decode the input_ids tensor\n",
        "print(tokenizer.decode(inputs[\"input_ids\"][0]))"
      ],
      "metadata": {
        "id": "jKUPA54OfAfi",
        "outputId": "c493aa6f-4dbd-4578-dc35-a9f95075875f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLS] how much music can this hold? [SEP] an mp3 is about 1 mb / minute, so about 6000 hours depending on file size. [SEP]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, we just need to instantiate the model with a QA head\n",
        "and run the inputs through the forward pass."
      ],
      "metadata": {
        "id": "RTZnLSrhgW0_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoModelForQuestionAnswering.from_pretrained(model_ckpt)"
      ],
      "metadata": {
        "id": "QIU7dkE0gYlT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with torch.no_grad():\n",
        "  outputs = model(**inputs)\n",
        "print(outputs)"
      ],
      "metadata": {
        "id": "bulp3pFqglbk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# get the logits for the start and end tokens\n",
        "start_logits = outputs.start_logits\n",
        "end_logits = outputs.end_logits\n",
        "\n",
        "print(f\"Input IDs shape: {inputs.input_ids.size()}\")\n",
        "print(f\"Start logits shape: {start_logits.size()}\")\n",
        "print(f\"End logits shape: {end_logits.size()}\")"
      ],
      "metadata": {
        "id": "-_cDXOwYhEmD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s_scores = start_logits.detach().numpy().flatten()\n",
        "e_scores = end_logits.detach().numpy().flatten()\n",
        "tokens = tokenizer.convert_ids_to_tokens(inputs[\"input_ids\"][0])\n",
        "\n",
        "fig, (ax1, ax2) = plt.subplots(nrows=2, sharex=True)\n",
        "colors = [\"C0\" if s != np.max(s_scores) else \"C1\" for s in s_scores]\n",
        "ax1.bar(x=tokens, height=s_scores, color=colors)\n",
        "ax1.set_ylabel(\"Start Scores\")\n",
        "colors = [\"C0\" if s != np.max(e_scores) else \"C1\" for s in e_scores]\n",
        "ax2.bar(x=tokens, height=e_scores, color=colors)\n",
        "ax2.set_ylabel(\"End Scores\")\n",
        "plt.xticks(rotation=\"vertical\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "stjoOqglh-ru"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "To get the final answer, we can compute the argmax over the start and end token logits\n",
        "and then slice the span from the inputs."
      ],
      "metadata": {
        "id": "eZqgOh_tiR4l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "start_idx = torch.argmax(start_logits)\n",
        "end_idx = torch.argmax(end_logits) + 1\n",
        "\n",
        "answer_span = inputs[\"input_ids\"][0][start_idx : end_idx]\n",
        "answer = tokenizer.decode(answer_span)\n",
        "\n",
        "print(f\"Question: {question}\")\n",
        "print(f\"Answer: {answer}\")"
      ],
      "metadata": {
        "id": "z8l1nAiBiSZm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In Transformers, all of these preprocessing and postprocessing\n",
        "steps are conveniently wrapped in a dedicated pipeline."
      ],
      "metadata": {
        "id": "oXeWCosDMVdF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipe = pipeline(\"question-answering\", model=model, tokenizer=tokenizer)\n",
        "pipe(question=question, context=context, top_k=3)"
      ],
      "metadata": {
        "id": "0FEnl3LpMWIb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# it is possible to have questions for which no answer is possible\n",
        "pipe(question=\"Why is there no data?\", context=context, handle_impossible_answer=True)"
      ],
      "metadata": {
        "id": "g8mzyx6aPHii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Dealing with long passages"
      ],
      "metadata": {
        "id": "xymWA-f5PfVF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For other tasks, like text classification, we simply truncated long texts under the\n",
        "assumption that enough information was contained in the embedding of the `[CLS]`\n",
        "token to generate accurate predictions. \n",
        "\n",
        "For QA, however, this strategy is problematic\n",
        "because the answer to a question could lie near the end of the context and thus would\n",
        "be removed by truncation."
      ],
      "metadata": {
        "id": "urfOKzBjPgUO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#caption Distribution of tokens for each question-context pair in the SubjQA training set\n",
        "def compute_input_length(row):\n",
        "    inputs = tokenizer(row[\"question\"], row[\"context\"])\n",
        "    return len(inputs[\"input_ids\"])\n",
        "\n",
        "dfs[\"train\"][\"n_tokens\"] = dfs[\"train\"].apply(compute_input_length, axis=1)\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "dfs[\"train\"][\"n_tokens\"].hist(bins=100, grid=False, ec=\"C0\", ax=ax)\n",
        "plt.xlabel(\"Number of tokens in question-context pair\")\n",
        "ax.axvline(x=512, ymin=0, ymax=1, linestyle=\"--\", color=\"C1\", label=\"Maximum sequence length\")\n",
        "plt.legend()\n",
        "plt.ylabel(\"Count\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rBsX6eRYR2h4",
        "outputId": "3d459c73-ec6f-4b8f-ba0b-95e5f147ac4b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The standard way to deal with this is to apply a sliding window across the inputs, where each window contains a passage of tokens that fit in the model’s context."
      ],
      "metadata": {
        "id": "2Xh8kwZ3R5c4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Let’s grab the first example from our training set and define a small window\n",
        "example = dfs[\"train\"].iloc[0][[\"question\", \"context\"]]\n",
        "tokenized_example = tokenizer(example[\"question\"], example[\"context\"],\n",
        "                              return_overflowing_tokens=True,\n",
        "                              max_length=100,\n",
        "                              stride=25)"
      ],
      "metadata": {
        "id": "m2tVBx5yRGr2",
        "outputId": "b8d9209e-92b9-4c6f-d1da-423ccb77ae8a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let’s check the number of tokens we have in each window\n",
        "for idx, window in enumerate(tokenized_example[\"input_ids\"]):\n",
        "  print(f\"Window #{idx} has {len(window)} tokens\")"
      ],
      "metadata": {
        "id": "WSdHRsEASEVp",
        "outputId": "f6fc2500-0972-4eeb-eb9b-5b9897b41ca8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Window #0 has 100 tokens\n",
            "Window #1 has 88 tokens\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Finally, we can see where two windows overlap by decoding the inputs\n",
        "for window in tokenized_example[\"input_ids\"]:\n",
        "  print(f\"{tokenizer.decode(window)} \\n\")"
      ],
      "metadata": {
        "id": "yyBP7vXJSyAe",
        "outputId": "bf0f8436-bc99-41e9-ec7a-8edda78702d8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLS] how is the bass? [SEP] i have had koss headphones in the past, pro 4aa and qz - 99. the koss portapro is portable and has great bass response. the work great with my android phone and can be \" rolled up \" to be carried in my motorcycle jacket or computer bag without getting crunched. they are very light and don't feel heavy or bear down on your ears even after listening to music with them on all day. the sound is [SEP] \n",
            "\n",
            "[CLS] how is the bass? [SEP] and don't feel heavy or bear down on your ears even after listening to music with them on all day. the sound is night and day better than any ear - bud could be and are almost as good as the pro 4aa. they are \" open air \" headphones so you cannot match the bass to the sealed types, but it comes close. for $ 32, you cannot go wrong. [SEP] \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Using Haystack to Build a QA Pipeline"
      ],
      "metadata": {
        "id": "CZ1vxTWhTJH3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Haystack is based on the retriever-reader architecture,\n",
        "abstracts much of the complexity involved in building these systems, and\n",
        "integrates tightly with Transformers."
      ],
      "metadata": {
        "id": "w8_7Mhg-nLh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Initializing a document store"
      ],
      "metadata": {
        "id": "jEBVM8esoTJZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "url = \"https://artifacts.elastic.co/downloads/elasticsearch/elasticsearch-7.9.2-linux-x86_64.tar.gz\"\n",
        "\n",
        "!wget -nc -q {url}\n",
        "!tar -xvf elasticsearch-7.9.2-linux-x86_64.tar.gz"
      ],
      "metadata": {
        "id": "GUY9N6EMoUAv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run Elasticsearch as a background process\n",
        "!chown -R daemon:daemon elasticsearch-7.9.2\n",
        "\n",
        "es_server = Popen(args=[\"elasticsearch-7.9.2/bin/elasticsearch\"], stdout=PIPE, stderr=STDOUT, preexec_fn=lambda: os.setuid(1))\n",
        "# Wait until Elasticsearch has started\n",
        "!sleep 30"
      ],
      "metadata": {
        "id": "d-RpPr1CoyAV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!curl -X GET \"localhost:9200/?pretty\""
      ],
      "metadata": {
        "id": "6oY6Czb0qv54",
        "outputId": "ac5594bd-2c80-428c-d17f-e12a92722669",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "  \"name\" : \"76f35057cb55\",\n",
            "  \"cluster_name\" : \"elasticsearch\",\n",
            "  \"cluster_uuid\" : \"N_5m2e9wThOCD2VquaK_Kg\",\n",
            "  \"version\" : {\n",
            "    \"number\" : \"7.9.2\",\n",
            "    \"build_flavor\" : \"default\",\n",
            "    \"build_type\" : \"tar\",\n",
            "    \"build_hash\" : \"d34da0ea4a966c4e49417f2da2f244e3e97b4e6e\",\n",
            "    \"build_date\" : \"2020-09-23T00:45:33.626720Z\",\n",
            "    \"build_snapshot\" : false,\n",
            "    \"lucene_version\" : \"8.6.2\",\n",
            "    \"minimum_wire_compatibility_version\" : \"6.8.0\",\n",
            "    \"minimum_index_compatibility_version\" : \"6.0.0-beta1\"\n",
            "  },\n",
            "  \"tagline\" : \"You Know, for Search\"\n",
            "}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from haystack.document_store.elasticsearch import ElasticsearchDocumentStore\n",
        "from haystack.retriever.sparse import ElasticsearchRetriever\n",
        "from haystack.reader.farm import FARMReader\n",
        "from haystack.pipeline import ExtractiveQAPipeline"
      ],
      "metadata": {
        "id": "r1w6efVrrq2R",
        "outputId": "74b3fab4-0321-42d4-8b8c-d89d6e4f5e1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 381
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImproperlyConfigured",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImproperlyConfigured\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-ad5496a7f4a0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mhaystack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdocument_store\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melasticsearch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mElasticsearchDocumentStore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mhaystack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretriever\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mElasticsearchRetriever\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mhaystack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfarm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFARMReader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mhaystack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpipeline\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mExtractiveQAPipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/haystack/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpkg_resources\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDistributionNotFound\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_distribution\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_version\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mhaystack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconstants\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDEFAULT_ALIAS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mhaystack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mloading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/haystack/constants.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Reserved field names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mID\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"HAYSTACK_ID_FIELD\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"id\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mDJANGO_CT\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"HAYSTACK_DJANGO_CT_FIELD\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"django_ct\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mDJANGO_ID\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"HAYSTACK_DJANGO_ID_FIELD\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"django_id\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/django/conf/__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;34m\"\"\"Return the value of a setting and cache it in self.__dict__.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrapped\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mempty\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m         \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrapped\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/django/conf/__init__.py\u001b[0m in \u001b[0;36m_setup\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m     65\u001b[0m                 \u001b[0;34m\"You must either define the environment variable %s \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m                 \u001b[0;34m\"or call settings.configure() before accessing settings.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m                 % (desc, ENVIRONMENT_VARIABLE))\n\u001b[0m\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrapped\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSettings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msettings_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImproperlyConfigured\u001b[0m: Requested setting HAYSTACK_ID_FIELD, but settings are not configured. You must either define the environment variable DJANGO_SETTINGS_MODULE or call settings.configure() before accessing settings."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_BgdeXulrzoY"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}