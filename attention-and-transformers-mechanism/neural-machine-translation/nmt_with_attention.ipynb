{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "nmt-with-attention.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN2j/9jYVgNhlsE7o+WtbeK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/transformers-research-and-practice/blob/main/attention-and-transformers-mechanism/neural-machine-translation/nmt_with_attention.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Neural Machine Translation With Attention Mechanism"
      ],
      "metadata": {
        "id": "6OU0hd_otqr6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Today, let’s join me in the journey of creating a neural machine translation model with attention mechanism by using the hottest-on-the-news Tensorflow 2.0.\n",
        "\n",
        "With that being said, our objective is pretty simple: we will use a very simple dataset (with only 20 examples) and we will try to overfit the training data with the renown Seq2Seq model. For the attention mechanism, we’re gonna use Luong attention, which I personally prefer over Bahdanau’s.\n",
        "\n",
        "Without talking too much about theories today, let’s jump right into the implementation. As usual, we will go through the steps below:\n",
        "\n",
        "* Data Preparation\n",
        "* Seq2Seq without Attention\n",
        "* Seq2Seq with Luong Attention"
      ],
      "metadata": {
        "id": "hjNayxuotrcB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Setup"
      ],
      "metadata": {
        "id": "sbGZ_wfTuUJw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import unicodedata\n",
        "import re"
      ],
      "metadata": {
        "id": "ysWbq2sEuVAS"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Data Preparation"
      ],
      "metadata": {
        "id": "OegM-1x8uYut"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let’s talk about the data. We’re gonna use 20 English – French pairs (which I extracted from the original dataset)."
      ],
      "metadata": {
        "id": "pcYJzrYCuZb8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw_data = (\n",
        "    ('What a ridiculous concept!', 'Quel concept ridicule !'),\n",
        "    ('Your idea is not entirely crazy.', \"Votre idée n'est pas complètement folle.\"),\n",
        "    (\"A man's worth lies in what he is.\", \"La valeur d'un homme réside dans ce qu'il est.\"),\n",
        "    ('What he did is very wrong.', \"Ce qu'il a fait est très mal.\"),\n",
        "    (\"All three of you need to do that.\", \"Vous avez besoin de faire cela, tous les trois.\"),\n",
        "    (\"Are you giving me another chance?\", \"Me donnez-vous une autre chance ?\"),\n",
        "    (\"Both Tom and Mary work as models.\", \"Tom et Mary travaillent tous les deux comme mannequins.\"),\n",
        "    (\"Can I have a few minutes, please?\", \"Puis-je avoir quelques minutes, je vous prie ?\"),\n",
        "    (\"Could you close the door, please?\", \"Pourriez-vous fermer la porte, s'il vous plaît ?\"),\n",
        "    (\"Did you plant pumpkins this year?\", \"Cette année, avez-vous planté des citrouilles ?\"),\n",
        "    (\"Do you ever study in the library?\", \"Est-ce que vous étudiez à la bibliothèque des fois ?\"),\n",
        "    (\"Don't be deceived by appearances.\", \"Ne vous laissez pas abuser par les apparences.\"),\n",
        "    (\"Excuse me. Can you speak English?\", \"Je vous prie de m'excuser ! Savez-vous parler anglais ?\"),\n",
        "    (\"Few people know the true meaning.\", \"Peu de gens savent ce que cela veut réellement dire.\"),\n",
        "    (\"Germany produced many scientists.\", \"L'Allemagne a produit beaucoup de scientifiques.\"),\n",
        "    (\"Guess whose birthday it is today.\", \"Devine de qui c'est l'anniversaire, aujourd'hui !\"),\n",
        "    (\"He acted like he owned the place.\", \"Il s'est comporté comme s'il possédait l'endroit.\"),\n",
        "    (\"Honesty will pay in the long run.\", \"L'honnêteté paye à la longue.\"),\n",
        "    (\"How do we know this isn't a trap?\", \"Comment savez-vous qu'il ne s'agit pas d'un piège ?\"),\n",
        "    (\"I can't believe you're giving up.\", \"Je n'arrive pas à croire que vous abandonniez.\"),\n",
        ")"
      ],
      "metadata": {
        "id": "VAjkbdNKuksF"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, we will need to clean up the raw data a little bit. This kind of task usually involves normalizing strings, filtering unwanted tokens, adding space before punctuation, etc."
      ],
      "metadata": {
        "id": "3j19XLadvi9A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def unicode_to_ascii(sent):\n",
        "  return \"\".join(char for char in unicodedata.normalize(\"NFD\", sent) if unicodedata.category(char) != \"Mn\")\n",
        "\n",
        "def normalize_string(sent):\n",
        "  sent = unicode_to_ascii(sent)\n",
        "  sent = re.sub(r\"([!.?])\", r\"\\1\", sent)\n",
        "  sent = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", sent)\n",
        "  sent = re.sub(r\"\\s+\", r\" \", sent)\n",
        "  return sent"
      ],
      "metadata": {
        "id": "t4ZOMdk3vj9k"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will now split the data into two separate lists, each containing its own sentences. \n",
        "\n",
        "Then we will apply the functions above and add two special tokens: `<start> and <end>`:"
      ],
      "metadata": {
        "id": "F7iYYR52wpz2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw_data_en, raw_data_fr = list(zip(*raw_data))\n",
        "raw_data_en, raw_data_fr = list(raw_data_en), list(raw_data_fr)\n",
        "\n",
        "raw_data_en = [normalize_string(data) for data in raw_data_en]\n",
        "\n",
        "raw_data_fr_in = [\"<start> \" + normalize_string(data) for data in raw_data_fr]\n",
        "raw_data_fr_out = [normalize_string(data) + \" <end>\" for data in raw_data_fr]"
      ],
      "metadata": {
        "id": "0RYBfqewwsX0"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_data_fr_in"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vdwgz27ryFym",
        "outputId": "408e7402-f7f3-40fa-c62d-c081e3a80de6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<start> Quel concept ridicule !',\n",
              " '<start> Votre idee n est pas completement folle.',\n",
              " '<start> La valeur d un homme reside dans ce qu il est.',\n",
              " '<start> Ce qu il a fait est tres mal.',\n",
              " '<start> Vous avez besoin de faire cela tous les trois.',\n",
              " '<start> Me donnez vous une autre chance ?',\n",
              " '<start> Tom et Mary travaillent tous les deux comme mannequins.',\n",
              " '<start> Puis je avoir quelques minutes je vous prie ?',\n",
              " '<start> Pourriez vous fermer la porte s il vous plait ?',\n",
              " '<start> Cette annee avez vous plante des citrouilles ?',\n",
              " '<start> Est ce que vous etudiez a la bibliotheque des fois ?',\n",
              " '<start> Ne vous laissez pas abuser par les apparences.',\n",
              " '<start> Je vous prie de m excuser ! Savez vous parler anglais ?',\n",
              " '<start> Peu de gens savent ce que cela veut reellement dire.',\n",
              " '<start> L Allemagne a produit beaucoup de scientifiques.',\n",
              " '<start> Devine de qui c est l anniversaire aujourd hui !',\n",
              " '<start> Il s est comporte comme s il possedait l endroit.',\n",
              " '<start> L honnetete paye a la longue.',\n",
              " '<start> Comment savez vous qu il ne s agit pas d un piege ?',\n",
              " '<start> Je n arrive pas a croire que vous abandonniez.']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_data_fr_out"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gvggmoGqyBVy",
        "outputId": "f5deecd6-bf01-4f08-f15d-1030d5b1d7c5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Quel concept ridicule ! <end>',\n",
              " 'Votre idee n est pas completement folle. <end>',\n",
              " 'La valeur d un homme reside dans ce qu il est. <end>',\n",
              " 'Ce qu il a fait est tres mal. <end>',\n",
              " 'Vous avez besoin de faire cela tous les trois. <end>',\n",
              " 'Me donnez vous une autre chance ? <end>',\n",
              " 'Tom et Mary travaillent tous les deux comme mannequins. <end>',\n",
              " 'Puis je avoir quelques minutes je vous prie ? <end>',\n",
              " 'Pourriez vous fermer la porte s il vous plait ? <end>',\n",
              " 'Cette annee avez vous plante des citrouilles ? <end>',\n",
              " 'Est ce que vous etudiez a la bibliotheque des fois ? <end>',\n",
              " 'Ne vous laissez pas abuser par les apparences. <end>',\n",
              " 'Je vous prie de m excuser ! Savez vous parler anglais ? <end>',\n",
              " 'Peu de gens savent ce que cela veut reellement dire. <end>',\n",
              " 'L Allemagne a produit beaucoup de scientifiques. <end>',\n",
              " 'Devine de qui c est l anniversaire aujourd hui ! <end>',\n",
              " 'Il s est comporte comme s il possedait l endroit. <end>',\n",
              " 'L honnetete paye a la longue. <end>',\n",
              " 'Comment savez vous qu il ne s agit pas d un piege ? <end>',\n",
              " 'Je n arrive pas a croire que vous abandonniez. <end>']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    }
  ]
}