{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "create-and-deploy-simple-sentiment-analysis-via-fastapi.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNWBIk5qJqiGSFSqH4Pj8V1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/natural-language-processing-case-studies/blob/master/bert-mechanism/create_and_deploy_simple_sentiment_analysis_via_fastapi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WyiJAay-HRq6"
      },
      "source": [
        "##Create and Deploy a Simple Sentiment Analysis via FastAPI"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7LTID-EcHtue"
      },
      "source": [
        "For this notebook, we will skip the building of our own model, and instead leverage the Pipeline class of the HuggingFace Transformers library. Transformers is full of SOTA NLP models which can be used out of the box as-is, as well as fine-tuned for specific uses and high performance.\n",
        "\n",
        "Using the Transformers library, FastAPI, and astonishingly little code, we are going to create and deploy a very simple sentiment analysis app."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1A3VCQsoIAky"
      },
      "source": [
        "##Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jrr-jeEIB_e"
      },
      "source": [
        "%%shell\n",
        "\n",
        "pip install transformers\n",
        "pip install fastapi\n",
        "pip install uvicorn\n",
        "pip install nest-asyncio \n",
        "pip install pyngrok"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLChRuAVI8bd"
      },
      "source": [
        "from transformers import pipeline\n",
        "from fastapi import FastAPI\n",
        "\n",
        "import nest_asyncio\n",
        "from pyngrok import ngrok\n",
        "import uvicorn"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3A5SMUBZImkp"
      },
      "source": [
        "## Sentiment Analysis API"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sNlWyplLJL0"
      },
      "source": [
        "For us, the task is `sentiment-analysis` and the model is `nlptown/bert-base-multilingual-uncased-sentiment`. This is a BERT model trained for multilingual sentiment analysis, and which has been contributed to the HuggingFace model repository by NLP Town."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRiOaIGWIW6-"
      },
      "source": [
        "nlp = pipeline(task=\"sentiment-analysis\", model=\"nlptown/bert-base-multilingual-uncased-sentiment\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gkWso9hcJcMA"
      },
      "source": [
        "app = FastAPI()\n",
        "\n",
        "@app.get(\"/\")\n",
        "def get_root():\n",
        "  return {\"message\": \"This is the sentiment analysis app\"}\n",
        "\n",
        "@app.get(\"/sentiment\")\n",
        "def query_sentiment(text: str):\n",
        "  return analyze_sentiment(text)\n",
        "\n",
        "\n",
        "def analyze_sentiment(text: str):\n",
        "  result = nlp(text)\n",
        "\n",
        "  sent = \"\"\n",
        "  if result[0][\"label\"] == \"1 star\":\n",
        "    sent = \"very negative\"\n",
        "  elif  result[0][\"label\"] == \"2 star\":\n",
        "    sent = \"negative\"\n",
        "  elif  result[0][\"label\"] == \"3 star\":\n",
        "    sent = \"neutral\"\n",
        "  elif  result[0][\"label\"] == \"4 star\":\n",
        "    sent = \"positive\"\n",
        "  else:\n",
        "    sent = \"very positive\"\n",
        "\n",
        "  prob = result[0][\"score\"]\n",
        "\n",
        "  return {\"sentiment\": sent, \"probability\": prob}"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-OADtXULXrk"
      },
      "source": [
        "And now we have a REST API capable of accepting get requests and performing sentiment analysis. Before we try it out, we have to run the Uvicorn web server which will provide the necessary back end functionality."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xIk6XJEZK7EQ",
        "outputId": "8104f971-da8a-4556-ce47-f801445359f1"
      },
      "source": [
        "ngrok_tunnel = ngrok.connect(8000)\n",
        "print('Public URL:', ngrok_tunnel.public_url)\n",
        "nest_asyncio.apply()\n",
        "uvicorn.run(app, port=8000)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Public URL: http://c17abd88f6ae.ngrok.io\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:     Started server process [60]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:     223.190.85.56:0 - \"GET /sentiment?text=welcome%20to%20my%20home! HTTP/1.1\" 200 OK\n",
            "INFO:     223.190.85.56:0 - \"GET /sentiment?text=i%20don%27t%20like%20your%20cat HTTP/1.1\" 200 OK\n",
            "INFO:     2600:1f18:65b9:df01:faa1:9722:e9eb:e34b:0 - \"GET /sentiment?text=welcome%20to%20my%20home! HTTP/1.1\" 200 OK\n",
            "INFO:     223.190.85.56:0 - \"GET /sentiment?text=that%20movie%20was%20just%20okay HTTP/1.1\" 200 OK\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:     Shutting down\n",
            "INFO:     Waiting for application shutdown.\n",
            "INFO:     Application shutdown complete.\n",
            "INFO:     Finished server process [60]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLMLKe1JLlCM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}