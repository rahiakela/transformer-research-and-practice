{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "transformer_position_encoding.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/natural-language-processing-case-studies/blob/bert-transformer-labs/transformer_position_encoding.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wSIW5dYmdGfE"
      },
      "source": [
        "# Transformer Position Encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZPoPd7GbdK0G"
      },
      "source": [
        "See [this notebook](https://github.com/rahiakela/natural-language-processing-case-studies/blob/bert-transformer-labs/transformer_model_for_language_understanding.ipynb) for a walk-through of full transformer implementation.\n",
        "\n",
        "The transformer architecture uses stacked attention layers in place of CNNs or RNNs. This makes it easy to learn long-range dependencies but it contains no built in information about the relative positions of items in a sequence. \n",
        "\n",
        "To give the model access to this information the transformer architecture adds a position encoding to the input.\n",
        "\n",
        "This encoding is a vector of sines and cosines at each position, where each sine-cosine pair rotates at a different frequency.  \n",
        "\n",
        "Nearby locations will have similar position-encoding vectors."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XLC5-V6sefM6"
      },
      "source": [
        "## Imports"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y6BDOVCnKPSW"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oCajWknYcYpV"
      },
      "source": [
        "The angle rates range from `1 [rads/step]` to `min_rate [rads/step]` over the vector depth.\n",
        "\n",
        "Formula for angle rate:\n",
        "\n",
        "$$angle\\_rate_d = (min\\_rate)^{d / d_{max}} $$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADsz4y85ANsB"
      },
      "source": [
        "num_positions = 50\n",
        "depth = 512\n",
        "min_rate = 1/10000\n",
        "\n",
        "assert depth%2 == 0, \"Depth must be even.\"\n",
        "angle_rate_exponents = np.linspace(0,1,depth//2)\n",
        "angle_rates = min_rate**(angle_rate_exponents)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E51Ne4cNe1i8"
      },
      "source": [
        "The resulting exponent goes from `0` to `1`, causing the `angle_rates` to drop exponentially from `1` to `min_rate`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ohldgW_Xg2sC"
      },
      "source": [
        "plt.semilogy(angle_rates)\n",
        "plt.xlabel('Depth')\n",
        "plt.ylabel('Angle rate [rads/step]')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fMaA6pUqh-tQ"
      },
      "source": [
        "Broadcasting a multiply over angle rates and positions gives a map of the position encoding angles as a function of depth."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rs2ABZ3XhYFg"
      },
      "source": [
        "positions = np.arange(num_positions) \n",
        "angle_rads = (positions[:, np.newaxis]) * angle_rates[np.newaxis, :]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eHEHWQa8_51Z"
      },
      "source": [
        "plt.figure(figsize = (14,8))\n",
        "plt.pcolormesh(\n",
        "    # Convert to degrees, and wrap around at 360\n",
        "    angle_rads*180/(2*np.pi) % 360,\n",
        "    # Use a cyclical colormap so that color(0) == color(360)\n",
        "    cmap='hsv', vmin=0, vmax=360)\n",
        "\n",
        "plt.xlim([0,len(angle_rates)])\n",
        "plt.ylabel('Position')\n",
        "plt.xlabel('Depth')\n",
        "bar = plt.colorbar(label='Angle [deg]')\n",
        "bar.set_ticks(np.linspace(0,360,6+1))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEGyhu_JiNDS"
      },
      "source": [
        "Raw angles are not a good model input (they're either unbounded, or discontinuous). So take the sine and cosine:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBnQuSSPGl8t"
      },
      "source": [
        "sines = np.sin(angle_rads)\n",
        "cosines = np.cos(angle_rads)\n",
        "pos_encoding = np.concatenate([sines, cosines], axis=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQrE2_nPHjXC"
      },
      "source": [
        "plt.figure(figsize=(14,8))\n",
        "plt.pcolormesh(pos_encoding, \n",
        "               # Use a diverging colormap so it's clear where zero is.\n",
        "               cmap='RdBu', vmin=-1, vmax=1)\n",
        "plt.xlim([0,depth])\n",
        "plt.ylabel('Position')\n",
        "plt.xlabel('Depth')\n",
        "plt.colorbar()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e536lUb-k-UQ"
      },
      "source": [
        "## Nearby positions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UzWWHKK1lu0z"
      },
      "source": [
        "Nearby locations will have similar position-encoding vectors. \n",
        "\n",
        "To demonstrate compare one position's encoding (here position 20) with each of the others:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kruiT670zjrZ"
      },
      "source": [
        "pos_encoding_at_20 = pos_encoding[20]\n",
        "\n",
        "dots = np.dot(pos_encoding, pos_encoding_at_20)\n",
        "SSE = np.sum((pos_encoding - pos_encoding_at_20)**2, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xH-sU6mzmjXI"
      },
      "source": [
        "Regardless of how you compare the vectors, they are most similar 20, and clearly diverge as you move away: "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQ-MqQ5Eo0ZT"
      },
      "source": [
        "plt.figure(figsize=(10,8))\n",
        "plt.subplot(2,1,1)\n",
        "plt.plot(dots)\n",
        "plt.ylabel('Dot product')\n",
        "plt.subplot(2,1,2)\n",
        "plt.plot(SSE)\n",
        "plt.ylabel('SSE')\n",
        "plt.xlabel('Position')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BVgAzBJ7iYda"
      },
      "source": [
        "## Relative positions\n",
        "\n",
        "The [paper](https://arxiv.org/pdf/1706.03762.pdf) explains, at the end of section 3.5, that any relative position encoding can be written as a linear function of the current position.\n",
        "\n",
        "To demonstrate, this section builds a matrix that calculates these relative position encodings. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHOBuNYnLHFF"
      },
      "source": [
        "def transition_matrix(position_delta, angle_rates = angle_rates):\n",
        "  # Implement as a matrix multiply:\n",
        "  #    sin(a+b) = sin(a) * cos(b) + cos(a) * sin(b)\n",
        "  #    cos(a+b) = cos(a) * cos(b) - sin(a) * sin(b)\n",
        "  \n",
        "  # b\n",
        "  angle_delta = position_delta * angle_rates\n",
        "\n",
        "  # sin(b), cos(b)\n",
        "  sin_delta = np.sin(angle_delta)\n",
        "  cos_delta = np.cos(angle_delta)\n",
        "\n",
        "  I = np.eye(len(angle_rates))\n",
        "  \n",
        "  # sin(a+b) = sin(a) * cos(b) + cos(a) * sin(b)\n",
        "  update_sin = np.concatenate([I*cos_delta, I*sin_delta], axis=0)\n",
        "  \n",
        "  # cos(a+b) = cos(a) * cos(b) - sin(a) * sin(b)\n",
        "  update_cos = np.concatenate([-I*sin_delta, I*cos_delta], axis=0)\n",
        "\n",
        "  return np.concatenate([update_sin, update_cos], axis=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GZKHXFAxkMb_"
      },
      "source": [
        "For example, create the matrix that calculates the position encoding 10 steps back, from the current position encoding:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x31yfQRQM6Q6"
      },
      "source": [
        "position_delta = -10\n",
        "update = transition_matrix(position_delta)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NznTFtWmklob"
      },
      "source": [
        "Applying this matrix to each position encoding vector gives position encoding vector from -10 steps away, resulting in a shifted position-encoding map:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hE7t9frqNQV3"
      },
      "source": [
        "plt.figure(figsize=(14,8))\n",
        "plt.pcolormesh(np.dot(pos_encoding, update), cmap='RdBu', vmin=-1, vmax=1)\n",
        "plt.xlim([0, depth])\n",
        "plt.ylabel('Position')\n",
        "plt.xlabel('Depth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a1IHJT2Jk16a"
      },
      "source": [
        "This is accurate to numerical precision."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tRmt2d-HQD8j"
      },
      "source": [
        "errors = np.dot(pos_encoding, update)[10:] - pos_encoding[:-10]\n",
        "abs(errors).max()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}