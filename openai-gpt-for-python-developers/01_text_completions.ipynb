{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN1MI261YqsKSNvBGajhYwY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/transformers-research-and-practice/blob/main/openai-gpt-for-python-developers/01_text_completions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##GPT Text Completions"
      ],
      "metadata": {
        "id": "I1Aj48gxotET"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "id": "KDyRIXxCoi2A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile .env\n",
        "API_KEY=XXXX"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fq0V5ophpb50",
        "outputId": "4783f521-8cd4-47a0-b63f-12a3c2edba5a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Writing .env\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai"
      ],
      "metadata": {
        "id": "4LWPGPFBpQV9"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def init_api():\n",
        "  with open(\".env\") as env:\n",
        "    for line in env:\n",
        "      key, value = line.strip().split(\"=\")\n",
        "      os.environ[key] = value\n",
        "  openai.api_key = os.environ.get(\"API_KEY\")"
      ],
      "metadata": {
        "id": "Ue-fZ7v5qo0O"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "init_api()"
      ],
      "metadata": {
        "id": "dT_3CKsOsWa7"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models = openai.Model.list()\n",
        "[data.id for data in models.data]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-iz5DVAsbPP",
        "outputId": "9b8a3922-8a76-4e77-a25e-96f7532a59f8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['whisper-1',\n",
              " 'babbage',\n",
              " 'davinci',\n",
              " 'text-davinci-edit-001',\n",
              " 'babbage-code-search-code',\n",
              " 'text-similarity-babbage-001',\n",
              " 'code-davinci-edit-001',\n",
              " 'text-davinci-001',\n",
              " 'ada',\n",
              " 'babbage-code-search-text',\n",
              " 'babbage-similarity',\n",
              " 'code-search-babbage-text-001',\n",
              " 'text-curie-001',\n",
              " 'code-search-babbage-code-001',\n",
              " 'gpt-3.5-turbo-0613',\n",
              " 'text-ada-001',\n",
              " 'text-similarity-ada-001',\n",
              " 'curie-instruct-beta',\n",
              " 'gpt-3.5-turbo-0301',\n",
              " 'gpt-3.5-turbo',\n",
              " 'ada-code-search-code',\n",
              " 'ada-similarity',\n",
              " 'code-search-ada-text-001',\n",
              " 'text-search-ada-query-001',\n",
              " 'davinci-search-document',\n",
              " 'ada-code-search-text',\n",
              " 'text-search-ada-doc-001',\n",
              " 'davinci-instruct-beta',\n",
              " 'text-similarity-curie-001',\n",
              " 'code-search-ada-code-001',\n",
              " 'ada-search-query',\n",
              " 'text-search-davinci-query-001',\n",
              " 'curie-search-query',\n",
              " 'davinci-search-query',\n",
              " 'babbage-search-document',\n",
              " 'ada-search-document',\n",
              " 'text-search-curie-query-001',\n",
              " 'text-search-babbage-doc-001',\n",
              " 'curie-search-document',\n",
              " 'text-search-curie-doc-001',\n",
              " 'babbage-search-query',\n",
              " 'text-babbage-001',\n",
              " 'text-search-davinci-doc-001',\n",
              " 'text-search-babbage-query-001',\n",
              " 'curie-similarity',\n",
              " 'gpt-3.5-turbo-16k-0613',\n",
              " 'curie',\n",
              " 'text-embedding-ada-002',\n",
              " 'gpt-3.5-turbo-16k',\n",
              " 'text-similarity-davinci-001',\n",
              " 'text-davinci-002',\n",
              " 'text-davinci-003',\n",
              " 'davinci-similarity']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Text Completions"
      ],
      "metadata": {
        "id": "Affya4qfmx-Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "next_txt = openai.Completion.create(\n",
        "    model=\"text-davinci-003\",\n",
        "    prompt=\"Once upon a time\",\n",
        "    max_tokens=7,\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "print(next_txt)"
      ],
      "metadata": {
        "id": "h-zYioGbm2G4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Letâ€™s test with a longer example\n",
        "next_txt = openai.Completion.create(\n",
        "    model=\"text-davinci-003\",\n",
        "    prompt=\"Once upon a time\",\n",
        "    max_tokens=15,\n",
        "    temperature=0\n",
        ")\n",
        "\n",
        "print(next_txt)"
      ],
      "metadata": {
        "id": "Oxa2KQH1pIcI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# For example, setting logprobs to 2 will return two versions of each token\n",
        "next_txt = openai.Completion.create(\n",
        "    model=\"text-davinci-003\",\n",
        "    prompt=\"Once upon a time\",\n",
        "    max_tokens=15,\n",
        "    temperature=0,\n",
        "    logprobs=3\n",
        ")\n",
        "\n",
        "print(next_txt)"
      ],
      "metadata": {
        "id": "s8y4cWe2pU7d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Controlling Creativity"
      ],
      "metadata": {
        "id": "es0u4EBRo6Ks"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# let's make it more creative\n",
        "next_txt = openai.Completion.create(\n",
        "    model=\"text-davinci-003\",\n",
        "    prompt=\"Once upon a time\",\n",
        "    max_tokens=15,\n",
        "    temperature=2\n",
        ")\n",
        "\n",
        "print(next_txt)"
      ],
      "metadata": {
        "id": "dIEv73h9o7G1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's consider only the highest probability mass 90%\n",
        "next_txt = openai.Completion.create(\n",
        "    model=\"text-davinci-003\",\n",
        "    prompt=\"Once upon a time\",\n",
        "    max_tokens=15,\n",
        "    top_p=.9\n",
        ")\n",
        "\n",
        "print(next_txt)"
      ],
      "metadata": {
        "id": "d6uG_0hVuVO8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's return a stream of tokens instead of a block containing all tokens\n",
        "next_txt = openai.Completion.create(\n",
        "    model=\"text-davinci-003\",\n",
        "    prompt=\"Once upon a time\",\n",
        "    max_tokens=15,\n",
        "    stream=True\n",
        ")\n",
        "\n",
        "print(next_txt)"
      ],
      "metadata": {
        "id": "kUBu7lsCvQlA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# If you want to only get the text\n",
        "next_txt = openai.Completion.create(\n",
        "    model=\"text-davinci-003\",\n",
        "    prompt=\"Once upon a time\",\n",
        "    max_tokens=15,\n",
        "    stream=True\n",
        ")\n",
        "\n",
        "# Read the generator text elements one by one\n",
        "for i in next_txt:\n",
        "  print(i[\"choices\"][0][\"text\"])"
      ],
      "metadata": {
        "id": "XyhVnULKvfKd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Controlling Repetitivity"
      ],
      "metadata": {
        "id": "Q2oTqE56v2FY"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9NQoGGVBv2te"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}