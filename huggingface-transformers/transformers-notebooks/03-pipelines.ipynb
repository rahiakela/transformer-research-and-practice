{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "pycharm": {
      "stem_cell": {
        "cell_type": "raw",
        "source": [],
        "metadata": {
          "collapsed": false
        }
      }
    },
    "colab": {
      "name": "03-pipelines.ipynb",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "599a86b5b5594f79bcf171299e7769fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DropdownModel",
          "state": {
            "_options_labels": [
              "sentiment-analysis",
              "ner",
              "fill_mask"
            ],
            "_view_name": "DropdownView",
            "style": "IPY_MODEL_c85f16ac883f42e7a2895183c58b11a7",
            "_dom_classes": [],
            "description": "Task:",
            "_model_name": "DropdownModel",
            "index": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "disabled": false,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a70a0f08d6e6448a89f3252145e2cc75"
          }
        },
        "c85f16ac883f42e7a2895183c58b11a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a70a0f08d6e6448a89f3252145e2cc75": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0030e8ca6390450d98cabdf2facb5b9a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "state": {
            "_view_name": "TextView",
            "style": "IPY_MODEL_120b05b1a8ea4108b15916cf3c6cd97d",
            "_dom_classes": [],
            "description": "Your input:",
            "_model_name": "TextModel",
            "placeholder": "Enter something",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "disabled": false,
            "_view_module_version": "1.5.0",
            "continuous_update": true,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d77b906b8cf942b4adc1946f24f6fe48"
          }
        },
        "120b05b1a8ea4108b15916cf3c6cd97d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d77b906b8cf942b4adc1946f24f6fe48": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "91275270bd1d49a1ae89bcd5366489e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextareaModel",
          "state": {
            "_view_name": "TextareaView",
            "style": "IPY_MODEL_82032c8102e94c11af023f782aa707e0",
            "rows": null,
            "_dom_classes": [],
            "description": "Context:",
            "_model_name": "TextareaModel",
            "placeholder": "Enter something",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Einstein is famous for the general theory of relativity",
            "_view_count": null,
            "disabled": false,
            "_view_module_version": "1.5.0",
            "continuous_update": true,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b0279adde5684d04b59115ade881e55f"
          }
        },
        "82032c8102e94c11af023f782aa707e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b0279adde5684d04b59115ade881e55f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "625c4cc001544485b3441d13a37c30ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextModel",
          "state": {
            "_view_name": "TextView",
            "style": "IPY_MODEL_06ea585dbfb4467d95a8b84184e8069a",
            "_dom_classes": [],
            "description": "Question:",
            "_model_name": "TextModel",
            "placeholder": "Enter something",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Why is Einstein famous for ?",
            "_view_count": null,
            "disabled": false,
            "_view_module_version": "1.5.0",
            "continuous_update": true,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f5b8443f5cf242088525b1c932c96283"
          }
        },
        "06ea585dbfb4467d95a8b84184e8069a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f5b8443f5cf242088525b1c932c96283": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/natural-language-processing-case-studies/blob/master/huggingface-transformers-practice/transformers-notebooks/03-pipelines.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "qUU7wy-brl_H"
      },
      "source": [
        "## How can I leverage State-of-the-Art Natural Language Models with only one line of code ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "-HLOHXuArl_L"
      },
      "source": [
        "Newly introduced in transformers v2.3.0, **pipelines** provides a high-level, easy to use,\n",
        "API for doing inference over a variety of downstream-tasks, including: \n",
        "\n",
        "- ***Sentence Classification _(Sentiment Analysis)_***: Indicate if the overall sentence is either positive or negative, i.e. *binary classification task* or *logitic regression task*.\n",
        "- ***Token Classification (Named Entity Recognition, Part-of-Speech tagging)***: For each sub-entities _(*tokens*)_ in the input, assign them a label, i.e. classification task.\n",
        "- ***Question-Answering***: Provided a tuple (`question`, `context`) the model should find the span of text in `content` answering the `question`.\n",
        "- ***Mask-Filling***: Suggests possible word(s) to fill the masked input with respect to the provided `context`.\n",
        "- ***Summarization***: Summarizes the ``input`` article to a shorter article.\n",
        "- ***Translation***: Translates the input from a language to another language.\n",
        "- ***Feature Extraction***: Maps the input to a higher, multi-dimensional space learned from the data.\n",
        "\n",
        "Pipelines encapsulate the overall process of every NLP process:\n",
        " \n",
        " 1. **Tokenization**: Split the initial input into multiple sub-entities with ... properties (i.e. tokens).\n",
        " 2. **Inference**: Maps every tokens into a more meaningful representation. \n",
        " 3. **Decoding**: Use the above representation to generate and/or extract the final output for the underlying task.\n",
        "\n",
        "The overall API is exposed to the end-user through the `pipeline()` method with the following \n",
        "structure:\n",
        "\n",
        "```python\n",
        "from transformers import pipeline\n",
        "\n",
        "# Using default model and tokenizer for the task\n",
        "pipeline(\"<task-name>\")\n",
        "\n",
        "# Using a user-specified model\n",
        "pipeline(\"<task-name>\", model=\"<model_name>\")\n",
        "\n",
        "# Using custom model/tokenizer as str\n",
        "pipeline('<task-name>', model='<model name>', tokenizer='<tokenizer_name>')\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "name": "#%% code\n"
        },
        "id": "4maAknWNrl_N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11df81d7-d9d0-494a-cd11-baad29800b24"
      },
      "source": [
        "!pip install -q transformers"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 2.3MB 24.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.3MB 43.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 901kB 52.0MB/s \n",
            "\u001b[?25h"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%% code \n"
        },
        "id": "uKaqzCh6rl_V"
      },
      "source": [
        "from __future__ import print_function\n",
        "import ipywidgets as widgets\n",
        "from transformers import pipeline"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "uDPZ42Uerl_b"
      },
      "source": [
        "## 1. Sentence Classification - Sentiment Analysis"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%% code\n"
        },
        "id": "AMRXHQw9rl_d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84ba5a34-5ce1-40f5-8dd4-a18056a252cd"
      },
      "source": [
        "nlp_sentence_classifier = pipeline('sentiment-analysis')\n",
        "nlp_sentence_classifier('Such a nice weather outside !')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'label': 'POSITIVE', 'score': 0.9997655749320984}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "RY8aUJTvrl_k"
      },
      "source": [
        "## 2. Token Classification - Named Entity Recognition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%% code\n"
        },
        "id": "B3BDRX_Krl_n",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6124573-1026-4d56-ec2a-8d56bbef743d"
      },
      "source": [
        "nlp_token_classifier = pipeline('ner')\n",
        "nlp_token_classifier('Hugging Face is a French company based in New-York.')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'end': 2,\n",
              "  'entity': 'I-ORG',\n",
              "  'index': 1,\n",
              "  'score': 0.9970937967300415,\n",
              "  'start': 0,\n",
              "  'word': 'Hu'},\n",
              " {'end': 7,\n",
              "  'entity': 'I-ORG',\n",
              "  'index': 2,\n",
              "  'score': 0.9345751404762268,\n",
              "  'start': 2,\n",
              "  'word': '##gging'},\n",
              " {'end': 12,\n",
              "  'entity': 'I-ORG',\n",
              "  'index': 3,\n",
              "  'score': 0.9787060618400574,\n",
              "  'start': 8,\n",
              "  'word': 'Face'},\n",
              " {'end': 24,\n",
              "  'entity': 'I-MISC',\n",
              "  'index': 6,\n",
              "  'score': 0.9981995820999146,\n",
              "  'start': 18,\n",
              "  'word': 'French'},\n",
              " {'end': 45,\n",
              "  'entity': 'I-LOC',\n",
              "  'index': 10,\n",
              "  'score': 0.9983047246932983,\n",
              "  'start': 42,\n",
              "  'word': 'New'},\n",
              " {'end': 46,\n",
              "  'entity': 'I-LOC',\n",
              "  'index': 11,\n",
              "  'score': 0.8913456201553345,\n",
              "  'start': 45,\n",
              "  'word': '-'},\n",
              " {'end': 50,\n",
              "  'entity': 'I-LOC',\n",
              "  'index': 12,\n",
              "  'score': 0.9979523420333862,\n",
              "  'start': 46,\n",
              "  'word': 'York'}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qIvUFEVarl_s"
      },
      "source": [
        "## 3. Question Answering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%% code\n"
        },
        "id": "ND_8LzQKrl_u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5ef79eaf-9823-489a-bd8c-2c216c67e387"
      },
      "source": [
        "nlp_qa = pipeline('question-answering')\n",
        "nlp_qa(context='Hugging Face is a French company based in New-York.', question='Where is based Hugging Face ?')"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'answer': 'New-York', 'end': 50, 'score': 0.9633593559265137, 'start': 42}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9W_CnP5Zrl_2"
      },
      "source": [
        "## 4. Text Generation - Mask Filling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%% code\n"
        },
        "id": "zpJQ2HXNrl_4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "694f3892-5502-4e63-b9c9-0aaa882f2248"
      },
      "source": [
        "nlp_fill = pipeline('fill-mask')\n",
        "nlp_fill('Hugging Face is a French company based in ' + nlp_fill.tokenizer.mask_token)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.27758949995040894,\n",
              "  'sequence': 'Hugging Face is a French company based in Paris',\n",
              "  'token': 2201,\n",
              "  'token_str': ' Paris'},\n",
              " {'score': 0.14941208064556122,\n",
              "  'sequence': 'Hugging Face is a French company based in Lyon',\n",
              "  'token': 12790,\n",
              "  'token_str': ' Lyon'},\n",
              " {'score': 0.045764174312353134,\n",
              "  'sequence': 'Hugging Face is a French company based in Geneva',\n",
              "  'token': 11559,\n",
              "  'token_str': ' Geneva'},\n",
              " {'score': 0.04576260223984718,\n",
              "  'sequence': 'Hugging Face is a French company based in France',\n",
              "  'token': 1470,\n",
              "  'token_str': ' France'},\n",
              " {'score': 0.04067583009600639,\n",
              "  'sequence': 'Hugging Face is a French company based in Brussels',\n",
              "  'token': 6497,\n",
              "  'token_str': ' Brussels'}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fbs9t1KvrzDy"
      },
      "source": [
        "## 5. Summarization\n",
        "\n",
        "Summarization is currently supported by `Bart` and `T5`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BaOgzi1u1Yc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29aaee34-7ff9-4d00-f48b-e20c1f119255"
      },
      "source": [
        "TEXT_TO_SUMMARIZE = \"\"\" \n",
        "New York (CNN)When Liana Barrientos was 23 years old, she got married in Westchester County, New York. \n",
        "A year later, she got married again in Westchester County, but to a different man and without divorcing her first husband. \n",
        "Only 18 days after that marriage, she got hitched yet again. Then, Barrientos declared \"I do\" five more times, sometimes only within two weeks of each other. \n",
        "In 2010, she married once more, this time in the Bronx. In an application for a marriage license, she stated it was her \"first and only\" marriage. \n",
        "Barrientos, now 39, is facing two criminal counts of \"offering a false instrument for filing in the first degree,\" referring to her false statements on the \n",
        "2010 marriage license application, according to court documents. \n",
        "Prosecutors said the marriages were part of an immigration scam. \n",
        "On Friday, she pleaded not guilty at State Supreme Court in the Bronx, according to her attorney, Christopher Wright, who declined to comment further. \n",
        "After leaving court, Barrientos was arrested and charged with theft of service and criminal trespass for allegedly sneaking into the New York subway through an emergency exit, said Detective \n",
        "Annette Markowski, a police spokeswoman. In total, Barrientos has been married 10 times, with nine of her marriages occurring between 1999 and 2002. \n",
        "All occurred either in Westchester County, Long Island, New Jersey or the Bronx. She is believed to still be married to four men, and at one time, she was married to eight men at once, prosecutors say. \n",
        "Prosecutors said the immigration scam involved some of her husbands, who filed for permanent residence status shortly after the marriages. \n",
        "Any divorces happened only after such filings were approved. It was unclear whether any of the men will be prosecuted. \n",
        "The case was referred to the Bronx District Attorney\\'s Office by Immigration and Customs Enforcement and the Department of Homeland Security\\'s \n",
        "Investigation Division. Seven of the men are from so-called \"red-flagged\" countries, including Egypt, Turkey, Georgia, Pakistan and Mali. \n",
        "Her eighth husband, Rashid Rajput, was deported in 2006 to his native Pakistan after an investigation by the Joint Terrorism Task Force. \n",
        "If convicted, Barrientos faces up to four years in prison.  Her next court appearance is scheduled for May 18.\n",
        "\"\"\"\n",
        "\n",
        "summarizer = pipeline('summarization')\n",
        "summarizer(TEXT_TO_SUMMARIZE)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'summary_text': ' Liana Barrientos pleaded not guilty to two counts of \"offering a false instrument for filing in the first degree\" She has been married to 10 men, nine of them between 1999 and 2002 . She is believed to still be married to four men, and at one time, she was married to eight men at once .'}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u5JA6IJsr-G0"
      },
      "source": [
        "## 6. Translation\n",
        "\n",
        "Translation is currently supported by `T5` for the language mappings English-to-French (`translation_en_to_fr`), English-to-German (`translation_en_to_de`) and English-to-Romanian (`translation_en_to_ro`)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FwayP4nwV3Z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "797129a9-dc14-41db-9264-39046c002102"
      },
      "source": [
        "# English to French\n",
        "translator = pipeline('translation_en_to_fr')\n",
        "translator(\"HuggingFace is a French company that is based in New York City. HuggingFace's mission is to solve NLP one commit at a time\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'translation_text': 'HuggingFace est une entreprise française basée à New York.'}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ra0-WfznwoIW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c405bb6-f580-4289-a8f9-7ea289bce6d1"
      },
      "source": [
        "# English to German\n",
        "translator = pipeline('translation_en_to_de')\n",
        "translator(\"The history of natural language processing (NLP) generally started in the 1950s, although work can be found from earlier periods.\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'translation_text': 'Die Geschichte der natürlichen Sprachenverarbeitung (NLP) begann im Allgemeinen in den 1950er Jahren, obwohl Arbeit aus früheren Zeiten gefunden werden kann.'}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPUpg0M8hCtB"
      },
      "source": [
        "## 7. Text Generation\n",
        "\n",
        "Text generation is currently supported by GPT-2, OpenAi-GPT, TransfoXL, XLNet, CTRL and Reformer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5pKfxTxohXuZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da3ea223-731c-4a69-d081-857c66b48890"
      },
      "source": [
        "text_generator = pipeline(\"text-generation\")\n",
        "text_generator(\"Today is a beautiful day and I will\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'generated_text': 'Today is a beautiful day and I will do everything in my power to support you,\" Clinton responded in a statement.\\n\\nFollow Jerome Hudson on Twitter @jeromeehudson'}]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Utmldmetrl_9"
      },
      "source": [
        "## 8. Projection - Features Extraction "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%% code\n"
        },
        "id": "O4SjR1QQrl__",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39d0658b-64a2-40b3-998c-e84fdd338502"
      },
      "source": [
        "import numpy as np\n",
        "nlp_features = pipeline('feature-extraction')\n",
        "output = nlp_features('Hugging Face is a French company based in Paris')\n",
        "np.array(output).shape   # (Samples, Tokens, Vector Size)\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilbert-base-cased were not used when initializing DistilBertModel: ['vocab_transform.bias', 'vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_projector.weight', 'vocab_projector.bias', 'vocab_layer_norm.bias']\n",
            "- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 12, 768)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {
          "name": "#%% md\n"
        },
        "id": "02j8km8YrmAE"
      },
      "source": [
        "Alright ! Now you have a nice picture of what is possible through transformers' pipelines, and there is more\n",
        "to come in future releases. \n",
        "\n",
        "In the meantime, you can try the different pipelines with your own inputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%% code\n"
        },
        "id": "yFlBPQHtrmAH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 79,
          "referenced_widgets": [
            "599a86b5b5594f79bcf171299e7769fa",
            "c85f16ac883f42e7a2895183c58b11a7",
            "a70a0f08d6e6448a89f3252145e2cc75",
            "0030e8ca6390450d98cabdf2facb5b9a",
            "120b05b1a8ea4108b15916cf3c6cd97d",
            "d77b906b8cf942b4adc1946f24f6fe48"
          ]
        },
        "outputId": "7c28832f-a7ff-4c88-8785-fcbe428d4223"
      },
      "source": [
        "task = widgets.Dropdown(\n",
        "    options=['sentiment-analysis', 'ner', 'fill_mask'],\n",
        "    value='ner',\n",
        "    description='Task:',\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "input = widgets.Text(\n",
        "    value='',\n",
        "    placeholder='Enter something',\n",
        "    description='Your input:',\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "def forward(_):\n",
        "    if len(input.value) > 0: \n",
        "        if task.value == 'ner':\n",
        "            output = nlp_token_class(input.value)\n",
        "        elif task.value == 'sentiment-analysis':\n",
        "            output = nlp_sentence_classif(input.value)\n",
        "        else:\n",
        "            if input.value.find('<mask>') == -1:\n",
        "                output = nlp_fill(input.value + ' <mask>')\n",
        "            else:\n",
        "                output = nlp_fill(input.value)                \n",
        "        print(output)\n",
        "\n",
        "input.on_submit(forward)\n",
        "display(task, input)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "599a86b5b5594f79bcf171299e7769fa",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Dropdown(description='Task:', index=1, options=('sentiment-analysis', 'ner', 'fill_mask'), value='ner')"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0030e8ca6390450d98cabdf2facb5b9a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Text(value='', description='Your input:', placeholder='Enter something')"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "pycharm": {
          "is_executing": false,
          "name": "#%% Question Answering\n"
        },
        "id": "GCoKbBTYrmAN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92,
          "referenced_widgets": [
            "91275270bd1d49a1ae89bcd5366489e5",
            "82032c8102e94c11af023f782aa707e0",
            "b0279adde5684d04b59115ade881e55f",
            "625c4cc001544485b3441d13a37c30ac",
            "06ea585dbfb4467d95a8b84184e8069a",
            "f5b8443f5cf242088525b1c932c96283"
          ]
        },
        "outputId": "38e27af4-9892-4cd6-def1-01ecf526c506"
      },
      "source": [
        "context = widgets.Textarea(\n",
        "    value='Einstein is famous for the general theory of relativity',\n",
        "    placeholder='Enter something',\n",
        "    description='Context:',\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "query = widgets.Text(\n",
        "    value='Why is Einstein famous for ?',\n",
        "    placeholder='Enter something',\n",
        "    description='Question:',\n",
        "    disabled=False\n",
        ")\n",
        "\n",
        "def forward(_):\n",
        "    if len(context.value) > 0 and len(query.value) > 0: \n",
        "        output = nlp_qa(question=query.value, context=context.value)            \n",
        "        print(output)\n",
        "\n",
        "query.on_submit(forward)\n",
        "display(context, query)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "91275270bd1d49a1ae89bcd5366489e5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Textarea(value='Einstein is famous for the general theory of relativity', description='Context:', placeholder=…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "625c4cc001544485b3441d13a37c30ac",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Text(value='Why is Einstein famous for ?', description='Question:', placeholder='Enter something')"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}