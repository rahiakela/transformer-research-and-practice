{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNOWR4HIAaITjxKOn2/wma5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/transformers-research-and-practice/blob/main/peft_huggingface_guide/01_peft_basic.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Setup"
      ],
      "metadata": {
        "id": "J9toBhmNfBmd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install peft"
      ],
      "metadata": {
        "id": "4MJ7r5SAe71K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import LoraConfig, TaskType\n",
        "from peft import get_peft_model\n",
        "from peft import AutoPeftModelForCausalLM\n",
        "\n",
        "import torch\n",
        "\n",
        "from transformers import AutoTokenizer\n",
        "from transformers import AutoModelForSeq2SeqLM\n",
        "from transformers import TrainingArguments, Trainer\n",
        "\n",
        "from huggingface_hub import notebook_login"
      ],
      "metadata": {
        "id": "5_iARsEIfHJ-"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step-1: PEFT Config"
      ],
      "metadata": {
        "id": "YMZ_LHVKfWFc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each PEFT method is defined by a `PeftConfig` class that stores all the important parameters for building a `PeftModel`."
      ],
      "metadata": {
        "id": "Mb24xcQUfh_C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load and create a LoraConfig\n",
        "peft_config = LoraConfig(\n",
        "    task_type=TaskType.SEQ_2_SEQ_LM,\n",
        "    inference_mode=False,\n",
        "    r=8,\n",
        "    lora_alpha=32,\n",
        "    lora_dropout=0.1\n",
        ")"
      ],
      "metadata": {
        "id": "pHkJcgGJfZQo"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the base model you want to finetune\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"bigscience/mt0-large\")"
      ],
      "metadata": {
        "id": "btL9quFsgOL3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Wrap the base model and peft_config with the get_peft_model() function to create a PeftModel.\n",
        "peft_model = get_peft_model(model, peft_config)\n",
        "\n",
        "peft_model.print_trainable_parameters()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aQc1u67mgZlr",
        "outputId": "f481ab67-1f0a-4365-ab9f-95e108c33e62"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 2,359,296 || all params: 1,231,940,608 || trainable%: 0.19151053100118282\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step-2: Fine-tuning"
      ],
      "metadata": {
        "id": "mlBafBkliEfL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "training_args = TrainingArguments(\n",
        "    output_dir=\"rahiakela/bigscience/mt0-large-lora\",\n",
        "    learning_rate=1e-3,\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=32,\n",
        "    num_train_epochs=2,\n",
        "    weight_decay=0.01,\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    load_best_model_at_end=True,\n",
        ")"
      ],
      "metadata": {
        "id": "U3T-D71RiHs1"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trainer = Trainer(\n",
        "    model=peft_model,\n",
        "    args=training_args,\n",
        "    train_dataset=tokenized_datasets[\"train\"],\n",
        "    eval_dataset=tokenized_datasets[\"test\"],\n",
        "    tokenizer=tokenizer,\n",
        "    data_collator=data_collator,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n",
        "\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "-oVtm1Tei5XN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Step-3: Inference"
      ],
      "metadata": {
        "id": "c0BD1FZ0jkCp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = AutoPeftModelForCausalLM.from_pretrained(\"ybelkada/opt-350m-lora\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"facebook/opt-350m\")\n",
        "\n",
        "model = model.to(\"cuda\")\n",
        "model.eval()\n",
        "inputs = tokenizer(\"Preheat the oven to 350 degrees and place the cookie dough\", return_tensors=\"pt\")\n",
        "\n",
        "outputs = model.generate(input_ids=inputs[\"input_ids\"].to(\"cuda\"), max_new_tokens=50)"
      ],
      "metadata": {
        "id": "6oAb91SBjmQu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(tokenizer.batch_decode(outputs.detach().cpu().numpy(), skip_special_tokens=True)[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e9FSOzckjuAR",
        "outputId": "e7caeaf0-5d90-40f2-ff5a-2b2f450b315d"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preheat the oven to 350 degrees and place the cookie dough in the center of the oven.\n",
            "\n",
            "In a large bowl, combine the flour, baking powder, baking soda, salt, and cinnamon.\n",
            "\n",
            "In a separate bowl, combine the egg yolks, sugar, and vanilla.\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}