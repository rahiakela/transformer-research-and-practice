{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1-linear-and-tree-based-models-for-email-sentiment-classification.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyNZhS524Tasqu8izSqj9HLW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/transfer-learning-for-natural-language-processing/blob/main/2-getting-started-with-baselines/1_linear_and_tree_based_models_for_email_sentiment_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0syenf2nUMgZ"
      },
      "source": [
        "# Linear & Tree-based models for Email Sentiment Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Tvj1R7TUOC2"
      },
      "source": [
        "Our goal is to establish a set of baselines for a pair of concrete NLP problems, which we will later be able to use to measure progressive improvements gained from leveraging increasingly sophisticated transfer learning\r\n",
        "approaches. In the process of doing this, we aim to advance your general NLP instincts and refresh your understanding of typical procedures involved in setting up problem-solving pipelines for such problems. You will review techniques ranging from tokenization to data structure and model selection. We first train some traditional machine learning models from scratch to establish some preliminary baselines for these problems.\r\n",
        "\r\n",
        "We will focus on a pair of important representative example NLP problems – spam\r\n",
        "classification of email, and sentiment classification of movie reviews. This exercise will arm you with a number of important skills, including some tips for obtaining, visualizing and preprocessing data. \r\n",
        "\r\n",
        "Three major model classes will be covered, namely linear models such as logistic regression, decision-tree-based models such as random forests, and neural-network-based models such as ELMo. These classes are additionally represented by support vector machines (SVMs) with linear kernels, gradient-boosting machines (GBMs) and BERT respectively. \r\n",
        "\r\n",
        "<img src='https://github.com/rahiakela/img-repo/blob/master/transfer-learning-for-natural-language-processing/content-classification-supervised-models.png?raw=1' width='800'/>\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inPFIdfP7n4K"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xlt8No657pZ_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8573be6-d47b-4e24-8426-60ca45b6bb89"
      },
      "source": [
        "import numpy as np  # linear algebra\r\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\r\n",
        "import email        # email package for processing email messages\r\n",
        "import random\r\n",
        "import re\r\n",
        "import time\r\n",
        "\r\n",
        "\r\n",
        "from sklearn.linear_model import LogisticRegression\r\n",
        "from sklearn.metrics import accuracy_score\r\n",
        "from sklearn.svm import SVC                              # Support Vector Classification model\r\n",
        "from sklearn.ensemble import RandomForestClassifier      # random forest classifier library\r\n",
        "from sklearn.model_selection import GridSearchCV         # for tune parameters systematically\r\n",
        "from sklearn.ensemble import GradientBoostingClassifier  # GBM algorithm\r\n",
        "from sklearn import metrics                              #Additional scklearn functions\r\n",
        "from sklearn.model_selection import cross_val_score\r\n",
        "\r\n",
        "import nltk\r\n",
        "nltk.download('stopwords')\r\n",
        "from nltk.corpus import stopwords\r\n",
        "\r\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JQ8un4hI7uw1",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "02c5ed73-3894-42a1-b2cb-8d54c5603f8f"
      },
      "source": [
        "from google.colab import files\r\n",
        "files.upload() # upload kaggle.json file"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-69af691c-b46e-4ce6-99c9-39c1d782ba67\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-69af691c-b46e-4ce6-99c9-39c1d782ba67\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving kaggle.json to kaggle.json\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'kaggle.json': b'{\"username\":\"rahiakela\",\"key\":\"484f91b2ebc194b0bff8ab8777c1ebff\"}'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJKVZMbo7va7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e253757-1c03-4f80-d9dc-cb09bde08613"
      },
      "source": [
        "%%shell\r\n",
        "\r\n",
        "mkdir -p ~/.kaggle\r\n",
        "mv kaggle.json ~/.kaggle/\r\n",
        "ls ~/.kaggle\r\n",
        "chmod 600 /root/.kaggle/kaggle.json\r\n",
        "\r\n",
        "# download dataset from kaggle\r\n",
        "kaggle datasets download -d wcukierski/enron-email-dataset\r\n",
        "unzip -qq enron-email-dataset.zip\r\n",
        "\r\n",
        "kaggle datasets download -d rtatman/fraudulent-email-corpus\r\n",
        "unzip -qq fraudulent-email-corpus.zip\r\n",
        "\r\n",
        "rm -rf enron-email-dataset.zip fraudulent-email-corpus.zip"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "kaggle.json\n",
            "Downloading enron-email-dataset.zip to /content\n",
            " 98% 350M/358M [00:04<00:00, 111MB/s] \n",
            "100% 358M/358M [00:04<00:00, 82.4MB/s]\n",
            "Downloading fraudulent-email-corpus.zip to /content\n",
            " 91% 5.00M/5.52M [00:00<00:00, 30.5MB/s]\n",
            "100% 5.52M/5.52M [00:00<00:00, 27.0MB/s]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Srh_wOUmwefT"
      },
      "source": [
        "def extract_messages(df):\r\n",
        "  messages = []\r\n",
        "  for item in df[\"message\"]:\r\n",
        "    # Return a message object structure from a string\r\n",
        "    e = email.message_from_string(item)\r\n",
        "    # get message body\r\n",
        "    message_body = e.get_payload()\r\n",
        "    messages.append(message_body)\r\n",
        "  print(\"Successfully retrieved message body from e-mails!\")\r\n",
        "  return messages"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQbAbRM7Wtfs"
      },
      "source": [
        "## Preprocessing Email Spam Classification Example Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HplaHzeVWwfg"
      },
      "source": [
        "Here, we are interested in developing an algorithm that can detect whether any given email is spam or not, at scale. To do this, we will build a dataset from two separate sources – the popular Enron email corpus as a proxy for email that is not spam, and a collection of “419” fraudulent emails as a proxy for email that is spam.\r\n",
        "\r\n",
        "We will view this as a supervised classification task, where we will first train a classifier on a collection of emails labeled as either spam or not spam. \r\n",
        "\r\n",
        "In particular, we will sample the Enron Corpus – the largest public email collection, related to the notorious Enron financial scandal – as a proxy for email that are not spam, and sample “419” fraudulent emails, representing the best known type of spam, as a proxy for email that is spam. Both of these types of emails are openly available on [Kaggle](https://www.kaggle.com/wcukierski/enron-email-dataset).\r\n",
        "\r\n",
        "The Enron corpus contains about half a million emails written by employees of the Enron Corporation, as collected by the Federal Energy Commission for the purposes of investigating the collapse of the company. It has been used extensively in the literature to study machine learning methods for email applications and is often the first data source researchers working with emails look to for initial experimentation with algorithm prototypes. On Kaggle, it is\r\n",
        "available as a single-column .csv file with one email per row. Note that this data is still cleaner than one can expect to typically find in many practical applications in the wild.\r\n",
        "\r\n",
        "<img src='https://github.com/rahiakela/img-repo/blob/master/transfer-learning-for-natural-language-processing/spam-email-preprocessing.png?raw=1' width='800'/>\r\n",
        "\r\n",
        "The body of the email will first be separated from the headers of the email, some statistics about the dataset will be teased out to get a sense for the data, stopwords will be removed from the email, and it will then be classified as either spam or not spam."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yl9EgWVOay5R"
      },
      "source": [
        "### Loading and Visualizing the Fraudulent Email Corpus"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U6g1Yz69a-w7"
      },
      "source": [
        "Having loaded the Enron emails, let’s do the same for the “419” fraudulent email corpus, so that we can have some example data in our training set representing the “spam” class.\r\n",
        "\r\n",
        "> Since this dataset comes as a .txt file, versus a .csv, the preprocessing steps are slightly different. First\r\n",
        "of all, we have to specify the encoding when reading the file as latin1, otherwise the default encoding option of\r\n",
        "utf-8 will fail. It is often the case in practice that one needs to experiment with a number of different encodings,\r\n",
        "with the aforementioned two being the most popular ones, to get some datasets to read correctly. Additionally,\r\n",
        "note that because this .txt file is one big column of emails (with headers) separated by line breaks and white\r\n",
        "space, and is not separated nicely into rows with one email per row – as was the case for the Enron corpus – we\r\n",
        "can’t use Pandas to neatly load it as was done before. We will read all the emails into a single string, and split\r\n",
        "the string on a code word that appears close to the beginning of each email’s header, i.e, “From r”."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KoaktA_bbB7e"
      },
      "source": [
        "filepath = \"./fradulent_emails.txt\"\r\n",
        "with open(filepath, \"r\", encoding=\"latin1\") as file:\r\n",
        "  data = file.read()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lXb0MfIbCdX"
      },
      "source": [
        "Print the first 20000 characters of read file string (this gives only a few emails), and notice the keyword From r close to the beginning of each email header"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKTeDH1hbFJX"
      },
      "source": [
        "print(data[:2000])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4bmdi9UxbHDo"
      },
      "source": [
        "Split on the code word From r appearing close to the beginning of each email"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DydgG-oQbJcL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c5d1b96-a53d-42a9-f6a5-3d0cc23db480"
      },
      "source": [
        "fraud_emails = data.split(\"From r\")\r\n",
        "print(\"Successfully loaded {} spam emails!\".format(len(fraud_emails)))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Successfully loaded 3978 spam emails!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IqSaPXPlbLfb"
      },
      "source": [
        "Now that the fraudulent data is loaded as a list, we can convert it into a Pandas DataFrame."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "boolbOhybOhv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "f61b10ba-9407-435d-cb59-470117b609c7"
      },
      "source": [
        "fraud_bodies = extract_messages(pd.DataFrame(fraud_emails, columns=[\"message\"], dtype=str))\r\n",
        "fraud_bodies_df = pd.DataFrame(fraud_bodies[1:])\r\n",
        "\r\n",
        "fraud_bodies_df.head()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Successfully retrieved message body from e-mails!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>FROM:MR. JAMES NGOLA.\\nCONFIDENTIAL TEL: 233-2...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Dear Friend,\\n\\nI am Mr. Ben Suleman a custom ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>FROM HIS ROYAL MAJESTY (HRM) CROWN RULER OF EL...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>FROM HIS ROYAL MAJESTY (HRM) CROWN RULER OF EL...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Dear sir, \\n \\nIt is with a heart full of hope...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   0\n",
              "0  FROM:MR. JAMES NGOLA.\\nCONFIDENTIAL TEL: 233-2...\n",
              "1  Dear Friend,\\n\\nI am Mr. Ben Suleman a custom ...\n",
              "2  FROM HIS ROYAL MAJESTY (HRM) CROWN RULER OF EL...\n",
              "3  FROM HIS ROYAL MAJESTY (HRM) CROWN RULER OF EL...\n",
              "4  Dear sir, \\n \\nIt is with a heart full of hope..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZFjsooY28CFg"
      },
      "source": [
        "### Loading and Visualizing the Enron Corpus"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9JO_OyeelZC"
      },
      "source": [
        "The first thing we need to do is load the data with the popular Pandas library, and to take a peek at a slice of the data to make sure we have a good sense of what it looks like."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5qxnwX82fZAE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7c196d5-3378-466c-8f6f-b9b460f89344"
      },
      "source": [
        "filepath = \"./emails.csv\"\r\n",
        "\r\n",
        "# Read the enron data into a pandas.DataFrame called emails\r\n",
        "emails = pd.read_csv(filepath)\r\n",
        "print(\"Successfully loaded {} rows and {} columns!\".format(emails.shape[0], emails.shape[1]))\r\n",
        "print(emails.head())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Successfully loaded 517401 rows and 2 columns!\n",
            "                       file                                            message\n",
            "0     allen-p/_sent_mail/1.  Message-ID: <18782981.1075855378110.JavaMail.e...\n",
            "1    allen-p/_sent_mail/10.  Message-ID: <15464986.1075855378456.JavaMail.e...\n",
            "2   allen-p/_sent_mail/100.  Message-ID: <24216240.1075855687451.JavaMail.e...\n",
            "3  allen-p/_sent_mail/1000.  Message-ID: <13505866.1075863688222.JavaMail.e...\n",
            "4  allen-p/_sent_mail/1001.  Message-ID: <30922949.1075863688243.JavaMail.e...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-rYJUDMShrGg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24f6785f-0993-460a-eed6-586eeb1890f5"
      },
      "source": [
        "# take a closer look at the first email\r\n",
        "print(emails.loc[0][\"message\"])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Message-ID: <18782981.1075855378110.JavaMail.evans@thyme>\n",
            "Date: Mon, 14 May 2001 16:39:00 -0700 (PDT)\n",
            "From: phillip.allen@enron.com\n",
            "To: tim.belden@enron.com\n",
            "Subject: \n",
            "Mime-Version: 1.0\n",
            "Content-Type: text/plain; charset=us-ascii\n",
            "Content-Transfer-Encoding: 7bit\n",
            "X-From: Phillip K Allen\n",
            "X-To: Tim Belden <Tim Belden/Enron@EnronXGate>\n",
            "X-cc: \n",
            "X-bcc: \n",
            "X-Folder: \\Phillip_Allen_Jan2002_1\\Allen, Phillip K.\\'Sent Mail\n",
            "X-Origin: Allen-P\n",
            "X-FileName: pallen (Non-Privileged).pst\n",
            "\n",
            "Here is our forecast\n",
            "\n",
            " \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZG5cG3UpiqNs"
      },
      "source": [
        "We see that the messages are contained within the message column of the resulting DataFrame, with the extra fields at the beginning of each message – including Message ID, To, From, etc.,– being referred to as the message’s header information or simply header.\r\n",
        "\r\n",
        "Traditional spam classification methods derive features from the header information for classifying the message as spam or not. Here, we would like to perform the same task based on the content of the message only. One possible motivation for this approach is the fact that email training data may often be de-identified in practice due to privacy concerns and regulations, thereby making header info unavailable. Thus, we need to separate the headers from the messages in our dataset."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3t4cgehjw3t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04cf9104-a7c7-47bf-f22b-5d7bed009b01"
      },
      "source": [
        "bodies = extract_messages(emails)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Successfully retrieved message body from e-mails!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sp43leIyj6iB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "069e2a0e-db36-4758-b54e-578f4471a406"
      },
      "source": [
        "# We then can display some processed emails\r\n",
        "bodies_df = pd.DataFrame(bodies)\r\n",
        "print(bodies_df.head())"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                                                   0\n",
            "0                          Here is our forecast\\n\\n \n",
            "1  Traveling to have a business meeting takes the...\n",
            "2                     test successful.  way to go!!!\n",
            "3  Randy,\\n\\n Can you send me a schedule of the s...\n",
            "4                Let's shoot for Tuesday at 11:45.  \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8b-w2r3kbRK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "343d05b2-3def-4169-c559-acc875978e3f"
      },
      "source": [
        "# extract random 10000 enron email bodies for building dataset\r\n",
        "bodies_df = pd.DataFrame(random.sample(bodies, 10000))\r\n",
        "\r\n",
        "# expand default pandas display options to make emails more clearly visible when printed\r\n",
        "pd.set_option(\"display.max_colwidth\", 300)\r\n",
        "# you could do print(bodies_df.head()), but Jupyter displays this nicer for pandas DataFrames\r\n",
        "bodies_df.head()"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Britt-- I can't find them. Either Wayne Gresham or Gail Brownfeld has them.\\n----- Forwarded by Richard B Sanders/HOU/ECT on 01/09/2001 10:25 AM -----\\n\\n\\tTwanda Sweet\\n\\t01/08/2001 03:44 PM\\n\\t\\t \\n\\t\\t To: Richard B Sanders/HOU/ECT@ECT\\n\\t\\t cc: \\n\\t\\t Subject: Mailroom Issue\\n\\nRichard, do y...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>\\nAs a supporter of BIPAC you have access to a wide array of \"tools,\" charts,\\npublications, the Candidate and Issues Databases, and many more.\\n\\nFind out where they are and how to use them. Attend one of our Use the Tools\\nWorkshops on the morning of October 24th in BIPAC's Conference Room. \\n...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Kate:\\n\\nThat is fine with me.  Are we OK with this?\\n\\nC\\n\\n\\n   Kate Symes                04/13/2001 11:04 AM\\n\\nTo: Kimberly Hundl/Corp/Enron@Enron, Melissa Ann Murphy/HOU/ECT@ECT, Rhonda L \\nDenton/HOU/ECT@ECT\\ncc: Chris H Foster/HOU/ECT@ECT, Samuel Schott/HOU/ECT@ECT \\nSubject: New CTPY Nam...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>I vote for waiting until Monday to discuss.  This is one part of the larger \\nPR / Government Affairs strategy in California.  We need Karen Denne (PR) to \\ncome to Portland for the meeting on Monday.\\n\\nJim\\n\\n\\n\\n\\n\\n\\tTim Belden@ECT\\n\\t10/24/2000 05:54 PM\\n\\t\\t \\n\\t\\t To: Mark Palmer/Corp/Enr...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>\\nPlease be aware that remote connectivity into the  Enron network has changed, IPASS is no longer available. Remote Connectivity into Enron may be obtained by using the eConnect solution.  Authorization to use eConnect may be requested via the eRequest system (you will find a link to eRequest o...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                                                                                                                                                                                                                                                                             0\n",
              "0  Britt-- I can't find them. Either Wayne Gresham or Gail Brownfeld has them.\\n----- Forwarded by Richard B Sanders/HOU/ECT on 01/09/2001 10:25 AM -----\\n\\n\\tTwanda Sweet\\n\\t01/08/2001 03:44 PM\\n\\t\\t \\n\\t\\t To: Richard B Sanders/HOU/ECT@ECT\\n\\t\\t cc: \\n\\t\\t Subject: Mailroom Issue\\n\\nRichard, do y...\n",
              "1  \\nAs a supporter of BIPAC you have access to a wide array of \"tools,\" charts,\\npublications, the Candidate and Issues Databases, and many more.\\n\\nFind out where they are and how to use them. Attend one of our Use the Tools\\nWorkshops on the morning of October 24th in BIPAC's Conference Room. \\n...\n",
              "2  Kate:\\n\\nThat is fine with me.  Are we OK with this?\\n\\nC\\n\\n\\n   Kate Symes                04/13/2001 11:04 AM\\n\\nTo: Kimberly Hundl/Corp/Enron@Enron, Melissa Ann Murphy/HOU/ECT@ECT, Rhonda L \\nDenton/HOU/ECT@ECT\\ncc: Chris H Foster/HOU/ECT@ECT, Samuel Schott/HOU/ECT@ECT \\nSubject: New CTPY Nam...\n",
              "3  I vote for waiting until Monday to discuss.  This is one part of the larger \\nPR / Government Affairs strategy in California.  We need Karen Denne (PR) to \\ncome to Portland for the meeting on Monday.\\n\\nJim\\n\\n\\n\\n\\n\\n\\tTim Belden@ECT\\n\\t10/24/2000 05:54 PM\\n\\t\\t \\n\\t\\t To: Mark Palmer/Corp/Enr...\n",
              "4  \\nPlease be aware that remote connectivity into the  Enron network has changed, IPASS is no longer available. Remote Connectivity into Enron may be obtained by using the eConnect solution.  Authorization to use eConnect may be requested via the eRequest system (you will find a link to eRequest o..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HjzHW02yni9B"
      },
      "source": [
        "The following (commented out) code is arguably the more \"pythonic\" way of achieving the extraction of bodies from messages. It is only 2 lines long and achieves the same result."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3g87bYPnnjNe"
      },
      "source": [
        "#messages = emails[\"message\"].apply(email.message_from_string)\r\n",
        "#bodies_df = messages.apply(lambda x: x.get_payload()).sample(10000)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsXoqMRdwC65"
      },
      "source": [
        "### Email text preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UeeYY2_OuxYw"
      },
      "source": [
        "Having loaded both datasets, we are now ready to sample emails from each one into a single DataFrame that will represent the overall dataset covering both classes of emails. Before doing this, we must decide how many samples to draw from each class. Ideally, the number of samples in each class will represent the natural distribution of emails in the wild, i.e, if we expect our classifier to encounter 60% spam emails and 40% nonspam emails when deployed, then a ratio such as 600 to 400 respectively might make sense.\r\n",
        "\r\n",
        "**Note that a severe imbalance in the data, such as 99% for nonspam and 1% for spam may overfit to predict nonspam most of the time, an issue than needs to be considered when building datasets.** Since this is an idealized experiment, and we do not have any information on natural distributions of classes, we will\r\n",
        "assume a 50/50 split. \r\n",
        "\r\n",
        "We also need to give some thought to how we are going to tokenize the emails, i.e., split emails into subunits of text - words, sentences, etc. To start off, we will tokenize into words, as this is the most common approach. \r\n",
        "\r\n",
        "We must also decide the maximum number of tokens per email, and the maximum length of each token, to ensure that the occasional “extremely long” email does not bog down the performance of our classifier. \r\n",
        "\r\n",
        "We do all these by specifying the following general hyperparameters, which will later be tuned experimentally to enhance performance as needed:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_qzNMcNsGh-"
      },
      "source": [
        "n_sample = 1000   # number of samples to generate in each class - 'spam', 'not spam'\r\n",
        "maxtokens = 50    # the maximum number of tokens per document\r\n",
        "maxtokenlen = 20  # the maximum length of each token"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRVD-qopxT2f"
      },
      "source": [
        "With these hyperparameters specified, we can now create a single DataFrame for the overarching training dataset. Let’s take the opportunity to also perform remaining preprocessing tasks, namely removing stop words, punctuations and tokenizing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2OTWZJ6w9-J"
      },
      "source": [
        "#### Tokenization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-dJjXYvxaK9"
      },
      "source": [
        "Let’s proceed by defining a function to tokenize emails by splitting them into words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42b-458pwdRh"
      },
      "source": [
        "def tokenize(row):\r\n",
        "  if row is None or row is \"\":\r\n",
        "    tokens = \"\"\r\n",
        "  else:\r\n",
        "    tokens = str(row).split(\" \")[:maxtokens]\r\n",
        "  return tokens"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_viulZEyUNO"
      },
      "source": [
        "#### Remove punctuation and unnecessary characters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MOkUJbxyUeG"
      },
      "source": [
        "Taking another look at the emails on the previous pair of pages, we see that they contain a lot of punctuation characters, and the spam emails tend to be capitalized. \r\n",
        "\r\n",
        "**In order to ensure that classification is done based on language content only, we have to remove punctuation marks and other non-word characters from the emails.** We do this by employing regular expressions with the Python regex library. We also normalize words by turning them into lower case."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2n-aNOVNx3mC"
      },
      "source": [
        "def reg_expressions(row):\r\n",
        "  tokens = []\r\n",
        "  try:\r\n",
        "    for token in row:\r\n",
        "      token = token.lower()          # make all characters lower case\r\n",
        "      token = re.sub(r\"[\\W\\d]\", \"\", token)\r\n",
        "      token = token[:maxtokenlen]    # truncate all tokens to hyperparameter maxtokenlen\r\n",
        "      tokens.append(token)\r\n",
        "  except:\r\n",
        "    token = \"\"\r\n",
        "    tokens.append(token)\r\n",
        "  return tokens"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ubr6_29dzvyA"
      },
      "source": [
        "#### Stop-word removal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjpNoFWhzwqu"
      },
      "source": [
        "Finally, let’s define a function to remove stopwords - words that occur so frequently in language that they offer no useful information for classification. This includes words such as “the” and “are”, and the popular library NLTK provides a heavily used list that we will employ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75fyCvyDzpFd"
      },
      "source": [
        "stop_words = stopwords.words(\"english\")\r\n",
        "\r\n",
        "def stop_word_removal(row):\r\n",
        "  token = [token for token in row if token not in stop_words]\r\n",
        "  token = filter(None, token)\r\n",
        "\r\n",
        "  return token"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2A14TaVP2Rro"
      },
      "source": [
        "### Assemble both Datasets"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BwhmZaVb2VDS"
      },
      "source": [
        "We are now going to put all these functions together to build the single dataset representing both classes. Most methods expect this dataset to be a Numpy array in order to process it, so we convert it to that form after combining the emails.\r\n",
        "\r\n",
        "Now, putting all the preprocessing steps together we assemble our dataset..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2rjwJFC0i7U"
      },
      "source": [
        "# Convert everything to lower-case, truncate to maxtokens and truncate each token to maxtokenlen\r\n",
        "\r\n",
        "# Apply predefined processing functions\r\n",
        "enron_emails = bodies_df.iloc[:, 0].apply(tokenize)\r\n",
        "enron_emails = enron_emails.apply(stop_word_removal)\r\n",
        "enron_emails = enron_emails.apply(reg_expressions)\r\n",
        "# sample the right number of emails from each class.\r\n",
        "enron_emails = enron_emails.sample(n_sample)\r\n",
        "\r\n",
        "# Apply predefined processing functions\r\n",
        "spam_emails = fraud_bodies_df.iloc[:, 0].apply(tokenize)\r\n",
        "spam_emails = spam_emails.apply(stop_word_removal)\r\n",
        "spam_emails = spam_emails.apply(reg_expressions)\r\n",
        "# sample the right number of emails from each class.\r\n",
        "spam_emails = spam_emails.sample(n_sample)\r\n",
        "\r\n",
        "# convert to Numpy array\r\n",
        "raw_data = pd.concat([enron_emails, spam_emails], axis=0).values"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "siEiJQvp4Q29"
      },
      "source": [
        "Now, let’s take a peek at the result to make sure things are proceeding as expected:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YSd-Yfri4KaB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a209ef93-719b-41b8-da57-f3ac046fe56c"
      },
      "source": [
        "print(\"Shape of combined data is:\", raw_data.shape)\r\n",
        "print(\"Data is:\")\r\n",
        "print(raw_data)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Shape of combined data is: (2000,)\n",
            "Data is:\n",
            "[list(['big', 'news', 'wolfcameracom', 'to', 'read', 'newsletter', 'online', 'go', 'httpwwwwolfcameracom', '', 'wolf', 'cameras', 'newsletter', 'holidays', '', 'vol', 'i', 'issue', 'imageimageimageimage', 'privacy', 'information', 'subscription', 'information', 'as', 'wolfcameracom', 'member', 'introduced', 'world', 'online', 'photographic', 'products', 'services', 'since'])\n",
            " list(['as', 'part', 'enron', 'industrial', 'markets', 'eim', 'move', 'pulp', 'paper', 'steel', 'markets', 'european', 'effort', 'well', 'underway', 'our', 'markets', 'global', 'in', 'nature', 'believe', 'need', 'strong', 'presence', 'europe', 'penetrate', 'that', 'market', 'effectively', 'accordingly', 'pleased', 'announce', 'bruce'])\n",
            " list(['note', 'information', 'background', 'ie', 'attributionalan', 'c', 'forwarded', 'alan', 'comnespdxect', '', '', 'pm', 'michael', 'etringer', '', 'amto', 'alan', 'comnespdxectectcc', 'subject', 'involuntary', 'bankruptcy', 'ca', 'forwarded', 'michael', 'etringerhouect', '', '', 'am', 'christopher', 'f', 'calger', '', 'pmto', 'michael', 'etringerhouectect', 'terry', 'w', 'donovanhouectectcc'])\n",
            " ...\n",
            " list(['from', 'the', 'desk', 'of', 'musa', 'garubabill', 'and', 'exchange', 'managerafrican', 'development', 'bankouagadougou', 'burkina', 'fasoi', 'manager', 'bill', 'exchange', 'foreign', 'remittance', 'departmentof', 'african', 'development', 'bank', 'burkina', 'faso', 'i', 'got', 'contact', 'addressthrough', 'internet', 'net', 'work', 'search', 'searching', 'good', 'reliableperson', 'assist'])\n",
            " list(['dear', 'sirmadami', 'conducting', 'standard', 'process', 'investigation', 'behalf', 'bank', 'aninternational', 'banking', 'conglomerate', 'this', 'investigation', 'involves', 'clientand', 'also', 'circumstances', 'surrounding', 'investments', 'made', 'clientwith', 'ourbankour', 'client', 'died', 'intestate', 'nominated', 'successor', 'title', 'theinvestments', 'made', 'bank', 'the', 'essence'])\n",
            " list(['hello', 'my', 'dear', 'i', 'mrs', 'rose', 'savimbi', 'please', 'need', 'help', 'since', '', 'incidence', 'lead', 'death', 'late', 'husbandmrjonas', 'savimbi', 'unita', 'angola', 'i', 'know', 'met', '', 'i', 'contacting', 'due', 'sense'])]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXy7SLuV44Xw"
      },
      "source": [
        "We see that the resulting array has divided the text into word units, as we intended to.\r\n",
        "\r\n",
        "Let’s create the headers corresponding to these emails, consisting of n_sample=1000 of spam emails followed by n_sample=1000 of non-spam emails:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o2hCPV3z4qXn"
      },
      "source": [
        "categories = [\"spam\", \"notspam\"]\r\n",
        "header = ([1] * n_sample)\r\n",
        "header.extend(([0] * n_sample)) "
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9La125o61fZ"
      },
      "source": [
        "We are now ready to convert this Numpy array into numerical features that can actually be fed to the algorithms for classification."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sj0jsZ9W65Yo"
      },
      "source": [
        "### Converting the Email Text Into Numbers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALmmE6Wo7A-6"
      },
      "source": [
        "We start by employing what is often considered the simplest method for vectorizing words, i.e., converting them into numerical vectors – the bag-of-words model. This model simply counts the frequency of word tokens contained in each email and thereby represents it as a vector of such frequency counts.\r\n",
        "\r\n",
        "Please observe that in doing this, we only retain tokens that appear more than once, as captured by the variable “used_tokens”. This enables us to keep the vector dimensions significantly lower than they would be otherwise. Please also\r\n",
        "note that one can achieve this using various in-built vectorizers in the popular library scikitlearn.\r\n",
        "\r\n",
        "We also note the scikit-learn vectorization methods include counting occurrences of sequences of any n words, or n-grams, as well as the tf-idf approach – important fundamental concepts you should brush on if rusty. For the problems looked at here, we did not notice an improvement when using these vectorization methods over the bag-of words approach.\r\n",
        "\r\n",
        "The assemble_bag() function assembles a new dataframe containing all the unique words found in the text documents. It counts the word frequency and then returns the new dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ve_ovHA36tk2"
      },
      "source": [
        "def assemble_bag(data):\r\n",
        "  used_tokens = []\r\n",
        "  all_tokens = []\r\n",
        "\r\n",
        "  for item in data:\r\n",
        "    for token in item:\r\n",
        "      if token in all_tokens:\r\n",
        "        # If token has been seen before, append it to output list used_tokens\r\n",
        "        if token not in used_tokens:\r\n",
        "          used_tokens.append(token)\r\n",
        "      else:\r\n",
        "        all_tokens.append(token)\r\n",
        "\r\n",
        "  df = pd.DataFrame(0, index=np.arange(len(data)), columns=used_tokens)\r\n",
        "\r\n",
        "  # Create a Pandas DataFrame counting frequencies of vocabulary words – corresponding to columns, in each email – corresponding to rows\r\n",
        "  for i, item in enumerate(data):\r\n",
        "    for token in item:\r\n",
        "      if token in used_tokens:\r\n",
        "        df.iloc[i][token] += 1\r\n",
        "\r\n",
        "  return df"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCJpbAgNUChs"
      },
      "source": [
        "We are now ready to convert these into numerical vectors!!\r\n",
        "\r\n",
        "Having defined the assemble_bag function, let’s use it to actually carry out the vectorization and visualize it as follows:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPvtszzgTaz5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "094df139-8da8-4b7a-8b2e-5c2827df39eb"
      },
      "source": [
        "# create bag-of-words model\r\n",
        "enron_spam_bag = assemble_bag(raw_data) \r\n",
        "\r\n",
        "# this is the list of words in our bag-of-words model\r\n",
        "predictors = [column for column in enron_spam_bag.columns]\r\n",
        "print(enron_spam_bag)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "      newsletter     information  ...  fasoi  departmentof  incidence\n",
            "0              2  2            2  ...      0             0          0\n",
            "1              0  0            0  ...      0             0          0\n",
            "2              0  6            1  ...      0             0          0\n",
            "3              0  0            0  ...      0             0          0\n",
            "4              0  1            0  ...      0             0          0\n",
            "...          ... ..          ...  ...    ...           ...        ...\n",
            "1995           0  0            0  ...      0             0          0\n",
            "1996           0  0            0  ...      0             0          0\n",
            "1997           0  0            0  ...      1             1          0\n",
            "1998           0  0            0  ...      0             0          0\n",
            "1999           0  2            0  ...      0             0          1\n",
            "\n",
            "[2000 rows x 4747 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "etyyQh-ZWWXf"
      },
      "source": [
        "The column labels indicate words in the vocabulary of the bag-of-words model, and the numerical entries in each row correspond to the frequency counts of each such word for each of the 2000 emails in our dataset. Notice that it is an extremely sparse DataFrame, i.e., it consists mostly of values of 0.\r\n",
        "\r\n",
        "\r\n",
        "Having fully vectorized the dataset, we must remember that it is not shuffled with respect to classes, i.e., it contains Nsamp = 1000 spam emails followed by an equal number of nonspam emails. Depending on how this dataset is split, in our case by picking the first 70% for training and the remainder for testing, this could lead to a training set composed of spam only, which would obviously lead to failure. In order to create a randomized ordering of class samples in the dataset, we will need to shuffle the data in unison with the header/list of labels.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1jUL1YnVBQN"
      },
      "source": [
        "# shuffle raw data first\r\n",
        "def unison_shuffle_data(data, header):\r\n",
        "  p = np.random.permutation(len(header))\r\n",
        "  data = data[p, :]\r\n",
        "  header = np.asarray(header)[p]\r\n",
        "\r\n",
        "  return data, list(header)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIGDs4kZYCIr"
      },
      "source": [
        "As the very last step of preparing the email dataset for training by our baseline classifiers, we split it into independent training and testing or validation sets. This will allow us to evaluate the performance of the classifier on a set of data that was not used for training, an important thing\r\n",
        "to ensure in machine learning practice. We elect to use 70% of the data for training, and 30% for testing/validation afterwards."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2bJ0TlTX3FW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7196144b-dfd0-40a2-8d94-77099bfd1a4f"
      },
      "source": [
        "data, header = unison_shuffle_data(enron_spam_bag.values, header)\r\n",
        "\r\n",
        "# split into independent 70% training and 30% testing sets\r\n",
        "idx = int(0.7 * data.shape[0])  # get 70% index value\r\n",
        "\r\n",
        "# 70% of data for training\r\n",
        "train_x = data[:idx, :]\r\n",
        "train_y = header[:idx]\r\n",
        "\r\n",
        "# remaining 30% for testing\r\n",
        "test_x = data[idx:, :]\r\n",
        "test_y = header[idx:]\r\n",
        "\r\n",
        "print(\"train_x/train_y list details, to make sure they are of the right form:\")\r\n",
        "print(len(train_x))\r\n",
        "print(train_x)\r\n",
        "print(len(train_y))\r\n",
        "print(train_y[:5])"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_x/train_y list details, to make sure they are of the right form:\n",
            "1400\n",
            "[[0 1 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 0 0]\n",
            " [0 1 0 ... 0 0 0]\n",
            " [0 0 0 ... 0 0 0]]\n",
            "1400\n",
            "[0, 0, 0, 0, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HQRPMa4Z8RB"
      },
      "source": [
        "Since 70% of 2000 is 1400, looks good! (for n_sample=1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAdf-aVkadDa"
      },
      "source": [
        "## Generalized Linear Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lyHf2bhnaeI8"
      },
      "source": [
        "Traditionally, the development of models in any area of applied mathematics has started with linear models. These models are mappings that preserve addition and multiplication in the input and output spaces. In other words, the net response from a pair of inputs will be the sum of the responses to each individual input. This property enables a significant reduction in associated\r\n",
        "statistical and mathematical theory.\r\n",
        "\r\n",
        "In this section, we will apply a pair of the most widely-used generalized linear machine learning algorithms to the pair of example problems that were introduced in the previous section– logistic regression and support vector machines (SVMs) with linear kernel. Other popular generalized linear machine learning models that will not be applied include the simple perceptron\r\n",
        "neural architecture with a linear activation function, latent dirichlet allocation (LDA) and Naive Bayes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wHMpH7umylgU"
      },
      "source": [
        "### Logistic Regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gL3uRvZsyl91"
      },
      "source": [
        "Logistic regression models the relationship between a categorical output variable and a set of input variables by estimating probabilities with the logistic function. Assuming the existence of a single input variables x, and a single output binary variable y with associated probability $P(y=1)=p$.\r\n",
        "\r\n",
        "Now, let’s go ahead and build our classifier using the popular library scikit-learn."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUorbYbDZw8b"
      },
      "source": [
        "def fit_model(train_x, train_y):\r\n",
        "  model = LogisticRegression()  # Instantiate model\r\n",
        "\r\n",
        "  try:\r\n",
        "    model.fit(train_x, train_y)  # Fit model to prepared labeled data\r\n",
        "  except:\r\n",
        "    pass\r\n",
        "\r\n",
        "  return model"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hed2Z4FrysZV"
      },
      "source": [
        "Now let's fit this model to our data for IMDB classification example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Vobk4LfyqQ9"
      },
      "source": [
        "model = fit_model(train_x, train_y)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ijD8G8DVyw7_"
      },
      "source": [
        "To evaluate performance, we must test on the “hold out” test/validation sets that were put together for each example."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHODA56Kyurl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9bae9ce-c05d-48ee-af43-85cbe28ef8f7"
      },
      "source": [
        "predicted_labels = model.predict(test_x)\r\n",
        "\r\n",
        "# print all labels for full trasparency\r\n",
        "print(\"DEBUG::The logistic regression predicted labels are::\")\r\n",
        "print(predicted_labels)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DEBUG::The logistic regression predicted labels are::\n",
            "[0 1 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 0 0 0 0 1 0 0 1 1 0 1 1 1 0 0 0 0 1 1 0\n",
            " 0 1 1 1 1 0 1 0 0 1 0 1 1 1 0 0 1 1 0 1 0 0 1 0 1 1 0 1 1 0 1 1 1 0 1 0 0\n",
            " 0 1 1 1 1 0 1 1 1 1 0 1 0 0 1 1 1 0 0 1 0 1 1 1 0 1 1 1 1 1 1 1 1 0 1 0 0\n",
            " 0 0 1 0 1 1 1 0 1 0 0 1 0 1 1 1 1 0 1 0 0 0 0 1 1 1 1 1 0 0 0 0 1 1 0 0 1\n",
            " 0 0 1 1 0 0 1 1 1 0 1 1 1 0 1 1 0 1 0 1 1 1 0 1 1 0 1 0 0 1 1 0 1 1 0 0 1\n",
            " 1 0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 0 0 1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 0 1 0 1\n",
            " 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 1 1 0 1 0 0 0 0 0 0 1 0 0 1 0 0 1 1 0 0 1\n",
            " 0 0 0 0 1 0 1 0 1 0 1 1 1 1 0 0 1 1 0 0 1 1 0 1 0 0 1 0 1 1 0 1 1 0 1 1 0\n",
            " 0 1 1 0 0 1 0 1 1 0 0 0 1 0 1 0 0 0 1 1 1 0 0 1 0 1 1 0 1 0 0 0 0 0 0 0 1\n",
            " 1 1 1 1 0 1 1 0 1 0 0 1 1 1 1 0 0 1 0 0 0 0 0 1 1 0 1 1 0 1 0 0 1 0 0 1 1\n",
            " 0 1 1 0 0 1 0 1 1 0 1 1 0 0 0 0 1 1 0 1 0 0 1 0 1 1 0 0 0 0 1 0 1 0 0 0 1\n",
            " 1 1 1 1 1 1 0 1 1 1 1 1 0 0 1 1 0 1 1 0 0 0 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1\n",
            " 0 0 1 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 0 1 0 0 1 0 0 1 1 1 0 1 0 1 1 1 1 0 0\n",
            " 0 1 0 0 0 1 0 0 1 1 1 0 1 1 0 1 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 1 0 1 0 1\n",
            " 1 1 0 1 0 0 0 1 1 1 0 1 0 1 0 0 0 1 1 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0\n",
            " 0 0 0 0 1 0 0 1 0 1 1 0 1 1 0 0 1 1 1 0 0 0 1 1 1 0 1 0 0 0 0 0 0 1 0 1 1\n",
            " 1 1 1 1 0 0 1 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YGx_Z8T-yzzi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d67710e-4683-4c53-ea73-eb8ba468e70e"
      },
      "source": [
        "acc_score = accuracy_score(test_y, predicted_labels)\r\n",
        "\r\n",
        "print(\"The logistic regression accuracy score is::\")\r\n",
        "print(acc_score)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The logistic regression accuracy score is::\n",
            "0.9716666666666667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYpts_bpy4zj"
      },
      "source": [
        "Before proceeding, it is important to address the use of accuracy as the metric for evaluating performance. Accuracy is defined as the ratio of correctly identified samples, i.e., the ratio of the number of true positives and negatives to the total number of samples. \r\n",
        "\r\n",
        "Other potential metrics that could be used here include precision – the ratio of the number of true positives to all predicted positives, and recall – the ratio of the number of true positives to all actual positives. These two measures could be useful if the costs of false positives and false negatives\r\n",
        "(respectively) are particularly important. \r\n",
        "\r\n",
        "Crucially, the F1-score – the harmonic mean of precision and recall – strikes a balance between the two, and is particularly useful for imbalanced datasets. This is the most common situation in practice, making this metric very important.\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J2n4qPUFy71U"
      },
      "source": [
        "### Support Vector Machine Classifier"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73y8d9W_y8UG"
      },
      "source": [
        "SVMs has traditionally been the most popular kind of kernel method.\r\n",
        "These methods attempt to find good decision boundaries by mapping data to a high dimensional space, using hyperplanes as decision boundaries and the kernel trick to reduce computing cost. When the kernel function is a linear function, SVMs are not only generalized linear models, but are indeed linear models.\r\n",
        "\r\n",
        "Note that because this classifier takes a bit longer to train than the logistic regression one, we employ the inbuilt Python library time to determine the training time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z-ShmEKGy2ND",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8383caab-9d9d-455c-a758-e590db2182bd"
      },
      "source": [
        "# Create a support vector classifier\r\n",
        "clf = SVC(C=1, gamma=\"auto\", kernel=\"linear\", probability=False)\r\n",
        "\r\n",
        "# Fit the classifier using the training data\r\n",
        "start_time = time.time()\r\n",
        "clf.fit(train_x, train_y)\r\n",
        "end_time = time.time()\r\n",
        "print(\"Training the SVC Classifier took %3d seconds\" % (end_time - start_time))\r\n",
        "\r\n",
        "# test and evaluate\r\n",
        "predicted_labels = clf.predict(test_x)\r\n",
        "print(\"DEBUG::The SVC Classifier predicted labels are::\")\r\n",
        "print(predicted_labels)\r\n",
        "\r\n",
        "acc_score = accuracy_score(test_y, predicted_labels)\r\n",
        "print(\"The SVC Classifier testing accuracy score is::\")\r\n",
        "print(acc_score)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training the SVC Classifier took   4 seconds\n",
            "DEBUG::The SVC Classifier predicted labels are::\n",
            "[0 1 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 0 0 0 0 1 0 0 1 0 0 1 1 0 0 0 0 0 1 1 0\n",
            " 0 1 1 1 1 0 1 0 0 1 0 1 1 0 0 0 1 1 0 1 0 0 1 0 1 1 0 1 1 0 1 1 1 0 1 0 0\n",
            " 0 1 1 1 1 0 1 1 1 1 0 1 0 0 1 1 1 0 0 1 0 1 1 1 0 1 1 1 1 1 1 1 1 0 1 0 0\n",
            " 0 0 1 0 1 1 1 0 1 0 0 1 0 1 1 1 1 0 1 0 0 0 0 1 1 1 1 1 0 0 0 0 1 1 0 0 1\n",
            " 0 0 1 1 0 0 1 1 1 0 1 1 1 0 1 1 0 1 0 1 1 1 0 1 1 0 1 0 0 1 1 0 1 1 0 0 1\n",
            " 1 0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 0 0 1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 0 1 0 1\n",
            " 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 1 1 0 1 0 0 0 0 0 0 1 0 0 1 0 0 1 1 0 0 1\n",
            " 0 0 0 0 1 0 1 0 1 0 1 1 1 1 0 0 1 1 0 1 1 1 0 1 0 0 1 0 1 1 0 1 0 0 1 1 0\n",
            " 0 1 1 0 0 1 0 1 1 0 0 0 1 0 1 0 0 0 1 1 1 0 0 1 0 1 1 0 1 0 0 0 0 0 0 1 1\n",
            " 1 1 1 1 0 1 1 0 1 0 0 1 1 1 1 0 0 1 0 0 0 0 0 1 1 0 1 1 0 1 0 0 1 0 0 1 1\n",
            " 0 1 1 0 0 1 0 1 1 0 1 1 0 0 0 0 1 1 0 1 0 0 1 0 1 1 0 0 0 0 1 0 1 0 0 0 1\n",
            " 1 1 1 1 1 1 0 1 1 1 1 1 0 0 1 1 0 1 1 0 0 0 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1\n",
            " 0 0 1 0 0 1 0 1 0 1 1 1 0 0 0 1 0 1 0 1 0 0 1 0 0 1 1 1 0 1 0 1 1 1 1 0 0\n",
            " 1 1 0 0 0 1 0 0 1 1 1 0 1 1 0 1 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 1 0 1 0 1\n",
            " 1 1 0 1 0 0 0 1 1 1 0 1 0 1 0 0 0 1 1 0 1 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0\n",
            " 0 0 0 0 1 0 0 1 0 1 1 0 1 1 0 0 1 1 1 0 0 0 1 1 1 0 1 0 0 0 1 0 0 1 0 1 1\n",
            " 1 1 1 1 0 0 1 0]\n",
            "The SVC Classifier testing accuracy score is::\n",
            "0.9633333333333334\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J6oXmj37zH_D"
      },
      "source": [
        "Training the SVM classifier on the email data took 64 seconds, and yielded an accuracy score of 0.98. We see that SVM significantly underperforms logistic regression for the email spam classification problem, while achieving lower but nearly comparable performance for the IMDB problem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JyO5Wc2ezaz8"
      },
      "source": [
        "## Decision-Tree-Based Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fgraLKGs6YKD"
      },
      "source": [
        "A decision tree is a decision support aid that models decisions and their consequences as trees - a graph where any two nodes are connected by exactly one path. An alternative definition of a tree is a flowchart transforming input values into output categories.\r\n",
        "\r\n",
        "In this section, we apply two of the most commonly used kinds of decision-tree-based methods – Random Forests and Gradient Boosting Machines – to the two illustrative running example problems. Other popular decision-tree-based methodologies that will not be explored include bagging, bootstrapping and boosting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VW4keHiT6Y_9"
      },
      "source": [
        "### Random Forests (RFs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v1ZRzpyt6buq"
      },
      "source": [
        "Random Forests (RFs) provide a practical machine learning method for applying decision trees. It involves generating a very large number of specialized trees and ensembling their outputs. RFs are extremely flexible and widely applicable, making them often the second algorithm practitioners try after logistic regression for baselining."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bg_BY5PDzA7s",
        "outputId": "9bea682b-dd0d-4af5-f4f0-4bf58cab843f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "clf = RandomForestClassifier(n_jobs=1, random_state=0)\r\n",
        "\r\n",
        "# Train the Classifier to take the training features and learn how they relate to the training y (spam, not spam?)\r\n",
        "start_time = time.time()\r\n",
        "clf.fit(train_x, train_y)\r\n",
        "end_time = time.time()\r\n",
        "print(\"Training the Random Forest Classifier took %3d seconds\" % (end_time - start_time))\r\n",
        "\r\n",
        "predicted_labels = clf.predict(test_x)\r\n",
        "print(\"DEBUG::The RF predicted labels are::\")\r\n",
        "print(predicted_labels)\r\n",
        "\r\n",
        "acc_score = accuracy_score(test_y, predicted_labels)\r\n",
        "print(\"DEBUG::The RF testing accuracy score is::\")\r\n",
        "print(acc_score)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training the Random Forest Classifier took   1 seconds\n",
            "DEBUG::The RF predicted labels are::\n",
            "[0 1 1 0 1 1 0 1 1 0 1 1 0 1 1 0 1 0 0 0 0 1 0 0 1 0 0 1 1 1 0 0 0 0 1 1 0\n",
            " 0 1 1 1 1 0 1 0 0 0 0 1 1 1 0 0 1 1 0 1 0 0 1 0 1 1 0 1 1 0 1 1 1 0 1 0 0\n",
            " 0 1 1 1 1 0 1 1 1 1 0 1 0 0 1 1 1 0 0 1 0 1 1 1 0 1 1 1 1 1 1 1 1 0 1 0 0\n",
            " 0 0 1 0 1 1 1 0 1 0 0 1 0 1 1 1 1 0 1 0 0 0 0 1 1 1 1 1 0 0 0 0 1 1 0 0 1\n",
            " 0 0 1 1 0 0 1 1 1 0 1 1 1 0 1 1 0 1 0 1 1 1 0 1 1 0 1 0 0 1 1 0 1 1 0 0 1\n",
            " 1 0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 0 0 1 1 1 1 1 1 1 0 0 1 1 0 1 0 1 0 0 0 1\n",
            " 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 1 1 0 1 0 0 0 0 0 0 1 0 0 1 0 0 1 1 0 0 1\n",
            " 0 0 0 0 1 0 1 0 1 0 1 1 1 1 0 0 1 1 0 1 0 1 0 1 0 0 1 0 1 1 0 1 0 0 1 1 0\n",
            " 0 1 1 0 0 1 0 1 1 0 0 0 1 0 1 0 0 0 1 1 1 0 0 1 0 1 1 0 1 0 0 0 0 0 0 0 1\n",
            " 1 1 1 1 0 1 1 0 1 0 0 1 1 1 1 0 0 1 0 0 0 0 0 1 1 0 1 1 0 1 0 0 0 0 0 1 1\n",
            " 0 1 1 0 0 1 0 1 1 0 1 1 0 0 0 0 1 1 0 1 0 0 1 0 1 1 0 0 0 0 1 0 1 0 0 0 1\n",
            " 1 1 1 1 1 1 0 1 1 1 1 1 0 0 1 1 0 1 1 0 0 0 1 1 1 1 1 0 1 0 1 1 0 1 1 0 1\n",
            " 0 0 1 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 0 1 0 0 1 0 0 1 0 1 0 1 0 1 1 1 1 0 0\n",
            " 0 1 0 0 0 1 0 0 1 1 1 0 1 1 0 1 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 1 0 1 0 1\n",
            " 1 1 0 1 0 0 0 1 1 1 0 1 0 1 0 0 0 1 1 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0\n",
            " 0 0 0 0 1 0 0 1 0 1 1 0 1 1 0 0 1 1 1 0 0 0 1 1 1 0 1 0 0 0 0 0 0 1 0 1 1\n",
            " 1 1 1 1 0 0 1 0]\n",
            "DEBUG::The RF testing accuracy score is::\n",
            "0.9666666666666667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "na_EZDCP-40e"
      },
      "source": [
        "Training the RF classifier on the email example data with this code took under a second in our experience, and achieved an accuracy score of 0.965."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v8csqE-L8RSI",
        "outputId": "57264ada-1906-4867-ca0c-87125577fa5e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Now, tune parameters systematically\r\n",
        "print(\"Available hyper-parameters for systematic tuning available with RF:\")\r\n",
        "print(clf.get_params())"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Available hyper-parameters for systematic tuning available with RF:\n",
            "{'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'auto', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_impurity_split': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'n_estimators': 100, 'n_jobs': 1, 'oob_score': False, 'random_state': 0, 'verbose': 0, 'warm_start': False}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRIiE9AS8-Yd",
        "outputId": "86e038e5-1788-43b2-d5e3-5e1d5dae070a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# select a subset of parameters to tune, and specify grid for each\r\n",
        "param_grid = {\r\n",
        "    \"min_samples_leaf\": [1, 2, 3],\r\n",
        "    \"min_samples_split\": [2, 6, 10],\r\n",
        "    \"n_estimators\": [10, 100, 1000]\r\n",
        "}\r\n",
        "\r\n",
        "grid_search = GridSearchCV(estimator=clf, param_grid=param_grid, cv=3, n_jobs=-1, verbose=2)\r\n",
        "# Fit the grid search to the data\r\n",
        "grid_search.fit(train_x, train_y)\r\n",
        "\r\n",
        "print(\"Best parameters found:\")\r\n",
        "print(grid_search.best_params_)\r\n",
        "\r\n",
        "print(\"Estimated accuracy is:\")\r\n",
        "acc_score = accuracy_score(test_y, grid_search.best_estimator_.predict(test_x))\r\n",
        "print(acc_score)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 27 candidates, totalling 81 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 2 concurrent workers.\n",
            "[Parallel(n_jobs=-1)]: Done  37 tasks      | elapsed:  2.3min\n",
            "[Parallel(n_jobs=-1)]: Done  81 out of  81 | elapsed:  4.7min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Best parameters found:\n",
            "{'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 1000}\n",
            "Estimated accuracy is:\n",
            "0.97\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-MVgzj4C-n7V"
      },
      "source": [
        "This further confirms the initial hunch from previous section that the IMDB review problem is harder than the email classification problem that was set up."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ls2HjpAAbBN"
      },
      "source": [
        "### Gradient Boosting Machines (GBMs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OP7RHhlxAdjR"
      },
      "source": [
        "This variant of decision-tree-based machine learning algorithms iteratively learns new decisiontree- based models that address weak points of models from the previous iterations. At the time of this writing, they are widely considered to be the best class of methods for addressing nonperceptual\r\n",
        "ML problems. This does come with some disadvantages unfortunately, including\r\n",
        "larger model size, higher risk of overfitting and less interpretability than some other decisiontree models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jfhufdsu-NYQ"
      },
      "source": [
        "def modelfit(alg, train_x, train_y, predictors, test_x, performCV=True, printFeatureImportance=False, cv_folds=5):\r\n",
        "  # Fit the algorithm on the data\r\n",
        "  alg.fit(train_x, train_y)\r\n",
        "\r\n",
        "  # Predict training set:\r\n",
        "  predictions = alg.predict(train_x)\r\n",
        "  predprob = alg.predict_proba(train_x)[:, 1]\r\n",
        "\r\n",
        "  # Perform cross-validation:\r\n",
        "  if performCV:\r\n",
        "    cv_score = cross_val_score(alg, train_x, train_y, cv=cv_folds, scoring=\"roc_auc\")\r\n",
        "\r\n",
        "  # Print model report:\r\n",
        "  print(\"\\nModel Report\")\r\n",
        "  print(\"Accuracy : %.4g\" % metrics.accuracy_score(train_y, predictions))\r\n",
        "  print(\"AUC Score (Train): %f\" % metrics.roc_auc_score(train_y, predprob))\r\n",
        "\r\n",
        "  if performCV:\r\n",
        "    print(\"CV Score : Mean - %.7g | Std - %.7g | Min - %.7g | Max - %.7g\" % (np.mean(cv_score), np.std(cv_score), np.min(cv_score), np.max(cv_score)))\r\n",
        "\r\n",
        "  # Print Feature Importance:\r\n",
        "  if printFeatureImportance:\r\n",
        "    feat_imp = pd.Series(alg.feature_importances_, predictors).sort_values(ascending=False)\r\n",
        "    feat_imp[:10].plot(kind=\"bar\", title=\"Feature Importances\")\r\n",
        "\r\n",
        "  return alg.predict(test_x), alg.predict_proba(test_x)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5MxZ98SiHTU_",
        "outputId": "678a069f-8f49-4b2e-86a1-c66310223bf8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "gbm0 = GradientBoostingClassifier(random_state=10)\r\n",
        "\r\n",
        "start_time = time.time()\r\n",
        "test_predictions, test_probs = modelfit(gbm0, train_x, train_y, predictors, test_x)\r\n",
        "end_time = time.time()\r\n",
        "print(\"Training the Gradient Boosting Classifier took %3d seconds\"%(end_time-start_time))\r\n",
        "\r\n",
        "predicted_labels = test_predictions\r\n",
        "print(\"DEBUG::The Gradient Boosting predicted labels are::\")\r\n",
        "print(predicted_labels)\r\n",
        "\r\n",
        "acc_score = accuracy_score(test_y, predicted_labels)\r\n",
        "print(\"DEBUG::The Gradient Boosting testing accuracy score is::\")\r\n",
        "print(acc_score)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Model Report\n",
            "Accuracy : 0.9793\n",
            "AUC Score (Train): 0.997339\n",
            "CV Score : Mean - 0.9803378 | Std - 0.007387046 | Min - 0.9692029 | Max - 0.9912227\n",
            "Training the Gradient Boosting Classifier took 113 seconds\n",
            "DEBUG::The Gradient Boosting predicted labels are::\n",
            "[1 1 1 0 1 1 0 1 1 1 1 1 0 1 1 0 1 0 0 0 0 1 1 0 1 0 0 1 1 1 0 0 0 0 1 1 0\n",
            " 0 1 1 1 1 0 1 0 0 1 0 1 1 1 0 0 1 1 0 1 0 0 1 0 1 1 0 1 1 0 1 1 1 0 1 0 0\n",
            " 0 1 0 1 1 0 1 1 1 1 0 1 0 0 1 1 1 0 0 1 0 1 1 1 0 1 1 1 1 1 1 1 1 0 1 0 0\n",
            " 0 0 1 0 1 1 0 0 1 0 0 1 0 1 1 1 1 0 1 0 0 0 0 1 1 1 1 1 0 0 0 0 1 1 0 0 1\n",
            " 0 0 1 1 0 0 1 1 1 0 1 1 1 0 1 1 1 1 0 1 1 1 0 1 1 0 1 0 0 1 1 0 1 1 0 0 1\n",
            " 1 0 0 0 1 1 0 0 1 0 0 0 0 1 0 0 0 0 1 1 1 1 1 1 1 0 0 1 1 1 1 0 1 0 1 0 1\n",
            " 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 1 1 0 1 0 0 0 0 0 0 1 0 0 1 0 0 1 1 0 0 1\n",
            " 0 0 0 0 1 0 1 0 1 0 1 1 1 1 0 1 1 1 0 1 1 1 0 1 0 0 1 0 1 1 0 1 0 0 1 1 0\n",
            " 0 1 1 0 0 1 0 1 1 0 0 0 1 0 1 0 0 0 1 1 1 0 0 1 0 1 1 0 1 0 0 0 0 0 0 1 1\n",
            " 1 1 1 1 0 1 1 0 1 0 0 1 1 1 1 0 0 1 0 0 0 0 0 1 1 0 1 0 0 1 0 0 1 0 0 1 1\n",
            " 0 1 1 0 0 1 0 1 1 0 1 1 0 0 0 0 1 1 0 1 0 0 1 0 1 1 0 0 0 0 1 0 1 0 0 0 1\n",
            " 1 1 1 1 1 1 0 1 1 1 1 1 0 0 1 1 0 1 1 0 0 0 1 1 1 1 1 0 1 0 1 1 0 1 1 1 1\n",
            " 0 0 1 0 0 1 0 1 0 1 1 1 0 1 0 1 1 1 0 1 0 0 1 0 0 1 1 1 0 1 0 1 1 1 1 0 0\n",
            " 0 1 0 0 0 1 1 0 1 1 1 0 1 1 0 1 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 1 1 0 1 0 1\n",
            " 1 1 0 1 0 0 0 1 1 1 0 1 0 1 1 0 0 1 1 0 1 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0\n",
            " 0 0 0 0 1 0 0 1 0 1 1 0 1 1 0 0 1 1 1 0 0 0 1 1 1 1 1 0 0 0 1 0 0 1 0 1 1\n",
            " 1 1 1 1 0 0 1 0]\n",
            "DEBUG::The Gradient Boosting testing accuracy score is::\n",
            "0.9483333333333334\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c5WOMQ9gI1an"
      },
      "source": [
        "Note that in addition to the usual training accuracy score, we report k-fold crossvalidation and the area under the Receiver Operating Characteristic curve (ROC AUC) to evaluate the model. We consider it necessary to do these here as GBMs are particularly prone to overfitting, and reporting these metrics helps us monitor that risk.\r\n",
        "\r\n",
        "More specifically, k-fold cross validation (with default value of k=5 folds) randomly splits the training dataset into k partitions or folds, trains the model on k-1 of them while evaluating/validating performance on the remaining kth partition, repeating this process k times with each partition serving as a validation set. It then reports the performance using the statistics of these k evaluation iterations. This allows us to reduce the risk of the model\r\n",
        "overfitting on some parts of the dataset while underperforming on others.\r\n",
        "\r\n",
        "> **NOTE**: Put simply, overfitting refers to fitting too many parameters to too little data. This scenario hurts the model’s ability to generalize to new data, and often manifests as improving training metrics with no improvement in validation metrics. It can be alleviated by collecting more data, simplifying the model to reduce the number of training parameters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjL1iLHTKNKM"
      },
      "source": [
        "We can see some evidence of overfitting, as the testing accuracy is lower than the k-fold training accuracy for the first example. Moreover, in the case of the IMDB example, the k-fold cross validation scores are noticeably lower than the training score on the overall dataset, underscoring the importance of using the k-fold cross-validation approach for tracking overfitting in this model type.\r\n",
        "\r\n",
        "So what exactly is the ROC curve? The ROC curve is the plot of the false positive rate (FPR) versus the true positive rate (TPR). It is an important characteristic used to evaluate and tune classifiers. It shows the tradeoff in these important qualities of a classifier as the decision threshold, the probability value beyond which a predicted confidence begins to be classified as\r\n",
        "a member of a given class, is varied between 0 and 1."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "18ZDjMR7H2UW",
        "outputId": "086abb39-9a01-427d-a2e2-554f73fa9bcd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        }
      },
      "source": [
        "# Make an ROC curve\r\n",
        "\r\n",
        "# first need to find probabilities corresponding to most likely class (max probability)\r\n",
        "test_probs_max = []\r\n",
        "for i in range(test_probs.shape[0]):\r\n",
        "  test_probs_max.append(test_probs[i, test_y[i]])\r\n",
        "print(len(test_probs_max))\r\n",
        "\r\n",
        "# now, generate the curve data\r\n",
        "fpr, tpr, thresholds = metrics.roc_curve(test_y, np.array(test_probs_max))\r\n",
        "\r\n",
        "# plot curve data\r\n",
        "fig,ax = plt.subplots()\r\n",
        "plt.plot(fpr,tpr,label='ROC curve')\r\n",
        "plt.plot([0, 1], [0, 1], color='navy', linestyle='--')\r\n",
        "plt.xlabel('False Positive Rate')\r\n",
        "plt.ylabel('True Positive Rate')\r\n",
        "plt.title('Receiver Operating Characteristic for Email Example')\r\n",
        "plt.legend(loc=\"lower right\")\r\n",
        "plt.show()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "600\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gk-DcdiFLyxe"
      },
      "source": [
        "The straight line with slope of 1 in the figure represents the FPR versus TPR tradeoff corresponding to random chance. The further to the left the ROC curve is from this line, the better performing the classifier. As a result, the area under the Receiver Operating Characteristic curve (ROC AUC) can be used as a measure of performance.\r\n",
        "\r\n",
        "It is important to caution you, however, that while these importance scores seem to work well for this example, they should not always be blindly trusted. For instance, it has been widely recognized that these importance scores can be biased towards continuous variables, as well as high cardinality categorical variables."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7BGemMq-PGAt"
      },
      "source": [
        "### XGBoost Model classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ZR5GJfNLdCn"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}