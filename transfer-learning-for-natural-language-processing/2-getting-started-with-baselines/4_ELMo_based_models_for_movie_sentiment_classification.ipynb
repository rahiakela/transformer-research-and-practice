{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4-ELMo-based-models-for-movie-sentiment-classification.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyP0Dxc7T3m5+QhNEPY8J7mG",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/transfer-learning-for-natural-language-processing/blob/main/2-getting-started-with-baselines/4_ELMo_based_models_for_movie_sentiment_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0syenf2nUMgZ"
      },
      "source": [
        "# ELMo based models for Movie Sentiment Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Tvj1R7TUOC2"
      },
      "source": [
        "Our goal is to establish a set of baselines for a pair of concrete NLP problems, which we will later be able to use to measure progressive improvements gained from leveraging increasingly sophisticated transfer learning\r\n",
        "approaches. In the process of doing this, we aim to advance your general NLP instincts and refresh your understanding of typical procedures involved in setting up problem-solving pipelines for such problems. You will review techniques ranging from tokenization to data structure and model selection. We first train some traditional machine learning models from scratch to establish some preliminary baselines for these problems.\r\n",
        "\r\n",
        "We will focus on a pair of important representative example NLP problems – spam\r\n",
        "classification of email, and sentiment classification of movie reviews. This exercise will arm you with a number of important skills, including some tips for obtaining, visualizing and preprocessing data. \r\n",
        "\r\n",
        "Three major model classes will be covered, namely linear models such as logistic regression, decision-tree-based models such as random forests, and neural-network-based models such as ELMo. These classes are additionally represented by support vector machines (SVMs) with linear kernels, gradient-boosting machines (GBMs) and BERT respectively. \r\n",
        "\r\n",
        "<img src='https://github.com/rahiakela/img-repo/blob/master/transfer-learning-for-natural-language-processing/content-classification-supervised-models.png?raw=1' width='800'/>\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "inPFIdfP7n4K"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eViYUVkrsQRx"
      },
      "source": [
        "Ref: https://stackoverflow.com/questions/57742410/error-on-scope-variable-while-using-tensorflow-hub"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "196aBN-ysBut"
      },
      "source": [
        "!pip install keras==2.2.4 # critical dependency\r\n",
        "!pip install tensorflow==1.15\r\n",
        "!pip install \"tensorflow_hub>=0.6.0\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xlt8No657pZ_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "679bb014-42e4-4e60-aa29-7eb440c5cf0e"
      },
      "source": [
        "import numpy as np  # linear algebra\r\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\r\n",
        "import email        # email package for processing email messages\r\n",
        "import random\r\n",
        "import re\r\n",
        "import time\r\n",
        "import os\r\n",
        "\r\n",
        "\r\n",
        "import tensorflow as tf\r\n",
        "import tensorflow_hub as hub\r\n",
        "from keras import backend as K\r\n",
        "import keras.layers as layers\r\n",
        "from keras.models import Model, load_model\r\n",
        "from keras.engine import Layer\r\n",
        "\r\n",
        "import nltk\r\n",
        "nltk.download('stopwords')\r\n",
        "from nltk.corpus import stopwords\r\n",
        "\r\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-5dMITwbsVei"
      },
      "source": [
        "# Initialize tensorflow/keras session\r\n",
        "sess = tf.Session()\r\n",
        "K.set_session(sess)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJKVZMbo7va7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67e0028c-bc59-44ea-e4a7-7a8786bcb8fd"
      },
      "source": [
        "%%shell\r\n",
        "\r\n",
        "wget -q \"http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\r\n",
        "tar xzf aclImdb_v1.tar.gz\r\n",
        "\r\n",
        "rm -rf aclImdb_v1.tar.gz\r\n",
        "rm -rf aclImdb/train/unsup"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              ""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zQbAbRM7Wtfs"
      },
      "source": [
        "## Preprocessing Movie Sentiment Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HplaHzeVWwfg"
      },
      "source": [
        "This notebook is concerned with classifying movie reviews from IMDB into\r\n",
        "positive or negative sentiments expressed. This is a prototypical sentiment analysis example that has been used widely in the literature to study many algorithms.\r\n",
        "\r\n",
        "We will use a popular labeled dataset of 25000 reviews for this, which was assembled by scraping the popular movie review website IMDB and mapping the number of stars corresponding to each review to either 0 or 1 – depending on whether it was less than or greater than 5 out of 10 stars respectively.It has been used widely in prior NLP literature, and this familiarity is part of the reason we choose it as an illustrative example for baselining.\r\n",
        "\r\n",
        "The sequence of steps used to preprocess each IMDB movie review before analysis is very similar to the one presented for the email spam classification example.\r\n",
        "\r\n",
        "The first major difference is that no email headers are attached to these reviews, so the header extraction step is not applicable. \r\n",
        "\r\n",
        "Additionally, since some stopwords – including “no” and “not” – may\r\n",
        "change the sentiment of the message, the stopword removal step may need to be carried out with extra care, first making sure to drop such stopwords from the target list. We did experiment with dropping such words from the list, and saw little to no effect on the result. This is likely because other non-stopwords in the reviews are very predictive features, rendering this step irrelevant.\r\n",
        "\r\n",
        "<img src='https://github.com/rahiakela/img-repo/blob/master/transfer-learning-for-natural-language-processing/spam-email-preprocessing.png?raw=1' width='800'/>\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rsXoqMRdwC65"
      },
      "source": [
        "### IMDB Movie Review Dataset preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UeeYY2_OuxYw"
      },
      "source": [
        "Before proceeding, we must decide how many samples to draw from each class. We must also decide the maximum number of tokens per email, and the maximum length of each token. This is done by setting the following overarching hyperparameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7_qzNMcNsGh-"
      },
      "source": [
        "n_sample = 1000   # number of samples to generate in each class\r\n",
        "maxtokens = 50    # the maximum number of tokens per document\r\n",
        "maxtokenlen = 20  # the maximum length of each token"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QRVD-qopxT2f"
      },
      "source": [
        "With these hyperparameters specified, we can now create a single DataFrame for the overarching training dataset. Let’s take the opportunity to also perform remaining preprocessing tasks, namely removing stop words, punctuations and tokenizing."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2OTWZJ6w9-J"
      },
      "source": [
        "#### Tokenization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A-dJjXYvxaK9"
      },
      "source": [
        "Let’s proceed by defining a function to tokenize text by splitting them into \r\n",
        "words."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42b-458pwdRh"
      },
      "source": [
        "def tokenize(row):\r\n",
        "  if row is None or row is \"\":\r\n",
        "    tokens = \"\"\r\n",
        "  else:\r\n",
        "    tokens = row.split(\" \")[:maxtokens]\r\n",
        "  return tokens"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5_viulZEyUNO"
      },
      "source": [
        "#### Remove punctuation and unnecessary characters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4MOkUJbxyUeG"
      },
      "source": [
        "**In order to ensure that classification is done based on language content only, we have to remove punctuation marks and other non-word characters from the emails.** We do this by employing regular expressions with the Python regex library. We also normalize words by turning them into lower case."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2n-aNOVNx3mC"
      },
      "source": [
        "def reg_expressions(row):\r\n",
        "  tokens = []\r\n",
        "  try:\r\n",
        "    for token in row:\r\n",
        "      token = token.lower()          # make all characters lower case\r\n",
        "      token = re.sub(r\"[\\W\\d]\", \"\", token)\r\n",
        "      token = token[:maxtokenlen]    # truncate all tokens to hyperparameter maxtokenlen\r\n",
        "      tokens.append(token)\r\n",
        "  except:\r\n",
        "    token = \"\"\r\n",
        "    tokens.append(token)\r\n",
        "  return tokens"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ubr6_29dzvyA"
      },
      "source": [
        "#### Stop-word removal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VjpNoFWhzwqu"
      },
      "source": [
        "Stop-words are also removed. Stop-words are words that are very common in text but offer no useful information that can be used to classify the text. Words such as is, and, the, are are examples of stop-words. The NLTK library contains a list of 127 English stop-words and can be used to filter our tokenized strings."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fObPMgFUZ40",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b3a33f90-0388-4025-e32b-916d0396c7df"
      },
      "source": [
        "stop_words = stopwords.words(\"english\")\r\n",
        "print(stop_words)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qoJ-_4jZUr0N"
      },
      "source": [
        "# it may be beneficial to drop negation words from the removal list, as they can change the positive/negative meaning of a sentence\r\n",
        "stop_words.remove(\"no\")\r\n",
        "stop_words.remove(\"nor\")\r\n",
        "stop_words.remove(\"not\")"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "75fyCvyDzpFd"
      },
      "source": [
        "def stop_word_removal(row):\r\n",
        "  token = [token for token in row if token not in stop_words]\r\n",
        "  token = filter(None, token)\r\n",
        "\r\n",
        "  return token"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sj0jsZ9W65Yo"
      },
      "source": [
        "### Converting the Sentiment Text Into Numbers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALmmE6Wo7A-6"
      },
      "source": [
        "Before using this function to train a model, we will need to adapt our preprocessed data a bit for this model architecture.\r\n",
        "\r\n",
        "We use the below function to combine each such list into a single text string. This is the format in which the ELMo TensorFlow hub model expects the input, and we are glad to oblige.\r\n",
        "\r\n",
        "> **NOTE**: The combined string in this case has stopwords removed – steps that are often not required in deep learning practice due to the uncanny ability of artificial neural networks to figure out what is important and isn’t,\r\n",
        "i.e., feature engineering, automatically. In our case, since we are trying to compare the strengths and weaknesses of the different model types for this problem, applying the same kind of preprocessing for all algorithms makes sense and is arguably the right approach. We note however that ELMo was pretrained on a corpus containing stopwords, as was BERT.\r\n",
        "\r\n",
        "Having fully vectorized the dataset, we must remember that it is not shuffled with respect to classes, i.e., it contains Nsamp = 1000 spam emails followed by an equal number of nonspam emails. Depending on how this dataset is split, in our case by picking the first 70% for training and the remainder for testing, this could lead to a training set composed of spam only, which would obviously lead to failure. In order to create a randomized ordering of class samples in the dataset, we will need to shuffle the data in unison with the header/list of labels.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPOqephWYXu6"
      },
      "source": [
        "# shuffle raw data first\r\n",
        "def unison_shuffle_data(data, header):\r\n",
        "  p = np.random.permutation(len(header))\r\n",
        "  data = data[p]\r\n",
        "  header = np.asarray(header)[p]\r\n",
        "\r\n",
        "  return data, header"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4w91A4yXqcc"
      },
      "source": [
        "Let's load dataset into a Numpy array after tokenizing, removing stopwords and punctuations, and shuffling."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mHgrPX9XX1Rr"
      },
      "source": [
        "# load data in appropriate form\r\n",
        "def load_data(path):\r\n",
        "  data, sentiments = [], []\r\n",
        "  for folder, sentiment in ((\"neg\", 0), (\"pos\", 1)):\r\n",
        "    folder = os.path.join(path, folder)\r\n",
        "    for name in os.listdir(folder):\r\n",
        "      with open(os.path.join(folder, name), \"r\") as reader:\r\n",
        "        text = reader.read()\r\n",
        "      text = tokenize(text)            # tokenizing\r\n",
        "      text = stop_word_removal(text)   # removing stopwords and punctuations\r\n",
        "      text = reg_expressions(text)\r\n",
        "      data.append(text)\r\n",
        "      sentiments.append(sentiment)     # Track corresponding sentiment labels\r\n",
        "\r\n",
        "  # converting to Numpy array\r\n",
        "  data_np = np.array(data)\r\n",
        "  # shuffling\r\n",
        "  data, sentiments = unison_shuffle_data(data_np, sentiments)\r\n",
        "\r\n",
        "  return data, sentiments"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XLpNdWmlaYjB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7def8aeb-bf7f-4717-a05d-2cabfdbdb13c"
      },
      "source": [
        "train_path = os.path.join(\"aclImdb\", \"train\")\r\n",
        "test_path = os.path.join(\"aclImdb\", \"test\")\r\n",
        "\r\n",
        "raw_data, raw_header = load_data(train_path)\r\n",
        "print(raw_data.shape)\r\n",
        "print(len(raw_header))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(25000,)\n",
            "25000\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:16: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  app.launch_new_instance()\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kzga3_25aXw3"
      },
      "source": [
        "Let's take n_sample*2 random entries of the loaded data for training:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vUWw0t6fdhZf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "434d218c-626b-4753-f2cb-be018b11cfd1"
      },
      "source": [
        "# Subsample required number of samples\r\n",
        "random_indices = np.random.choice(range(len(raw_header)), size=(n_sample * 2, ), replace=False)\r\n",
        "data_train = raw_data[random_indices]\r\n",
        "header = raw_header[random_indices]\r\n",
        "\r\n",
        "print(\"DEBUG::data_train::\")\r\n",
        "print(data_train[:5])"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DEBUG::data_train::\n",
            "[list(['i', 'watched', 'movie', '', 'years', 'ago', 'company', 'best', 'female', 'friend', 'i', 'got', 'judgment', 'teeth', 'pulled', 'i', 'feel', 'goodbr', 'br', 'i', 'ended', 'liking', 'big', 'time', 'its', 'hard', 'watch', 'take', 'account', 'deals', 'friendship', 'unwanted'])\n",
            " list(['the', 'movie', 'fun', 'staring', 'sunsheriff', 'pataki', 'total', 'retard', 'loves', 'nothing', 'better', 'sit', 'fat', 'rear', 'making', 'smoke', 'ring', 'puffy', 'cigars', 'drinking', 'booze', 'doctor', 'acts', 'like', 'zombie', 'version', 'nicholas', 'cage'])\n",
            " list(['rebar', 'astronaut', 'goes', 'worlds', 'first', 'space', 'mission', 'saturn', 'course', 'horror', 'movie', 'things', 'turn', 'ugly', 'returns', 'earth', 'survivor', 'stricken', 'bizarre', 'condition', 'causes', 'slowly', 'melt', 'lose', 'mind', 'unless'])\n",
            " list(['a', 'quiet', 'sweet', 'beutifully', 'nostalgic', 'movie', 'confronted', 'old', 'friends', 'surroundings', 'youth', 'memories', 'problems', 'sorrows', 'present', 'you', 'a', 'movie', 'makes', 'feel', 'good', 'all', 'ingredients', 'here', 'old', 'jelousy'])\n",
            " list(['i', 'never', 'panned', 'film', 'online', 'i', 'felt', 'moved', 'so', 'seeing', 'one', 'one', 'show', 'someones', 'funeral', 'say', 'bereaved', 'my', 'relatives', 'died', 'i', 'care', 'yoursbr', 'br', 'minus', 'propaganda', 'little', 'anything'])]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "htBzFn8Bgb7N"
      },
      "source": [
        "Before proceeding, we need to check the balance of the resulting data with regards to class. In general, we don’t want one of the labels to represent most of the dataset, unless that is the distribution expected in practice."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADYCfHfsgegJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6abfd11-f801-4143-d829-3a59da20ebe0"
      },
      "source": [
        "# Display sentiments and their frequencies in the dataset, to ensure it is roughly balanced between classes\r\n",
        "unique_elements, counts_elements = np.unique(header, return_counts=True)\r\n",
        "print(\"Sentiments and their frequencies:\")\r\n",
        "print(unique_elements)\r\n",
        "print(counts_elements)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sentiments and their frequencies:\n",
            "[0 1]\n",
            "[1029  971]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9CWfDvIvLef"
      },
      "source": [
        "# function for converting data into the right format, due to the difference in required format from sklearn models\r\n",
        "# we expect a single string per email here, versus a list of tokens for the sklearn models previously explored\r\n",
        "def convert_data(raw_data, header):\r\n",
        "  converted_data, labels = [], []\r\n",
        "  for i in range(raw_data.shape[0]):\r\n",
        "    # combine list of tokens representing each email into single string\r\n",
        "    out = \" \".join(raw_data[i])\r\n",
        "    converted_data.append(out)\r\n",
        "    labels.append(header[i])\r\n",
        "  converted_data = np.array(converted_data, dtype=object)[:, np.newaxis]\r\n",
        "\r\n",
        "  return converted_data, np.array(labels)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TIGDs4kZYCIr"
      },
      "source": [
        "As the very last step of preparing the sentiment dataset for training by our baseline classifiers, we split it into independent training and testing or validation sets. This will allow us to evaluate the performance of the classifier on a set of data that was not used for training, an important thing\r\n",
        "to ensure in machine learning practice. We elect to use 70% of the data for training, and 30% for testing/validation afterwards."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2bJ0TlTX3FW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa645a75-a706-4b70-c911-dc099fd9eb26"
      },
      "source": [
        "data_train, header = unison_shuffle_data(data_train, header)\r\n",
        "\r\n",
        "# split into independent 70% training and 30% testing sets\r\n",
        "idx = int(0.7 * data_train.shape[0])  # get 70% index value\r\n",
        "\r\n",
        "# 70% of data for training\r\n",
        "train_x, train_y = convert_data(data_train[:idx], header[:idx])\r\n",
        "\r\n",
        "# remaining 30% for testing\r\n",
        "test_x, test_y = convert_data(data_train[idx:], header[idx:])\r\n",
        "\r\n",
        "print(\"train_x/train_y list details, to make sure they are of the right form:\")\r\n",
        "print(len(train_x))\r\n",
        "print(train_x[:5])\r\n",
        "print(len(train_y))\r\n",
        "print(train_y[:5])"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "train_x/train_y list details, to make sure they are of the right form:\n",
            "1400\n",
            "[['where begin movie bad thisbr br do mention cast unlikeable heroes the overthetop acting the dreadful scriptbr br no you say anyone pays money see film poor needs head looking at i']\n",
            " ['truly one dire films ive ever sat through ive never actually taken time write one felt compelled witnessing affront filmmaking feel somewhat aggrieved wasting time piece turd honest']\n",
            " ['i firstly completely confidently disagree user calls spoof crispin glover serious film he personally introduced film screening i saw chicago he worked film years first']\n",
            " ['citizen x superbly told true story hunt one historys worst serial killers what makes story even compelling took place soviet union sbr br  mild spoilers br br  viktor burakov magnificently played']\n",
            " ['i really get people made film thought worth work put it even puzzling watched film without feeling cheated  minutes something valuable like cleaning couch reading leviticus br']]\n",
            "1400\n",
            "[0 0 0 1 0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7HQRPMa4Z8RB"
      },
      "source": [
        "Since 70% of 2000 is 1400, looks good! (for n_sample=1000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yAdf-aVkadDa"
      },
      "source": [
        "## Neural Network Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lyHf2bhnaeI8"
      },
      "source": [
        "Neural networks are the most important class of machine learning algorithms for handling perceptual problems such as computer vision and NLP.\r\n",
        "\r\n",
        "we will train two representative pretrained neural network language models\r\n",
        "on the two illustrative example problems we have been baselining.\r\n",
        "\r\n",
        "The two models we will consider here are:\r\n",
        "\r\n",
        "- **ELMo** – Embeddings from Language Models, and\r\n",
        "- **BERT** – Bidirectional Encoder Representations from Transformers.\r\n",
        "\r\n",
        "ELMo includes elements of convolutional and recurrent (specifically LSTM) elements, while the appropriately named BERT is transformer-based.\r\n",
        "\r\n",
        "The simplest form of transfer learning fine-tuning will be employed, where a single dense classification layer is trained on top of the corresponding pretrained embedding over our dataset of labels.\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tlwt9xNU6ESE"
      },
      "source": [
        "### Embeddings from Language Models (ELMo)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jm2Qs3zL6F_M"
      },
      "source": [
        "The Embeddings from Language Models (ELMo) model, named after the popular Sesame Street character, was among the first models to demonstrate the effectiveness of transferring pretrained language model knowledge to general NLP tasks. The model was trained to predict the next word in a sequence of words, which can be done in an unsupervised manner on very large corpuses, and showed that the weights obtained as a result could generalize to a variety\r\n",
        "of other NLP tasks.\r\n",
        "\r\n",
        "It will suffice to mention here that the model employs character-level convolutions to build up preliminary embeddings of each word token, followed by bidirectional LSTM layers which introduce context of surrounding words into\r\n",
        "the final embeddings produced by the model.\r\n",
        "\r\n",
        "The ELMo model is available through the Tensorflow Hub, which provides an\r\n",
        "easy platform for sharing Tensorflow models. We will use Keras with Tensorflow backend to build our model. In order to make the tensorflow hub model usable by Keras, we will need to define a custom Keras layer that instantiates it in the right format.\r\n",
        "\r\n",
        "Let's create a custom tf hub ELMO embedding layer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-z3ZAXn6-RtP"
      },
      "source": [
        "class ElmoEmbeddingLayer(Layer):\r\n",
        "\r\n",
        "  def __init__(self, **kwargs):\r\n",
        "    # initialize output dimension of ELMo embedding\r\n",
        "    self.dimensions = 1024\r\n",
        "    self.trainable = True\r\n",
        "    super(ElmoEmbeddingLayer, self).__init__(**kwargs)\r\n",
        "\r\n",
        "  def build(self, input_shape):\r\n",
        "    \"\"\"function for building ELMo embedding\"\"\"\r\n",
        "    # Download pretrained ELMo model from Tensorflow Hub\r\n",
        "    self.elmo = hub.Module(\"https://tfhub.dev/google/elmo/2\", trainable=self.trainable, name=\"{}_module\".format(self.name)) \r\n",
        "    # extract trainable parameters, which are only a small subset of the total - this is a constraint of\r\n",
        "    # the tf hub module as shared by the authors - see https://tfhub.dev/google/elmo/2\r\n",
        "    # the trainable parameters are 4 scalar weights on the sum of the outputs of ELMo layers \r\n",
        "    self.trainable_weights += K.tf.trainable_variables(scope=\"^{}_module/.*\".format(self.name))\r\n",
        "\r\n",
        "  def call(self, x, mask=None):\r\n",
        "    \"\"\"specify function for calling embedding\"\"\"\r\n",
        "    result = self.elmo(K.squeeze(K.cast(x, tf.string), axis=1), as_dict=True, signature=\"default\")[\"default\"]\r\n",
        "\r\n",
        "    return result\r\n",
        "\r\n",
        "  def compute_output_shape(self, input_shape):\r\n",
        "    \"\"\"specify output shape\"\"\"\r\n",
        "    return (input_shape[0], self.dimensions)"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSVYP1TK-vQe"
      },
      "source": [
        "We now use the custom TF hub ELMo embedding layer within a higher-level function to define the overall model. More specifically, we put a dense trainable layer of output dimension 256 on top of the ELMo embedding."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4XnCjA1-Sr-"
      },
      "source": [
        "def build_model():\r\n",
        "  input_text = layers.Input(shape=(1,), dtype=\"string\")\r\n",
        "  embedding = ElmoEmbeddingLayer()(input_text)\r\n",
        "  dense = layers.Dense(256, activation=\"relu\")(embedding)      # new layer outputting 256-dimensional feature vectors\r\n",
        "  prediction = layers.Dense(1, activation=\"sigmoid\")(dense)\r\n",
        "\r\n",
        "  # we could use sigmoid activation as well, but we choose softmax\r\n",
        "  # to enable us use sparse_categorical_crossentropy and sparse_categorical_accuracy below\r\n",
        "  model = Model(inputs=[input_text], outputs=prediction)\r\n",
        "  # use sparse_categorical_crossentropy and sparse_categorical_accuracy do avoid having to one-hot encode the labels\r\n",
        "  model.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\r\n",
        "\r\n",
        "  model.summary()\r\n",
        "\r\n",
        "  return model"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QolVseJU-fQ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5337fbe1-c06a-4f54-c08c-2aed00f8e854"
      },
      "source": [
        "# Build and fit\r\n",
        "model = build_model()\r\n",
        "history = model.fit(train_x, train_y, validation_data=(test_x, test_y), epochs=5, batch_size=32)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         (None, 1)                 0         \n",
            "_________________________________________________________________\n",
            "elmo_embedding_layer_1 (Elmo (None, 1024)              4         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 256)               262400    \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 257       \n",
            "=================================================================\n",
            "Total params: 262,661\n",
            "Trainable params: 262,661\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train on 1400 samples, validate on 600 samples\n",
            "Epoch 1/5\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "1400/1400 [==============================] - 444s 317ms/step - loss: 0.6211 - acc: 0.6507 - val_loss: 0.5776 - val_acc: 0.7017\n",
            "Epoch 2/5\n",
            "1400/1400 [==============================] - 429s 307ms/step - loss: 0.5424 - acc: 0.7400 - val_loss: 0.5987 - val_acc: 0.6833\n",
            "Epoch 3/5\n",
            "1400/1400 [==============================] - 437s 312ms/step - loss: 0.5078 - acc: 0.7414 - val_loss: 0.6896 - val_acc: 0.6233\n",
            "Epoch 4/5\n",
            "1400/1400 [==============================] - 442s 316ms/step - loss: 0.4983 - acc: 0.7593 - val_loss: 0.5484 - val_acc: 0.7167\n",
            "Epoch 5/5\n",
            "1400/1400 [==============================] - 435s 311ms/step - loss: 0.4496 - acc: 0.7921 - val_loss: 0.5592 - val_acc: 0.7067\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wUfBUPurxqrl"
      },
      "source": [
        "# Save trained model\r\n",
        "model.save(\"ELMoModel.h5\")"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-thuK3lxtWm"
      },
      "source": [
        "First of all, notice that we have added an additional layer on top the pretrained ELMo embedding, producing 256-dimensional feature vectors. We have also added a classification layer of output dimension 1. The activation function ‘sigmoid’ transforms its input into the interval between 0 and 1.\r\n",
        "\r\n",
        "Its output can be interpreted as the probability of the positive class, and when it exceeds some prespecified threshold (usually 0.5) the corresponding input to the network can be classified as the said positive class.\r\n",
        "\r\n",
        "We note that most of the trainable parameters in this case (approximately 260 thousand of them) are coming from the layers we added on top of the custom ELMo model. In other words, this is our first instance of transfer learning – learning a pair of new layers on top of the pretrained model shared by ELMo’s creators.\r\n",
        "\r\n",
        "In practice, one can increase the value of this parameter until the speed of convergence of a typical problem instance does not benefit from the increase, or whenever the GPU memory is no longer large enough for a single data batch to\r\n",
        "fit on it during an iteration of the algorithm, whichever happens first. Additionally, when dealing with a multi-GPU scenario, some evidence that the optimal scaling-up schedule of the batch size is linear in the number of GPUs, has been presented."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KP9SwddtxwbO",
        "outputId": "905004eb-c106-44e1-f6ef-4f2addc90f11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        }
      },
      "source": [
        "df_history = pd.DataFrame(history.history)\r\n",
        "\r\n",
        "fig,ax = plt.subplots()\r\n",
        "plt.plot(range(df_history.shape[0]),df_history['val_acc'],'bs--',label='validation')\r\n",
        "plt.plot(range(df_history.shape[0]),df_history['acc'],'r^--',label='training')\r\n",
        "plt.xlabel('epoch')\r\n",
        "plt.ylabel('accuracy')\r\n",
        "plt.title('ELMo Movie Review Classification Training')\r\n",
        "plt.legend(loc='best')\r\n",
        "plt.grid()\r\n",
        "plt.show()\r\n",
        "# Save figures\r\n",
        "fig.savefig('ELMoConvergence.eps', format='eps')\r\n",
        "fig.savefig('ELMoConvergence.pdf', format='pdf')\r\n",
        "fig.savefig('ELMoConvergence.png', format='png')\r\n",
        "fig.savefig('ELMoConvergence.svg', format='svg')"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:matplotlib.backends.backend_ps:The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n",
            "WARNING:matplotlib.backends.backend_ps:The PostScript backend does not support transparency; partially transparent artists will be rendered opaque.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "McjwONRhx0q8"
      },
      "source": [
        "We see that a validation accuracy of approximately 70.76% is attained at the 4th epoch, i.e., in under a minute. This performance is comparable to the performance of the logistic regression approach, which is only slightly better at 70.76%. We note that the behavior of the algorithm is stochastic, i.e., it behaves differently from run to run.\r\n",
        "\r\n",
        "Finally, we note that the divergence of training and validation accuracies is suggestive of the beginning of overfitting as indicative in the figure. This\r\n",
        "lends credence to the hypothesis that increasing the amount of signal by increasing the length of tokens, as specified by hyper-parameter maxtokenlen, and the number of tokens per email, as specified by maxtokens, may increase performance further. Naturally, increasing the number of samples per class by cranking up Nsamp should also work to improve performance.\r\n",
        "\r\n",
        "Each epoch again takes approximately 10 seconds and a validation accuracy of approximately 70% is achieved in under a minute at the 3rd epoch.\r\n",
        "\r\n",
        "**Note that some evidence of overfitting can be observed at the 3rd and later epochs, as the training accuracy continues to improve, i.e., the fit to the data improves, while the validation accuracy remains lower.**"
      ]
    }
  ]
}