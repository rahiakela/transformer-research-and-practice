{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "01-ner-fine-tuning.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyObQny9s4AoSC5oFxywaxl7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/transformers-research-and-practice/blob/main/mastering-transformers/06-fine-tuning-language-models-for-token-classification/01_ner_fine_tuning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##NER Fine-tuning"
      ],
      "metadata": {
        "id": "ON7GeIdxwkhp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this notebook, we will fine-tune BERT for the following tasks: fine-tuning BERT for token classification problems such as NER and POS, fine-tuning a language model for an NER problem, and thinking of the QA problem as a start/stop token classification."
      ],
      "metadata": {
        "id": "mmqCspc-xAkU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Setup"
      ],
      "metadata": {
        "id": "ihXa5N6pxE28"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets tokenizers\n",
        "!pip install seqeval"
      ],
      "metadata": {
        "id": "QkSu3LX8wnde"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import datasets \n",
        "from transformers import BertTokenizerFast\n",
        "from transformers import AutoModelForTokenClassification \n",
        "from transformers import TrainingArguments, Trainer \n",
        "from transformers import DataCollatorForTokenClassification\n",
        "from transformers import pipeline\n",
        "\n",
        "import numpy as np \n",
        "import pandas as pd\n",
        "import json"
      ],
      "metadata": {
        "id": "LNbEp-eRxPMN"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Loading dataset"
      ],
      "metadata": {
        "id": "kJ7tT25bxmon"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "conll2003 = datasets.load_dataset(\"conll2003\")"
      ],
      "metadata": {
        "id": "7u-4gQqcxsy1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# double-check the dataset by accessing the train samples\n",
        "conll2003[\"train\"][0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "75XiyRbex5G2",
        "outputId": "5641606e-5d8d-4eae-f111-61af7221326f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'chunk_tags': [11, 21, 11, 12, 21, 22, 11, 12, 0],\n",
              " 'id': '0',\n",
              " 'ner_tags': [3, 0, 7, 0, 0, 0, 7, 0, 0],\n",
              " 'pos_tags': [22, 42, 16, 21, 35, 37, 16, 21, 7],\n",
              " 'tokens': ['EU',\n",
              "  'rejects',\n",
              "  'German',\n",
              "  'call',\n",
              "  'to',\n",
              "  'boycott',\n",
              "  'British',\n",
              "  'lamb',\n",
              "  '.']}"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we will use only NER tags\n",
        "conll2003[\"train\"].features[\"ner_tags\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bM5mVmpMyLP_",
        "outputId": "9a287016-50bd-4670-c0cf-e130d1dd3de3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequence(feature=ClassLabel(num_classes=9, names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC', 'B-MISC', 'I-MISC'], id=None), length=-1, id=None)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Load tokenizer"
      ],
      "metadata": {
        "id": "KV_KizhKygID"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizerFast.from_pretrained(\"bert-base-uncased\")"
      ],
      "metadata": {
        "id": "Q-zasVkcyiOp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's see how tokenizer can be used with a white-space tokenized sentence\n",
        "token_dict = tokenizer([\"Oh\", \"this\", \"sentence\", \"is\", \"tokenized\", \"and\", \"splitted\", \"by\", \"spaces\"], is_split_into_words=True)"
      ],
      "metadata": {
        "id": "4kfuxnu7zGRT"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame.from_dict({\"input_ids\": token_dict[\"input_ids\"], \n",
        "                        \"token_type_ids\": token_dict[\"token_type_ids\"],\n",
        "                        \"attention_mask\": token_dict[\"attention_mask\"]}).T"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "bMEu2P9L0Gyy",
        "outputId": "4ce44182-80ca-4c11-b998-5d98b9bdb0be"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                 0     1     2     3     4      5     6     7     8     9   \\\n",
              "input_ids       101  2821  2023  6251  2003  19204  3550  1998  3975  3064   \n",
              "token_type_ids    0     0     0     0     0      0     0     0     0     0   \n",
              "attention_mask    1     1     1     1     1      1     1     1     1     1   \n",
              "\n",
              "                  10    11   12  \n",
              "input_ids       2011  7258  102  \n",
              "token_type_ids     0     0    0  \n",
              "attention_mask     1     1    1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3ceae94a-ecbd-4c01-8dd8-a2ecbf0cf0b4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>input_ids</th>\n",
              "      <td>101</td>\n",
              "      <td>2821</td>\n",
              "      <td>2023</td>\n",
              "      <td>6251</td>\n",
              "      <td>2003</td>\n",
              "      <td>19204</td>\n",
              "      <td>3550</td>\n",
              "      <td>1998</td>\n",
              "      <td>3975</td>\n",
              "      <td>3064</td>\n",
              "      <td>2011</td>\n",
              "      <td>7258</td>\n",
              "      <td>102</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>token_type_ids</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attention_mask</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3ceae94a-ecbd-4c01-8dd8-a2ecbf0cf0b4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-3ceae94a-ecbd-4c01-8dd8-a2ecbf0cf0b4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-3ceae94a-ecbd-4c01-8dd8-a2ecbf0cf0b4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "It is required to preprocess the data before using it for training. \n",
        "\n",
        "To do so, we must\n",
        "use the following function and map into the entire dataset:"
      ],
      "metadata": {
        "id": "GILIjRO62QJO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_and_align_labels(examples, label_all_tokens=True):\n",
        "  tokenized_inputs = tokenizer(examples[\"tokens\"], truncation=True, is_split_into_words=True)\n",
        "  labels = []\n",
        "\n",
        "  for i, label in enumerate(examples[\"ner_tags\"]):\n",
        "    word_ids = tokenized_inputs.word_ids(batch_index=i)\n",
        "    previous_word_idx = None\n",
        "    label_ids = []\n",
        "    for word_idx in word_ids:\n",
        "      if word_idx is None:\n",
        "        label_ids.append(-100)\n",
        "      elif word_idx != previous_word_idx:\n",
        "        label_ids.append(label[word_idx])\n",
        "      else:\n",
        "        label_ids.append(label[word_idx] if label_all_tokens else -100)\n",
        "      previous_word_idx = word_idx\n",
        "    labels.append(label_ids)\n",
        "  tokenized_inputs[\"labels\"] = labels\n",
        "  return tokenized_inputs"
      ],
      "metadata": {
        "id": "1GnYHlDU2RmH"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's test it giving a single sample\n",
        "q = tokenize_and_align_labels(conll2003[\"train\"][4:5])\n",
        "\n",
        "pd.DataFrame.from_dict({\"input_ids\": q[\"input_ids\"], \n",
        "                        \"token_type_ids\": q[\"token_type_ids\"],\n",
        "                        \"attention_mask\": q[\"attention_mask\"],\n",
        "                        \"labels\": q[\"labels\"]}).T"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "4l2OBn-U387R",
        "outputId": "baa1006f-34d7-41fd-e285-d7318d78bded"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                                                0\n",
              "input_ids       [101, 2762, 1005, 1055, 4387, 2000, 1996, 2647...\n",
              "token_type_ids  [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...\n",
              "attention_mask  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
              "labels          [-100, 5, 0, 0, 0, 0, 0, 3, 4, 0, 0, 0, 0, 1, ..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a311b767-7017-4a55-a4bc-fe69a1587404\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>input_ids</th>\n",
              "      <td>[101, 2762, 1005, 1055, 4387, 2000, 1996, 2647...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>token_type_ids</th>\n",
              "      <td>[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>attention_mask</th>\n",
              "      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>labels</th>\n",
              "      <td>[-100, 5, 0, 0, 0, 0, 0, 3, 4, 0, 0, 0, 0, 1, ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a311b767-7017-4a55-a4bc-fe69a1587404')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-a311b767-7017-4a55-a4bc-fe69a1587404 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-a311b767-7017-4a55-a4bc-fe69a1587404');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's make it readable\n",
        "for token, label in zip(tokenizer.convert_ids_to_tokens(q[\"input_ids\"][0]), q[\"labels\"][0]):\n",
        "  print(f\"{token:_<40} {label}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X5nV9fj24woF",
        "outputId": "69ec08b7-9470-4468-cd32-23ebe22ebc2f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CLS]___________________________________ -100\n",
            "germany_________________________________ 5\n",
            "'_______________________________________ 0\n",
            "s_______________________________________ 0\n",
            "representative__________________________ 0\n",
            "to______________________________________ 0\n",
            "the_____________________________________ 0\n",
            "european________________________________ 3\n",
            "union___________________________________ 4\n",
            "'_______________________________________ 0\n",
            "s_______________________________________ 0\n",
            "veterinary______________________________ 0\n",
            "committee_______________________________ 0\n",
            "werner__________________________________ 1\n",
            "z_______________________________________ 2\n",
            "##wing__________________________________ 2\n",
            "##mann__________________________________ 2\n",
            "said____________________________________ 0\n",
            "on______________________________________ 0\n",
            "wednesday_______________________________ 0\n",
            "consumers_______________________________ 0\n",
            "should__________________________________ 0\n",
            "buy_____________________________________ 0\n",
            "sheep___________________________________ 0\n",
            "##me____________________________________ 0\n",
            "##at____________________________________ 0\n",
            "from____________________________________ 0\n",
            "countries_______________________________ 0\n",
            "other___________________________________ 0\n",
            "than____________________________________ 0\n",
            "britain_________________________________ 5\n",
            "until___________________________________ 0\n",
            "the_____________________________________ 0\n",
            "scientific______________________________ 0\n",
            "advice__________________________________ 0\n",
            "was_____________________________________ 0\n",
            "clearer_________________________________ 0\n",
            "._______________________________________ 0\n",
            "[SEP]___________________________________ -100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# let's apply it on the entire dataset\n",
        "tokenized_datasets = conll2003.map(tokenize_and_align_labels, batched=True)"
      ],
      "metadata": {
        "id": "2qiiSRo951-M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Fine-tuning model"
      ],
      "metadata": {
        "id": "uSfNWV1q6V0W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load the BERT model\n",
        "model = AutoModelForTokenClassification.from_pretrained(\"bert-base-uncased\", num_labels=9)"
      ],
      "metadata": {
        "id": "KS77OdT97oJY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare the trainer and training parameters\n",
        "training_args = TrainingArguments(\"test-ner\",\n",
        "                                  evaluation_strategy=\"epoch\",\n",
        "                                  learning_rate=2e-5,\n",
        "                                  per_device_train_batch_size=16,\n",
        "                                  per_device_eval_batch_size=16,\n",
        "                                  num_train_epochs=3,\n",
        "                                  weight_decay=0.01)"
      ],
      "metadata": {
        "id": "tIllUjbcM6dx"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prepare the data collator that will apply batch operations on the training dataset to use less memory and perform faster\n",
        "data_collator = DataCollatorForTokenClassification(tokenizer)"
      ],
      "metadata": {
        "id": "fDuv-si6Nmh6"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the sequence evaluation metric for NER\n",
        "metric = datasets.load_metric(\"seqeval\")"
      ],
      "metadata": {
        "id": "iKfzTlH3N_IV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's see how the metric works\n",
        "example = conll2003[\"train\"][0]"
      ],
      "metadata": {
        "id": "030fS6ASORSN"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "label_list = conll2003[\"train\"].features[\"ner_tags\"].feature.names\n",
        "labels = [label_list[i] for i in example[\"ner_tags\"]]\n",
        "\n",
        "metric.compute(predictions=[labels], references=[labels])"
      ],
      "metadata": {
        "id": "brcwJuaaOfL0",
        "outputId": "69a117ba-d1ec-442b-a5d3-8926cc55e981",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'MISC': {'f1': 1.0, 'number': 2, 'precision': 1.0, 'recall': 1.0},\n",
              " 'ORG': {'f1': 1.0, 'number': 1, 'precision': 1.0, 'recall': 1.0},\n",
              " 'overall_accuracy': 1.0,\n",
              " 'overall_f1': 1.0,\n",
              " 'overall_precision': 1.0,\n",
              " 'overall_recall': 1.0}"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# so let's define compute the metrics\n",
        "def compute_metrics(preds):\n",
        "  predictions, labels = preds\n",
        "  predictions = np.argmax(predictions, axis=2)\n",
        "\n",
        "  true_predictions = [\n",
        "     [label_list[p] for (p, l) in zip(prediction, label) if l != -100]\n",
        "     for prediction, label in zip(predictions, labels)                 \n",
        "  ]\n",
        "  true_labels = [\n",
        "     [label_list[l] for (p, l) in zip(prediction, label) if l != -100]\n",
        "     for prediction, label in zip(predictions, labels)                 \n",
        "  ]\n",
        "\n",
        "  results = metric.compute(predictions=true_predictions, references=true_labels)\n",
        "\n",
        "  return {\n",
        "    \"precision\": results[\"overall_precision\"],\n",
        "    \"recall\": results[\"overall_recall\"],\n",
        "    \"f1\": results[\"overall_f1\"],\n",
        "    \"accuracy\": results[\"overall_accuracy\"],\n",
        "  }"
      ],
      "metadata": {
        "id": "o0jKQXVMSWoX"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# in the last step, let's last steps are to make a trainer and train it accordingly\n",
        "trainer = Trainer(\n",
        "  model, training_args, \n",
        "  train_dataset=tokenized_datasets[\"train\"],\n",
        "  eval_dataset=tokenized_datasets[\"validation\"],\n",
        "  data_collator=data_collator,\n",
        "  tokenizer=tokenizer,\n",
        "  compute_metrics=compute_metrics\n",
        ")\n",
        "\n",
        "# train the model\n",
        "trainer.train()"
      ],
      "metadata": {
        "id": "6cQswYK0T52L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's save the model and tokenizer after training\n",
        "model.save_pretrained(\"ner_model\")"
      ],
      "metadata": {
        "id": "IvGVpX9QVxkr",
        "outputId": "d3361d4a-7932-483e-b045-49d75a05cad4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Configuration saved in ner_model/config.json\n",
            "Model weights saved in ner_model/pytorch_model.bin\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.save_pretrained(\"tokenizer\")"
      ],
      "metadata": {
        "id": "Zk0ydHffWBjH",
        "outputId": "c5e09358-015d-4da1-fb1e-40c6a0f8b94d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "tokenizer config file saved in tokenizer/tokenizer_config.json\n",
            "Special tokens file saved in tokenizer/special_tokens_map.json\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('tokenizer/tokenizer_config.json',\n",
              " 'tokenizer/special_tokens_map.json',\n",
              " 'tokenizer/vocab.txt',\n",
              " 'tokenizer/added_tokens.json',\n",
              " 'tokenizer/tokenizer.json')"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "If you wish to use the model with the pipeline, you must read the config file and assign `label2id` and `id2label` correctly according to the labels you have used in the `label_list` object."
      ],
      "metadata": {
        "id": "g3tI3d1XW1q-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# let's define id-to-label and label-to-id\n",
        "id2label = {str(i): label for i, label in enumerate(label_list)}\n",
        "label2id = {label: str(i) for i, label in enumerate(label_list)}"
      ],
      "metadata": {
        "id": "NWj4B0KGW74t"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# let's load the config file and assign label2id and id2label correctly\n",
        "config = json.load(open(\"ner_model/config.json\"))"
      ],
      "metadata": {
        "id": "S_AsCCxoXo2J"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "config[\"id2label\"] = id2label\n",
        "config[\"label2id\"] = label2id"
      ],
      "metadata": {
        "id": "nyeeBzwGXzNR"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "json.dump(config, open(\"ner_model/config.json\", \"w\"))"
      ],
      "metadata": {
        "id": "1RpIaFn1X8EO"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Afterward, it is easy to use the saved model using `pipeline`."
      ],
      "metadata": {
        "id": "_cXrT36fYOLa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fine_tuned_model = AutoModelForTokenClassification.from_pretrained(\"ner_model\")"
      ],
      "metadata": {
        "id": "8rX-i5tmYRwB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ner_pipeline = pipeline(\"ner\", model=fine_tuned_model, tokenizer=tokenizer)"
      ],
      "metadata": {
        "id": "XP0YszR3Yqna"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example = \"I live in New Delhi\"\n",
        "\n",
        "ner_results = ner_pipeline(example)\n",
        "print(ner_results)"
      ],
      "metadata": {
        "id": "tF6egiSVY7Sp",
        "outputId": "9d8fa236-c63e-4804-ce51-000156d9ef17",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'entity': 'B-LOC', 'score': 0.99875283, 'index': 4, 'word': 'new', 'start': 10, 'end': 13}, {'entity': 'I-LOC', 'score': 0.99805224, 'index': 5, 'word': 'delhi', 'start': 14, 'end': 19}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example = \"I live in Mumbai\"\n",
        "\n",
        "ner_results = ner_pipeline(example)\n",
        "print(ner_results)"
      ],
      "metadata": {
        "id": "tC4YI1GJZdLf",
        "outputId": "a6f7faa9-2551-4eea-f6dd-2c441414626f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'entity': 'B-LOC', 'score': 0.9977386, 'index': 4, 'word': 'mumbai', 'start': 10, 'end': 16}]\n"
          ]
        }
      ]
    }
  ]
}