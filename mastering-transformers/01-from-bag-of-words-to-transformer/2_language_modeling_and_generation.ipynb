{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2-language-modeling-and-generation.ipynb",
      "provenance": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPZw+sTf2ezvTYt2472tSq8",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rahiakela/transformer-research-and-practice/blob/main/mastering-transformers/01-from-bag-of-words-to-transformer/2_language_modeling_and_generation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Yp_vtV4LqYI"
      },
      "source": [
        "## Language modeling and generation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68q67XAdLrJc"
      },
      "source": [
        "For language-generation problems, the traditional approaches are based on leveraging n-gram language models. This is also called a Markov process, which is a stochastic model in which each word (event) depends on a subset of previous words—`unigram, bigram, or n-gram`, outlined as follows:\n",
        "\n",
        "- **Unigram** (all words are independent and no chain): This estimates the probability of word in a vocabulary simply computed by the frequency of it to the total word count.\n",
        "- **Bigram** (First-order Markov process): This estimates the `P (wordi| wordi-1)`. probability of wordi depending on `wordi-1`, which is simply computed by the ratio of `P(wordi , wordi-1)` to `P (wordi-1)`.\n",
        "- **Ngram** (N-order Markov process): This estimates `P(wordi | word0, ..., wordi-1)`.\n",
        "\n",
        "Let's give a simple language model implementation with the Natural Language Toolkit\n",
        "(NLTK) library. In the following implementation, we train a Maximum Likelihood\n",
        "Estimator (MLE) with order `n=2`. We can select any n-gram order such as `n=1` for unigrams, `n=2` for bigrams, `n=3` for trigrams, and so forth:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q_ivtbEDPvmu",
        "outputId": "72b9693c-33cd-412f-eb3c-b1d58a6727db"
      },
      "source": [
        "!pip -q install -U nltk==3.4"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l\r\u001b[K     |▎                               | 10 kB 31.2 MB/s eta 0:00:01\r\u001b[K     |▌                               | 20 kB 38.8 MB/s eta 0:00:01\r\u001b[K     |▊                               | 30 kB 25.6 MB/s eta 0:00:01\r\u001b[K     |█                               | 40 kB 22.5 MB/s eta 0:00:01\r\u001b[K     |█▏                              | 51 kB 13.4 MB/s eta 0:00:01\r\u001b[K     |█▍                              | 61 kB 14.7 MB/s eta 0:00:01\r\u001b[K     |█▋                              | 71 kB 13.1 MB/s eta 0:00:01\r\u001b[K     |█▉                              | 81 kB 14.1 MB/s eta 0:00:01\r\u001b[K     |██                              | 92 kB 15.1 MB/s eta 0:00:01\r\u001b[K     |██▎                             | 102 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |██▌                             | 112 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |██▊                             | 122 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |███                             | 133 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |███▏                            | 143 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |███▍                            | 153 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |███▋                            | 163 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |████                            | 174 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |████▏                           | 184 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |████▍                           | 194 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |████▋                           | 204 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |████▉                           | 215 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |█████                           | 225 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |█████▎                          | 235 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 245 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 256 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |██████                          | 266 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |██████▏                         | 276 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 286 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |██████▋                         | 296 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 307 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |███████                         | 317 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 327 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |███████▌                        | 337 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 348 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |████████                        | 358 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 368 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 378 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 389 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |█████████                       | 399 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 409 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 419 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 430 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |█████████▉                      | 440 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |██████████                      | 450 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 460 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |██████████▌                     | 471 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 481 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |███████████                     | 491 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 501 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 512 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |███████████▊                    | 522 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |████████████                    | 532 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 542 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |████████████▍                   | 552 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 563 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 573 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 583 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |█████████████▎                  | 593 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 604 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 614 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 624 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 634 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 645 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 655 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 665 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 675 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |███████████████▎                | 686 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 696 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |███████████████▉                | 706 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |████████████████                | 716 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 727 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 737 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 747 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 757 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████▏              | 768 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 778 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 788 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 798 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 808 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 819 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 829 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████▊             | 839 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 849 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████▏            | 860 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 870 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████▊            | 880 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 890 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 901 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 911 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████▋           | 921 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 931 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████           | 942 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▎          | 952 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 962 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████▊          | 972 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 983 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 993 kB 12.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 1.0 MB 12.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 1.0 MB 12.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 1.0 MB 12.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▏        | 1.0 MB 12.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 1.0 MB 12.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▋        | 1.1 MB 12.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 1.1 MB 12.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 1.1 MB 12.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 1.1 MB 12.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 1.1 MB 12.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 1.1 MB 12.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 1.1 MB 12.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 1.1 MB 12.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 1.1 MB 12.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 1.1 MB 12.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▉      | 1.2 MB 12.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 1.2 MB 12.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 1.2 MB 12.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▌     | 1.2 MB 12.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 1.2 MB 12.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 1.2 MB 12.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 1.2 MB 12.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▌    | 1.2 MB 12.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 1.2 MB 12.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 1.2 MB 12.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 1.3 MB 12.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▍   | 1.3 MB 12.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 1.3 MB 12.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 1.3 MB 12.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 1.3 MB 12.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 1.3 MB 12.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 1.3 MB 12.5 MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▊  | 1.3 MB 12.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 1.3 MB 12.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 1.4 MB 12.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 1.4 MB 12.5 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 1.4 MB 12.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 1.4 MB 12.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 1.4 MB 12.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 1.4 MB 12.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 1.4 MB 12.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 1.4 MB 12.5 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.4 MB 12.5 MB/s \n",
            "\u001b[?25h  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oy5X6IIVL4He",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0753c9b-732a-4203-91d8-d06c1828183f"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.corpus import gutenberg\n",
        "from nltk.lm import MLE\n",
        "from nltk.lm.preprocessing import padded_everygram_pipeline\n",
        "\n",
        "nltk.download('gutenberg')\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/gutenberg.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mCTrN4FZMuXw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb90fb10-4abb-4719-e4df-60a5b79bfbd4"
      },
      "source": [
        "macbeth = gutenberg.sents(\"shakespeare-macbeth.txt\")\n",
        "macbeth[:5]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[['[',\n",
              "  'The',\n",
              "  'Tragedie',\n",
              "  'of',\n",
              "  'Macbeth',\n",
              "  'by',\n",
              "  'William',\n",
              "  'Shakespeare',\n",
              "  '1603',\n",
              "  ']'],\n",
              " ['Actus', 'Primus', '.'],\n",
              " ['Scoena', 'Prima', '.'],\n",
              " ['Thunder', 'and', 'Lightning', '.'],\n",
              " ['Enter', 'three', 'Witches', '.']]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "woQg8ZitM8rk",
        "outputId": "42a8ab5d-008c-4813-f973-df07447275a1"
      },
      "source": [
        "model, vocab = padded_everygram_pipeline(2, macbeth)\n",
        "lm = MLE(2)\n",
        "lm.fit(model, vocab)\n",
        "\n",
        "print(list(lm.vocab)[:10])\n",
        "print(f\"The number of words is {len(lm.vocab)}\")"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['<s>', '[', 'The', 'Tragedie', 'of', 'Macbeth', 'by', 'William', 'Shakespeare', '1603']\n",
            "The number of words is 4020\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKkGzcllOKmO"
      },
      "source": [
        "The following code produces what the language model learned so far:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gFUobu4bN7v1",
        "outputId": "d84d62e5-d4e5-4956-b426-b90123a78763"
      },
      "source": [
        "print(f\"The frequency of the term 'Macbeth' is {lm.counts['Macbeth']}\")\n",
        "print(f\"The language model probability score of 'Macbeth' is {lm.score('Macbeth')}\")\n",
        "print(f\"The number of times 'Macbeth' follows 'Enter' is {lm.counts[['Enter']]['Macbeth']}\")\n",
        "print(f\"P(Macbeth | Enter) is {lm.score('Macbeth', ['Enter'])}\")\n",
        "print(f\"P(shaking | for) is {lm.score('shaking', ['for'])}\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The frequency of the term 'Macbeth' is 61\n",
            "The language model probability score of 'Macbeth' is 0.0022631149365585812\n",
            "The number of times 'Macbeth' follows 'Enter' is 15\n",
            "P(Macbeth | Enter) is 0.1875\n",
            "P(shaking | for) is 0.012195121951219513\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ak0qRrrnOvIe"
      },
      "source": [
        "The n-gram language model keeps `n-gram` counts and computes the conditional\n",
        "probability for sentence generation. `lm=MLE(2)` stands for MLE, which yields the maximum probable sentence from each token probability. \n",
        "\n",
        "The following code produces a random sentence of 10 words with the `<s>` starting condition given:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vx8XahcYPqds",
        "outputId": "e1431c6c-a8fa-444c-ad68-b56ca1c9ee64"
      },
      "source": [
        "lm.generate(10, text_seed=[\"<s>\"], random_seed=42)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['My', 'first', 'i', \"'\", 's', 'not', 'put', 'that', 'most', 'may']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E_2XbnMGaODS"
      },
      "source": [
        "We can give a specific starting condition through the text_seed parameter, which\n",
        "makes the generation be conditioned on the preceding context. \n",
        "\n",
        "In our preceding example, the preceding context is <s>, which is a special token indicating the beginning of a sentence."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QqYcTBGrP2iK",
        "outputId": "9892693d-dd0d-4d44-ccf1-422dcf018538"
      },
      "source": [
        "lm.generate(10, text_seed=[\"love\"], random_seed=42)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['done', 'double', 'sence', ',', 'as', 'palpable', ',', 'as', 'palpable', ',']"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    }
  ]
}